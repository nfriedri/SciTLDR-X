Nous fournissons des formes analytiques nécessaires et suffisantes pour les points critiques des fonctions de perte carrées pour divers réseaux neuronaux, et nous exploitons les formes analytiques pour caractériser les propriétés du paysage pour les fonctions de perte de ces réseaux neuronaux.
Les algorithmes d'apprentissage biologiquement plausibles, en particulier la symétrie des signes, fonctionnent bien sur ImageNet.
Nous introduisons le transformateur 2-simplicial et montrons que cette architecture est un biais inductif utile pour le raisonnement logique dans le contexte de l'apprentissage par renforcement profond.
Prévision précise sur de très longs horizons temporels à l'aide de RNN tensoriels
Nous proposons un algorithme variationnel de passage de messages pour les modèles qui contiennent à la fois le modèle profond et le modèle graphique probabiliste.
Une modification simple de la factorisation à faible rang qui améliore les performances (dans les tâches d'image et de langage) tout en restant compacte.
Nous proposons un format de données simple, général et peu encombrant pour accélérer l'apprentissage profond en permettant de sélectionner dynamiquement la fidélité de l'échantillon au moment de la formation.
APPRENTISSAGE DE REPRÉSENTATION DISCRIMINATIVE ROBUSTE VIA LA REMISE À L'ÉCHELLE DU GRADIENT : UNE PERSPECTIVE DE RÉGULARISATION DE L'EMPHASE
Le succès des GAN est-il dû à l'entraînement contradictoire ou à l'utilisation de ConvNets ? Nous montrons qu'un générateur ConvNet entraîné avec une perte de reconstruction simple et des vecteurs de bruit apprenables possède plusieurs des propriétés souhaitables d'un GAN.
Équiper les GAN MMD d'un nouveau noyau de forêt aléatoire.
Une méthode pour des estimations plus précises des critiques dans l'apprentissage par renforcement.
Nous introduisons un cadre systématique pour quantifier la robustesse des classificateurs aux perturbations naturelles des images trouvées dans les vidéos.
Apprentissage profond pour l'apprentissage automatique de données tabulaires structurées en utilisant un modèle CNN pré-entraîné à partir d'ImageNet.
Le décodage des pixels peut toujours fonctionner pour l'apprentissage de la représentation sur les images.
AdaGrad/Adam rapide, véritablement évolutif, à matrice complète, avec théorie pour l'optimisation stochastique non convexe adaptative
Dans cet article, nous proposons d'apprendre un système de dialogue qui paramètre indépendamment différentes compétences de dialogue, et apprend à sélectionner et combiner chacune d'entre elles par le biais de l'attention sur les paramètres (AoP). 
Nous proposons de distiller un grand ensemble de données en un petit ensemble de données synthétiques qui peuvent entraîner des réseaux proches des performances originales. 
Nous proposons une méthode de sous-gradient primal-dual pour l'entraînement des GAN et cette méthode atténue efficacement l'effondrement des modes.
Nous constatons que l'irrationalité d'un démonstrateur expert peut aider un apprenant à déduire ses préférences. 
Nous comparons la robustesse des modèles de 4 tâches populaires de NLP : Q&A, NLI, NER et Analyse de Sentiment en testant leur performance sur des entrées perturbées.
Un nouvel algorithme d'apprentissage par programme basé sur les clusters est proposé pour résoudre la formation robuste des modèles génératifs.
Nous proposons une nouvelle attaque par porte dérobée distribuée sur l'apprentissage fédéré et montrons qu'elle est non seulement plus efficace que les attaques centralisées standard, mais aussi plus difficile à défendre par les méthodes FL robustes existantes.
Réseau neuronal pour l'apprentissage semi-supervisé basé sur les graphes ; revisite les classiques et propage les *labels* plutôt que les représentations des caractéristiques.
Architecture neuronale Recherche d'une série de tâches de compréhension du langage naturel. Concevoir l'espace de recherche pour les tâches NLU. Et appliquer la recherche d'architecture différentiable pour découvrir de nouveaux modèles.
Dans cet article, nous présentons EvalNE, une boîte à outils Python pour automatiser l'évaluation des méthodes d'intégration de réseaux sur la prédiction des liens et assurer la reproductibilité des résultats.
Garantie de récupération de la descente de gradient stochastique avec initialisation aléatoire pour l'apprentissage d'un réseau neuronal à deux couches avec deux nœuds cachés, des poids à norme unitaire, des fonctions d'activation ReLU et des entrées gaussiennes.
Jumpout applique trois modifications simples mais efficaces au dropout, basées sur une nouvelle compréhension des performances de généralisation des DNN avec ReLU dans les régions locales.
Nous étudions l'émergence naturelle de la sparsité dans les activations et les gradients de certaines couches d'un modèle de langage LSTM dense, au cours de la formation.
Les réseaux de mémoire conventionnels génèrent de nombreux vecteurs latents redondants, ce qui entraîne un surajustement et la nécessité d'utiliser des mémoires plus grandes. Nous introduisons l'abandon de mémoire comme une technique automatique qui encourage la diversité dans l'espace latent.
Nous dérivons la méthode de Nesterov comme une discrétisation simple d'une ODE différente de celle de Su-Boyd-Candes et prouvons l'accélération du cas stochastique.
Nous proposons l'apprentissage par transfert (L2TL) pour améliorer l'apprentissage par transfert sur un ensemble de données cible par l'extraction judicieuse d'informations d'un ensemble de données source.
Dans Deep RL, les fonctions invariables par ordre peuvent être utilisées en conjonction avec des modules de mémoire standard pour améliorer la décroissance du gradient et la résistance au bruit.
Cet article présente un algorithme pour traiter un problème d'optimisation avec des contraintes multiples sous la vision d'un collecteur.
Une méthode pour faire de l'apprentissage Q sur des espaces d'action continus en prédisant une séquence d'actions 1-D discrétisées.
Notre méthode incorpore le WGAN pour réaliser la correspondance des mesures d'occupation pour l'apprentissage des transitions.
La normalisation gaussienne effectue un ajustement par la méthode des moindres carrés pendant la rétropropagation, ce qui permet de centrer à zéro et de décorréler les dérivées partielles des activations normalisées.
Nous présentons une analyse théorique de la capacité de la normalisation par lots à régler automatiquement les taux d'apprentissage, dans le contexte de la recherche de points stationnaires pour un objectif d'apprentissage profond.
Nous proposons DVD-GAN, un grand modèle génératif vidéo qui est à la pointe de l'art pour plusieurs tâches et produit des vidéos très complexes lorsqu'il est entraîné sur de grands ensembles de données du monde réel.
Nous proposons une nouvelle architecture de mémoire récurrente qui peut suivre les changements d'état de sens commun des entités en simulant les effets causaux des actions.
Nous étudions l'efficacité spatiale des réseaux neuronaux à mémoire augmentée lors de l'apprentissage de l'appartenance à un ensemble.
Nous construisons une approximation de Laplace factorisée de Kronecker pour les réseaux neuronaux qui conduit à une distribution normale matricielle efficace sur les poids.
La régularisation des graphiques force l'intégration spectrale à se concentrer sur les plus grands clusters, ce qui rend la représentation moins sensible au bruit. 
Nous montrons que le biais d'exposition pourrait être beaucoup moins grave que ce que l'on suppose actuellement pour la formation MLE LM.
Une étude contrôlée du rôle des environnements par rapport aux propriétés dans les protocoles de communication émergents.
Représentation de documents basée sur une grille avec des vecteurs d'intégration contextualisés pour les documents avec une mise en page en 2D
Les politiques de RL profond peuvent être attaquées par d'autres agents qui prennent des mesures de manière à créer des observations naturelles contradictoires.
Nous présentons un nouvel algorithme itératif basé sur des modèles de bas rang généralisés pour le calcul et l'interprétation des modèles d'intégration des mots.
Nous apprenons un flux autorégressif conditionnel pour proposer des perturbations qui n'induisent pas d'échec du simulateur, améliorant ainsi les performances d'inférence.
Nous améliorons la réponse aux questions qui nécessitent un raisonnement multi-sauts en extrayant une chaîne intermédiaire de phrases.
Nous développons une nouvelle méthode pour l'estimation de la constante de normalisation (évidence bayésienne) en utilisant l'échantillonnage optimal du pont et un nouveau flux de normalisation, qui s'avère plus performant que les méthodes existantes en termes de précision et de temps de calcul.
Nous vérifions les modèles DNN pour l'oubli catastrophique en utilisant un nouveau schéma d'évaluation qui reflète les conditions d'application typiques, avec des résultats surprenants.
La moyenne fédérée est déjà un algorithme de méta-apprentissage, tandis que les méthodes entraînées par le centre de données sont beaucoup plus difficiles à personnaliser.
Nous identifions le sous-échantillonnage comme un mécanisme de mémorisation dans les autoencodeurs convolutifs.
Nous proposons un algorithme d'apprentissage par renforcement inverse contradictoire capable d'apprendre des fonctions de récompense qui peuvent être transférées à des environnements nouveaux et non vus.
La généralisation est fortement corrélée avec l'évidence bayésienne, et le bruit de gradient conduit SGD vers des minima dont l'évidence est grande.
réseaux adversariaux, mécanisme d'attention, images positroniques, pénurie de données
 Inspiré par la recherche en neurosciences, il résout trois faiblesses majeures du modèle d'attention récurrente largement cité en ajoutant simplement deux termes à la fonction objectif.
Cet article présente un algorithme d'apprentissage actif sur les graphes basé sur le regroupement.
Nous proposons l'InfoCNF, une CNF conditionnelle efficace qui utilise des réseaux de déclenchement pour apprendre les tolérances d'erreur des solveurs d'ODE.  
Une méthode d'apprentissage non supervisé qui utilise le méta-apprentissage pour permettre un apprentissage efficace des tâches de classification d'images en aval, en surpassant les méthodes de pointe.
VAE conditionnel sur des espaces latents de modèles génératifs pré-entraînés qui permet le transfert entre des domaines radicalement différents tout en préservant la localité et l'alignement sémantique.
Une nouvelle méthode d'apprentissage inductif par transfert qui utilise l'apprentissage contradictoire et l'apprentissage multi-tâches pour résoudre le problème de la divergence entre l'espace d'entrée et l'espace de sortie.
Une nouvelle architecture très performante pour la reconnaissance d'entités nommées et l'extraction de relations de bout en bout qui est rapide à entraîner.
 Schéma de Bayes variationnel pour les réseaux neuronaux récurrents
étude de cas sur le modèle optimal d'apprentissage profond pour les drones
Nous montrons la première utilisation réussie de Transformer pour générer de la musique qui présente une structure à long terme. 
Nous proposons un nouvel algorithme de Monte Carlo de recherche dans l'arbre et de déploiement qui s'appuie sur une recherche basée sur la largeur pour construire un lookahead.
Nous proposons une nouvelle couche de réseau neuronal profond pour normaliser la covariance intra-classe d'une représentation interne dans un réseau neuronal, ce qui permet d'améliorer considérablement la généralisation des représentations apprises.
L'ajout d'un critère de diversité inspiré de la DPP dans l'objectif du GAN évite l'effondrement des modes et conduit à de meilleures générations. 
Nous suggérons une limite de généralisation qui pourrait expliquer en partie l'amélioration de la généralisation avec la sur-paramétrisation.
Nous introduisons trois blocs génériques de traitement des nuages de points qui améliorent à la fois la précision et la consommation de mémoire de plusieurs réseaux de pointe, permettant ainsi de concevoir des réseaux plus profonds et plus précis.
Méthodes d'apprentissage d'incorporations de mots acoustiques contextuelles à partir d'un modèle de reconnaissance de la parole de bout en bout, avec des performances compétitives par rapport aux incorporations de mots basées sur le texte.
Cet article propose une méthode de masque qui résout le problème des résultats flous de l'estimation monoculaire non supervisée de la profondeur causés par l'occlusion.
Nous présentons une nouvelle façon de représenter les graphes en tant que structures semblables à des images multicanaux, ce qui permet de les traiter par des CNN 2D classiques.
Nous proposons une mesure de la mémoire à long terme et prouvons que les réseaux récurrents profonds sont bien mieux adaptés pour modéliser les dépendances temporelles à long terme que les réseaux superficiels.
Nous comparons les représentations perceptives, neurales et modélisées de la communication animale en utilisant l'apprentissage automatique, le comportement et la physiologie. 
Le principe du goulot d'étranglement de l'information appliqué aux ResNets, en utilisant les modèles PixelCNN++ pour décoder l'information mutuelle et générer conditionnellement des images pour illustrer l'information.
L'adaptation d'un agent RL dans un environnement cible à la dynamique inconnue est rapide et sûre lorsque nous transférons l'expérience antérieure dans une variété d'environnements et que nous sélectionnons des actions à faible risque pendant l'adaptation.
Nous proposons le Neuro-Symbolic Concept Learner (NS-CL), un modèle qui apprend les concepts visuels, les mots et l'analyse sémantique des phrases sans supervision explicite de l'un d'entre eux.
Nous introduisons un processus gaussien prioritaire sur les poids dans un réseau neuronal et nous explorons sa capacité à modéliser les poids dépendant de l'entrée avec des avantages pour diverses tâches, y compris l'estimation de l'incertitude et la généralisation dans le cadre d'un échantillon faible.
Nous effectuons une étude approfondie de l'adéquation des modèles d'auto-attention pour la traduction automatique neuronale au niveau des caractères.
nous présentons les résultats de l'état de l'art de l'utilisation des réseaux neuronaux pour le diagnostic des radiographies pulmonaires.
Nous démontrons l'utilité d'une technique récente d'explicabilité de l'IA en visualisant les caractéristiques apprises d'un CNN entraîné à la classification binaire des mouvements du poisson zèbre.
Les contraintes de cohérence interne améliorent la capacité des agents à développer des protocoles émergents qui se généralisent à travers les rôles communicatifs.
Nous présentons une nouvelle technique d'analyse qui permet de découvrir une structure compositionnelle interprétable dans des réseaux neuronaux récurrents notoirement difficiles à interpréter.
Nous avons reproduit les représentations neuronales que l'on trouve dans les systèmes visuels biologiques en simulant leurs contraintes de ressources neuronales dans un modèle convolutif profond.
une théorie reliant le hessien de la solution et le pouvoir de généralisation du modèle
Nous avons introduit la maximisation de l'entropie dans les GAN, ce qui conduit à une réinterprétation de la critique comme une fonction d'énergie.
Nous présentons un algorithme de transfert de style musical audio à longue échelle temporelle qui synthétise l'audio dans le domaine temporel, mais utilise des représentations temps-fréquence de l'audio.
Nous proposons une tâche de référence répétée et une approche d'apprentissage continu régularisé pour la communication adaptative avec les humains dans des domaines non familiers.
Trier dans l'encodeur et annuler le tri dans le décodeur pour éviter le problème de responsabilité dans les encodeurs automatiques réglés
Nous présentons un cadre d'apprentissage hiérarchique pour la navigation dans un contexte d'apprentissage incarné.
L'attribution peut parfois être trompeuse
Transformateur efficace avec hachage sensible à la localité et couches réversibles
Nous montrons que la compréhension du langage par la lecture est un moyen prometteur d'apprendre des politiques qui se généralisent à de nouveaux environnements.
Nous proposons une hypothèse sur la raison pour laquelle la descente par gradient se généralise, basée sur la façon dont les gradients par exemple interagissent entre eux.
Nouvelle architecture pour la synthèse de vues stéréoscopiques avec des décalages arbitraires de la caméra, utilisant des noyaux adaptatifs en forme de T avec des dilatations adaptatives.
Cet article propose une théorie fondamentale et des algorithmes optimaux pour l'entraînement des DNN, qui réduisent jusqu'à 80 % la mémoire d'entraînement des DNN les plus populaires.
Cet article prouve l'approximabilité universelle des réseaux neuronaux ReLU quantifiés et propose une limite de complexité pour une erreur arbitraire.
Un cadre général d'apprentissage par renforcement basé sur la valeur pour le contrôle continu
L'entraînement du réseau adversarial génératif est un problème d'apprentissage continu.
Un cadre unifié pour l'apprentissage à quelques coups et l'apprentissage à zéro coup basé sur la reparamétrisation du réseau.
GraphQA est une méthode d'évaluation de la qualité des protéines basée sur les graphes qui améliore l'état de l'art des approches manuelles et d'apprentissage par représentation.
Nous abordons l'apprentissage actif dans un contexte de lot avec des oracles bruyants et utilisons l'incertitude du modèle pour coder la qualité de la décision de l'algorithme d'apprentissage actif pendant l'acquisition.
Transfert de style stochastique avec caractéristiques ajustables. 
Nous proposons AGILE, un cadre pour l'entraînement des agents à exécuter des instructions à partir d'exemples d'états buts respectifs.
Dans Hierarchical RL, nous introduisons la notion d'option "douce", c'est-à-dire adaptable, et nous montrons que cela facilite l'apprentissage dans des contextes multitâches.
Apprentissage d'un modèle génératif contrôlable en effectuant un apprentissage par désenchevêtrement des représentations latentes.
Améliorer le modèle linguistique pour les tâches d'apprentissage supervisé 
générer dynamiquement des filtres conditionnés par l'image d'entrée pour les CNN dans chaque passe avant 
Nous proposons un nouveau réseau neuronal à tout moment qui permet une évaluation partielle par des sous-réseaux de différentes largeurs ainsi que de différentes profondeurs.
Nous proposons un nouveau modèle pour faire des prédictions de réactions rétrosynthétiques généralisables et diverses.
Disentanglement-PyTorch est une bibliothèque pour l'apprentissage par représentation variationnelle
Nous étendons les idées récentes liées à la cohérence des softmax pour obtenir des résultats de pointe en matière de contrôle continu.
Nous adaptons une famille de jeux combinatoires dont la difficulté est réglable et dont la politique optimale peut être exprimée sous la forme d'un réseau linéaire, en la développant comme un environnement riche pour l'apprentissage par renforcement, en montrant les contrastes de performance avec l'apprentissage supervisé, et en analysant l'apprentissage multi-agent et la généralisation. 
Une méthode complémentaire d'apprentissage profond pour détecter les valeurs aberrantes pendant la prédiction
Une architecture entièrement connectée est utilisée pour produire des incorporations de mots à partir de représentations de caractères. Elle est plus performante que les incorporations traditionnelles et donne un aperçu de la sparsité et de l'abandon.
Nous menons des attaques adverses contre les réseaux neuronaux binarisés et montrons que nous réduisons l'impact des attaques les plus fortes, tout en maintenant une précision comparable dans un cadre de boîte noire.
Une étude empirique de l'alignement d'espaces vectoriels de mots basé sur le GAN, en se concentrant sur les cas où les transformations linéaires existent de manière prouvée, mais où la formation est instable.
L'objectif de cet article est de proposer une nouvelle approche pour aborder le problème de l'apprentissage par transfert de projets logiciels étiquetés vers des projets non étiquetés dans le contexte de la SVD, afin de résoudre le problème d'effondrement des modes auquel sont confrontées les approches précédentes.
Une méthode plus rapide pour générer des incorporations de nœuds qui utilise un certain nombre de permutations sur le voisinage immédiat d'un nœud comme contexte pour générer sa représentation.
Nous montrons comment initialiser les architectures récurrentes avec la solution en forme fermée d'un autoencodeur linéaire pour les séquences. Nous montrons les avantages de cette approche par rapport aux RNNs orthogonaux.
Nous fournissons une compréhension approfondie du NER de marquage de séquence et proposons d'utiliser deux types de structures croisées, qui apportent toutes deux des améliorations théoriques et empiriques.
Nous présentons un modèle génératif d'intégration de graphes de connaissances qui a fait ses preuves sur le plan théorique. 
Nous étudions empiriquement la difficulté de récupérer les parties manquantes des modèles formés.
Cet article propose l'adaptation variationnelle de domaine, un cadre uniﬁé, évolutif et simple pour l'apprentissage de distributions multiples par inférence variationnelle.
Nous proposons une nouvelle combinaison d'entraînement contradictoire et de défenses prouvables qui produit un modèle avec une précision de pointe et une robustesse certifiée sur CIFAR-10. 
Les programmes ont une structure qui peut être représentée sous forme de graphes, et les réseaux neuronaux de graphes peuvent apprendre à trouver des bogues sur ces graphes.
Nous introduisons et analysons plusieurs critères pour détecter l'overfitting.
Nous développons un solveur d'itération de valeur basé sur des points pour les POMDP avec des tâches de perception et de planification actives.
Nous présentons un réseau neuronal profond simple, non-convolutionnel et sous-paramétré qui peut, sans entraînement, représenter efficacement des images naturelles et résoudre de manière compétitive des tâches de traitement d'images telles que la compression et le débruitage.
Cet article 1) caractérise les fonctions représentables par les DNN ReLU, 2) étudie formellement l'avantage de la profondeur dans ces architectures, 3) donne un algorithme pour implémenter la minimisation du risque empirique jusqu'à l'optimalité globale pour les réseaux ReLU à deux couches.
Repères pour les algorithmes d'apprentissage biologiquement plausibles sur des ensembles de données et des architectures complexes
Nous avons proposé d'utiliser le récent régularisateur GrOWL pour la sparsité et la liaison simultanées des paramètres dans l'apprentissage des DNN. 
Une analyse des structures d'apprentissage et d'optimisation de la recherche d'architecture dans les réseaux neuronaux et au-delà.
Nous effectuons une compression sans perte de grands ensembles de données d'images en utilisant un VAE, en battant les algorithmes de compression existants.
Optimisation des hyperparamètres en ligne basée sur l'optimisation bayésienne.
Dans cet article, nous proposons le Latent Question Reformulation Network (LQR-net), un réseau attentif multi-sauts et parallèle conçu pour les tâches de réponse aux questions qui nécessitent des capacités de raisonnement.
Explication des modèles de séries chronologiques multivariées par la recherche d'observations importantes dans le temps à l'aide de contrefactuels
Nous utilisons l'auto-supervision sur les deux domaines afin de les aligner pour l'adaptation non supervisée des domaines.
Le minimum d'un ensemble de hachages distribués de façon exponentielle a une probabilité de collision très utile qui généralise l'indice de Jaccard aux distributions de probabilité.
Un modèle de réseau neuronal graphique dont les paramètres sont générés à partir de langages naturels, qui peut effectuer un raisonnement multi-sauts. 
Nous présentons Meta-Critic, un module de critique auxiliaire pour les méthodes de critique d'acteur hors politique qui peut être méta-appris en ligne pendant l'apprentissage d'une seule tâche.
Nous obtenons des limites de généralisation non vicieuses sur les réseaux neuronaux profonds à l'échelle d'ImageNet en combinant une limite PAC-Bayes originale et une méthode de compression de réseau neuronal standard.
Nous proposons une mesure alternative pour déterminer l'efficacité des attaques adverses dans les modèles NLP selon une méthode basée sur la mesure de distance comme le gain L2 incrémental en théorie du contrôle.
Nous proposons le réseau résiduel warpé qui utilise un opérateur warp parallélisable pour la propagation vers l'avant et vers l'arrière vers des couches distantes qui s'entraîne plus rapidement que le réseau neuronal résiduel original. 
Nous proposons une série de mesures qui capturent les propriétés souhaitées des algorithmes d'explicabilité et nous les utilisons pour comparer et évaluer objectivement ces méthodes.
Une méthode récente de détection de la non-répartition permet de mesurer la confiance des prédictions des RNN pour certaines tâches de TAL.
séparation profondeur-2-vs-3 pour les réseaux neuronaux sigmoïdaux sur des distributions générales
Nous proposons une méthode évolutive pour approximer les vecteurs propres du Laplacien dans le contexte de l'apprentissage par renforcement et nous montrons que les représentations apprises peuvent améliorer les performances d'un agent RL.
Traduction de simulations en images réelles et génération de vidéos
Nous proposons PocketFlow, un cadre automatisé pour la compression et l'accélération des modèles, afin de faciliter le déploiement des modèles d'apprentissage profond sur les appareils mobiles.
Comment apprendre les GAN à partir d'observations bruyantes, déformées et partielles ?
Voir le résumé.  (Pour la révision, l'article est identique, à l'exception d'un matériel supplémentaire de 59 pages, qui peut servir de version de rapport technique autonome de l'article).
Nous introduisons un mécanisme d'attention pour améliorer l'extraction de caractéristiques pour l'apprentissage actif profond (AL) dans le cadre semi-supervisé.
Nous appliquons des formes canoniques de complexes de gradients (codes-barres) pour explorer les surfaces de perte des réseaux neuronaux.
Utilisation de mises à jour asynchrones du gradient pour accélérer la formation de réseaux neuronaux dynamiques
Nous étudions le problème de la conception des récompenses dans un MARL coopératif basé sur des environnements de routage de paquets. Les résultats expérimentaux nous rappellent qu'il faut faire attention à la conception des récompenses, car elles sont très importantes pour guider le comportement de l'agent.
Les réseaux de Neumann constituent une approche d'apprentissage de bout en bout, efficace sur le plan de l'échantillonnage, pour résoudre les problèmes inverses linéaires en imagerie. Cette approche est compatible avec l'approche optimale MSE et admet une extension à l'apprentissage par patchs.
GLMP : Un encodeur de mémoire globale (RNN de contexte, pointeur global) et un décodeur de mémoire locale (RNN d'esquisse, pointeur local) qui partagent des connaissances externes (MemNN) sont proposés pour renforcer la génération de réponses dans un dialogue orienté tâche.
Nous proposons un nouveau module d'amélioration des damiers aritifs (ACE) qui guide les attaques vers un espace de pixels pré-spécifié et le défend avec succès par une simple opération de remplissage.
Nous analysons systématiquement le comportement de convergence d'algorithmes de gradient populaires pour résoudre des jeux bilinéaires, avec des mises à jour simultanées et alternées.
Nous utilisons les VAE pour apprendre une intégration partagée de l'espace latent entre les caractéristiques et les attributs de l'image et obtenons ainsi des résultats de pointe dans l'apprentissage généralisé de l'image zéro.
Les informations spatiales des dernières couches ne sont pas nécessaires pour une bonne précision de la classification.
Nous utilisons les réseaux siamois pour guider et démêler le processus de génération dans les GAN sans données étiquetées.
Nous présentons Predicted Variables, une approche visant à faire de l'apprentissage automatique un citoyen de première classe dans les langages de programmation.
Nous montrons comment former un modèle de prédiction vidéo hiérarchique sans avoir besoin d'étiquettes de pose.
Dans ce travail, nous étudions le problème de l'apprentissage de représentations pour identifier de nouveaux objets en explorant les objets à l'aide de la détection tactile. Le point clé ici est que la requête est fournie dans le domaine de l'image.
Nous utilisons des schémas de compression homomorphique linéaire pour représenter les statistiques suffisantes d'un modèle de champ aléatoire conditionnel de la coréférence, ce qui nous permet d'échelonner l'inférence et d'améliorer la vitesse d'un ordre de grandeur.
Nous donnons une analyse théorique de la mesure et de l'optimisation de l'information mutuelle.
En brisant la hiérarchie des couches, nous proposons une approche en 3 étapes pour la construction de réseaux à hiérarchie de neurones qui surpassent les NAS, SMASH et la représentation hiérarchique avec moins de paramètres et un temps de recherche plus court.
Nous proposons un algorithme qui ajuste automatiquement les paramètres d'un moteur de simulation afin de générer des données de formation pour un réseau neuronal de manière à maximiser la précision de la validation.
Un schéma de régularisation agnostique pour l'estimation de la densité conditionnelle basée sur un réseau neuronal.
Une formulation du goulot d'étranglement basée sur le patch dans un cadre VAE qui apprend des représentations non supervisées mieux adaptées à la reconnaissance visuelle.
Pour résoudre les problèmes de disparition/explosion du gradient, nous proposons une paramétrisation efficace de la matrice de transition du RNN qui ne perd pas de pouvoir expressif, converge plus rapidement et présente une bonne généralisation.
Un article proposant une méthode pour transformer le style des images à l'aide de réseaux neuronaux profonds.
Nous améliorons les systèmes de dialogue existants pour répondre aux personnes qui partagent des histoires personnelles, en incorporant des représentations de prédiction des émotions et nous publions également un nouveau repère et un nouvel ensemble de données de dialogues empathiques.
Une nouvelle architecture de réseau neuronal récurrent pour la détection de la causalité de Granger par paire entre des séries chronologiques à interaction non linéaire. 
Un algorithme d'apprentissage stochastique basé sur les variables de contrôle pour les réseaux convolutifs à graphes dont le champ réceptif ne peut être que de deux voisins par nœud.
Méthodes de Monte Carlo pour quantifier des modèles pré-entraînés sans entraînement supplémentaire.
Approche théorique de l'information pour l'apprentissage non supervisé d'un hybride de représentations discrètes et continues, 
Il est important de considérer l'optimisation dans l'espace des fonctions, et pas seulement dans l'espace des paramètres. Nous introduisons une règle d'apprentissage qui réduit la distance parcourue dans l'espace des fonctions, tout comme SGD limite la distance parcourue dans l'espace des paramètres.
Théorie de la convergence pour les estimateurs de gradient biaisés (mais cohérents) dans l'optimisation stochastique et application aux réseaux convolutifs de graphes.
Nous utilisons des instantanés du processus de formation pour améliorer toute méthode d'estimation de l'incertitude d'un classificateur DNN.
Un nouveau jeu de données d'images de visages pour l'équilibre entre la race, le sexe et l'âge, qui peut être utilisé pour mesurer et atténuer les préjugés.
Nous tentons de modéliser le processus de dessin des polices de caractères en construisant des modèles génératifs séquentiels de graphiques vectoriels (SVG), une représentation hautement structurée des caractères de police.
Nous développons "l'inférence relationnelle neuronale dynamique", un modèle d'autoencodeur variationnel qui peut représenter de manière explicite et interprétable les relations dynamiques cachées entre les neurones.
À notre connaissance, DeePa est le premier cadre d'apprentissage profond qui contrôle et optimise le parallélisme des CNN dans toutes les dimensions parallélisables à la granularité de chaque couche.
Nous combinons la méthode des noyaux avec des modèles connexionnistes et montrons que les architectures profondes qui en résultent peuvent être entraînées par couches et présentent une dynamique d'apprentissage plus transparente. 
Nous proposons une méthode d'optimisation stochastique des pénalités de second ordre et montrons comment elle peut s'appliquer à la formation de classificateurs sensibles à l'équité.
Nous montrons que les dérivés des réseaux d'apprentissage profond ont une structure à faible rang, et cette structure nous permet d'utiliser les informations des dérivés de second ordre pour calculer les taux d'apprentissage de façon adaptative et d'une manière réalisable sur le plan informatique.
Un cadre unifié d'optimisation min-max pour l'attaque et la défense adversariale.
réduction de la dimensionnalité pour les cas où les exemples peuvent être représentés comme des distributions de probabilités molles
Nous proposons une nouvelle architecture d'exploration de buts intrinsèquement motivée avec un apprentissage non supervisé des représentations de l'espace des buts, et nous évaluons comment diverses implémentations permettent la découverte d'une diversité de politiques.
Nous proposons une étape de formation supplémentaire, appelée post-formation, qui calcule les poids optimaux pour la dernière couche du réseau.
Compression de l'encastrement des mots de plus de 94% sans nuire aux performances.
OE apprend aux détecteurs d'anomalies à apprendre des heuristiques pour détecter des anomalies non vues ; les expériences portent sur la classification, l'estimation de la densité et la calibration dans des contextes de TAL et de vision ; nous ne nous accordons pas sur des échantillons de distribution de test, contrairement aux travaux antérieurs.
Procédé pour apprendre une transformation entre une paire d'ensembles de données source/cible et l'appliquer à un ensemble de données source distinct pour lequel il n'existe pas d'ensemble de données cible.
Combinaison de l'apprentissage par imitation et de l'apprentissage par renforcement pour apprendre à surpasser l'expert
Une approche d'apprentissage non supervisée pour la séparation de deux signaux structurés à partir de leur superposition
Nous explorons la relation entre les flux normalisateurs et les auto-codeurs variationnels et de débruitage, et proposons un nouveau modèle qui les généralise.
Nous utilisons l'apprentissage par renforcement pour la reformulation de requêtes dans deux tâches et nous constatons de manière surprenante que, lors de la formation de plusieurs agents, la diversité des reformulations est plus importante que la spécialisation.
Un cadre général pour l'incorporation de contraintes de sécurité à long terme dans l'apprentissage par renforcement basé sur des politiques.
Évaluation des réseaux génératifs par leur capacité d'augmentation des données sur les modèles discriminants.
Nouveau : application de la modélisation seq2seq à l'automatisation du journalisme scientifique ; ensemble de données hautement abstraites ; astuces d'apprentissage par transfert ; mesure d'évaluation automatique.
Nous présentons une approche pour reconcevoir l'environnement de telle sorte que les comportements ininterprétables des agents soient minimisés ou éliminés.
Nous proposons une nouvelle classe de modèles d'inférence qui codent itérativement les gradients pour estimer des distributions postérieures approximatives.
Nous présentons une règle d'apprentissage pour les poids de rétroaction dans un réseau de neurones à pointes qui aborde le problème du transport des poids.
Nous combinons l'inférence variationnelle et l'apprentissage des manifolds (en particulier les VAE et les cartes de diffusion) pour construire un modèle génératif basé sur une marche aléatoire de diffusion sur un manifold de données ; nous générons des échantillons en tirant de la distribution stationnaire de la marche.
Nous développons une approche simple et générale pour éviter les interférences entre les gradients de différentes tâches, ce qui améliore les performances de l'apprentissage multi-tâches dans les domaines de l'apprentissage supervisé et de l'apprentissage par renforcement.
Apprendre à échantillonner en limitant le taux d'acceptation de l'algorithme de Metropolis-Hastings.
BERT généralisé pour les entrées continues et intermodales ; représentations vidéo autosupervisées de pointe.
Une architecture dynamique générique qui utilise un mécanisme de bifurcation différentiable spécifique au problème pour coder les hypothèses de structure de données difficiles. Appliquée à CLEVR VQA et à l'évaluation des expressions.
Nous unifions l'estimation du support avec la famille des algorithmes d'apprentissage par imitation adversariale dans l'apprentissage par imitation adversariale guidée par le support, un cadre d'apprentissage par imitation plus robuste et stable.
Nous appliquons le méta-apprentissage basé sur le gradient au domaine des graphes et introduisons une nouvelle fonction de transfert spécifique aux graphes pour renforcer le processus.
Nous proposons une nouvelle méthode pour entraîner de manière incrémentielle un modèle génératif de mélange afin d'approximer la projection d'information de la distribution réelle des données.
Récupérer des vidéos à partir de mesures compressives en apprenant une représentation à faible dimension (low-rank) directement à partir des mesures tout en formant un générateur profond. 
Nous étudions une généralisation multicouche de l'élagage basé sur la magnitude.
Nous introduisons la maximisation de l'hypervolume pour l'entraînement des GAN avec des discriminateurs multiples, montrant des améliorations de performance en termes de qualité et de diversité des échantillons. 
Un nouvel état de l'art sur Imagenet pour la configuration mobile
Un cadre de simulation robotique et de développement d'algorithmes à haute performance.
Un nouveau paradigme d'adaptation non supervisée à un domaine, qui consiste à effectuer l'adaptation sans accéder aux données sources ("sans source") et sans supposer l'écart entre les catégories source et cible ("universel").
Laisser un méta-apprenant décider de la tâche sur laquelle s'entraîner pour un agent dans un contexte multitâche améliore considérablement la capacité multitâche.
Nous proposons la génération de phrases contenant des réponses (ASGen), une nouvelle méthode de pré-entraînement pour générer des données synthétiques pour la compréhension automatique de la lecture.
Approche de quantification douce pour apprendre des représentations pures à point fixe de réseaux neuronaux profonds
Nous présentons une nouvelle architecture de réseau pour l'apprentissage de réseaux neuronaux profonds compacts et efficaces.
Nous étudions pour la première fois les attaques adverses par apprentissage automatique contre les mécanismes de suivi d'objets multiples. 
Coupler l'apprentissage semi-supervisé avec l'apprentissage auto-supervisé et modéliser explicitement la tâche auto-supervisée conditionnée par la tâche semi-supervisée.
Une architecture de réseau de pointeurs pour le reclassement des articles, apprise à partir des journaux de clics.
La méthode du gradient stochastique avec momentum se généralise.
Apprendre à imiter un expert en l'absence d'actions optimales ; apprendre un modèle dynamique tout en explorant l'environnement.
Nous montrons la possibilité d'élaguer pour trouver un petit sous-réseau avec un taux de convergence significativement plus élevé que le modèle complet.
Nous proposons une approche basée sur l'inférence variationnelle pour encourager l'inférence de latents désenchevêtrés. Nous proposons également une nouvelle métrique pour quantifier le désenchevêtrement. 
L'ASN que nous proposons caractérise l'influence de différentes actions sur d'autres agents en utilisant des réseaux neuronaux basés sur la sémantique des actions entre elles.
 Nous démontrons un réseau de neurones à pointes asynchrones récurrents à déclenchement qui correspond à une unité LSTM.
Classification vidéo efficace utilisant un module de déclenchement conditionnel basé sur les images pour sélectionner les images les plus dominantes, suivi d'une modélisation temporelle et d'un classificateur.
Programmation dynamique différentiable sur des poids d'entrée perturbés avec application au VAE semi-supervisé
Sans apprentissage, il est impossible d'expliquer les décisions d'un modèle d'apprentissage automatique.
Réseau neuronal graphique simple et efficace avec un mélange de pas de marche aléatoire et d'attention
Nous présentons une reconstruction d'apprentissage profond non supervisée pour les problèmes inverses d'imagerie qui combine des réseaux neuronaux avec des contraintes basées sur des modèles.
Nous présentons une tâche de diagnostic qui est une variation de l'apprentissage en quelques coups et nous présentons un ensemble de données pour cette tâche.
Nous présentons l'utilisation d'un codeur-décodeur secondaire comme fonction de perte pour aider à former un résumeur.
Un cadre de traduction non supervisé de vidéo à vidéo, cohérent dans le temps et flexible en termes de modalité, entraîné de manière auto-supervisée.
Les cadres d'argumentation sont utilisés pour représenter la causalité des plans/modèles à utiliser pour les explications.
Nous proposons une approche par réseau neuronal génératif pour les nuages de points cohérents dans le temps.
Nous présentons une vue unifiée des attaques adverses de type boîte noire comme un problème d'estimation de gradient, puis nous présentons un cadre (basé sur l'optimisation de bandits) pour intégrer les prieurs dans l'estimation de gradient, ce qui conduit à une augmentation significative des performances.
Améliorer l'efficacité de l'étiquetage par l'apprentissage multi-tâches sur des données auditives
L'article présente deux techniques permettant d'incorporer une structure de haut niveau dans la génération de texte procédural à partir d'une séquence d'images.
Nous avons introduit un nouvel estimateur de gradient utilisant la méthode de Stein, et comparé avec d'autres méthodes sur l'apprentissage de modèles implicites pour l'inférence approximative et la génération d'images.
Méthodologie idéale pour injecter du bruit dans les données d'entrée pendant l'entraînement du CNN.
Nous proposons de modéliser explicitement les distributions de caractéristiques profondes des données source et cible en tant que distributions de mélange gaussien pour l'adaptation non supervisée au domaine (UDA) et obtenons des résultats supérieurs à ceux des méthodes de pointe dans plusieurs tâches UDA.
Nous apprenons une abstraction de l'environnement sous forme de graphe du monde, indépendante de la tâche, et nous montrons comment son utilisation pour une exploration structurée peut accélérer de manière significative la RL spécifique à la tâche en aval.
Nous représentons un programme informatique à l'aide d'un ensemble de programmes plus simples et utilisons cette représentation pour améliorer les techniques de synthèse de programmes.
Comment pouvons-nous construire des agents artificiels qui résolvent les dilemmes sociaux (situations dans lesquelles les individus sont tentés d'augmenter leurs gains au détriment du bien-être total) ?
Nous proposons un nouveau modèle de gradient basé sur la transformation généralisée et proposons un estimateur de gradient basé sur le modèle polynomial.
apprentissage semi-supervisé et par transfert sur la classification des flux de paquets, via un système de blocs neuronaux coopératifs ou adversaires
Ce travail présente une factorisation de Kronecker des matrices de poids récurrentes pour des réseaux neuronaux récurrents efficaces en termes de paramètres et bien conditionnés.
Nous proposons une méthode pour calculer des représentations robustes contre les adversaires d'une manière entièrement non supervisée.
Nous proposons une nouvelle approche de l'apprentissage structurel/causal basée sur les scores, qui tire parti des réseaux neuronaux et d'une formulation récente de ce problème sous contrainte continue.
L'article analyse le problème de la conception d'attaques adversariales contre des classificateurs multiples, en introduisant des algorithmes qui sont optimaux pour les classificateurs linéaires et qui fournissent des résultats de pointe pour l'apprentissage profond.
Nous présentons une analyse générale en boucle fermée pour les jeux à potentiel de Markov et montrons que l'apprentissage par renforcement profond peut être utilisé pour apprendre un équilibre de Nash approximatif en boucle fermée.
Nous augmentons la compression sans perte avec des variables latentes, en battant les approches existantes sur des images ImageNet de grande taille.
Nous émettons l'hypothèse que la vulnérabilité des modèles d'image aux petites perturbations adverses est un résultat naturel de la géométrie de haute dimension du collecteur de données. Nous explorons et prouvons théoriquement cette hypothèse pour un ensemble de données synthétiques simples.
Nous présentons Variational Intrinsic Successor FeatuRes (VISR), un nouvel algorithme qui apprend des caractéristiques contrôlables pouvant être exploitées pour fournir une inférence rapide des tâches par le biais du cadre des caractéristiques du successeur.
Une méthode d'adaptation au domaine pour une sortie structurée via l'apprentissage de représentations de caractéristiques discriminantes au niveau du patch.
Une nouvelle attaque contradictoire qui peut attaquer directement les modèles d'apprentissage automatique en boîte noire du monde réel sans transfert.
La confidentialité différentielle au niveau de l'utilisateur pour les modèles de langage des réseaux neuronaux récurrents est possible avec un ensemble de données suffisamment grand.
L'entraînement des convnets avec une taille d'image mixte peut améliorer les résultats sur plusieurs tailles lors de l'évaluation.
Cet article présente une méthode d'apprentissage des réseaux récurrents génératifs qui permet de planifier à l'avance. Nous faisons fonctionner un second RNN en sens inverse et établissons une contrainte souple entre les états cotemporels avant et arrière.
Nous proposons de structurer le générateur d'un GAN pour qu'il prenne en compte les objets et leurs relations de manière explicite, et qu'il génère des images par composition.
Nous parvenons à faire émerger la communication avec des agents égoïstes, contrairement à la vision actuelle en ML
nous proposons un nouveau cadre pour la régularisation des DNN en fonction des données qui peut empêcher les DNN de s'adapter de manière excessive à des données ou des étiquettes aléatoires.
L'apprentissage multitâche améliore la reconnaissance de la parole au niveau des mots et des caractères en interpolant les biais de préférence de ses composantes : préférence de fréquence et de longueur de mot.
Nous apprenons un réseau neuronal qui uniformise la distribution des entrées, ce qui permet d'obtenir des performances d'indexation compétitives dans un espace à haute dimension.
Cet article fournit une étude rigoureuse de l'apprentissage TD à variance réduite et caractérise ses avantages par rapport à l'apprentissage TD classique.
Un réseau multiflux est une architecture dynamique pour l'adaptation au domaine qui apprend des graphes de calcul potentiellement différents par domaine, afin de les mettre en correspondance avec une représentation commune où l'inférence peut être effectuée de manière agnostique par rapport au domaine.
IMPACT aide les agents RL à se former plus rapidement en réduisant le temps de formation et en augmentant simultanément l'efficacité des échantillons.
Cet article présente un schéma de coloration pour la désambiguïsation des nœuds dans les réseaux de neurones à graphes basé sur la séparabilité, qui s'avère être une extension universelle des MPNN.
En représentant les mélodies comme des images avec des unités sémantiques alignées, nous pouvons les générer en utilisant un DCGAN sans aucune composante récurrente.
Nous présentons et analysons le phénomène des "hallucinations" en T.N.M., c'est-à-dire des traductions erronées sans rapport avec le texte source, et proposons des méthodes pour en réduire la fréquence.
Un cadre d'évaluation basé sur un réseau de neurones du monde réel pour les méthodes explicatives post-hoc
Nous présentons une méthode inspirée des neurosciences et basée sur les réseaux neuronaux pour la recherche dans l'espace latent.
En introduisant la notion d'espace de représentation optimal, nous fournissons un argument théorique et une validation expérimentale montrant qu'un modèle non supervisé pour les phrases peut donner de bons résultats dans les tâches de similarité supervisée et de transfert non supervisé.
Un jeu de données de tests de closure conçu par des enseignants pour évaluer les compétences linguistiques
Les réseaux de neurones artificiels entraînés par descente de gradient sont capables de récapituler à la fois une activité neuronale réaliste et l'organisation anatomique d'un circuit biologique.
Prune et ReLU dans le domaine de Winograd pour un réseau de neurones convolutifs efficace
Un nouvel algorithme pour entraîner les réseaux neuronaux profonds. Testé sur des fonctions d'optimisation et MNIST.
Nous présentons le flipout, une méthode efficace pour décorréler les gradients calculés par les poids des réseaux neuronaux stochastiques dans un mini-lot en échantillonnant implicitement des perturbations de poids pseudo-indépendantes pour chaque exemple.
Un nouveau modèle d'autoencodeur inversible latent est proposé pour résoudre le problème de l'inférence variationnelle dans le VAE en utilisant le réseau inversible et l'entraînement adversarial à deux étapes.
Nous présentons le modèle PHP pour la représentation hiérarchique des programmes neuronaux, ainsi qu'un algorithme d'apprentissage des PHP à partir d'un mélange de supervision forte et faible.
Nous proposons une méthode de transfert de connaissances entre des tâches de LR connexes à l'aide de mappings visuels, et nous démontrons son efficacité sur des variantes visuelles du jeu Atari Breakout et sur différents niveaux de Road Fighter, un jeu de conduite de voiture Nintendo.
Les méthodes de gradient adaptatif, lorsqu'elles sont bien faites, n'entraînent pas de pénalité de généralisation. 
Nous présentons un modèle qui généralise rapidement à partir de quelques observations en stockant des informations surprenantes et en s'occupant des données les plus pertinentes à chaque point de temps.
Nous développons une approche entraînable de bout en bout pour l'écrémage, la relecture et l'arrêt précoce applicable aux tâches de classification. 
Nous considérons l'exploration en RL comme un problème de correspondance d'une distribution marginale sur les états.
Nous présentons G-HexaConv, un réseau neuronal convolutif équivariant de groupe sur des treillis hexagonaux.
Proposition d'une nouvelle approche de localisation (détection) d'objets basée sur l'interprétation du réseau CNN profond à l'aide de la représentation interne et des pensées du réseau.
Les réseaux Trellis constituent une nouvelle architecture de modélisation des séquences qui jette un pont entre les modèles récurrents et convolutifs et établit un nouvel état de l'art en matière de modélisation du langage au niveau des mots et des caractères.
Il est possible d'obtenir une grande précision de détection des objets en formant des modèles compacts spécifiques à un domaine, et la formation peut être très courte.
Nous comparons les algorithmes de RL basés sur un modèle profond et ceux sans modèle en étudiant l'approximabilité des fonctions, des politiques et de la dynamique de $Q$ par les réseaux neuronaux. 
Nous présentons une nouvelle approche du raisonnement physique fondé sur le bon sens, qui apprend à découvrir des objets et à modéliser leurs interactions physiques à partir d'images visuelles brutes, de manière purement non supervisée.
Un très fort biais en faveur des sorties simples est observé dans de nombreuses cartes entrées-sorties simples. On constate que la carte paramètre-fonction des réseaux profonds est biaisée de la même manière.
Dans cet article, nous proposons des modèles imitatifs pour combiner les avantages de la VA et de la planification orientée vers un but : des modèles prédictifs probabilistes de comportements souhaitables capables de planifier des trajectoires interprétables à la manière d'un expert pour atteindre des buts spécifiques.
Nouvelle architecture de mécanisme d'attention basé sur la mémoire pour la communication multi-agents.
Ce travail applique la dynamique hamiltonienne au contrôle pour apprendre les modèles du système à partir des données de position et de vitesse intégrées, et exploite cette dynamique physiquement cohérente pour synthétiser le contrôle basé sur le modèle via la mise en forme de l'énergie.
Nous étudions les raisons internes de nos observations, à savoir la diminution des effets des méthodes d'optimisation des hyperparamètres bien connues sur l'apprentissage fédéré à partir de données décentralisées non IID.
Une nouvelle attaque par imitation adversariale pour tromper les modèles d'apprentissage automatique.
Apprentissage par lots de grande taille à l'aide de l'apprentissage contradictoire et d'informations de second ordre
premier réseau neuronal profond pour la modélisation de la mémoire spatiale égocentrique, inspiré par les découvertes neurophysiologiques des cellules de navigation dans le cerveau des mammifères
Nous prouvons la généralisation des DNN en ajoutant un terme de régularisation de Lipschitz à la perte d'entraînement. Nous résolvons une question posée dans Zhang et al. (2016).
Nous formons des réseaux résiduels étendus qui peuvent être immédiatement déployés en utilisant un seul bit pour chaque poids convolutif, avec une précision nettement supérieure à celle des méthodes précédentes.
Visualisation immersive des espaces classiques non euclidiens à l'aide du traçage de rayons en temps réel.
Nous proposons l'autoencodeur d'ensembles, un modèle d'apprentissage de représentation non supervisé pour les ensembles d'éléments.
Nous proposons une méthode autonome pour un apprentissage par renforcement sûr et efficace qui apprend simultanément une politique avant et arrière, la politique arrière réinitialisant l'environnement pour une tentative ultérieure.
Nous présentons des preuves que les LMs capturent le sens commun avec des résultats de pointe sur le Winograd Schema Challenge et le Commonsense Knowledge Mining.
Un algorithme en ligne pour l'acquisition et la prédiction de caractéristiques en fonction des coûts
Nous soutenons que les réseaux convolutifs devraient être considérés comme le point de départ par défaut pour les tâches de modélisation de séquences.
Entraînement de DNN pour interfacer des fonctions de boîte noire avec des étiquettes intermédiaires en utilisant un sous-réseau d'estimation qui peut être remplacé par la boîte noire après l'entraînement.
Nous proposons l'algorithme Dual Actor-Critic, qui est dérivé de manière raisonnée de la forme Lagrangienne duale de l'équation d'optimalité de Bellman. L'algorithme atteint les performances les plus élevées sur plusieurs benchmarks.
Une adaptation robuste au domaine en employant une perte spécifique à la tâche dans l'apprentissage cyclique adversarial.
Optimisation de la politique en utilisant les bons déroulements passés de l'agent ; apprentissage des récompenses façonnées via la minimisation de la divergence ; SVPG avec noyau JS pour l'exploration basée sur la population.
Nous étudions le fonctionnement des autoencodeurs dans un cadre simple et conseillons de nouvelles stratégies pour leur régularisation afin d'obtenir une meilleure généralisation avec l'interpolation latente en vue de la synthèse d'images. 
Nous présentons une idée simple qui permet d'enregistrer un locuteur dans une langue donnée et de synthétiser sa voix dans d'autres langues qu'il ne connaît peut-être même pas.
Dans cet article, nous avons proposé un algorithme de VA sans modèle et hors politique pour le contrôle continu. Les résultats expérimentaux ont montré que notre algorithme obtient des résultats compétitifs avec le GAIL tout en réduisant considérablement les interactions avec l'environnement.
Un système de réécriture de texte conditionné par de multiples attributs contrôlables
Nous développons une nouvelle approche d'optimisation pour le RNN basé sur la vanille ReLU qui permet la mémorisation à long terme et l'identification de systèmes dynamiques non linéaires arbitraires avec des échelles de temps très différentes.
Proposer un cadre amélioré pour les WGAN et démontrer ses meilleures performances en théorie et en pratique.
Les opérations dans l'espace latent du GAN peuvent induire un décalage de distribution par rapport à la distribution d'entraînement, et nous y remédions en utilisant un transport optimal pour faire correspondre les distributions. 
Une nouvelle méthode d'apprentissage de l'intégration sémantique des programmes
Nous proposons une extension de la normalisation par lot, montrons une analyse de convergence inédite pour cette extension et montrons dans des expériences numériques qu'elle a de meilleures performances que la normalisation par lot originale.
Nous proposons un cadre pour modifier les opérations de l'espace latent de manière à éliminer complètement le décalage de distribution entre les sorties résultantes et la distribution antérieure sur laquelle le modèle génératif a été formé.
Cet article propose une approche multi-flux de bout en bout pour apprendre des encastrements unifiés pour les paires question-réponse dans les systèmes de dialogue en exploitant ensemble les informations contextuelles, syntaxiques, sémantiques et externes.
Techniques permettant de combiner des politiques généralisées et des algorithmes de recherche afin d'exploiter les forces et de surmonter les faiblesses de chacun lors de la résolution de problèmes de planification probabiliste.
Nous obtenons l'état de l'art en matière de robustesse aux changements de données, et nous maintenons la calibration en cas de changement de données, même si la précision diminue.
Nous extrayons automatiquement des informations sur le doigté à partir de vidéos de performances de piano, afin de les utiliser dans des modèles de prédiction automatique du doigté.
SOTA sur l'adaptation non supervisée du domaine en tirant parti de l'hypothèse des clusters.
Modèles génératifs graphiques basés sur la généralisation du passage de messages au temps continu à l'aide d'équations différentielles ordinaires 
Nous montrons que plusieurs affirmations de la théorie du goulot d'étranglement de l'information de l'apprentissage profond ne sont pas vraies dans le cas général.
Les réseaux neuronaux ont, de par leur conception, des gradients importants, ce qui les rend vulnérables à l'adversité.
Nous présentons l'optimisation proximale amortie (APO), une méthode permettant d'adapter en ligne une variété d'hyperparamètres d'optimisation pendant l'apprentissage, notamment les taux d'apprentissage, les coefficients d'amortissement et les exposants de variance du gradient.
Sans nécessiter de contraintes ou de post-traitement, nous montrons que les dimensions saillantes des vecteurs de mots peuvent être interprétées comme des caractéristiques sémantiques. 
stratégie de réparation des réseaux neuronaux endommagés
Génération automatique de questions à partir de paragraphes à l'aide de modèles hiérarchiques
L'interrogation d'un réseau neuronal en boîte noire révèle de nombreuses informations à son sujet. Nous proposons de nouveaux "métamodèles" pour extraire efficacement des informations d'une boîte noire.
Utilisation d'un cadre de modélisation supervisée des variables latentes pour déterminer la récompense dans une tâche d'apprentissage par renforcement inverse
Cet article combine la recherche arborescente de Monte Carlo avec la recherche locale 2-opt dans un mode de voisinage variable pour résoudre efficacement la TSP.
Application de la synthèse de programmes aux tâches de complétion et de génération d'images dans un cadre d'apprentissage profond
Cet article présente un modèle de calcul pour l'adaptation efficace du contrôle postural humain basé sur des fonctions d'acquisition hiérarchiques avec des caractéristiques bien connues. 
Nous étudions le problème des agents de contrôle continu dans le RL profond avec des attaques adverses et nous avons proposé un algorithme en deux étapes basé sur la dynamique du modèle appris. 
Nous étudions le biais induit par la spartialité des modèles profonds, causé par leur dynamique d'apprentissage.
Les divergences adverses paramétriques définissent implicitement des pertes de tâches plus significatives pour la modélisation générative, nous faisons le parallèle avec la prédiction structurée pour étudier les propriétés de ces divergences et leur capacité à encoder la tâche d'intérêt.
Nous fournissons une comparaison rigoureuse de différents réseaux neuronaux graphiques pour la classification des graphes.
Apprentissage automatique de l'augmentation des données à l'aide d'une architecture basée sur un GAN pour améliorer un classificateur d'images
Nouvelle classe d'auto-encodeurs avec architecture pseudo-invertible
Nous exploitons un schéma d'inversion pour les réseaux neuronaux profonds arbitraires afin de développer un nouveau cadre d'apprentissage semi-supervisé applicable à de nombreuses topologies.
Comparaison de réseaux neuronaux siamois, de GAN et de VAT pour l'apprentissage de quelques plans. 
Nous proposons une amélioration légère de l'attention et une architecture neuronale, FusionNet, pour réaliser SotA sur SQuAD et SQuAD adverse.
Modèle génératif hiérarchique entraîné de façon adversariale avec une représentation latente robuste et sémantiquement apprise.
Nous observons que les solveurs numériques d'EDP peuvent être considérés comme des processus de désicion de Markov, et nous proposons d'utiliser l'apprentissage par renforcement pour résoudre des lois de conservation scalaires 1D.
Nous présentons une architecture de rendu neuronal qui aide les VAE à apprendre des représentations latentes démêlées.
Les déficits sensoriels dans les premières phases de formation peuvent entraîner une perte de performance irréversible dans les réseaux artificiels et neuronaux, suggérant que les phénomènes d'information en sont la cause commune, et soulignant l'importance du transitoire initial et de l'oubli.
Nous proposons une méthode d'apprentissage incrémentiel d'un espace d'intégration sur le domaine des architectures de réseau, afin de permettre une sélection minutieuse des architectures à évaluer lors de la recherche d'architecture compressée.
Amélioration de la performance d'un agent RL dans le domaine de l'action continue et de l'espace d'état en utilisant la relecture prioritaire de l'expérience et le bruit des paramètres.
montrent que le poids de l'attention multicanal contient une caractéristique sémantique pour résoudre la tâche d'inférence en langage naturel.
Nous approximons les processus ponctuels déterminants avec des réseaux neuronaux ; nous justifions notre modèle sur le plan théorique et empirique.
Cet article présente une architecture de réseau pour résoudre le problème de la structure à partir du mouvement (SfM) via l'ajustement du faisceau de caractéristiques (BA).
Nous montrons que l'ajout d'une contrainte aux mises à jour du TD stabilise l'apprentissage et permet l'apprentissage profond du Q sans réseau cible.
Nous proposons DuoRC, un nouveau jeu de données pour la compréhension en lecture (CR) contenant 186 089 paires d'AQ générées par des humains et créées à partir d'une collection de 7680 paires d'intrigues de films parallèles. Nous introduisons une tâche de CR consistant à lire une version de l'intrigue et à répondre à des questions créées à partir de l'autre version ; ainsi, par conception, cela exige un raisonnement complexe et une compréhension plus profonde de la langue pour surmonter le faible chevauchement lexical entre l'intrigue et la question.
Un composant de planification basé sur un modèle améliore l'analyse sémantique basée sur RL sur les questions WikiTable.
Une nouvelle façon de quantifier l'activation d'un réseau neuronal profond via un écrêtage paramétré qui optimise l'échelle de quantification par descente de gradient stochastique.
Nous démontrons que les méthodes d'élagage qui introduisent une plus grande instabilité dans la perte confèrent également une meilleure généralisation, et nous explorons les mécanismes qui sous-tendent cet effet.
Les réseaux neuronaux profonds moins invraisemblables sur le plan biologique, formés sans transport de poids, peuvent être plus difficiles à tromper.
Un modèle génératif pour la prédiction des réactions qui apprend les étapes électroniques mécanistiques d'une réaction directement à partir des données brutes de la réaction.
L'incorporation de la capacité de dire "je ne sais pas" peut améliorer l'équité d'un classificateur sans sacrifier trop de précision, et cette amélioration s'amplifie lorsque le classificateur a un aperçu de la prise de décision en aval.
Une approche pour effectuer la planification HTN en utilisant des procédures externes pour évaluer les prédicats au moment de l'exécution (attachements sémantiques).
Les vecteurs de mots maximaux avec une similarité d'ensemble de Jaccard floue constituent une base de référence extrêmement compétitive pour la similarité sémantique ; nous proposons une variante dynamique simple qui est encore plus performante.
L'objectif global de ce travail est de permettre une imitation efficace de l'échantillon à partir de démonstrations d'experts, avec et sans la fourniture d'étiquettes d'actions d'experts, grâce à l'utilisation de f-divergences.
Grâce à une interface cerveau-machine cognitive, nous montrons un lien direct entre les effets de l'attention sur la précision perceptive et le gain neuronal en puissance EEG-SSVEP, dans le cerveau humain.
Un cadre général et facile à utiliser qui améliore la robustesse aux adversaires des modèles de classification profonde par la régularisation de l'intégration.
Nous proposons un algorithme de regroupement de tâches basé sur le remplissage de la matrice pour l'apprentissage profond multi-tâches et l'apprentissage en quelques minutes dans des environnements comportant un grand nombre de tâches diverses.
Cette approche permet de surmonter les problèmes d'évolutivité et implique de nouvelles connexions mathématiques entre la physique quantique des corps multiples, la théorie quantique de l'information et l'apprentissage automatique.
Nous entraînons une combinaison de réseaux neuronaux pour prédire les trajectoires optimales de systèmes physiques complexes.
Nous fournissons une garantie de généralisation basée sur PAC-Bayes pour les réseaux profonds déterministes non compressés, en généralisant la résistance au bruit du réseau sur les données d'entraînement aux données de test.
Nous prouvons que pour une grande classe de fonctions f, il existe un réseau robuste certifié par intervalle qui approxime f avec une précision arbitraire.
Il s'agit d'un travail visant à améliorer toutes les méthodes d'élagage et d'imitation existantes.
Nous introduisons un objectif préalable gaussien supplémentaire dépendant des données pour augmenter la formation MLE actuelle, qui est conçue pour capturer la connaissance préalable dans les données de base.
Nous proposons une approche interactive pour classer les requêtes en langage naturel en demandant aux utilisateurs des informations supplémentaires en utilisant le gain d'information et un contrôleur de politique d'apprentissage par renforcement.
Autoencodeurs convolutifs généralisés aux surfaces maillées pour le codage et la reconstruction d'expressions faciales extrêmes en 3D.
Jiffy est une approche convolutive de l'apprentissage d'une métrique de distance pour les séries temporelles multivariées qui surpasse les méthodes existantes en termes de précision de classification par les plus proches voisins.
Une architecture modulaire extensible est proposée pour développer une variété de comportements d'agents dans le DQN.
Nous isolons un facteur de généralisation de RL en analysant le cas où l'agent ne surajuste qu'aux observations. Nous montrons que des régularisations implicites architecturales se produisent dans ce régime.
Dans cet article, nous proposons un nouveau modèle de langage neuronal, appelé "Parsing-Reading-Predict Networks" (PRPN), qui peut simultanément induire la structure syntaxique de phrases non annotées et exploiter la structure inférée pour apprendre un meilleur modèle de langage.
Nous avons proposé une approche globale pour l'apprentissage non supervisé de l'intégration sur la base de l'algorithme AND.
Nous proposons une méthode d'apprentissage faiblement supervisée pour la classification et la localisation de cancers dans des images de lames entières d'histopathologie à très haute résolution, en utilisant uniquement les étiquettes de l'image.
 Nous proposons une nouvelle méthode d'utilisation des informations ontologiques pour améliorer les performances des problèmes de prédiction/classification massivement multi-labels.
Nous appliquons une affectation gourmande sur les échantillons projetés au lieu de les trier pour approximer la distance de Wasserstein.
Cet article étudie les interactions entre les modèles d'apprentissage rapide et de prédiction lente et démontre comment ces interactions peuvent améliorer la capacité des machines à résoudre les problèmes conjoints d'apprentissage tout au long de la vie et d'apprentissage à court terme.
La première méthode d'initialisation de poids fondée sur des principes pour les hyperréseaux
Un nouveau cadre d'apprentissage profond bayésien qui capture et met en relation des concepts sémantiques et visuels hiérarchiques, et qui donne de bons résultats dans une variété de tâches de modélisation et de génération d'images et de textes.
Cet article présente la mise à la terre partielle pour résoudre le problème qui se pose lorsque le processus de mise à la terre complète, c'est-à-dire la traduction d'une tâche d'entrée PDDL en une représentation de base comme STRIPS, est irréalisable en raison de contraintes de mémoire ou de temps.
Présentation de la méthode de caractérisation des réponses pour l'interprétation de la dynamique cellulaire dans les réseaux de mémoire à long terme (LSTM) savants. 
À notre connaissance, il s'agit de la première étude à montrer comment les représentations neuronales de l'espace, y compris les cellules en forme de grille et les cellules frontières telles qu'observées dans le cerveau, pourraient émerger de l'entraînement d'un réseau neuronal récurrent pour effectuer des tâches de navigation.
Nous comparons les performances d'un modèle basé sur le spectrogramme à celles d'un modèle entraîné de bout en bout dans le domaine des formes d'onde.
Nous proposons une solution évolutive pour l'évaluation multi-agents avec une complexité linéaire en temps et en mémoire en fonction du nombre d'agents.
Nous proposons une nouvelle approche d'apprentissage semi-supervisé avec une performance SOTA pour combattre l'apprentissage avec des étiquettes bruyantes.
Nous concevons une méthode de formation contradictoire pour les réseaux neuronaux bayésiens, qui offre une défense beaucoup plus solide contre les attaques contradictoires de type boîte blanche.
Attaques efficaces par empoisonnement de modèle sur l'apprentissage fédéré, capables de provoquer une classification erronée ciblée à haute confiance des entrées souhaitées.
 Dans cet article, nous émettons l'hypothèse que des points de données superficiellement perturbés ne devraient pas simplement correspondre à la même classe - ils devraient correspondre à la même représentation.
modèle acoustique harmonique
résoudre le problème de la dépendance des classes à l'égard des domaines en améliorant les réseaux adversariens de domaine.
Nous proposons FVD : une nouvelle métrique pour les modèles génératifs de vidéo basés sur FID. Une étude humaine à grande échelle confirme que la FVD est en bonne corrélation avec le jugement humain qualitatif des vidéos générées.
Une architecture à double mémoire inspirée du cerveau humain pour apprendre séquentiellement des tâches entrantes, tout en évitant les oublis catastrophiques.
La modélisation linguistique pour l'apprentissage des langues tout au long de la vie.
Nous utilisons des idées issues de l'informatique quantique pour proposer des incorporations de mots qui utilisent beaucoup moins de paramètres à former.
Nous formons des agents de réseaux neuronaux pour développer un langage avec des propriétés de composition à partir d'une entrée de pixels bruts.
Nous apprenons une fonction d'échantillonnage de diversité avec les DPP pour obtenir un ensemble diversifié d'échantillons à partir d'un modèle génératif.
Les représentations issues de modèles de langage donnent systématiquement de meilleurs résultats que les codeurs de traduction dans les tâches de prédiction d'auxiliaires syntaxiques.
Nous proposons un échantillonnage de Langevin contraint basé sur les substituts, avec une application dans la conception de la configuration des matériaux nano-poreux.
Améliorer les modèles d'intégration hiérarchique en utilisant le lissage du noyau
Approche d'amorçage augmentée combinant les informations d'un ensemble de référence avec des affinements itératifs des étiquettes souples pour améliorer la reconnaissance d'entités nominatives à partir de la littérature biomédicale.
Nous étendons les SVM quantiques à un cadre semi-supervisé, afin de traiter le problème probable des nombreuses étiquettes de classe manquantes dans les grands ensembles de données.
Cet article établit un lien entre les architectures de réseaux profonds et les équations différentielles numériques (stochastiques). Cette nouvelle perspective permet de concevoir de nouveaux réseaux neuronaux profonds plus efficaces.
CNN et LSTM pour générer un code de type balisage décrivant des images d'interface utilisateur graphique.
Nous montrons que les incorporations hyperboliques sont utiles pour les tâches de vision par ordinateur de haut niveau, en particulier pour la classification de quelques images.
Nous présentons une méthode pour apprendre des représentations interprétables sur des séries temporelles en utilisant des idées provenant des autoencodeurs variationnels, des cartes auto-organisatrices et des modèles probabilistes.
Architecture convolutive pour l'apprentissage de poids dépendant des données pour la prévision autorégressive des séries temporelles.
Nous présentons une nouvelle interprétation de MixUp comme appartenant à une classe très analogue à l'entraînement contradictoire, et sur cette base nous introduisons une généralisation simple qui surpasse MixUp.
Traitement de l'incertitude dans la perception visuelle pour la reconnaissance de plans
Accès multi-sauts différentiable à une base de connaissances textuelles de représentations contextuelles indexées
Algorithme de factorisation polyvalent et évolutif - permet également de contourner le problème du démarrage à froid.
Nous présentons un système de création de didacticiels d'assemblage multimédias qui rationalise la création de vidéos, d'images, de textes et d'instructions dynamiques in situ.
Nous démontrons que l'utilisation des notes cliniques en conjonction avec les données des instruments de l'USI améliore la performance des tâches de référence de la gestion de l'USI.
Nous proposons un gradient de politique basé sur les événements pour former le leader et un gradient de politique d'abstraction d'action pour former les suiveurs dans un jeu de Markov leader-suiveur.
Nous utilisons la transmission culturelle pour encourager la compositionnalité dans les langages qui émergent des interactions entre les agents neuronaux.
Nous proposons une méthode basée sur SVD pour explorer la dimension locale du collecteur d'activation dans les réseaux neuronaux profonds.
L'inférence dans les grands transformateurs est coûteuse en raison de l'auto-attention dans les couches multiples. Nous montrons qu'une simple technique de décomposition peut produire un modèle plus rapide, à faible empreinte mémoire et tout aussi précis que les modèles originaux.
Une adaptation à l'apprentissage profond de l'itération aléatoire de la valeur des moindres carrés.
Les paramètres d'un réseau neuronal formé peuvent être permutés pour produire un modèle complètement différent pour une tâche différente, ce qui permet d'intégrer des réseaux de type cheval de Troie dans un autre réseau.
Nous présentons une conception alternative de GAN basée sur des routes aléatoires dans le générateur, qui peut servir d'outil pour l'interprétabilité des modèles génératifs.
Nous présentons un cadre théorique et expérimental pour définir, comprendre et réaliser la généralisation, et par conséquent la robustesse, dans l'apprentissage profond en nous appuyant sur la théorie de l'information algorithmique et la théorie du codage.
Nous présentons la découverte de la structure causale comme une sélection de modèles bayésiens d'une manière qui nous permet de discriminer les graphes équivalents de Markov pour identifier le graphe causal unique.
Limite inférieure pour la détection comprimée avec des modèles génératifs qui correspond aux limites supérieures connues.
Cet article présente une analyse empirique sur le rôle de différents types de représentations d'images et sonde les propriétés de ces représentations pour la tâche de sous-titrage d'images.
Nous concevons des analyseurs incrémentiels de séquences d'actions pour des tâches de texte à SQL et obtenons des résultats SOTA. Nous améliorons encore les résultats en utilisant des oracles non déterministes pour permettre plusieurs séquences d'actions correctes. 
Une approche qui accélère de 10 fois la recherche d'architectures neuronales, tout en utilisant 100 fois moins de ressources informatiques.
Nous proposons une nouvelle architecture DNN pour l'apprentissage profond sur des données tabulaires.
Un cadre qui effectue un raffinement en ligne des pseudo-étiquettes avec une nouvelle perte douce softmax-triplet pour l'adaptation non supervisée du domaine sur la réidentification des personnes.
Nous présentons la première approche permettant de certifier la robustesse des réseaux neuronaux contre les perturbations dues au bruit dans le domaine audio.
Ce travail présente une méthode de génération et d'utilisation efficace d'ensembles pour identifier des exemples bruités en présence de bruit d'annotation. 
Un algorithme d'apprentissage basé sur le déroulement de l'optimisation de la minimisation alternée pour la récupération de graphes épars.
Nous avons proposé un cadre neuronal double pour résoudre un jeu d'information imparfaite à grande échelle. 
Nous présentons la première vérification qu'un réseau neuronal pour les tâches de perception produit une sortie correcte dans une tolérance spécifiée pour chaque entrée d'intérêt. 
Nous étudions les approximations de distorsion de taux pour évaluer les modèles génératifs profonds, et nous montrons que les courbes de distorsion de taux fournissent plus d'informations sur le modèle que la log-vraisemblance seule, tout en exigeant à peu près le même coût de calcul.
Un algorithme méta-RL basé sur un modèle qui permet à un robot réel de s'adapter en ligne dans des environnements dynamiques.
L'article analyse l'espace latent appris par des approches sans modèle dans un jeu d'information incomplète miniature, forme un modèle avant dans l'espace latent et l'applique à la recherche arborescente de Monte-Carlo, ce qui donne des performances positives.
Nous analysons le pouvoir expressif des connexions utilisées dans les DenseNets via des décompositions tensorielles.
Nous utilisons le feedback humain implicite (via les potentiels d'erreur, EEG) pour accélérer et optimiser l'entraînement d'un algorithme DRL, de manière pratique.
TCN pour l'apprentissage semi-supervisé multimodal + étude de l'ablation de ses mécanismes + interprétations des représentations latentes
Adaptation de Adam, Amsgrad, Adagrad aux collecteurs riemanniens. 
Défense contre les attaques physiquement réalisables sur la classification des images
Les poids plastiques de Hebbian peuvent se comporter comme un stockage compressé de la mémoire épisodique dans les réseaux neuronaux et, avec la combinaison de la consolidation synaptique spécifique à la tâche, peuvent améliorer la capacité à atténuer l'oubli catastrophique dans l'apprentissage continu.
Cet article prouve que les réseaux neuronaux cutanés ne peuvent pas approximer certaines fonctions, quelle que soit leur profondeur.
Nous présentons le réseau logique continu (CLN), une nouvelle architecture neuronale pour l'apprentissage automatique des invariants de boucle et des formules SMT générales.
Nos découvertes permettent de prévenir la progression du cancer
Nous étendons les flux autorégressifs et RealNVP aux données discrètes.
Une architecture d'apprentissage profond robuste au bruit.
Nous apprenons des encastrements neuronaux de graphes dans un espace hyperbolique plutôt qu'euclidien.
Idées pour les futurs ICKEPS
Nous générons des articles Wikipédia de manière abstraite conditionnée par le texte du document source.
Un algorithme pour unifier SGD et Adam et étude empirique de ses performances
Apprentissage de politiques hiérarchiques à partir de démonstrations non segmentées à l'aide d'informations dirigées
Les algorithmes traditionnels de traitement d'images sont combinés avec les réseaux neuronaux convolutifs， un nouveau réseau neuronal.
Nous avons proposé une méthode spécifique de rétropropagation via un sous-gradient spectral approprié pour intégrer le processus ponctuel déterminant au cadre d'apprentissage profond.
Nous inventons un nouveau cadre de cluster à cluster pour la formation NMT, qui peut mieux comprendre la diversité de la langue source et de la langue cible.
Un modèle ILP différentiable efficace qui apprend des règles de logique du premier ordre pouvant expliquer les données.
Nous présentons une nouvelle méthode de synthèse d'exemples contradictoires robustes dans le monde physique et l'utilisons pour fabriquer les premiers objets contradictoires en 3D.
Apprenez à permuter un ensemble, puis à coder l'ensemble permuté avec le RNN pour obtenir une représentation de l'ensemble.
Utiliser l'apprentissage par renforcement profond pour concevoir les attributs physiques d'un robot conjointement avec une politique de contrôle.
Nous proposons une approche qui confère à un seul modèle la capacité de représenter les deux extrêmes : la formation conjointe et la formation indépendante, ce qui conduit à un apprentissage multi-tâches efficace.
Nous proposons un terme de régularisation qui, lorsqu'il est ajouté à l'objectif d'apprentissage par renforcement, permet à la politique de maximiser la récompense et d'apprendre simultanément à être invariant aux changements non pertinents dans l'entrée....
Ce travail a proposé une représentation visuelle universelle pour la traduction automatique neuronale (NMT) en utilisant des images récupérées avec des sujets similaires à la phrase source, étendant l'applicabilité des images dans la NMT.
En combinant des idées issues de la conception d'algorithmes traditionnels et de l'apprentissage par renforcement, nous présentons un nouveau cadre pour l'apprentissage d'algorithmes qui résolvent des problèmes d'optimisation combinatoire en ligne.
Une approche fonctionnelle révèle que l'initialisation plate, préservée par la descente de gradient, conduit à la capacité de généralisation.
La profondeur du réseau augmente les valeurs propres aberrantes dans le hessien. Les connexions résiduelles atténuent ce phénomène.
Un article expérimental qui prouve la quantité de poids redondants qui peuvent être gelés à partir de la troisième époque seulement, avec seulement une très légère baisse de la précision.
Une nouvelle approche de l'apprentissage des programmes d'études par l'apprentissage incrémentiel des étiquettes et le lissage adaptatif des étiquettes pour les échantillons mal classés, ce qui augmente la performance moyenne et diminue l'écart type.
Nous proposons une méthode pour traiter les mots rares en calculant leur encastrement à partir des définitions.
Cet article propose un classificateur génératif profond qui permet de détecter efficacement les échantillons hors distribution et de classer les échantillons en distribution, en intégrant le concept d'analyse discriminante gaussienne dans les réseaux neuronaux profonds.
Montrer que l'âge nuit à la détection des troubles cognitifs + résoudre le problème par l'apprentissage de représentations équitables + proposer des métriques et des modèles.
Nous présentons NetScore, une nouvelle métrique conçue pour fournir une évaluation quantitative de l'équilibre entre la précision, la complexité de calcul et la complexité de l'architecture du réseau d'un réseau neuronal profond.
attaques adverses top-k ordonnées
La propagation personnalisée des prédictions neuronales (PPNP) améliore les réseaux neuronaux de graphes en les séparant en prédiction et propagation via un PageRank personnalisé.
Le choix de la langue pivot (cible) affecte la qualité des encastrements interlinguistiques, qui ne devraient pas être évalués uniquement sur des dictionnaires centrés sur l'anglais.
L'entraînement typique du GAN n'optimise pas Jensen-Shannon, mais quelque chose comme une divergence KL inversée.
Nous montrons qu'en tirant plusieurs échantillons (prédictions) par entrée (point de données), nous pouvons apprendre avec moins de données car nous obtenons librement une ligne de base REINFORCE.
Nous résolvons efficacement les problèmes multitâches avec un algorithme de génération automatique de programmes d'études basé sur un modèle génératif qui suit les performances de l'agent d'apprentissage.
Cet article identifie des classes de problèmes pour lesquels les exemples contradictoires sont inévitables, et dérive des limites fondamentales sur la susceptibilité de tout classificateur aux exemples contradictoires. 
En diminuant la précision (à 4 bits, 2 bits et même binaire) et en élargissant les banques de filtres, on obtient des réseaux aussi précis que ceux obtenus avec des poids et des activations FP32.
Nous intégrons un CRF dans un VAE de tokens et de balises NER pour l'apprentissage semi-supervisé et montrons des améliorations dans des environnements à faibles ressources.
Un cadre de principe pour la quantification de modèles utilisant la méthode du gradient proximal.
Une nouvelle technique de modélisation générative basée sur l'entraînement contradictoire asymétrique, et ses applications à la détection d'exemples contradictoires et à la classification robuste.
Le méta-apprentissage d'algorithmes de curiosité par la recherche dans un riche espace de programmes permet d'obtenir de nouveaux mécanismes qui se généralisent à des domaines d'apprentissage par renforcement très différents.
Cet article propose une procédure simple pour évaluer la structure compositionnelle dans les représentations apprises, et utilise cette procédure pour explorer le rôle de la compositionnalité dans quatre problèmes d'apprentissage.
Un modèle DL pour la prédiction de la structure secondaire de l'ARN, qui utilise un algorithme déroulé dans l'architecture pour faire respecter les contraintes.
Nous présentons la propagation de l'admissibilité comme une alternative à la TPP qui est compatible avec les données expérimentales sur la plasticité synaptique et qui rivalise avec la TPP sur des benchmarks d'apprentissage automatique.
Extraction d'une machine à états finis à partir d'un réseau neuronal récurrent par quantification à des fins d'interprétabilité, avec des expériences sur Atari.
Nous étudions les preuves théoriques et pratiques de l'amélioration de l'apprentissage par renforcement sur les politiques en réutilisant les données de plusieurs politiques consécutives.
Nous utilisons la transformation de Fourier non euclidienne de formes définies par un complexe simplicial pour l'apprentissage profond, obtenant ainsi de bien meilleurs résultats que les techniques d'échantillonnage par points utilisées dans la littérature actuelle sur l'apprentissage 3D.
Nous appliquons l'apprentissage par renforcement à la découverte causale basée sur le score et obtenons des résultats prometteurs sur des ensembles de données tant synthétiques que réels.
Nous avons proposé une méthode universelle qui peut être utilisée dans l'étape de prétraitement des données pour générer le sujet le plus significatif qui représente le mieux le document donné.
Nous proposons un nouveau cadre d'apprentissage multi-tâches qui extrait automatiquement les relations de dépendance multi-vues et les utilise pour guider le transfert de connaissances entre différentes tâches.
Test de l'invariance globale en translation dans les réseaux convolutifs et les réseaux de capsules
Nous développons une méthode analytique pour étudier l'inférence bayésienne des réseaux neuronaux à largeur finie et constatons que l'image du flux du groupe de renormalisation émerge naturellement.
comprendre théoriquement l'effet de régularisation de la distillation. Nous montrons que l'arrêt précoce est essentiel dans ce processus. Dans cette perspective, nous avons développé une méthode de distillation pour l'apprentissage avec étiquette corrompue avec des garanties théoriques.
une nouvelle approche pour l'apprentissage en ligne tout au long de la vie en utilisant des noyaux de sortie.
Nous modélisons un scénario de construction de maison dans Minecraft en planification classique et HTN et comparons les avantages et inconvénients de ces deux types de modèles.
Nous présentons un cadre pour l'évaluation des exemples contradictoires dans le traitement du langage naturel et démontrons que les exemples contradictoires générés ne sont souvent pas sémantiquement préservés, syntaxiquement corrects ou non suspects.
Peut-on faire confiance à l'explication d'un réseau neuronal pour sa prédiction ? Nous examinons la robustesse de plusieurs notions populaires d'interprétabilité des réseaux neuronaux, notamment les cartes de saillance et les fonctions d'influence, et nous concevons des exemples contradictoires à leur encontre.
L'article conçoit deux algorithmes pour le problème de maximisation stochastique de l'AUC avec des complexités de pointe lors de l'utilisation d'un réseau neuronal profond comme modèle prédictif, qui sont également vérifiés par des études empiriques.
Nous nous attaquons à des tâches conditionnées par un objectif en combinant les algorithmes de reprise d'expérience a posteriori et d'apprentissage par imitation, montrant une convergence plus rapide que le premier et une performance finale plus élevée que le second.
Nous dérivons une nouvelle limite PAC-Bayes pour les fonctions de perte non bornées (par exemple, la vraisemblance logarithmique négative). 
Nous proposons une technique simple d'augmentation des données autosupervisées qui améliore les performances des scénarios entièrement supervisés, y compris l'apprentissage en quelques coups et la classification déséquilibrée.
Une architecture de réseau basée sur un LSTM à deux branches apprend la représentation et la dynamique des maillages 3D des simulations numériques de collision.
Les vecteurs de caractéristiques de SoundNet peuvent prédire l'activité cérébrale des sujets regardant un film dans les régions du cerveau liées à l'audition et au langage.
Nous proposons un auto-codeur génératif qui peut apprendre des distributions expressives de vraisemblance postérieure et conditionnelle en utilisant des distributions implicites, et nous entraînons le modèle en utilisant une nouvelle formulation de l'ELBO.
Les enfants utilisent le biais d'exclusivité mutuelle (EM) pour apprendre de nouveaux mots, alors que les réseaux neuronaux standard présentent le biais inverse, ce qui entrave l'apprentissage dans des scénarios naturalistes tels que l'apprentissage tout au long de la vie.
Des réseaux de neurones récurrents à dopage effectuant une tâche de mémoire de travail utilisent de longues échelles de temps hétérogènes, étonnamment similaires à celles observées dans le cortex préfrontal.
 Dans cet article, nous abordons le problème de l'apprentissage de l'expansion d'un réseau à bas bruit.
Nous présentons un modèle de questionnement humain qui combine des réseaux neuronaux et des programmes symboliques, qui peuvent apprendre à générer de bonnes questions avec ou sans exemples supervisés.
Un mécanisme de compréhension visuelle pour les environnements spéciaux
Une meilleure formation contradictoire en apprenant à se recaler sur le collecteur de données avec des autoencodeurs dans les états cachés.  
Nous montrons que la minimisation de la perte d'entropie croisée en utilisant une méthode de gradient peut conduire à une marge très faible si les caractéristiques de l'ensemble de données se trouvent dans un sous-espace de faible dimension.
Un nouveau modèle RNN qui surpasse de manière significative la frontière actuelle des modèles dans une variété de tâches séquentielles.
Résultats négatifs surprenants sur Model Based + Model deep RL
Inspirés par la théorie du goulot d'étranglement de l'information, nous proposons une nouvelle architecture de GAN pour l'apprentissage d'une représentation démêlée.
Explication de la situation de partialité avec les GAN MMD ; les GAN MMD fonctionnent avec des réseaux critiques plus petits que les WGAN-GP ; nouvelle métrique d'évaluation des GAN.
Un cadre de classification multi-modale semi-supervisée, TCN, qui surpasse les performances de divers repères.
Une méthode neuronale itérative pour extraire des signaux qui ne sont observés que mélangés à d'autres signaux
Incorporation de signaux physiologiques pour la performance de prédiction et le transfert hospitalier avec une méthode générale d'interprétabilité de la valeur Shapley pour les modèles empilés.
Nous présentons un algorithme prouvable pour récupérer exactement les deux facteurs du modèle d'apprentissage par dictionnaire. 
Extraction de relations augmentée par les données avec GPT-2
Un algorithme d'inférence approximative pour l'apprentissage profond
Nous proposons une nouvelle stratégie de régularisation des collecteurs basée sur la formation contradictoire, qui peut améliorer de manière significative les performances de l'apprentissage semi-supervisé.
Une nouvelle méthode d'apprentissage supervisé par la subdivision de l'espace d'entrée et l'approximation des fonctions.
Attaques adverses sur des enrobages de nœuds non supervisés basées sur la théorie de la perturbation des valeurs propres.
Nous présentons un nouvel algorithme pour la découverte hiérarchique de sous-tâches qui exploite le cadre du processus de décision de Markov linéaire multitâche.
Nous proposons un modèle de réseau de mémoire pour résoudre les instances de LP binaires où les informations de la mémoire sont conservées pour une utilisation à long terme. 
Nous présentons une nouvelle méthode pour former les modèles Seq2Seq avec des modèles de langage qui convergent plus rapidement, se généralisent mieux et peuvent être presque entièrement transférés à un nouveau domaine en utilisant moins de 10 % de données étiquetées.
Nous introduisons la problématique du méta-apprentissage en ligne pour mieux saisir l'esprit et la pratique de l'apprentissage continu.
Les poids d'attention n'exposent pas complètement ce que BERT sait de la syntaxe.
Nous proposons une nouvelle méthode de super résolution du visage qui incorpore explicitement des prieurs faciaux 3D qui saisissent les structures faciales nettes.
L'auto-formation avec différentes vues de l'entrée donne d'excellents résultats pour la reconnaissance d'images semi-supervisée, l'étiquetage des séquences et l'analyse syntaxique des dépendances.
Un moyen non réversible de prendre des décisions d'acceptation ou de rejet peut être bénéfique.
Nous fournissons un nouveau cadre pour MAML dans le cadre ES/blackbox, et montrons qu'il permet des politiques déterministes et linéaires, une meilleure exploration, et des opérateurs d'adaptation non-différenciables.
Nous présentons un cadre logiciel pour la transformation des distributions et démontrons sa flexibilité sur la relaxation des hypothèses de champ moyen dans l'inférence variationnelle avec l'utilisation de flux de couplage pour répliquer la structure du modèle génératif cible.
Adversarial Domain adaptation and Multi-domain learning : a new loss to handle multi- and single-domain classes in the semi-supervised setting.
Un réseau d'apprentissage qui généralise le cadre MLP pour effectuer une régression de distribution à distribution.
Proposition de méthodes de représentation d'événements dépendant du temps et de régularisation pour la prédiction de séquences ; évaluation de ces méthodes sur cinq ensembles de données impliquant une série de tâches de prédiction de séquences.
Nous développons une méthode d'apprentissage par renforcement hors ligne stable à partir de données enregistrées. La clé est de régulariser la politique d'apprentissage par renforcement vers un modèle appris "pondéré par les avantages" des données.
Cet article présente un modèle d'apprentissage profond qui combine des cartes auto-organisées et des réseaux de neurones convolutifs pour l'apprentissage de la représentation de données multi-omiques.
La sparsification comme réglage fin des modèles de langue
Méthode pour traiter le décalage des covariables dans l'apprentissage par imitation en utilisant l'incertitude d'ensemble
Nous utilisons un réglage fin supervisé des vecteurs de caractéristiques pour améliorer le transfert de la simulation au monde réel.
Nous introduisons la capacité d'exploiter les informations sur le degré d'atteinte d'un objectif arbitraire alors qu'un autre objectif était destiné à la politique des méthodes de gradient.
Nous proposons une nouvelle référence pour la compréhension de vidéos, avec des tâches qui, par conception, nécessitent un raisonnement temporel pour être résolues, contrairement à la plupart des ensembles de données vidéo existants.
Nous proposons un algorithme d'apprentissage fédéré asynchrone efficace et robuste sur l'existence de traînards.
L'ajout d'un nouvel ensemble de poids au LSTM qui fait pivoter la mémoire cellulaire améliore les performances pour certaines tâches bAbI.
Nouvelle méthode d'inférence marginale variationnelle des permutations basée sur l'algorithme de Sinkhorn, appliquée à l'identification probabiliste des neurones.
Nous proposons la première mesure de robustesse indépendante des attaques, appelée CLEVER, qui peut être appliquée à n'importe quel classificateur de réseau neuronal.
Cet article propose un schéma d'apprentissage de communication spontanée et auto-organisée (SSoC) pour les tâches de RL multi-agents.
Utilisation de BERT comme codeur pour la prédiction séquentielle des étiquettes dans une tâche de classification de textes à étiquettes multiples.
DNN et Encoder FM amélioré avec attention bilinéaire et max-pooling pour CTR
L'inférence bayésienne basée sur la suppression est étendue pour traiter la multi-modalité et est évaluée sur des tâches d'anticipation de scènes.
Nous introduisons un nouveau type de GAN conditionnel, qui vise à tirer parti de la structure de l'espace cible du générateur. Nous augmentons le générateur avec une nouvelle voie non supervisée pour apprendre la structure cible. 
Dans cet article, nous proposons un nouveau cadre de formation adversariale régularisée ATLPA, à savoir Adversarial Tolerant Logit Pairing with Attention.
Nous abordons le problème de la généralisation de l'apprentissage par renforcement aux espaces d'action non vus.
Apprendre dans les processus ponctuels temporels en modélisant la densité conditionnelle, et non l'intensité conditionnelle.
Un modèle profond pour la modélisation des sujets
Nouveau cadre GAN basé sur la normalisation adaptative des instances pour les VC non parallèles de type "many-to-many" et "zero-shot". 
Ce travail propose un transformateur épars pour améliorer la concentration de l'attention sur le contexte global par une sélection explicite des segments les plus pertinents pour l'apprentissage de séquence à séquence. 
Les représentations non supervisées apprises avec le codage prédictif contrastif permettent une classification des images efficace en termes de données.
La redistribution et la croissance des poids en fonction de l'ampleur de l'élan permettent l'apprentissage de réseaux épars à partir d'initialisations aléatoires qui peuvent atteindre des niveaux de performance denses avec des poids de 5 à 50 % tout en accélérant l'apprentissage jusqu'à 5,6 fois.
La surface de perte des réseaux neuronaux est une union disjointe de régions où chaque minimum local est un minimum global de la région correspondante.
Nous distillons les représentations des modèles de langage pour la syntaxe par un apprentissage métrique non supervisé.
Nous présentons une nouvelle architecture de mémoire pour la navigation dans des environnements inconnus, inspirée de la navigation basée sur les points de repère chez les animaux.
Nous proposons une nouvelle architecture qui parcourt une pyramide d'images de manière descendante, en ne visitant que les régions les plus informatives en cours de route.
Nous utilisons un hyper-réseau pour prédire les poids optimaux en fonction des hyperparamètres, et nous entraînons tout ensemble.
Nous proposons une nouvelle métrique pour évaluer les GAN conditionnels qui capture la qualité de l'image, la cohérence conditionnelle et la diversité intra-conditionnement en une seule mesure.
Nous présentons TreeQN et ATreeC, de nouvelles architectures pour l'apprentissage par renforcement profond dans des domaines d'action discrète qui intègrent la planification arborescente en ligne différentiable dans la fonction ou la politique de valeur de l'action.
Nous proposons des réseaux Encodeur-Décodeur à passage de messages pour une manière rapide et précise de modéliser les dépendances d'étiquettes pour la classification multi-labels.
Nous proposons une méthode pour effectuer une régression à quelques coups en apprenant un ensemble de fonctions de base pour représenter la distribution de la fonction.
Nous proposons une manière agnostique de tirer parti de BERT pour la génération de textes et obtenons des améliorations par rapport à Transformer pour deux tâches sur quatre ensembles de données.
CNN-F étend CNN avec un réseau génératif de rétroaction pour une vision robuste.
Il est démontré que les CNN de type ResNet constituent un approximateur universel et que leur capacité d'expression n'est pas inférieure à celle des réseaux de neurones entièrement connectés (FNN) avec une structure \textit{block-sparse}, même si la taille de chaque couche du CNN est fixée.
Une nouvelle méthode d'apprentissage en quelques coups pour générer des poids de classification spécifiques aux requêtes via la maximisation de l'information.
Une méthode neuronale pour répondre à des questions conversationnelles avec un mécanisme d'attention et une nouvelle utilisation de BERT comme encastrement contextuel.
alternative à la pénalité de gradient
recherche automatique d'architectures multitâches qui réduisent l'utilisation des fonctions par tâche
Nous proposons le chevauchement du plus proche voisin, une procédure qui quantifie la similarité entre les encastrements d'une manière indépendante de la tâche, et nous l'utilisons pour comparer 21 encastrements de phrases.
Nous proposons un nouvel objectif pour l'entraînement des VAE-GAN hybrides qui conduit à une amélioration significative de la couverture et de la qualité des modes.
Une nouvelle méthode utilise les informations du score de levier statistique pour mesurer l'importance des échantillons de données dans chaque tâche et adopte une approche de directions fréquentes pour permettre une propriété d'apprentissage tout au long de la vie.
Nous apprenons des cartes de caractéristiques invariantes à la translation, et équivariantes à la rotation et à l'échelle.
Un algorithme spécifique de méta-apprentissage basé sur le gradient, MAML, est équivalent à une procédure d'inférence dans un modèle bayésien hiérarchique. Nous utilisons cette connexion pour améliorer MAML via des méthodes issues de l'inférence approximative et de l'estimation de la courbure.
Automatiser le système d'apprentissage automatique à l'aide d'un algorithme de recherche efficace et d'une structure innovante pour fournir de meilleurs modèles de base.
Nous proposons des stratégies de conception expérimentale bayésienne par lots et une méthode de quantification de l'incertitude des sommaires postérieurs dans un cadre de calcul bayésien approximatif basé sur un substitut de processus gaussien.
Nous fournissons un taux de convergence efficace pour la descente du gradient sur l'objectif d'apprentissage du dictionnaire orthogonal complet basé sur une analyse géométrique.
Nous montrons que des architectures RNN conçues et entraînées de manière créative peuvent décoder des codes séquentiels bien connus et atteindre des performances proches de l'optimum.
Nous analysons et résolvons le problème de non-convergence d'Adam.
Dans cet article, nous proposons une méthode générative pour l'adaptation de domaine multisource basée sur la décomposition des facteurs de contenu, de style et de domaine.
Utilisation de l'échantillonnage par importance recuit sur le problème de la co-génération. 
Nous développons une nouvelle méthode d'estimation des paramètres sans vraisemblance qui est équivalente au maximum de vraisemblance sous certaines conditions.
Notre méthode permet d'inférer des contraintes sur l'exécution des tâches en s'appuyant sur le principe de l'entropie maximale pour quantifier la façon dont les démonstrations diffèrent du comportement attendu, sans contrainte.
Système pour apprendre des tâches robotiques dans le monde réel avec l'apprentissage par renforcement sans instrumentation
Nous utilisons un auto-codeur variationnel pour séparer le style et le contenu, et réalisons la conversion de la voix en modifiant l'intégration et le décodage du style. Nous étudions l'utilisation d'un corpus de parole multi-langue et examinons ses effets.
L'article propose une méthode permettant de forcer les CNN à tirer parti de l'attention spatiale pour apprendre des représentations plus centrées sur l'objet et plus performantes à divers égards.
Réseaux neuronaux récurrents pour les cas d'utilisation de la cybersécurité
Structuration des entrées le long du chaos pour la stabilité
Nous abordons l'entraînement des GAN avec des données discrètes en formulant un gradient de politique qui se généralise à travers les f-divergences.
Les bases de référence dépendantes de l'action peuvent être exemptes de biais et permettre une plus grande réduction de la variance que les bases de référence dépendantes de l'état uniquement pour les méthodes de gradient de politique.
Nous proposons un algorithme d'apprentissage multitâche actif qui réalise un transfert de connaissances entre les tâches.
Nous avons découvert un codec d'image avec perte efficace qui peut être optimisé pour faciliter la détection fiable des manipulations de photos à un coût minime en termes de charge utile/qualité et même à des débits binaires faibles.
Cet article propose un modèle de séquence générique efficace qui exploite les forces des RNN et de l'attention multi-têtes.
Une approche structurée à variables latentes qui ajoute des états de contrôle discrets au sein d'un paradigme neuronal autorégressif standard pour fournir une base arbitraire aux décisions du modèle interne, sans sacrifier le pouvoir de représentation des modèles neuronaux.
Estimation de la distribution des données d'entraînement à partir du classificateur entraîné en utilisant le GAN.
Nous établissons que les lois d'échelle dérivées dans (Bora et al., 2017) sont optimales ou quasi-optimales en l'absence d'autres hypothèses.
méta-apprentissage d'un algorithme d'apprentissage capable de raisonnement causal
L'algorithme basé sur le corpus est développé pour générer un lexique de sentiments en amharique en s'appuyant sur le corpus.
Nous augmentons les estimations de la valeur Q avec un bonus basé sur le nombre qui garantit l'optimisme pendant la sélection des actions et le bootstrap, même si les estimations de la valeur Q sont pessimistes.
Nous proposons soft actor-critic, un algorithme RL profond de critique d'acteur hors politique basé sur le cadre d'apprentissage par renforcement à entropie maximale.
La mise en correspondance des distributions par la minimisation de la divergence fournit un terrain commun pour comparer les méthodes adverses d'apprentissage par renforcement inverse à entropie maximale au clonage du comportement.
Nous proposons un cadre générique qui permet d'exploiter la structure à faible rang dans la planification et l'apprentissage par renforcement profond.
Une référence pour évaluer l'intégration neuronale des identifiants dans le code source.
Le réarrangement des termes de l'écart moyen maximal donne une bien meilleure fonction de perte pour le discriminateur des réseaux adversariens génératifs.
Cet article présente des algorithmes qui utilisent directement des représentations compressées sans perte de réseaux feedforward profonds, pour effectuer une inférence sans décompression complète.
Nous intégrons les GAN dans le cadre de l'inégalité variationnelle et importons des techniques de cette littérature pour mieux optimiser les GAN ; nous donnons des extensions algorithmiques et testons empiriquement leurs performances pour l'entraînement des GAN.
Aborder le problème de l'hétérogénéité des tâches dans le méta-apprentissage en introduisant un graphe de métaconnaissance.
 Un algorithme de boosting profond est développé pour apprendre un classificateur d'ensemble plus discriminant en combinant de manière transparente un ensemble de CNN profonds de base.
Une méthode automatique pour convertir la musique entre les instruments et les styles
Nous proposons plusieurs nouvelles attaques et une méthodologie pour mesurer la robustesse contre les attaques adverses imprévues.
Deep-Net : Réseau neuronal profond pour les cas d'utilisation de la cybersécurité
Nous apprenons un espace de primitives motrices à partir de démonstrations de robots non annotées, et montrons que ces primitives sont sémantiquement significatives et peuvent être composées pour de nouvelles tâches robotiques.
Nous démontrons la faisabilité d'une approche de classification des séries temporelles faiblement supervisée pour les données des capteurs portables. 
Nous proposons un cadre d'alignement local-global pour apprendre des correspondances sémantiques à partir de paires données-texte bruyantes avec une faible supervision.
Apprendre à atteindre des objectifs à partir de zéro en utilisant l'apprentissage par imitation avec réétiquetage des données
Dans cet article, nous avons proposé une méthode d'ensemble appelée InterBoost pour la formation de réseaux neuronaux pour la classification de petits échantillons. Cette méthode présente de meilleures performances de généralisation que d'autres méthodes d'ensemble et réduit considérablement les variances.
Nous détectons les interactions statistiques capturées par un réseau neuronal multicouche feedforward en interprétant directement ses poids appris.
Nous évaluons le modèle linéaire neuronal sur les ensembles de données UCI et UCI "gap".
Nous avons reproduit AlphaZero sur Google Cloud Platform
Nous établissons la convergence globale vers l'optimalité pour les GANs basés sur IPM où le générateur est un réseau neuronal surparamétré. 
Nous développons des procédures efficaces d'intégration de réseaux attribués approximatifs multi-échelles avec des propriétés prouvables.
 Une étude empirique détaillée sur la classification de "few-shot" qui révèle les défis du cadre d'évaluation standard et montre une nouvelle direction.
Nous présentons un modèle d'inférence bayésienne pour inférer des explications contrastives (en tant que spécifications LTL) décrivant comment deux ensembles de traces de plans diffèrent.
La géométrie tropicale peut être exploitée pour représenter les limites de décision des réseaux neuronaux et mettre en lumière des informations intéressantes.
Une nouvelle méthode Gram-Gauss-Newton pour former les réseaux neuronaux, inspirée du noyau tangent neuronal et de la méthode Gauss-Newton, avec une vitesse de convergence rapide tant sur le plan théorique qu'expérimental.
Nous étudions la connaissance syntaxique implicite des encastrements de phrases en utilisant un nouvel ensemble d'analyse de phrases annotées grammaticalement avec des jugements d'acceptabilité.
Nous proposons une extension de l'apprentissage multi-sorties à un continuum de tâches en utilisant des noyaux à valeur d'opérateur.
Nous prouvons que, pour les fonctions d'activation satisfaisant certaines conditions, lorsqu'un réseau profond s'élargit, les longueurs des vecteurs des variables cachées convergent vers une carte de longueur.
Nous proposons une approche d'augmentation des données pour le méta-apprentissage et prouvons qu'elle est valide.
Un cadre général pour distiller les attentes bayésiennes postérieures pour les réseaux neuronaux profonds.
Dans cet article, nous introduisons une hiérarchie discrète de variables latentes catégorielles que nous entraînons en utilisant la relaxation Concrete/Gumbel-Softmax et nous dérivons une limite supérieure pour la différence absolue entre l'objectif non biaisé et l'objectif biaisé.
Nous proposons une nouvelle classe d'optimiseurs pour l'optimisation non convexe accélérée via une transformation non linéaire du gradient. 
Résoudre des tâches impliquant une locomotion humanoïde guidée par la vision, en réutilisant le comportement de locomotion à partir de données de capture de mouvement.
Nous proposons les réseaux Gated Linear Unit - un modèle dont les performances sont similaires à celles des réseaux ReLU sur des données réelles tout en étant beaucoup plus facile à analyser sur le plan théorique.
Nous proposons une méthode de recherche d'architecture pour identifier une distribution d'architectures et l'utiliser pour construire un ensemble bayésien pour la détection des aberrations.
Une nouvelle approche qui détecte les valeurs aberrantes dans les données d'image, tout en préservant la précision de la classification des images
Cet article présente CloudLSTM, une nouvelle branche de modèles neuronaux récurrents adaptés à la prévision sur des flux de données générés par des sources géospatiales ponctuelles.
Nous proposons TransINT, une nouvelle méthode d'encastrement KG interprétable qui préserve de manière isomorphe l'ordre d'implication entre les relations dans l'espace d'encastrement d'une manière explicable, robuste et géométriquement cohérente.
Nous présentons une nouvelle stratégie d'apprentissage à objectifs complémentaires basée sur le détachement du gradient pour la détection d'objets adaptative au domaine.
Nous proposons une nouvelle approche pour connecter les réseaux spécifiques aux tâches dans un contexte d'apprentissage multi-tâches, basée sur les récentes avancées en matière de réseaux résiduels.
How to use cross-entropy loss for zero shot learning with soft labeling on unseen classes : a simple and effective solution that achieves state-of-the-art performance on five ZSL benchmark datasets.
L'accroissement progressif de l'espace d'action disponible est un excellent programme d'apprentissage pour les agents.
Une solution de théorie des jeux pour les attaques et les défenses adverses.
Une nouvelle méthode pour créer des descripteurs denses du temps (Time Embeddings) afin de faire des modèles simples pour comprendre les structures temporelles.
Nous proposons une nouvelle architecture de réseau neuronal graphique basée sur la matrice de non-retour définie sur les adjacences des bords et nous démontrons son efficacité dans les tâches de détection de communautés sur les graphes.
Les connexions résiduelles réalisent réellement une inférence itérative
Nous améliorons le temps et la qualité de la reconstruction sur un imageur sans objectif expérimental basé sur un masque en utilisant une approche d'apprentissage de bout en bout qui incorpore la connaissance du modèle d'imagerie.
Nous présentons un nouveau modèle d'apprentissage par représentation, à savoir le "Sample-Ensemble Genetic Evolutionary Network" (SEGEN), qui peut servir d'approche alternative aux modèles d'apprentissage profond.
Nous proposons d'utiliser le méta-apprentissage pour un apprentissage plus efficace des langues, via une sorte de "randomisation du domaine". 
MARTHE : une nouvelle méthode pour ajuster les programmes de taux d'apprentissage spécifiques aux tâches du point de vue de l'optimisation des hyperparamètres
Génération interactive d'images à partir de graphes de scènes à croissance incrémentielle en plusieurs étapes à l'aide de GAN, tout en préservant le contenu de l'image générée lors des étapes précédentes.
Nous étudions des scénarios de classification à faible et très faible rapport signal/bruit, où les objets en corrélation avec l'étiquette de classe occupent une proportion minuscule de l'image entière (par exemple, l'imagerie médicale ou hyperspectrale).
Une couche d'auto-attention peut effectuer une convolution et apprend souvent à le faire en pratique.
Les algorithmes basés sur l'apprentissage peuvent améliorer les performances des algorithmes classiques pour le problème d'approximation de rangs bas tout en conservant la garantie du pire cas.
Architecture proposée pour résoudre la tâche d'accord morphologique
Cet article propose l'utilisation de méthodes d'éléments spectraux pour l'apprentissage rapide et précis d'équations différentielles ordinaires neuronales pour l'identification de systèmes.
Un nouveau signal de récompense intrinsèque basé sur les caractéristiques du successeur et une nouvelle façon de combiner la récompense extrinsèque et intrinsèque.
Nous proposons d'utiliser une politique d'exploration distincte pour collecter les trajectoires de pré-adaptation dans MAML. Nous montrons également que l'utilisation d'un objectif auto-supervisé dans la boucle interne conduit à une formation plus stable et à de bien meilleures performances.
Généralisation de la propagation à rebours, à l'aide de méthodes formelles issues de la supersymétrie.
La régularisation de la trajectoire d'optimisation avec les informations de Fisher des anciennes tâches réduit considérablement l'oubli catastrophique.
Nous donnons une méthode pour générer des programmes sûrs au niveau du type dans un langage de type Java, étant donné une petite quantité d'informations syntaxiques sur le code désiré.
Nous montrons comment les flux autorégressifs peuvent être utilisés pour améliorer les modèles séquentiels à variables latentes.
Des exemples contradictoires peuvent tromper le système de détection des droits d'auteur de YouTube
Nous proposons une version continue de la propagation de l'équilibre, où la dynamique des neurones et des synapses se produit simultanément tout au long de la deuxième phase, avec des garanties théoriques et des simulations numériques.
Nous proposons un nouveau réseau méta-modulaire pour résoudre certaines des restrictions du réseau neuronal modulaire précédent afin d'obtenir de bonnes performances sur un ensemble de données de raisonnement visuel réaliste.
Nous proposons une nouvelle attaque pour prendre le contrôle total des politiques neuronales dans un contexte réaliste.
Il peut générer des codes de hachage efficaces pour une recommandation efficace de démarrage à froid et, en même temps, fournir une stratégie de marketing réalisable.
Nous proposons un cadre neuronal qui peut apprendre à résoudre le problème de la satisfaction des circuits à partir d'instances de circuits (non étiquetées).
Une perspective unifiée de divers algorithmes d'apprentissage pour la génération de séquences, tels que MLE, RL, RAML, data noising, etc.
Nous présentons un schéma de "construction collaborative de ressources" pour créer des KB, des Wikipedia structurés. 
Un modèle de pointe basé sur le raisonnement global pour la super-résolution d'images
Proposer un cadre d'évaluation pour l'analyse et l'apprentissage du filtre convolutif de graphes.
Une nouvelle couche de mise en commun pour les GNN qui apprend comment mettre en commun les nœuds, en fonction de leurs caractéristiques, de la connectivité du graphe et de l'objectif de la tâche en aval.
 Nous proposons TuckER, un modèle linéaire relativement simple mais puissant pour la prédiction de liens dans les graphes de connaissances, basé sur la décomposition Tucker de la représentation tensorielle binaire des triples de graphes de connaissances. 
Un algorithme permettant de réduire la quantité de mémoire nécessaire à l'entraînement des réseaux profonds, basé sur une stratégie d'approximation.
Les algorithmes de flux de données peuvent être améliorés grâce à l'apprentissage profond, tout en conservant des garanties de performance.
Nous proposons Neural Hyperlink Predictor (NHP). NHP adapte les réseaux convolutifs de graphes pour la prédiction de liens dans les hypergraphes.
Une méthode qui apprend des représentations séparées pour le sens et la forme d'une phrase.
Nous avons exploré les conceptions de visualisation qui peuvent aider les patients chroniques à présenter et à examiner leurs données de santé avec les prestataires de soins lors des visites cliniques.
Nous proposons un prédicteur de dynamique avant stochastique et différentiable qui est capable d'échantillonner plusieurs trajectoires physiquement plausibles sous le même état d'entrée initial et nous montrons qu'il peut être utilisé pour former des politiques sans modèle plus efficacement.
Analyse au-delà du pire cas du pouvoir de représentation des réseaux ReLU et des noyaux polynomiaux, en particulier en présence d'une structure latente éparse.
Un modèle pour contrôler la génération d'images avec GAN et beta-VAE en ce qui concerne l'échelle et la position des objets
Nous proposons une famille différentiable de "matrices kaléidoscope", nous prouvons que toutes les matrices structurées peuvent être représentées sous cette forme et nous les utilisons pour remplacer les cartes linéaires fabriquées à la main dans les modèles d'apprentissage profond.
Apprentissage de la représentation des étiquettes pour les réseaux profonds
Nous proposons Choco-SGD - un SGD décentralisé avec une communication compressée - pour des objectifs non convexes et nous montrons sa forte performance dans diverses applications d'apprentissage profond (apprentissage sur appareil, cas du centre de données).
Nous montrons que l'Entropy-SGD optimise l'antériorité d'une limite PAC-Bayes, violant l'exigence selon laquelle l'antériorité doit être indépendante des données ; nous utilisons la confidentialité différentielle pour résoudre ce problème et améliorer la généralisation.
Nous montrons expérimentalement que l'apprentissage par transfert rend les caractéristiques éparses dans le réseau et produit ainsi un réseau plus compressible. 
Nous étendons les méthodes classiques de propation d'étiquettes pour modéliser conjointement les informations sur les graphes et les caractéristiques dans une perspective de filtrage de graphes, et nous montrons les liens avec les réseaux convolutionnels de graphes.
Nous proposons un logiciel qui simplifie, automatise et améliore radicalement l'évaluation des optimiseurs d'apprentissage profond.
extraire des incorporations contextuelles à partir d'un modèle supervisé prêt à l'emploi. Aide les modèles NLP en aval dans les environnements à faibles ressources.
Algorithmes adaptatifs pratiques pour le méta-apprentissage basé sur le gradient avec des garanties prouvables.
Nous cherchons à exploiter la diversité des structures linguistiques pour construire des représentations de phrases.
L'analyse non supervisée des données enregistrées à partir du système nerveux périphérique débruitage et catégorisation des signaux.
Nous améliorons les défenses existantes basées sur la transformation en utilisant un classificateur de distribution sur la distribution des softmax obtenus à partir d'images transformées.
Nous proposons une approche pour apprendre des politiques décentralisées dans des environnements multi-agents en utilisant des critiques basées sur l'attention et nous démontrons des résultats prometteurs dans des environnements avec des interactions complexes.
Nous appliquons le RNN pour résoudre le problème biologique de la prédiction des modèles de repliement de la chromatine à partir de marques épigénétiques et démontrons pour la première fois que l'utilisation de la mémoire des états séquentiels de la molécule d'ADN est importante pour obtenir les meilleures performances.
Nous proposons une méthode efficace, prouvable et indépendante des données pour la compression de réseaux via l'élagage neuronal en utilisant des coresets de neurones -- une nouvelle construction proposée dans cet article.
Réseau à mémoire augmentée pour planifier dans des environnements partiellement observables. 
Une procédure pour distiller des modèles contextuels en encastrements statiques ; nous appliquons notre méthode à 9 modèles populaires et démontrons des gains clairs en qualité de représentation par rapport à Word2Vec/GloVe et un potentiel d'analyse amélioré par une étude approfondie du biais social.
Le méta-apprentissage de règles de mise à jour non supervisées pour les réseaux neuronaux améliore les performances et démontre potentiellement comment les neurones du cerveau apprennent sans avoir accès aux étiquettes globales.
Nous montrons que la suppression des termes constants des architectures CNN permet d'interpréter la méthode de débruitage via des techniques d'algèbre linéaire et améliore également les performances de généralisation à travers les niveaux de bruit.
Nous fournissons pour la première fois une preuve rigoureuse que l'initialisation orthogonale accélère la convergence par rapport à l'initialisation gaussienne, pour les réseaux linéaires profonds.
Une première estimation différentielle privée de la fonction de survie
CAML est une instance de MAML avec des dépendances de classes conditionnelles.
Nous étudions le problème de la prédiction multi-ensembles et proposons une nouvelle fonction de perte multi-ensembles, en fournissant une analyse et des preuves empiriques qui démontrent son efficacité.
Cet article présente un cadre théorique qui modélise explicitement la distribution des données pour un réseau ReLU profond et localement connecté.
Nous présentons un algorithme évolutionnaire modulaire d'inspiration biologique dans lequel des agents RL profonds apprennent à coopérer dans un jeu social multi-agents difficile, ce qui pourrait contribuer à expliquer l'évolution de l'altruisme.
Nous présentons un type de réseau neuronal qui est structurellement résistant aux attaques adverses, même lorsqu'il est formé sur des ensembles de formation non augmentés.  Cette résistance est due à la stabilité des unités du réseau par rapport aux perturbations d'entrée.
Nous montrons que la robustesse des adversaires peut se faire au détriment des performances de classification standard, mais qu'elle présente aussi des avantages inattendus.
L'entraînement sur des combinaisons convexes entre des exemples d'entraînement aléatoires et leurs étiquettes améliore la généralisation dans les réseaux neuronaux profonds
Nous présentons une nouvelle approche du tri des pointes en utilisant le processus de regroupement neuronal (NCP), une architecture neuronale récemment introduite qui effectue une inférence bayésienne approximative amortie évolutive pour un regroupement probabiliste efficace.
Méthode proposée pour trouver la solution la plus généralisable qui est stable par rapport aux perturbations des données d'entraînement.
Implémentation et évaluation de la mémoire épisodique pour RL.
Nous présentons une méthode d'adaptation des hyperparamètres des modèles probabilistes utilisant le transport optimal, avec des applications en robotique.
Un algorithme d'apprentissage d'une représentation d'état prédictive avec des fonctions de valeur générales et un apprentissage hors politique est appliqué au problème de la direction basée sur la vision dans la conduite autonome.
Nous abordons l'apprentissage de bout en bout de représentations basées sur l'énergie pour des ensembles de données d'observation de signaux et d'images avec des modèles d'échantillonnage irréguliers.
Un nouvel algorithme d'apprentissage par méta-reinforcement fondé sur la théorie
L'ajustement latéral adapte un réseau pré-entraîné en formant un réseau "latéral" léger qui est fusionné avec le réseau pré-entraîné (inchangé) à l'aide d'un simple processus additif.
Entraînement des GAN avec confidentialité différentielle pour générer des ensembles de données artificielles préservant la confidentialité.
Cet article présente des méthodes pour démêler et interpréter les effets contextuels qui sont encodés dans un réseau neuronal profond.
Proposition d'une nouvelle méthode basée sur l'attention guidée pour renforcer la sportivité dans les réseaux neuronaux profonds.
Nous récupérons de manière prouvée la couche la plus basse d'un réseau neuronal profond en supposant que la couche la plus basse utilise une activation à "seuil élevé" et que le réseau ci-dessus est un polynôme "bien conformé".
Nous présentons FedProx, un cadre permettant de traiter l'hétérogénéité statistique dans des environnements fédérés avec des garanties de convergence et une robustesse et une stabilité améliorées.
Nous permettons à la fois l'évolution culturelle du langage et l'évolution génétique des agents dans un jeu référentiel, en utilisant un nouveau moteur de transmission du langage.
Nous avons introduit une nouvelle méthode d'augmentation des données, simple et efficace, qui permet d'améliorer les performances des GAN existants lorsque les données d'entraînement sont limitées et diverses.  
Nous développons un simulateur de corps et de connectome entier pour C. elegans et démontrons l'inférence conjointe d'espace d'état et de paramètres dans le simulateur.
Inspiré par CapsNet, nous proposons une nouvelle architecture pour l'intégration de graphes sur la base des caractéristiques des nœuds extraites du GNN.
Gen-RKM : un nouveau cadre pour les modèles génératifs utilisant des machines à noyau restreint avec génération multi-vues et apprentissage de caractéristiques non corrélées.
Nous comparons plusieurs tâches et combinaisons de tâches pour le pré-entraînement de BiLSTM au niveau de la phrase pour des tâches NLP. La modélisation du langage est la meilleure tâche de pré-entraînement, mais les tâches de base simples donnent également de bons résultats.
Un aperçu de la raison de la vulnérabilité adversariale, une méthode de défense efficace contre les attaques adversariales.
Appliquer la recherche arborescente de Monte Carlo à la génération d'épisodes dans Alpha Zero
Pour les réseaux neuronaux à graphes, l'agrégation sur un graphe peut bénéficier d'un espace continu sous-jacent au graphe.
Nous utilisons un algorithme de recherche simple impliquant un RNN et une file d'attente prioritaire pour trouver des solutions aux tâches de codage.
Nous présentons le réseau neuronal à ondelettes de graphe (GWNN), un nouveau réseau neuronal convolutif de graphe (CNN), qui exploite la transformée en ondelettes de graphe pour remédier aux lacunes des méthodes précédentes de CNN de graphe spectral qui dépendent de la transformée de Fourier de graphe.
Nous fournissons une autre explication nouvelle de la décroissance du taux d'apprentissage : un taux d'apprentissage initialement élevé empêche le réseau de mémoriser des données bruyantes, tandis que la décroissance du taux d'apprentissage améliore l'apprentissage de modèles complexes.
L'adaptation de l'exploration UCB à l'apprentissage Q d'ensemble est meilleure que les méthodes antérieures telles que Double DQN, A3C+ sur le benchmark Atari.
Les primitifs moteurs probabilistes neuronaux compriment les politiques de suivi de la capture de mouvement en un modèle flexible capable d'imitation et de réutilisation en tant que contrôleur de bas niveau.
Nous présentons une augmentation des données adaptative et automatisée qui fonctionne pour plusieurs tâches différentes. 
Nous proposons une nouvelle technique de régularisation basée sur la distillation des connaissances.
Des stratégies de régularisation et d'optimisation efficaces pour les modèles de langage basés sur les LSTM permettent d'atteindre le SOTA sur la PTB et le WT2. 
Recherche de détecteurs d'objets à l'aide de nombreuses mesures de sélectivité différentes ; les CNN sont légèrement sélectifs, mais pas suffisamment pour être qualifiés de détecteurs d'objets.
Une méthode pour transformer les séquences d'ADN en images 2D en utilisant les courbes de Hilbert de remplissage d'espace pour améliorer les forces des CNNs.
Un objectif de regroupement apprenant pour faciliter l'apprentissage par transfert entre domaines et tâches
Méthode conjointe d'apprentissage d'enchâssements translinguistiques avec des performances de pointe pour les tâches translinguistiques et la qualité monolingue.
Modèle génératif de données temporelles, qui construit un état de croyance en ligne, opère dans un espace latent, fait des prédictions et des déploiements d'états par à-coups.
Présente un objectif de formation théorique de l'information pour la co-formation et démontre sa puissance dans l'apprentissage non supervisé de la phonétique.
Nos modèles génèrent des voix chantées sans paroles ni partitions. Ils prennent l'accompagnement en entrée et produisent des voix chantées.
Nous augmentons l'efficacité des analyseurs syntaxiques de dépendance à base de réseaux neuronaux grâce à la distillation professeur-élève.
Les auto-codeurs régularisés de manière adversariale apprennent des représentations lisses de structures discrètes, ce qui permet d'obtenir des résultats intéressants dans la génération de textes, tels que le transfert de style non aligné, l'apprentissage semi-supervisé, ainsi que l'interpolation et l'arithmétique de l'espace latent.
Nous présentons une méthode pour estimer des collections de modèles de régression dans lesquelles chaque modèle est personnalisé à un seul échantillon.
Une cellule de réseau neuronal récurrent avec une mémoire à court terme étendue et un modèle RNN multitâche pour les problèmes de type "séquence dans la séquence".
Nous nous entraînons dans des sous-espaces aléatoires de l'espace des paramètres pour mesurer combien de dimensions sont réellement nécessaires pour trouver une solution.
Un modèle de réseau de neurones à double graphe primitif pour l'apprentissage semi-supervisé
Nous décrivons deux analyseurs syntaxiques de bout en bout à codage automatique pour l'analyse syntaxique semi-supervisée des dépendances à base de graphe.
Un réseau Fast Weight amélioré qui donne de meilleurs résultats sur une tâche générale de jouet.
Introduction d'une nouvelle méthode d'optimisation et son application à l'apprentissage profond.
Introduction d'une nouvelle classe de réseaux neuronaux quantiques pour l'apprentissage de représentations à base de graphes sur des ordinateurs quantiques.
"Dans cet article, nous avons testé l'influence des stratégies de communication sur les modèles mentaux des utilisateurs concernant une violation de données."
Une approche de reconnaissance de but basée sur une heuristique de comptage d'opérateurs utilisée pour tenir compte du bruit dans l'ensemble de données.
la distillation de modèles monotâches en un modèle multitâches améliore les performances de la compréhension du langage naturel
Évaluation des méthodes de détection de la non-répartition au niveau du pixel sur deux nouveaux ensembles de données du monde réel en utilisant PSPNet et DeeplabV3+.
Nous présentons une nouvelle méthode contradictoire d'adaptation des représentations neuronales basée sur une critique qui détecte les caractéristiques non discriminantes.
Nous proposons un cadre statistique et une procédure théoriquement cohérente pour l'estimation de la saillance.
Nous avons exploré comment une nouvelle méthode d'intégration d'ensembles compositionnels peut à la fois percevoir et représenter non pas une seule classe mais un ensemble entier de classes associées aux données d'entrée.
Nous présentons un ensemble de données, des modèles et des protocoles de formation et d'évaluation pour une tâche de dessin collaborative qui permet d'étudier la génération et la compréhension du langage basée sur les objectifs et sur la perception et l'action. 
Nous proposons une méthode basée sur la stratégie d'apprentissage contradictoire pour apprendre des caractéristiques discriminantes non biaisées et invariantes par rapport au(x) facteur(s) de confusion en incorporant une fonction de perte qui encourage une corrélation disparue entre le biais et les caractéristiques apprises.
Une approche modulaire composée d'un module de sélection de phrases suivi d'un modèle d'AQ peut être rendue plus robuste aux attaques adverses par rapport à un modèle d'AQ entraîné sur le contexte complet.
Incorporation de graphes multi-relationnels avec des manifestes riemanniens et une fonction de perte de type TransE. 
Nous proposons un méta-algorithme d'apprentissage pour l'apprentissage continu qui peut prévenir efficacement le problème de l'oubli catastrophique et soutenir l'apprentissage par transfert en arrière.
Analyse des réseaux convolutifs profonds en termes d'agencement associé d'hyperplans
Nous avons proposé une méthode de méta-échantillonnage bayésien pour adapter l'incertitude du modèle dans le méta-apprentissage.
Modèle d'entropie adaptatif au contexte à utiliser dans la compression d'images optimisée de bout en bout, qui améliore sensiblement les performances de compression
Une méthode d'apprentissage de meilleures représentations, qui agit comme un régularisateur et qui, malgré son coût de calcul supplémentaire non significatif, permet d'obtenir des améliorations par rapport à des bases solides dans des tâches d'apprentissage supervisé et semi-supervisé.
Emballage des régions d'intérêt (ROI) telles que les régions cancéreuses identifiées dans les données volumiques 3D, emballage de sphères à l'intérieur de la ROI, rotation de la ROI, mesures de la différence d'emballage des sphères avant et après la rotation.
La sparsité au niveau du filtre apparaît implicitement dans les CNN entraînés avec des approches de descente de gradient adaptatives en raison de divers phénomènes, et l'étendue de la sparsité peut être affectée par inadvertance par différents hyperparamètres apparemment sans rapport.
En établissant un parallèle avec l'apprentissage humain, nous proposons un cadre unifié pour présenter de nombreuses capacités d'apprentissage tout au long de la vie dans les réseaux neuronaux en utilisant un petit nombre de paramètres de consolidation des poids.
Nous montrons que les prieurs GAN robustes fonctionnent mieux que les prieurs GAN pour la reconstruction CT à angle limité qui est un problème inverse hautement sous-déterminé.
Une nouvelle forme d'attention qui fonctionne bien dans le cadre de la supervision à distance, et une approche d'apprentissage multitâche pour ajouter des annotations au niveau des phrases. 
Analyse du mécanisme d'attention dans diverses tâches de PNL.
La représentation des programmes sous forme de graphes, y compris la sémantique, facilite la génération de programmes.
Une nouvelle méthode pour déduire un modèle, estimer le taux d'entropie et prédire les processus à temps continu et à événements discrets.
Un modèle unifié pour améliorer la robustesse du modèle face à des tâches multiples
Nous avons proposé une méthode d'apprentissage progressif pour améliorer l'apprentissage et le démêlage des représentations latentes à différents niveaux d'abstraction.
Nous appliquons la transformation de la copule au goulot d'étranglement de l'information profonde, ce qui permet de restaurer les propriétés d'invariance et d'obtenir un espace latent démêlé avec des capacités prédictives supérieures.
Repère et méthode pour mesurer la généralisation de la composition en maximisant la divergence de la fréquence des composés à une faible divergence de la fréquence des atomes.
Les réseaux non supervisés apprennent du bas vers le haut ; les machines et les nourrissons acquièrent les classes visuelles dans des ordres différents.
Pour les problèmes de classification à k classes, nous montrons que le gradient tend à vivre dans un minuscule sous-espace qui évolue lentement et qui est couvert par les vecteurs propres correspondant aux k plus grandes valeurs propres du hessien.
Un récupérateur récurrent basé sur le graphique qui apprend à récupérer les chemins de raisonnement sur le graphique de Wikipédia surpasse l'état de l'art le plus récent sur HotpotQA de plus de 14 points.
Nous avons introduit un réseau d'extraction de la plume peu profonde avec un grand champ réceptif pour les tâches de correspondance stéréo, qui utilise une structure simple pour obtenir de meilleures performances.
L'article propose une nouvelle couche de sortie pour les réseaux profonds qui permet l'utilisation d'un retour de bandit contextuel enregistré pour la formation. 
Classification des familles de protéines à l'aide de l'apprentissage profond
Cet article vise à fournir une réponse empirique à la question de savoir si un modèle de réponse au dialogue bien entraîné peut produire des réponses malveillantes.
diagnostiqué tout le problème des VAE de STOA de manière théorique et qualitative
Nous proposons un nouveau mécanisme d'attention éparse et structuré, TVmax, qui favorise l'éparpillement et encourage le poids des emplacements adjacents apparentés à être le même.
Les incorporations de phonèmes apprises par un réseau neuronal de synthèse vocale multilingue pourraient représenter les relations de prononciation des phonèmes entre les langues.
Les représentations GAN sont examinées en détail, et des ensembles d'unités de représentation sont trouvés qui contrôlent la génération de concepts sémantiques dans la sortie.
Les réseaux mobiles épars sont plus rapides que les réseaux denses avec les noyaux appropriés.
 Nous proposons un nouveau cadre d'apprentissage par inférence de graphes en construisant des relations structurelles pour déduire des étiquettes de nœuds inconnues à partir des nœuds étiquetés de bout en bout.
La sécurité devenant une notion essentielle de l'apprentissage automatique, nous pensons que ce travail peut servir de base à un certain nombre d'orientations de recherche telles que les algorithmes d'apprentissage tenant compte de la sécurité.
Nous présentons deux approches pour une inférence efficace et évolutive dans les simulateurs stochastiques pour lesquels la densité ne peut être évaluée directement en raison, par exemple, de boucles d'échantillonnage de rejet.
Même s'il n'y a pas de compromis dans la limite des données infinies, la formation adversariale peut avoir une précision standard plus mauvaise même dans un problème convexe.
Nous montrons que les connexions de raccourci doivent être placées selon des modèles qui minimisent les distances entre les couches pendant la rétropropagation, et nous concevons des réseaux qui atteignent des distances log L en utilisant L log(L) connexions.
Réseau Q profond basé sur le graphique pour la navigation sur le Web 
Nous construisons un cadre théorique pour le démêlage faiblement supervisé et menons de nombreuses expériences pour étayer la théorie.
Nous proposons pour la première fois une approche basée sur l'expansion pour l'apprentissage continu sans tâche. Notre modèle consiste en un ensemble d'experts en réseaux neuronaux et procède à l'expansion du nombre d'experts selon le principe non paramétrique bayésien.
Amortir l'élan de Nesterov pour un apprentissage profond plus robuste, léger et rapide.
Nous proposons un nouveau modèle qui permet de démêler les multiples facteurs dynamiques dans les données séquentielles.
Nous vérifions les propriétés déterministes et probabilistes des réseaux neuronaux en utilisant des relaxations non convexes sur les transformations visibles spécifiées par les modèles génératifs.
Un schéma efficace de résumé vidéo multi-vues avancé pour la reconnaissance d'activité dans les environnements IoT.
La rectification dans les réseaux neuronaux profonds les conduit naturellement à privilégier une représentation invariante.
L'architecture Wave-U-Net, récemment introduite par Stoller et al pour la séparation des sources musicales, est très efficace pour l'amélioration de la parole, dépassant l'état de l'art.
Nous introduisons un nouveau cadre pour l'apprentissage à partir de la démonstration qui utilise un retour humain continu ; nous évaluons ce cadre sur le contrôle continu pour les véhicules autonomes.
et améliorer la VQ-VAE avec des prieurs puissants pour générer des images proches de la réalité.
Approche de la recherche arborescente de Monte Carlo assistée par un réseau de neurones graphiques pour le problème du voyageur de commerce
Le passage de messages directionnels intègre des informations directionnelles spatiales pour améliorer les réseaux neuronaux graphiques.
Nous concevons une méthode simple et efficace sans modèle pour l'apprentissage par renforcement basé sur l'image, qui correspond aux méthodes de pointe basées sur un modèle en termes d'efficacité d'échantillonnage.
Nous présentons un nouvel opérateur simple, le chopout, avec lequel les réseaux neuronaux sont formés, même en un seul processus de formation, de manière à ce que les sous-réseaux tronqués soient aussi performants que possible.
La distribution guassienne multimodale de l'espace latent dans les modèles GAN améliore les performances et permet d'arbitrer entre qualité et diversité.
SlowMo améliore les performances d'optimisation et de généralisation des algorithmes décentralisés efficaces en termes de communication sans sacrifier la vitesse.
Planifier la structure syntaxique de la traduction en utilisant des codes
 Nous identifions la mémorisation comme le biais inductif de l'interpolation dans les auto-encodeurs surparamétrés entièrement connectés et convolutifs. 
Nous récupérons de manière prouvée la portée d'un réseau neuronal multicouche profond avec une structure latente et appliquons empiriquement des algorithmes efficaces de récupération de la portée pour attaquer les réseaux en masquant les entrées.
Nous étudions le biais implicite de la descente de gradient et prouvons sous un ensemble minimal d'hypothèses que la direction des paramètres des modèles homogènes converge vers les points KKT d'un problème naturel de maximisation de la marge.
nous proposons un LSTM convolutif tensor-train, qui apprend efficacement un LSTM convolutif d'ordre supérieur en utilisant la décomposition convolutive tensor-train. 
La méthode proposée est un SVM neuronal de bout en bout, qui est optimisé pour l'apprentissage en quelques coups.
Une nouvelle structure CNN 4D pour l'apprentissage de la représentation au niveau de la vidéo, surpassant les CNN 3D récents.
Nous étudions le problème de l'apprentissage et de l'optimisation par des simulations physiques via la programmation différentiable, en utilisant le langage de programmation et le compilateur DiffSim que nous proposons.
Nous présentons une méthode d'interprétation des modèles de boîte noire en utilisant la sélection rétrograde par instance pour identifier les sous-ensembles minimaux de caractéristiques qui, à eux seuls, suffisent à justifier une décision particulière prise par le modèle.
Nous proposons une méthode qui extrait les incertitudes des caractéristiques dans chaque couche de DNNs et les combine pour détecter les échantillons OOD lors de la résolution de tâches de classification.
Nous utilisons les autoencodeurs déterministes comme modèles génératifs en proposant des fonctions de mélange qui combinent les états cachés de paires d'images. Ces mélanges sont rendus réalistes grâce à un cadre contradictoire.
Nous introduisons un espace de caractéristiques robustes augmentées pour les données wifi en continu qui est capable de s'attaquer à la dérive des concepts pour la localisation intérieure.
nous présentons une approche de principe au problème de l'adaptation de domaine fédéré, qui vise à aligner les représentations apprises parmi les différents nœuds avec la distribution de données du nœud cible.
Les réseaux de capsules avec matrices de pose apprises et routage EM améliorent l'état de l'art de la classification sur smallNORB, améliorent la généralisation à de nouveaux points de vue et la robustesse des adversaires de la boîte blanche.  
Nous proposons un cadre de méta-apprentissage qui apprend une politique transférable à partir d'une faible supervision pour résoudre des tâches de synthèse avec différentes spécifications logiques et grammaires.
Rendre le transformateur fluide avec une attention monotone.
Apprentissage de la cartographie optimale avec deepNN entre les distributions avec des garanties théoriques.
Une nouvelle approche pour construire un encastrement non supervisé de documents (phrases) à partir d'encastrements de mots pré-entraînés.
Nous présentons une approche statistique de l'évaluation de la robustesse des réseaux neuronaux qui fournit une notion informative de la robustesse d'un réseau, plutôt que la simple affirmation binaire conventionnelle de la violation ou non d'une propriété.
Améliorer la robustesse des modèles de transformation pré-entraînés contre le biais de chevauchement lexical en étendant les phrases d'entrée des données d'entraînement avec leurs structures prédicat-argument correspondantes. 
La régression par réseau neuronal doit utiliser la distribution de sortie de Dirichlet lorsque les cibles sont des probabilités, afin de quantifier l'incertitude des prédictions.
Apprendre à rechercher un DenseNet efficace avec un élagage par couche
Nous formons des modèles prédictifs sur les informations proprioceptives et montrons qu'ils représentent les propriétés des objets externes.
Une méthode basée sur le GAN pour apprendre les caractéristiques topologiques importantes d'un graphe d'entrée arbitraire.
Prévision du prix de vente aux enchères des plaques d'immatriculation des véhicules à Hong Kong à l'aide d'un réseau neuronal récurrent profond, sur la base des caractères figurant sur les plaques.
Nous présentons un nouveau modèle latent profond d'images naturelles qui peut être entraîné à partir d'ensembles de données non étiquetées et peut être utilisé pour résoudre diverses tâches de restauration d'images.
Notez automatiquement les dissertations sur des données éparses en comparant les nouvelles dissertations avec des échantillons connus grâce au réseau d'arbitres. 
Nous combinons le cadre du réseau d'appariement pour l'apprentissage en quelques coups dans un modèle multi-label à grande échelle pour la classification des séquences génomiques.
L'application de la fonction softmax dans la formation conduit à une supervision indirecte et inattendue des caractéristiques. Nous proposons un nouvel objectif de formation pour induire explicitement des régions de caractéristiques denses pour des échantillons localement suffisants afin de bénéficier de la robustesse des adversaires.
Les représentations GAN sont examinées en détail, et des ensembles d'unités de représentation sont trouvés qui contrôlent la génération de concepts sémantiques dans la sortie.
Les plus proches voisins par pixel sont utilisés pour générer des images multiples à partir d'antécédents incomplets tels que des images à faible résolution, des normales de surface, des bords, etc.
Nous proposons une procédure d'entraînement rapide et fondée sur des principes avec des garanties de performance informatique et statistique.
Nous décomposons l'écart entre la log-vraisemblance marginale et la borne inférieure de l'évidence et étudions l'effet de la postériorité approximative sur la vraie distribution postérieure dans les VAE.
Utilisation d'ensembles et de pseudo-étiquettes pour la mise en grappes non supervisée 
Apprentissage efficace de dictionnaires par minimisation de L1 via une nouvelle analyse de la géométrie non convexe non lisse.
Nous fournissons la première analyse théorique de la récupération garantie des réseaux neuronaux à une couche cachée sous perte d'entropie croisée pour les problèmes de classification.
Notre codec pour réseaux neuronaux (qui est basé sur le codage par transformation et le regroupement) permet une compression transparente peu complexe et très efficace des réseaux neuronaux.
Nous accélérons l'inférence DNN sécurisée dans les environnements d'exécution de confiance (par un facteur de 4x-20x) en externalisant sélectivement le calcul des couches linéaires à un coprocesseur plus rapide mais non fiable.
Cet article propose une méthode efficace de compression des réseaux neuronaux basée sur les résultats récents de la théorie de l'information.
Un cadre général pour la création de réseaux de neurones à graphes covariants
Dans cet article, nous proposons une méthode d'élagage basée sur la régularisation tridimensionnelle pour accélérer le 3D-CNN.
Une proposition pratique pour une technologie PNL plus éthique et plus réactive, en opérationnalisant la transparence des données de test et de formation.
Découvrir la structure des modèles causaux fonctionnels à l'aide de réseaux neuronaux génératifs
Dans le cadre de l'élagage des réseaux, l'ajustement fin d'un modèle élagué ne donne que des performances comparables ou inférieures à celles de l'apprentissage à partir de zéro. Cela plaide en faveur d'une refonte des algorithmes d'élagage existants.
Cet article introduit la théorie des valeurs extrêmes dans les k-means pour mesurer la similarité et propose un nouvel algorithme appelé Extreme Value k-means pour le regroupement.
Nous proposons Tendency RL pour résoudre efficacement les tâches orientées vers un but avec un grand espace d'état en utilisant l'apprentissage automatique du curriculum et la récompense discriminante de mise en forme, ce qui a le potentiel de s'attaquer aux tâches de manipulation de robots avec perception.
Nous présentons les programmes de scène, une représentation structurée de la scène qui capture à la fois l'apparence des objets de bas niveau et la régularité de haut niveau dans la scène.
Compression des réseaux neuronaux qui améliore les techniques de pointe d'approximation à faible rang et est complémentaire de la plupart des autres techniques de compression. 
Nous présentons une technique d'attribution qui tire parti des normes induisant la sparsité pour obtenir l'interprétabilité.
Nous utilisons la sparsité pour améliorer la complexité de calcul des méthodes de réduction de la variance.
Nous proposons un nouveau cadre basé sur le VAE qui apprend à partir de données partiellement observées pour l'imputation et la génération. 
Insights on the domain adaptation challenge, when predicting user intent in enterprise email.
Nous proposons HiPPO, un algorithme stable d'apprentissage par renforcement hiérarchique qui peut entraîner plusieurs niveaux de la hiérarchie simultanément, donnant de bonnes performances à la fois dans la découverte et l'adaptation des compétences.
Nous faisons un pas vers la mesure de la difficulté des tâches d'apprentissage et démontrons qu'en pratique, la performance dépend fortement de la correspondance entre la représentation de l'information et le modèle qui l'interprète.
Nous combinons des processus gaussiens à sorties multiples avec des réseaux Q récurrents profonds pour apprendre des traitements optimaux pour le sepsis et montrons une performance améliorée par rapport aux méthodes d'apprentissage par renforcement profondes standard,
Nous développons un nouveau modèle génératif profond pour l'apprentissage semi-supervisé et proposons une nouvelle entropie croisée Max-Min pour l'entraînement des CNN.
Nous proposons une technique de randomisation simple pour améliorer la généralisation de l'apprentissage par renforcement profond dans des tâches comportant divers motifs visuels non vus.
Décrit une étude portant sur l'interférence, le transfert et la rétention de mappings multiples avec le même ensemble de boutons d'accord.
Vérification formelle d'une spécification sur la sous-sensibilité de prédiction d'un modèle à l'aide de la propagation de limites d'intervalles.
Nous proposons un nouveau format de 8 bits qui élimine le besoin d'échelonnement des pertes, d'arrondis stochastiques et d'autres techniques de faible précision.
Nouvel algorithme pour l'apprentissage incrémental du VAE avec une architecture fixe.
MAML est excellent, mais il présente de nombreux problèmes. Nous résolvons un grand nombre de ces problèmes et, par conséquent, nous apprenons la plupart des hyperparamètres de bout en bout, accélérons l'apprentissage et l'inférence et établissons un nouveau SOTA en quelques clics.
Détection des communautés qui se chevauchent dans les graphes à l'aide de réseaux neuronaux de graphes
Nous réfutons empiriquement une hypothèse fondamentale de la stratégie de partage de poids largement adoptée dans la recherche d'architecture neuronale et expliquons pourquoi les algorithmes NAS de pointe fonctionnent de manière similaire à la recherche aléatoire.
Dans cet article, nous utilisons la distance de Wasserstein tranchée pour modeler la distribution latente d'un auto-encodeur en n'importe quelle distribution antérieure échantillonnable. 
Nous introduisons une classe de modèles génératifs qui apprennent de manière fiable la dynamique hamiltonienne à partir d'observations à haute dimension. L'hamiltonien appris peut être appliqué à la modélisation de séquences ou comme flux normalisateur.
Dans ce bref article, nous présentons brièvement les avantages de l'utilisation de la planification de l'IA dans la migration des nuages, un prototype préliminaire, ainsi que les chal- lenges qui requièrent l'attention de la société de planification et d'ordonnancement.
Une limite supérieure générale sur le risque du domaine cible qui reflète le rôle de la complexité de l'intégration.
Afin de prévoir des séries chronologiques stationnaires multivariées, nous apprenons des encastrements contenant des caractéristiques contextuelles dans un RNN ; nous appliquons le cadre aux données du transport public.
Nous étudions un cadre pour la découverte : la conservation d'une grande collection de prédictions, qui sont utilisées pour construire la représentation de l'agent dans des domaines partiellement observables.
Une stratégie d'inférence de géolocalisation globale avec une nouvelle stratégie de maillage et la démonstration de l'incorporation d'informations supplémentaires peut être utilisée pour améliorer les performances globales d'un modèle d'inférence de géolocalisation.
Technique d'apprentissage de modèles génératifs profonds avec des variables latentes partagées, appliquée à Omniglot avec un décodeur PixelCNN.
Dans cet article, nous présentons une architecture de lecture agnostique pour l'intégration dynamique de connaissances de fond explicites dans les modèles neuronaux NLU. 
Technique de précision dynamique pour l'entraînement des réseaux neuronaux profonds
Nous introduisons la fonction d'activation ISRLU qui est continuellement différentiable et plus rapide que l'ELU. L'ISRU connexe remplace tanh et sigmoïde.
Nous explorons le problème de la généralisation compositionnelle et proposons un moyen de doter les architectures de réseaux neuronaux de la capacité de se composer elles-mêmes pour résoudre ces problèmes.
Nous étendons la méthode du goulot d'étranglement de l'information au cadre multiview non supervisé et montrons des résultats de pointe sur des ensembles de données standard.
Nous décrivons un algorithme d'apprentissage biologiquement plausible pour les réseaux récurrents à point fixe sans poids liés.
Nous formons un modèle 3D génératif de formes à partir d'images naturelles de manière totalement non supervisée.
Nous montrons qu'un schéma d'attaque adversariale en boîte noire relativement simple utilisant l'optimisation bayésienne et le suréchantillonnage des dimensions est préférable aux méthodes existantes lorsque le nombre de requêtes disponibles est très faible.
Nous revisitons l'idée simple de l'élagage des connexions des DNN par le biais de la régularisation $\ell_1$ en obtenant des résultats de pointe sur plusieurs ensembles de données avec des garanties théoriques.
Une méthode non paramétrique pour mesurer les moments d'erreur des régresseurs sans vérité terrain peut être utilisée avec des régresseurs biaisés
Caractérisation des réseaux neuronaux cnvolutionnels pour la détection et la compréhension des classifications rétrogrades.
Nous pouvons apprendre des contraintes à haute dimension à partir de démonstrations en échantillonnant des trajectoires dangereuses et en tirant parti d'une paramétrisation connue des contraintes.
Apprentissage paramétrique des formes avec des réseaux de neurones dans un cadre géométrique 
Nous proposons une généralisation des compteurs de visites qui évaluent la propagation de la valeur exploratoire sur les trajectoires, permettant une exploration efficace pour les RL sans modèle.
Nous proposons une nouvelle combinaison de stratégie d'évolution et d'apprentissage par renforcement profond qui tire le meilleur des deux mondes.
Une comparaison empirique des réseaux profonds bayésiens pour l'échantillonnage de Thompson
Comprendre comment les étiquettes de classe aident à la formation des GAN. Proposer une nouvelle métrique d'évaluation pour les modèles génératifs. 
Algorithme itératif rapide pour équilibrer l'énergie d'un réseau tout en restant dans la même classe d'équivalence fonctionnelle
Nous trouvons des environnements dans lesquels les agents SOTA formés à des tâches de navigation présentent des échecs extrêmes suggérant des échecs de généralisation.
Estimation bayésienne robuste par écart moyen maximal
Nous créons un estimateur sans biais pour la probabilité logarithmique des modèles à variables latentes, ce qui permet d'étendre ces modèles à un plus grand nombre d'applications.
Les lots de petite taille peuvent être plus performants que les lots de très grande taille sur l'ensemble de test avec des budgets de pas constants et des programmes de taux d'apprentissage correctement réglés.
Meilleur algorithme d'apprentissage par renforcement profond pour l'approximation de la minimisation des regrets contrefactuels
Génère des données jamais vues pendant la formation à partir d'une condition souhaitée. 
Nous analysons la descente de gradient pour les réseaux neuronaux linéaires profonds, en fournissant une garantie de convergence vers l'optimum global à un taux linéaire.
Une couche modélisant les connectomes aléatoires locaux dans le cortex au sein de réseaux profonds capables d'apprendre des invariances générales non paramétriques à partir des données elles-mêmes.
Nous présentons un cadre efficace et général pour incorporer des informations de conditionnement dans les modèles génératifs basés sur l'inférence.
Cet article décrit trois techniques permettant à un planificateur non rétroactif et limité en termes de calcul de considérer un petit nombre d'activités alternatives en fonction de la disponibilité des ressources.
Nous utilisons des modifications simples et biologiquement motivées des techniques d'apprentissage standard pour atteindre des performances de pointe sur des repères d'oubli catastrophique.
Utilisation de techniques d'apprentissage profond pour les tâches liées à la voix des chanteurs.
Génération de langage à l'aide de modèles seq2seq qui produisent des encastrements de mots au lieu d'une distribution basée sur la méthode softmax sur le vocabulaire à chaque étape, ce qui permet un apprentissage beaucoup plus rapide tout en maintenant la qualité de la génération.
Résultats en forme fermée pour l'apprentissage profond dans la limite de découplage des couches, applicables aux réseaux résiduels.
 Dans cet article, une nouvelle méthode que nous appelons Attaque Initiale Centrée (CIA) est proposée. Elle assure par construction que la perturbation maximale est inférieure à un seuil fixé au préalable, sans le processus d'écrêtage.
Répondre à une large classe de requêtes logiques sur des graphes de connaissances avec des encastrements de boîtes dans un espace vectoriel
Nous abordons l'optimisation hyperparamétrique entièrement parallèle avec les processus ponctuels déterminants. 
Une approche spectrale multi-niveaux pour améliorer la qualité et l'évolutivité de l'intégration non supervisée de graphes.
Un nouveau modèle génératif pour les données structurées discrètes. L'attribut paresseux stochastique proposé convertit la vérification sémantique hors ligne en un guidage en ligne pour le décodage stochastique, ce qui permet de traiter efficacement les contraintes syntaxiques et sémantiques et d'obtenir des performances supérieures.
les modèles proposés avec des connaissances externes améliorent encore l'état de l'art sur le jeu de données SNLI.
Approche visant à améliorer la précision des prédictions par l'apprentissage de caractéristiques profondes sur des images de scènes voisines dans l'analyse d'images de scènes satellites.
Nous proposons des réseaux de graphes de différences sensibles à la physique, conçus pour apprendre efficacement les différences spatiales afin de modéliser les dynamiques observées de manière éparse.
Apprentissage de hiérarchies fonctionnellement décomposées pour des tâches de navigation continue
L'article décrit un nouvel algorithme permettant d'inférer des modèles de correspondance sonore pour plusieurs langues.
Une règle d'apprentissage biologiquement plausible pour la formation de réseaux neuronaux récurrents
Une nouvelle méthode pour l'apprentissage non supervisé de représentations sur des graphes, reposant sur la maximisation de l'information mutuelle entre les représentations locales et globales dans un graphe. Des résultats à la pointe de la technologie, compétitifs avec l'apprentissage supervisé.
Un modèle rétrospectif de l'état précédent (état, action) étant donné l'état suivant, c'est-à-dire P(s_t, a_t | s_{t+1}), peut être utilisé pour simuler des trajectoires supplémentaires se terminant à des états d'intérêt ! Améliore l'efficacité de l'apprentissage RL.
Ce travail porte sur une méthode basée sur les tenseurs pour l'apprentissage de la représentation des prépositions.
Nous utilisons la dynamique en temps continu pour définir un modèle génératif avec des vraisemblances exactes et un échantillonnage efficace qui est paramétré par des réseaux neuronaux non restreints.
Une nouvelle approche non contradictoire basée sur l'appariement des caractéristiques pour former des modèles génératifs qui donne des résultats de pointe.
Une nouvelle architecture pour la classification en quelques coups capable de traiter l'incertitude.
Nous montrons que les CNN et ResNets avec des prieurs appropriés sur les paramètres sont des processus gaussiens dans la limite d'un nombre infini de filtres convolutifs.
Nous présentons une méthodologie de conception de bout en bout pour un déploiement efficace de l'apprentissage profond. 
Accélérer l'optimisation distribuée en exploitant les traînards.
Grâce à un nouveau moteur de rendu différentiable, nous proposons une nouvelle mesure qui a des implications dans le monde réel pour évaluer les algorithmes d'apprentissage automatique adverses, en résolvant le manque de réalisme de la mesure existante basée sur les normes de pixels.
Nous montrons que l'architecture Transformer et le Neural GPU sont complets au sens de Turing.
Nous utilisons VAE pour capturer la caractéristique de forme pour l'évaluation de la segmentation automatique.
Nous étudions les valeurs propres des couches linéaires dans les réseaux profonds et montrons que les distributions développent un comportement de queue lourde pendant la formation.
Nous proposons un nouveau type de module d'attention entraînable de bout en bout, qui applique des équilibres de poids globaux entre les couches en utilisant un RNN à copropagation avec un CNN.
Les caractéristiques générées automatiquement par le modèle bio-mimétique MothNet améliorent considérablement la précision des tests des méthodes ML standard sur les MNIST vectorisés. Les caractéristiques générées par MothNet sont également plus performantes que les générateurs de caractéristiques standard.
En se concentrant davantage sur les prédictions finales dans les prédicteurs anytime (tels que les très récents Multi-Scale-DenseNets), nous faisons en sorte que les petits modèles anytime surpassent les grands modèles qui n'ont pas une telle concentration. 
Nous proposons une procédure d'apprentissage efficace en termes de mémoire qui exploite la réversibilité des couches du réseau afin de permettre une conception axée sur les données pour l'imagerie informatique à grande échelle.
Neuron as an Agent (NaaA) nous permet d'entraîner la communication multi-agents sans tiers de confiance.
Une nouvelle méthode de pré-entraînement qui établit de nouveaux résultats de pointe sur les benchmarks GLUE, RACE et SQuAD tout en ayant moins de paramètres par rapport à BERT-large. 
Apprentissage profond sur des données tabulaires structurées à l'aide d'une intégration bidimensionnelle des mots avec un modèle CNN pré-entraîné ImageNet finement ajusté.
liens entre le codage prédictif et les VAE + nouvelles frontières
Nouvelles variantes des méthodes d'optimisation qui combinent les avantages des méthodes adaptatives et non adaptatives.
Dans cet article, nous avons proposé un nouvel algorithme, GenDICE, pour l'estimation de la correction de la distribution stationnaire générale, qui peut traiter à la fois l'évaluation de l'actualisation et de la moyenne des hors-politiques sur de multiples échantillons de comportement.
Une exploration intuitive, empirique et visuelle des propriétés de généralisation des réseaux neuronaux profonds.
Nous utilisons la convolution pour que les réseaux neuronaux se comportent davantage comme des systèmes symboliques.
Formulation analytique des phénomènes d'ondes stationnaires équatoriales : Application à QBO et ENSO
Nous proposons de former un réseau neuronal inversible pour chaque classe afin d'effectuer un apprentissage continu classe par classe.
Un nouvel ensemble de systèmes de conversation à domaine ouvert basés sur la recherche et la génération.
Comprendre la transférabilité du point de vue de l'amélioration de la généralisation, de l'optimisation et de la faisabilité de la transférabilité.
Nous prouvons qu'il existe des réseaux ReLU dont les paramètres sont déterminés de manière presque unique par la fonction qu'ils mettent en œuvre.
Nous proposons un réseau de modulation descendante pour les applications d'apprentissage multi-tâches qui présente plusieurs avantages par rapport aux systèmes actuels.    
Nouvel algorithme de regroupement de données de séries chronologiques basé sur les caractéristiques des systèmes dynamiques.
Une méthode pour encourager les attributions axiomatiques de caractéristiques d'un modèle profond à correspondre à l'intuition humaine.
Nous proposons des LSTM très performants avec des poids binaires/ternaires, qui peuvent réduire considérablement la complexité de mise en œuvre.
Nous abordons le problème de la reconnaissance non supervisée de quelques images, où toutes les images d'entraînement ne sont pas étiquetées et ne partagent pas de classes avec les images de test.
Attaques de la boîte noire basées sur des requêtes contre des réseaux neuronaux profonds avec des taux de réussite contradictoires correspondant aux attaques de la boîte blanche.
Nous convertissons les sous-graphes en images structurées et les classons en utilisant 1. l'apprentissage profond et 2. l'apprentissage par transfert (Caffe) et obtenons des résultats étonnants.
Algorithme basé sur l'auto-enchevêtrement pour l'adaptation au domaine visuel, résultats de l'état de l'art, remporté le défi de l'adaptation au domaine de classification d'images VisDA-2017.
Une variante de VAE qui peut créer diverses images correspondant à de nouveaux "concepts" concrets ou abstraits décrits à l'aide de vecteurs d'attributs.
Nous proposons une méthode basée sur un modèle, appelée "Search with Amortized Value Estimates" (SAVE), qui tire parti de l'expérience réelle et planifiée en combinant l'apprentissage Q avec la recherche arborescente de Monte-Carlo, ce qui permet d'obtenir de bonnes performances avec de très petits budgets de recherche.
Une courte preuve de l'équivalence de l'apprentissage Q doux et des gradients de politique.
Nous proposons un algorithme de transfert de politique qui peut surmonter les écarts importants et difficiles dans la dynamique du système tels que la latence, l'erreur de modélisation de l'actionneur, etc.
Apprenez à quantifier le signal vocal et à appliquer aux données audio des algorithmes nécessitant des entrées discrètes, comme le BERT.
Nous développons Hierarchical Agent with Self-play (HASP), une approche d'apprentissage pour obtenir des politiques hiérarchiquement structurées qui peuvent atteindre des performances plus élevées que l'auto jeu conventionnel sur des jeux stratégiques compétitifs en temps réel.
Incorporation de mots en entrée à capacité variable et SOTA sur WikiText-103, Billion Word benchmarks.
un modèle profond multivarié de mélange de gaussiens pour la régression de la boîte de délimitation sous occlusion
Nous remplaçons la contrainte de la boule Lp par les cellules de Voronoï des données d'entraînement pour produire des modèles plus robustes. 
Nous proposons d'apprendre une politique plus généralisée pour les tâches de navigation fondées sur le langage naturel via l'apprentissage multitâche agnostique.
Nous proposons d'utiliser les barycentres de Wasserstein pour l'assemblage de modèles sémantiques.
Classification audio efficace en termes d'étiquettes grâce à l'apprentissage multi-tâches et à l'autosupervision
Proposer les premières méthodes d'optimisation exacte de la distribution softmax en utilisant le gradient stochastique avec un temps d'exécution indépendant du nombre de classes ou de points de données.
Utilisation de la recherche arborescente Monte Carlo et des homoglyphes pour générer des échantillons contradictoires indiscernables sur des données textuelles.
Apprenez à convertir un croquis dessiné à la main en un programme de haut niveau.
Cet article utilise des principes issus du domaine de la calibration en apprentissage machine sur les logits d'un réseau neuronal pour se défendre contre les attaques adverses
Nous entraînons conjointement un modèle de saut de programme multilingue et un modèle de similarité de phrase interlingue pour apprendre des incorporations de texte multilingue de haute qualité qui donnent de bons résultats dans le scénario de ressources limitées.
Nous avons proposé un modèle génératif flexible qui apprend de manière stable en minimisant directement la distance de Wasserstein empirique exacte.
Une étude de la manière dont les différents composants du pipeline NAS contribuent à la précision finale. Egalement, un benchmark de 8 méthodes sur 5 jeux de données.
Trouver des correspondances entre les domaines en effectuant des itérations de mise en correspondance et de mappage.
un modèle neuronal de sujet amélioré par la dispersion basé sur VAE
Keras pour les réseaux neuronaux infinis.
Nous présentons NLProlog, un système qui effectue un raisonnement à base de règles sur le langage naturel en s'appuyant sur des encastrements de phrases pré-entraînés et un réglage fin avec des stratégies d'évolution, et nous l'appliquons à deux tâches de réponse à des questions à sauts multiples.
Nous proposons l'apprentissage pondéré par la fidélité, une approche maître-élève semi-supervisée pour la formation de réseaux neuronaux utilisant des données faiblement étiquetées.
Nous prouvons que la descente de gradient est robuste à la corruption d'étiquette malgré la sur-paramétrisation sous un modèle de jeu de données riche.
Nous présentons un nouveau schéma de codage des poids qui permet un taux de compression élevé et une conversion rapide des matrices éparses en matrices denses.
Amélioration d'un réseau de peinture de pixels basé sur le GAN pour la récupération d'images sismiques comprimées et proposition d'une recommandation d'échantillonnage non uniforme, qui peut être facilement appliquée à la médecine et à d'autres domaines pour la technique de détection compressive.
Nous développons Simplified Action Decoder, un algorithme MARL simple qui bat de loin le précédent SOTA sur Hanabi pour des parties de 2 à 5 joueurs.
Reconnaissance optique de caractères de bout en bout et entraînable sur des documents imprimés ; nous obtenons des résultats de pointe, battant Tesseract4 sur des ensembles de données de référence à la fois en termes de précision et de temps d'exécution, en utilisant une approche purement basée sur la vision par ordinateur.
NovoGrad - une méthode SGD adaptative avec normalisation du gradient par couche et décroissance découplée des poids. 
Meilleure synthèse audio en combinant un DSP interprétable avec un apprentissage de bout en bout.
Une nouvelle approche de la classification de graphes basée sur les réseaux convolutifs de graphes spectraux et son extension aux multigraphes avec relations apprenables et structure hiérarchique. Nous montrons les résultats de l'état de l'art sur des ensembles de données chimiques, sociales et d'images.
Nous montrons comment réaliser avec succès des attaques par porte dérobée sans modifier les étiquettes de formation.
Nous constatons que les réseaux profonds qui généralisent mal sont plus dépendants des directions uniques que ceux qui généralisent bien, et nous évaluons l'impact de l'abandon et de la normalisation des lots, ainsi que de la sélectivité de classe sur la dépendance à la direction unique.
Au lieu d'apprendre les paramètres d'un modèle graphique à partir des données, apprenez un réseau d'inférence qui peut répondre aux mêmes requêtes probabilistes.
Nous démontrons comment les blocs résiduels peuvent être considérés comme des étapes de Gauss-Newton ; nous proposons un nouveau bloc résiduel qui exploite l'information de second ordre.
Nous présentons un modèle d'apprentissage automatique qui utilise des caractéristiques indépendantes du domaine pour estimer la criticité de l'état actuel pour provoquer un état indésirable connu.
Nous développons un cadre pour trouver des représentations internes modulaires dans les modèles génératifs et les manipuler pour générer des exemples contrefactuels.
Les poids plastiques de Hebbian peuvent se comporter comme un stockage compressé de la mémoire épisodique dans les réseaux neuronaux ; améliorant ainsi leur capacité à atténuer l'oubli catastrophique dans l'apprentissage continu.
Nous développons une approche permettant de répartir une couche cachée dans un DNN en groupes fonctionnellement apparentés, en appliquant le coclustering spectral sur les scores d'attribution des neurones cachés.
Déployer des applications de classification de textes et d'analyse de sentiments pour l'anglais et le chinois sur une puce accélératrice CNN de 300mW pour des scénarios d'application sur dispositif.
Nous développons des VAE où l'encodeur prend en entrée un vecteur de paramètres de modèle, ce qui nous permet d'effectuer une inférence rapide pour de nombreux modèles.
Secret est une méthode de transfert pour RL basée sur le transfert de l'affectation des crédits.
Working toward generative knowledge graph models to better estimate predictive uncertainty in knowledge inference. 
Un système dynamique basé sur le flux de gradient pour la modélisation générative inversible
Nous introduisons une couche mémoire efficace qui peut apprendre la représentation et dégrossir les graphes d'entrée simultanément sans dépendre du passage de messages.
Un nouveau schéma d'encodage utilisant {-1, +1} pour décomposer les QNN en réseaux binaires multi-branches, dans lequel nous avons utilisé des opérations sur les bits (xnor et bitcount) pour obtenir une compression du modèle, une accélération du calcul et une économie de ressources. 
Nous proposons une nouvelle façon d'incorporer les informations conditionnelles de l'image dans le discriminateur des GANs en utilisant la fusion de caractéristiques qui peut être utilisée pour des tâches de prédiction structurées.
Nous proposons un algorithme d'apprentissage de compétences utiles sans fonction de récompense, et montrons comment ces compétences peuvent être utilisées pour résoudre des tâches en aval.
L'article résout un problème d'ambiguïté lexicale causé par un homonyme dans la traduction neuronale par BERT.
Cet article se concentre sur la génération synthétique de données sur la mobilité humaine dans les zones urbaines à l'aide de GANs. 
Cet article propose un schéma de codage efficace pour les réseaux neuronaux qui encode un ensemble aléatoire de poids provenant d'une distribution variationnelle.
En analysant un algorithme minimisant une perte non convexe, nous montrons que tous les bruits, sauf une petite fraction, peuvent être supprimés d'une image en utilisant un antécédent génératif basé sur un réseau neuronal profond.
Une architecture multi-tâches à grande échelle résout ImageNet et la traduction ensemble et montre l'apprentissage par transfert.
Une approche inspirée de la philosophie continentale pour apprendre avec peu de données.
Apprendre à synthétiser des formes d'onde audio brutes avec des GANs
Une nouvelle méthode d'adaptation au domaine pour aligner les manifestes des domaines source et cible en utilisant la propagation des étiquettes pour une meilleure précision.
Cet article propose une nouvelle méthode pour l'apprentissage des réseaux de neurones dans des contextes de bandits en ligne en marginalisant la dernière couche.
Nous montrons en théorie et en pratique que la combinaison de plusieurs méthodes d'explication pour les DNN améliore l'explication.
Apprendre avec des données de formation limitées en exploitant les instances "utiles" d'une source de données riche.  
Nous augmentons la quantité de supervision de traces qu'il est possible d'utiliser lors de la formation d'architectures de machines neuronales entièrement différenciables.
Nous proposons des réseaux quantifiés bayésiens, pour lesquels nous apprenons une distribution postérieure sur leurs paramètres quantifiés.
L'entraînement contradictoire en cascade + l'apprentissage de la similarité à bas niveau améliorent la robustesse contre les attaques de la boîte blanche et de la boîte noire.
Nous montrons que, contrairement à ce que l'on pense généralement, le problème du gradient explosif n'a pas été résolu et qu'il limite la profondeur à laquelle les MLP peuvent être entraînés efficacement. Nous montrons pourquoi les gradients explosent et comment ResNet les gère.
Nous avons constaté que la formation contradictoire accélère non seulement la formation du GAN, mais améliore également la qualité de l'image.
Une méthode pour binariser à la fois les poids et les activations d'un réseau neuronal profond qui est efficace en termes de calcul et d'utilisation de la mémoire et qui donne de meilleurs résultats que l'état de l'art.
Nous présentons Good-Enough Model Spaces (GEMS), un cadre pour l'apprentissage d'un modèle agrégé sur des nœuds distribués en un petit nombre de tours de communication.
Nous proposons un nouvel auto-encodeur basé sur la distance de Wasserstein, qui améliore les propriétés d'échantillonnage du VAE.
Préservation de la confidentialité différentielle dans l'apprentissage adversarial avec une robustesse prouvable aux exemples adversariens.
Nous construisons et explorons automatiquement un petit processus de décision de Markov abstrait, ce qui nous permet d'obtenir des résultats de pointe sur Montezuma's Revenge, Pitfall ! et Private Eye avec une marge significative.
Nous montrons que le contrôle KL d'une antériorité pré-entraînée peut permettre aux modèles RL d'apprendre à partir d'un lot statique de données collectées, sans possibilité d'explorer en ligne dans l'environnement.
Transfert d'une politique à épisode unique dans une famille d'environnements aux dynamiques connexes, par le biais d'un sondage optimisé pour une inférence rapide des variables latentes et l'exécution immédiate d'une politique universelle.
Nous proposons un modèle d'encodeur-décodeur basé sur un réseau convolutif graphique avec une attention séquentielle pour les systèmes de dialogue orientés vers un but.
Mécanisme d'incorporation de séquences de nœuds qui capture les propriétés des graphes et des textes.
Cet article vise à tirer parti des bonnes propriétés des caractéristiques visuelles robustes comme SIFT pour rénover les architectures CNN afin d'obtenir une meilleure précision et une plus grande robustesse.
La théorie prédit la transition de phase entre les valeurs inapprenables et apprenables de bêta pour l'objectif du goulot d'étranglement de l'information.
Générer des images d'entraînement corrompues qui sont imperceptibles mais qui modifient le comportement du CNN sur une cible lors de tout nouvel entraînement.
Nous donnons un algorithme pour apprendre un réseau neuronal à deux couches avec une distribution symétrique des entrées. 
Nous montrons que la formation d'un réseau d'étudiants et d'enseignants de manière itérative, plutôt que conjointe, peut produire des stratégies d'enseignement émergentes et interprétables.
Analyse non asymptotique de SGD et SVRG, montrant la force de chaque algorithme en termes de vitesse de convergence et de coût de calcul, dans des contextes sous-paramétrés et sur-paramétrés.
Nous examinons systématiquement pourquoi la distillation des connaissances est cruciale pour l'entraînement des modèles de traduction non autorégressive (NAT), et nous proposons des méthodes pour améliorer encore les données distillées afin qu'elles correspondent au mieux à la capacité d'un modèle NAT.
Nous réussissons à stabiliser les transformateurs pour la formation dans le cadre de la RL et démontrons une amélioration importante par rapport aux LSTM sur DMLab-30, correspondant à une architecture de mémoire externe.
Inspirés par la variabilité d'un essai à l'autre dans le cerveau qui peut résulter de multiples sources de bruit, nous introduisons la variabilité par le bruit dans le cadre de la distillation des connaissances et nous étudions leur effet sur la généralisation et la robustesse.
Nous présentons une nouvelle approche de bout en bout pour l'apprentissage du regroupement en l'absence d'exemples étiquetés. Nous définissons une fonction de perte différentiable équivalente aux coupes normalisées attendues.
Nous présentons plusieurs jeux de données pour l'OCR en cyrillique et une méthode pour sa reconnaissance.
Nous proposons une méthode non supervisée d'apprentissage d'enchâssements multiples pour les phrases et les expressions. 
Exemples d'algorithmes efficaces pour adapter un modèle de synthèse vocale à un nouveau style de voix avec des performances de pointe.
Cet article présente un cadre probabiliste pour la classification d'images en k-shot qui permet d'obtenir des résultats à la pointe de la technologie.
Recherche sur la combinaison des réseaux neuronaux récurrents et de la relecture d'expérience menant à un agent de pointe sur Atari-57 et DMLab-30 en utilisant un seul ensemble d'hyperparamètres.
Notre combinaison de l'apprentissage multi-tâches et de l'auto-attention, en entraînant le modèle à s'intéresser aux parents dans un arbre d'analyse syntaxique, permet d'obtenir les meilleurs résultats CoNLL-2005 et CoNLL-2012 SRL pour les modèles utilisant des prédicats.
Nous proposons un nouveau module qui améliore toutes les architectures de type ResNet en imposant un comportement "sélectif" aux couches convolutives.
Une théorie et un cadre algorithmique pour la prédiction en cas de changement de distribution, y compris l'estimation de l'effet causal et l'adaptation au domaine.
Nous étudions les ensembles profonds sous l'angle du paysage des pertes et de l'espace des prédictions, en démontrant que le pouvoir de décorrélation des initialisations aléatoires est inégalé par l'échantillonnage du sous-espace qui n'explore qu'un seul mode.
Peut-on faire confiance à nos modèles d'apprentissage profond ? Un cadre pour mesurer et améliorer la confiance d'un modèle d'apprentissage profond pendant la formation.
Une approche RL basée sur un modèle qui utilise une pénalité d'incertitude différentiable pour apprendre des politiques de conduite à partir de données purement observationnelles.
Adaptation des prédictions des modèles de séquence (tels que les LDS et les RNN) via un code latent explicite.
Nous proposons une nouvelle méthode d'entraînement contradictoire avec adaptation au domaine qui améliore considérablement la capacité de généralisation sur des exemples contradictoires provenant de différentes attaques.
Cet article propose un nouveau transformateur léger pour la modélisation du langage au niveau des caractères, en utilisant des opérations par groupes.
Une approche stable de formation adversariale au domaine pour une adaptation robuste et complète au domaine.
Nous utilisons l'apprentissage automatique pour générer des synonymes pour les grandes taxonomies de shopping.
MOHART utilise un mécanisme d'auto-attention pour effectuer un raisonnement relationnel dans le suivi multi-objets.
Nous étudions et proposons des solutions pour deux défis dans l'apprentissage par renforcement : (a) l'apprentissage efficace de l'acteur-critique avec relecture de l'expérience (b) la stabilité de l'apprentissage très hors-politique.
Nous proposons un algorithme de sélection de l'estimateur du gradient dans le but d'améliorer l'efficacité de l'optimisation.
Nous étudions le problème de l'atténuation de l'instabilité de la procédure de formation du GAN par la conception d'une nouvelle architecture, avec des garanties théoriques.
Ce travail prouve la non-accélération de la SGD de Nesterov avec n'importe quels hyper-paramètres, et propose un nouvel algorithme qui accélère de manière prouvée la SGD dans le cadre sur-paramétré.
Une couche d'anticipation pour incorporer la fluidité structurée dans un modèle d'apprentissage profond.
Ne déformez pas vos convolutions - déformez vos noyaux.
Nous présentons une méthode d'apprentissage de modèles d'intégration de séquences de protéines utilisant des informations structurelles sous la forme d'une similarité structurelle globale entre les protéines et au sein des contacts résidu-résidu des protéines.
En considérant le processus d'optimisation des réseaux neuronaux comme un problème de sélection de modèle, nous introduisons une méthode de normalisation biologiquement plausible qui extrait la régularité statistique selon le principe MDL pour résoudre le problème des données déséquilibrées et limitées.
"Modélisation générative sans besoin de formation contradictoire".
Nous proposons une méthode d'apprentissage par imitation pour apprendre à partir de démonstrations de qualité diverse recueillies par des démonstrateurs ayant des niveaux d'expertise différents.
Description d'une heuristique sémantique qui s'appuie sur une description de service OWL-S et utilise des mesures de distance entre mots et phrases pour évaluer l'utilité des services pour un objectif donné. 
Réseau convolutif graphique basé sur la topologie (GCN)
Des réseaux de neurones artificiels ont développé les mêmes structures que celles présentes dans les systèmes olfactifs des mouches et des souris après avoir été entraînés à classer les odeurs.
La régularisation douce sur le graphe d'échantillons pour la traduction image à image non appariée permet d'améliorer considérablement la cohérence.
Un réseau neuronal à convolution pour la correspondance stéréo multi-vues dont la conception est inspirée des meilleures pratiques des approches traditionnelles basées sur la géométrie.
Nous augmentons l'apprentissage de politiques sans modèle avec des fonctions de récompense de substitution au niveau de la séquence et une prime de visite basée sur le nombre de visites, et nous démontrons son efficacité dans le régime de lots importants et de faible rotation observé dans la conception de séquences d'ADN et de protéines.
Nous utilisons l'apprentissage par renforcement pour entraîner un agent à résoudre un ensemble de tâches d'arithmétique visuelle en utilisant des modules perceptifs pré-entraînés et des transformations de représentations internes créées par ces modules.
Un nouvel algorithme RL appelé différenciation de politique intérieure est proposé pour apprendre une collection de politiques diverses pour une tâche primaire donnée.
Une évaluation empirique sur les réseaux adversariens génératifs
Prédiction des valeurs numériques des attributs associés aux entités dans les bases de connaissances.
Nous proposons des procédures d'évaluation et de renforcement de l'alignement de l'encastrement contextuel et montrons qu'elles permettent à la fois d'améliorer le transfert XNLI zéro-shot de BERT multilingue et de fournir des informations utiles sur le modèle.
Nous utilisons des réseaux neuronaux formés pour le débruitage d'images comme prieurs prêts à l'emploi dans des algorithmes de minimisation de l'énergie pour les problèmes de reconstruction d'images avec une convergence prouvable.
Nous proposons une nouvelle méthode pour calibrer les modèles d'intégration des graphes de connaissances sans avoir besoin d'exemples négatifs.
Une nouvelle perte d'apprentissage par curriculum adaptatif pour la reconnaissance profonde des visages
L'entraînement des adversaires à l'aide de méthodes en une seule étape est surdimensionné et reste vulnérable aux attaques simples de type boîte noire et boîte blanche. Nous montrons que l'inclusion d'exemples contradictoires provenant de sources multiples permet de se défendre contre les attaques de type boîte noire.
Cet article propose une nouvelle approche pour incorporer l'invariance souhaitée à l'apprentissage des représentations, basée sur l'observation que l'état actuel de l'AFL présente des problèmes pratiques.
La surface de perte est *très* dégénérée, et il n'y a pas de barrières entre les solutions à grande et à petite échelle.
Nous proposons le CR-NAS pour réallouer les ressources de calcul engagées dans différentes résolutions et positions spatiales.
Une méthode d'apprentissage qui permet aux algorithmes d'apprentissage profond de mieux fonctionner sur les puces informatiques neuromorphiques présentant des incertitudes.
Une architecture CNN qui peut rejeter efficacement les inconnues dans les objets de test.
Nous réalisons une inférence variationnelle amortie sur un modèle de processus gaussien latent pour obtenir des performances d'imputation supérieures sur des séries temporelles multivariées avec des données manquantes.
Nous réalisons des études expérimentales massives caractérisant les relations entre les normes jacobiennes, les régions linéaires et la généralisation.
Le bruit dans l'espace des paramètres permet aux algorithmes d'apprentissage par renforcement d'explorer en perturbant les paramètres au lieu des actions, ce qui conduit souvent à une amélioration significative des performances d'exploration.
Nous présentons de nouvelles techniques de distillation qui permettent de former des modèles d'étudiants avec différents vocabulaires et de compresser BERT par 60 fois avec une baisse de performance mineure.
Apprentissage de bout en bout de représentations invariantes avec des variables à travers des exemples tels que si quelqu'un est allé quelque part alors il est là.
Nous résolvons les problèmes inverses mal posés avec peu d'exemples de vérité au sol en estimant un ensemble de projections aléatoires du modèle au lieu du modèle lui-même.
Technique permettant d'accélérer la sélection d'une architecture neuronale en approximant les poids de chaque architecture candidate au lieu de les entraîner individuellement.
Nous proposons quatre nouvelles méthodes de collecte des données NLI. Certaines sont légèrement utiles comme données de pré-entraînement, toutes permettent de réduire les artefacts d'annotation.
Prédiction vidéo variationnelle stochastique dans des contextes réels.
Modélisation d'interactions multi-agents complexes dans un cadre d'apprentissage par imitation multi-agents avec modélisation explicite des politiques corrélées par approximation des politiques des adversaires. 
Un système de détection de plagiat interlingue (anglais-russe)
Nous avons proposé une mise en œuvre pour accélérer l'apprentissage parallèle des données DNN en réduisant les besoins en bande passante de communication.
Les perturbations peuvent être utilisées pour apprendre les poids de rétroaction sur de grands réseaux entièrement connectés et convolutifs.
Nous suggérons le nombre suffisant de bits pour représenter les poids des DNNs et les bits optimaux sont conservateurs lors de la résolution de problèmes réels.
Affiner les propositions de segmentation en effectuant une inférence itérative avec des autoencodeurs de débruitage conditionnel.
Nous proposons une architecture GAN basée sur l'auto-attention pour la génération inconditionnelle de texte et améliorons les résultats précédents basés sur le code adversarial.
Nous proposons un nouveau réseau neuronal encodeur-décodeur de filigrane. Ils effectuent un jeu coopératif pour définir leur propre schéma de filigrane. Les gens n'ont plus besoin de concevoir des méthodes de filigrane.
Nous dérivons un estimateur de gradient sans biais et à faible variance pour les attentes sur les variables aléatoires discrètes basées sur l'échantillonnage sans remplacement.
Nous proposons une méthode qui permet de plier les CNN pour créer des connexions récurrentes.
L'écrêtage par gradient ne confère pas de robustesse au bruit des étiquettes, mais une simple variante basée sur la perte le fait.
montrent des preuves expérimentales de la faible corrélation entre les probabilités de flux et la sémantique des images.
Nous appliquons une stratégie de défense agnostique contre les exemples adverses et obtenons une précision de 60% en boîte blanche et de 90% en boîte noire contre les principaux algorithmes d'attaque.
Nous apportons la toute première preuve de convergence d'un algorithme accéléré asynchrone qui atteint un gain de vitesse.
Nous intégrons les échantillonneurs SG-MCMC dans une approximation variationnelle.
Nous soutenons théoriquement que le simple fait de supposer que les poids d'un réseau ReLU sont distribués de manière gaussienne (sans même un formalisme bayésien) pourrait régler ce problème ; pour une incertitude plus calibrée, une simple méthode bayésienne pourrait déjà être suffisante.
Nous utilisons des représentations entraînées sans données parallèles pour créer des alignements de mots.
Une nouvelle approche pour l'apprentissage avec des récompenses bruyantes dans l'apprentissage par renforcement.
Cet article se concentre sur un mécanisme traditionnellement négligé : une architecture avec des unités cachées privées et partagées explicitement conçues pour atténuer l'influence néfaste de la perte auxiliaire non supervisée sur la tâche principale supervisée.
Une étude théorique de l'apprentissage multitâche avec des implications pratiques pour améliorer l'entraînement multitâche et l'apprentissage de transfert
Nouvelle méthode pour évaluer la quailité des évaluateurs de similarité et montrer le potentiel des modèles de langue basés sur les transformateurs pour remplacer BLEU et ROUGE.
Les méthodes de méta-apprentissage utilisées pour la vision, directement appliquées au TAL, donnent de moins bons résultats que les voisins les plus proches sur les nouvelles classes ; nous pouvons faire mieux avec les signatures distributionnelles.
Une analyse théorique d'une nouvelle classe de RNNs, entraînés sur des tâches neuroscientifiques, nous permet d'identifier le rôle de la dimensionnalité dynamique et des classes de cellules dans les calculs neuronaux.
Nous proposons le discriminateur de fusion, une nouvelle architecture pour incorporer des informations conditionnelles dans le discriminateur des GAN pour les tâches de prédiction structurées.
Nous définissons, explorons et commençons à traiter la question de l'inadéquation des objectifs dans l'apprentissage par renforcement basé sur un modèle.
Nous donnons une explication détaillée des trajectoires dans le plan d'information et étudions son utilisation pour la conception de réseaux neuronaux (élagage).
Utilisation de mesures d'intrication quantique pour quantifier les corrélations dans l'apprentissage profond, et utilisation de la connexion pour adapter l'architecture du réseau profond aux corrélations dans les données.
Nous utilisons un apprentissage par renforcement sur les graphes moléculaires pour générer des justifications pour la prédiction de propriétés moléculaires interprétables.
Nous unifions les réseaux convolutifs de graphes en tant que co-training et factorisation matricielle unitisée.
Un modèle autorégressif basé sur le flux pour la génération de graphes moléculaires. Atteindre des résultats de pointe sur la génération de molécules et l'optimisation des propriétés.
Nous proposons un nouveau cadre pour l'apprentissage des préconditionneurs, déduisons de nouvelles formes de préconditionneurs et de méthodes d'apprentissage, et révélons la relation avec des méthodes comme RMSProp, Adam, Adagrad, ESGD, KFAC, la normalisation par lots, etc.
Des techniques simples d'augmentation du texte peuvent améliorer de manière significative les performances des tâches de classification de texte, en particulier pour les petits ensembles de données.
Nous proposons un modèle capable d'effectuer l'estimation des paramètres physiques des systèmes à partir de la vidéo, où les équations différentielles régissant la dynamique de la scène sont connues, mais où les états ou les objets étiquetés ne sont pas disponibles.
ASAL est une méthode d'apprentissage actif basée sur un pool qui génère des échantillons à haute entropie et récupère les échantillons correspondants dans le pool en un temps sub-linéaire.
Nous soulignons les problèmes importants que pose la pratique courante consistant à utiliser la meilleure performance d'un modèle unique pour comparer les architectures d'apprentissage profond, et nous proposons une méthode qui corrige ces défauts.
Nous étudions l'effet de la complexité d'intégration dans l'apprentissage de représentations invariantes par rapport au domaine et nous développons une stratégie qui atténue la sensibilité à cette complexité.
Nous proposons une nouvelle architecture appelée Dual Adversarial Transfer Network (DATNet) pour la reconnaissance d'entités nommées (NER) à faibles ressources et obtenons de nouvelles performances de pointe pour CoNLL et Twitter NER.
Les GAN de Coulomb peuvent apprendre une distribution de manière optimale en posant le problème de l'apprentissage de la distribution comme l'optimisation d'un champ de potentiel.
Nous proposons un réseau convolutif graphique basé sur la confiance pour l'apprentissage semi-supervisé.
Nous proposons ImageNet-C pour mesurer la robustesse de la corruption des classificateurs et ImageNet-P pour mesurer la robustesse des perturbations.
Obfusquer le code à l'aide de réseaux seq2seq, et l'exécuter en utilisant le code obfusqué et la paire de clés.
Méthode basée sur le GAN pour la synthèse conjointe d'images et d'annotations par pixel
Nous introduisons une nouvelle tâche et un nouvel ensemble de données sur la navigation multilingue par vision et par langue, et nous proposons un cadre général de VLN multilingue pour cette tâche.
Classification non supervisée par modélisation générative profonde avec apprentissage contrôlable des caractéristiques, évaluée dans une tâche difficile du monde réel.
Modèles de représentation Apprentissage sur des graphes dynamiques en tant que processus caché latent reliant deux processus observés d'évolution topologique et d'interactions sur des graphes dynamiques.
Nous présentons une classe de jeux à n joueurs adaptés aux méthodes basées sur le gradient.
Nous étudions la classe des langages formels acceptables par les contre-automates en temps réel, un modèle de calcul lié à certains types de réseaux neuronaux récurrents.
Un modèle de résumé combinant une nouvelle méthode d'apprentissage par intra-attention et renforcement pour augmenter les scores ROUGE et la qualité du résumé pour les longues séquences.
Nous étudions si et comment l'augmentation adaptative des données et la distillation des connaissances peuvent être exploitées simultanément de manière synergique pour mieux former les réseaux d'étudiants.
Nous présentons une procédure simple pour réaffecter des modèles de langage pré-entraînés basés sur des transformateurs afin de réaliser un bon résumé abstrait.
Nous présentons une architecture basée sur la mémoire neuronale pour l'adaptation incrémentale au domaine, et fournissons des résultats théoriques et empiriques.
En formulant la récupération de signaux épars comme un problème de prise de décision séquentielle, nous développons une méthode basée sur RL et MCTS qui apprend une politique pour découvrir le support du signal épars. 
Apprentissage de l'encastrement pour le contrôle avec des observations à haute dimension
Premières découvertes à l'intersection de la neuroscience des réseaux et de l'apprentissage profond. Le cortex visuel de C. Elegans et d'une souris apprend à reconnaître des chiffres manuscrits.
Une méthode d'apprentissage de structure non supervisée pour les réseaux profonds à action directe parcimonieux.
Utilisation de GANs comme prieurs pour une inférence bayésienne efficace de champs complexes.
Omniglot et miniImageNet sont trop simples pour un apprentissage en quelques coups, car nous pouvons les résoudre sans utiliser d'étiquettes lors de la méta-évaluation, comme le montre une méthode appelée réseaux centroïdes
Identifier les états de décision (où l'agent peut prendre des mesures importantes) sans supervision de la récompense, l'utiliser pour le transfert.
Une approche permettant de combiner l'inférence variationnelle et l'optimisation bayésienne pour résoudre des problèmes inverses compliqués
Nous montrons que sous certaines hypothèses sur la dynamique du véhicule et l'incertitude de l'environnement, il est possible de synthétiser automatiquement des primitives de mouvement qui n'accumulent pas d'erreur au fil du temps.
Les réseaux convolutifs profonds existants dans les tâches de classification d'images sont sensibles aux motifs de bruit de Gabor, c'est-à-dire que de petits changements structurés en entrée entraînent de grands changements en sortie.
L'étude de la robustesse et de la redondance dans les réseaux neuronaux profonds révèle des caractéristiques limitant la capacité qui contribuent à expliquer l'absence d'overfitting.
Un algorithme évolutif pour établir des dérivés robustes des réseaux profonds par rapport aux entrées.
Dans cet article, nous explorons une structure de réseau interne dense mais externe clairsemée des réseaux neuronaux profonds et analysons ses principales propriétés.
Dans ce travail, nous cherchons à améliorer les MCMC et VI par une nouvelle méthode hybride basée sur l'idée de réduire le biais de simulation des chaînes MCMC de longueur finie en utilisant l'optimisation basée sur le gradient.
Les informations permettant de savoir si la sortie d'un réseau neuronal sera correcte ou incorrecte sont quelque peu présentes dans les sorties des couches intermédiaires du réseau.
Algorithme d'auto-imitation non supervisé capable d'inférer à partir d'une seule démonstration experte.
Nous développons un cadre pour générer des explications compréhensibles par l'homme sur les raisons de l'infaisabilité dans les instances surcontraintes d'une classe de problèmes d'ordonnancement avec contraintes de ressources.
Nous montrons que les gradients sont incapables de capturer les changements de saillance dus à des perturbations adverses et nous présentons une défense alternative utilisant des modèles de saillance appris qui est efficace contre les attaques de type boîte noire et boîte blanche.
Inadéquation des mesures de désenchevêtrement
Nous proposons un apprentissage par renforcement de la gestion multi-agents conscient de l'esprit (M^3RL) pour former un gestionnaire à motiver les travailleurs intéressés à atteindre une collaboration optimale en leur attribuant des contrats appropriés.
Une méthode pour les états latents persistants dans les ResBlocks démontrée pour la super-résolution de séquences d'images alisées.
Nous proposons Diversely Stale Parameters pour briser les verrouillages de l'algorithme de rétropropoagation et former un CNN en parallèle.
Une tâche de prédiction auxiliaire peut accélérer l'apprentissage dans les configurations d'émergence de langue.
Module TEB pour IPC
Algorithme d'apprentissage métrique entièrement parallélisable et résistant au bruit adverse avec des garanties théoriques.
Nous développons des modèles de sous-titrage d'images engageants conditionnés par la personnalité qui sont également à la pointe de la technologie pour les tâches de sous-titrage ordinaires.
Nous proposons une descente de gradient stochastique à lissage laplacien différentiellement privée pour entraîner des modèles d'apprentissage machine avec une meilleure utilité et maintenir des garanties de confidentialité différentielles.
Nous fournissons une analyse statistique et computationnelle du problème de détection comprimée à un bit avec un antécédent génératif. 
Une approche fondée sur des principes pour l'apprentissage de la structure des réseaux neuronaux profonds avec une nouvelle interprétation de la profondeur et de la connectivité intercouche. 
Nous étudions comment et pourquoi la régularisation forte L1/L2 échoue et proposons une méthode qui permet d'obtenir une régularisation forte.
Ce travail vise à fournir des réponses quantitatives à l'importance relative des concepts d'intérêt via des vecteurs d'activation de concepts (CAV). En particulier, ce cadre permet aux experts en apprentissage non-machine d'exprimer des concepts d'intérêt et de tester des hypothèses en utilisant des exemples (par exemple, un ensemble d'images qui illustrent le concept). Nous montrons que le CAV peut être appris à partir d'un ensemble relativement restreint d'exemples. Le test d'hypothèses avec CAV peut répondre à la question de savoir si un concept particulier (par exemple, le sexe) est plus important pour prédire une classe donnée (par exemple, le médecin) que d'autres ensembles de concepts. L'interprétation des réseaux avec CAV ne nécessite pas de réentraînement ou de modification du réseau. 
Le goulot d'étranglement de l'entropie conditionnelle est une fonction objective de la théorie de l'information pour l'apprentissage de représentations optimales.
Nous proposons une approche pour apprendre des représentations clairsemées de haute dimension qui sont rapides à rechercher, en incorporant un substitut du nombre d'opérations directement dans la fonction de perte.
Combiner l'entraînement auxiliaire et l'entraînement contradictoire pour interroger et aider à la compréhension physique.
Modèles basés sur les flux, mais non inversables, pour apprendre également les variables discrètes.
Nous prouvons de manière constructive que même les fonctions d'activation non linéaires les plus légères introduisent des minima locaux parasites, pour des ensembles de données et des fonctions d'activation généraux.
Planification compositionnelle basée sur les attributs qui se généralise à des tâches de test longues, bien qu'elle ait été entraînée sur des tâches courtes et simples.
Nous identifions et formalisons le problème de mémorisation dans le méta-apprentissage et résolvons ce problème à l'aide d'une nouvelle méthode de méta-régularisation, ce qui élargit considérablement le domaine dans lequel le méta-apprentissage peut être applicable et efficace.
Nous proposons un nouveau cadre pour le méta-apprentissage d'une règle de mise à jour basée sur le gradient, qui va au-delà de l'apprentissage en quelques coups et qui est applicable à toute forme d'apprentissage, y compris l'apprentissage continu.
Defense-GAN utilise un réseau adversarial génératif pour se défendre contre les attaques en boîte blanche et en boîte noire dans les modèles de classification.
Nous développons des méthodes efficaces pour former des modèles d'intégration neuronale avec une structure de produit de points, en reformulant la fonction objective en termes de matrices de Gram généralisées, et en maintenant les estimations de ces matrices.
Nous présentons une plateforme de benchmark et d'analyse multi-tâches pour évaluer la généralisation dans les systèmes de compréhension du langage naturel.
Une méthode modulaire pour l'apprentissage par renforcement multi-agent multi-objectif entièrement coopératif, basée sur l'apprentissage par programme pour une exploration efficace et l'attribution de crédits pour les interactions action-objectif.
Nous abordons l'inefficacité de l'échantillonnage et le biais de récompense dans les algorithmes d'apprentissage par imitation adversariale tels que GAIL et AIRL.
Une variante des réseaux de capsules qui peut être utilisée pour les tâches d'apprentissage par paires. Les résultats montrent que les réseaux de capsules siamoises fonctionnent bien dans le cadre de l'apprentissage en quelques coups.
Cet article présente la neuromodulation dans les réseaux de neurones artificiels.
Nous proposons une méthode de convolution dynamique pour accélérer de manière significative le temps d'inférence des CNN tout en maintenant la précision.
Dans cet article, nous présentons une méthode d'apprentissage, appelée quantification par table de consultation (LUT-Q), qui apprend un dictionnaire et attribue chaque poids à l'une des valeurs du dictionnaire.
Nous examinons le transfert négatif du point de vue de l'adaptation au domaine afin de dériver un algorithme d'apprentissage contradictoire.
Nous formons des machines de Boltzmann quantiques à l'aide d'une méthode d'empilement de répliques et d'un recycleur quantique pour effectuer une tâche d'apprentissage par renforcement.
Nous avons proposé une méthode Nesterov Iterative Fast Gradient Sign (NI-FGSM) et une méthode d'attaque invariante à l'échelle (SIM) qui peuvent améliorer la transférabilité des exemples adverses pour la classification des images.
Nous présentons une méthode de formation stochastique pour former un réseau de neurones binaires avec des poids et des activations binaires.
Nous analysons l'impact de l'espace latent des générateurs entièrement entraînés en les pseudo-inversant.
Nous proposons un processus de construction de modèle de bout en bout qui est universellement applicable à une grande variété de corpus de vérification de la paternité et qui surpasse l'état de l'art avec peu ou pas de modification ou de réglage fin.
Nous envisageons de nous attaquer à un problème de RL à agent unique en le distribuant à $n$ apprenants.
Un modèle hybride utilisant à la fois l'audio brut et les informations du spectrogramme pour les tâches d'amélioration de la parole.
Cet article compare les tests statistiques pour les comparaisons RL (faux positifs, puissance statistique), vérifie la robustesse aux hypothèses en utilisant des distributions simulées et des distributions empiriques (SAC, TD3), fournit des directives pour les étudiants et les chercheurs RL.
Nous présentons une analyse théorique de l'objectif de goulot d'étranglement de l'information afin de comprendre et de prédire les transitions de phase observées dans le compromis entre la prédiction et la compression.
Proposition de fonctions d'activation localement adaptatives dans les réseaux de neurones profonds et informés par la physique pour une convergence plus rapide
Analyse de l'inférence des hyperparamètres bayésiens dans la régression par processus gaussien 
Nous entraînons des modèles variationnels avec des réseaux quantifiés pour le déterminisme computationnel. Cela permet de les utiliser pour la compression de données multiplateforme.
Une simulation neuronale de la machine de Turing universelle
La décroissance du taux d'apprentissage et l'augmentation de la taille du lot pendant l'apprentissage sont équivalentes.
Nous présentons le DCN+ avec la co-intention résiduelle profonde et le RL à objectifs mixtes, qui atteint des performances de pointe sur le Stanford Question Answering Dataset.
Un benchmark NAS applicable à presque tous les algorithmes NAS.
Nous proposons une pénalité de gradient centrée sur zéro pour améliorer la généralisation et la stabilité des GAN.
Une vue sobre sur l'état actuel des GANs d'un point de vue pratique
Nous proposons une approche agnostique du modèle pour expliquer le comportement d'agents RL profonds en boîte noire, entraînés à jouer à des jeux d'Atari et de société, en mettant en évidence les caractéristiques pertinentes d'un état d'entrée.
Nous étudions la représentation profonde des architectures CNN-DCN non entraînées et à poids aléatoire, et nous montrons leur qualité de reconstruction d'images et leurs applications possibles.
Cet article présente une nouvelle approche de représentation dynamique des caractéristiques afin de fournir un moyen plus efficace de faire de l'inférence sur les réseaux neuronaux profonds.
Lorsqu'ils sont initialisés correctement, les réseaux neuronaux peuvent apprendre la classe simple des fonctions symétriques ; lorsqu'ils sont initialisés de manière aléatoire, ils échouent.  
Nous proposons une méthode de recherche efficace d'architecture neuronale multi-objectifs basée sur l'héritage lamarckien et les algorithmes évolutionnaires.
Modèle neuronal unifié de modélisation des sujets et du langage pour introduire la structure du langage dans les modèles de sujets pour les vecteurs de sujets contextualisés. 
Nous proposons une nouvelle façon de compresser les réseaux neuronaux en utilisant des structures de données probabilistes.
Nous étudions l'impact de l'utilisation de différents types d'unités de sous-mots sur la qualité des représentations résultantes lorsqu'elles sont utilisées pour modéliser la syntaxe, la sémantique et la morphologie.
Une étude empirique qui fournit une nouvelle perspective sur l'apprentissage en quelques coups, dans laquelle une méthode de réglage fin montre une précision comparable aux méthodes plus complexes de l'état de l'art dans plusieurs tâches de classification.
Nous proposons une approche pour générer des données boursières réalistes et de haute fidélité basée sur des réseaux adversariens génératifs.
Nous présentons une approche d'estimation du gradient basée sur le signe, plutôt que sur la magnitude, qui fait passer l'estimation du gradient d'une optimisation continue à une optimisation binaire en boîte noire.
Nous analysons la propagation du gradient dans les RNN profonds et, à partir de notre analyse, nous proposons un nouveau RNN profond multicouche.
Nous analysons mathématiquement l'effet de la normalisation des lots sur un modèle simple et obtenons de nouvelles idées clés qui s'appliquent à l'apprentissage supervisé général.
Pour les contraintes complexes pour lesquelles il n'est pas facile d'estimer le gradient, nous utilisons la pénalité actualisée comme signal de guidage. Nous prouvons que sous certaines hypothèses, elle converge vers une solution réalisable.
L'article étudie l'acquisition de cibles pour les panneaux virtuels portatifs dans la RV et montre que la largeur de la cible, la distance, la direction d'approche par rapport à la gravité et l'angle d'approche ont tous un impact sur les performances de l'utilisateur.
iSparse élimine les bords du réseau non pertinents ou insignifiants avec un impact minimal sur les performances du réseau en déterminant l'importance des bords par rapport à la sortie finale du réseau. 
Nous apprenons des représentations d'entités qui peuvent reconstruire les catégories de Wikipédia avec seulement quelques exemples.
En utilisant le logarithme déformé en q, nous obtenons des limites plus serrées que celles de l'IWAE, pour entraîner des auto-codeurs variationnels.
Le dilemme de Bregman est démontré dans l'apprentissage profond que l'amélioration des marges des modèles sur-paramétrés peut entraîner un sur-ajustement, et la dynamique des distributions de marges normalisées est proposée pour prédire l'erreur de généralisation et identifier un tel dilemme. 
Nous avons proposé un système de dialogue de bout en bout avec un nouveau système de suivi de l'état du dialogue à plusieurs niveaux et avons obtenu des performances cohérentes sur MultiWOZ2.1 en matière de suivi de l'état, d'achèvement des tâches et de génération de réponses.
Nous présentons une approximation évolutive pour un large éventail d'objectifs EBM, ainsi que des applications dans les VAE et WAE implicites.
Cet article développe une méthode fondée sur des principes pour l'apprentissage continu dans les modèles profonds.
Un algorithme RL profond pour résoudre les POMDPs par auto-encodage des états sous-jacents en utilisant un modèle récurrent variationnel.
Cet article formalise le problème de la sélection d'algorithmes en ligne dans le contexte de l'apprentissage par renforcement.
Nous proposons un nouveau modèle de variable latente pour apprendre des encastrements latents pour certaines données à haute dimension. 
Nous proposons des stratégies de défense contradictoire basées sur la fonction d'activation dépendant des données, la minimisation de la variation totale et l'augmentation des données d'entraînement.
Ce travail présente une solution évolutive pour la reconnaissance visuelle continue de la parole.
Nous proposons un modèle d'autoencodeurs variationnels pour la modélisation de textes sans affaiblir le décodeur, ce qui améliore la qualité de la génération de textes et l'interprétabilité des représentations acquises.
Nous démontrons que les modèles volumineux mais élagués (large-sparse) sont plus performants que leurs homologues plus petits mais denses (small-dense) avec une empreinte mémoire identique.
Nous contrôlons le sujet et le sentiment de la génération de texte (presque) sans aucune formation. 
Le relâchement de la contrainte des hiérarchies partagées permet un apprentissage multitâche profond plus efficace.
Nous proposons un cadre pour apprendre des réseaux calibrés par la confiance en concevant une nouvelle fonction de perte qui incorpore l'incertitude prédictive estimée par des inférences stochastiques.
Apprendre la dynamique des particules avec des graphes d'interaction dynamiques pour simuler et contrôler des corps rigides, des objets déformables et des fluides. 
Nous introduisons une théorie pour expliquer l'échec des GANs sur des ensembles de données complexes et proposons une solution pour y remédier.
L'augmentation des données et l'entraînement contradictoire sont très efficaces pour démêler le locuteur corrélé et le bruit, ce qui permet un contrôle indépendant de chaque attribut pour la synthèse de la parole à partir du texte.
Les LSTM apprennent les dépendances à longue portée par composition en les construisant à partir de constituants plus courts au cours de la formation.
Nous formons les réseaux neuronaux en les linéarisant localement et en utilisant un solveur SVM linéaire (Frank-Wolfe) à chaque itération.
Nous présentons une version améliorée de la méthode DRL basée sur les caractéristiques universelles des successeurs qui peut améliorer l'apprentissage par transfert des agents.
Une méthode d'apprentissage des représentations d'images qui permettent à la fois de démêler les facteurs de variation et d'obtenir des reconstructions fidèles.
Nous utilisons le rang non négatif des matrices d'activation ReLU comme mesure de complexité et montrons qu'il est en corrélation (négative) avec une bonne généralisation.
L'objectif de cet article est d'obtenir l'effet des réseaux à enseignants multiples en exploitant les blocs stochastiques et les connexions sautées.
Nous avons construit un clavier Android avec des capacités de suggestion d'emoji à la fois lexicales (basées sur les mots) et sémantiques (basées sur le sens) et avons comparé leurs effets dans deux études de chat différentes. 
Nous proposons un paradigme d'apprentissage auto-adversaire (SAL) qui améliore le générateur de manière auto-adaptative pour améliorer les performances des GANs dans la génération de texte.
Dans cette étude, nous introduisons une nouvelle méthode qui s'appuie sur SVD pour découvrir le nombre de dimensions latentes.
Une nouvelle approche de détection contradictoire, qui utilise des méthodes d'explicabilité pour identifier les images dont les explications sont incompatibles avec la classe prédite.  
Une méthode de compression de modèle entraînable de bout en bout optimisant la précision conjointement avec la taille prévue du modèle.
Nous proposons une technique intelligente de sélection des lots appelée Ada-Boundary.
Nous présentons des architectures de réseaux neuronaux basées sur l'ontologie pour la classification des événements sonores.
Notre travail montre que l'information positionnelle a été implicitement encodée dans un réseau. Cette information est importante pour détecter les caractéristiques dépendant de la position, par exemple la sémantique et la saillance.
Réseau de neurones général à détaillé (GDNN) avec apprentissage multi-tâches en incorporant l'esquisse inter-domaine (CDS) pour l'analyse sémantique.
Nous montrons que l'apprenabilité de différentes architectures neuronales peut être caractérisée directement par des mesures calculables de la complexité des données.
S'attaquer à la conception inverse par le biais d'algorithmes génétiques augmentés de réseaux neuronaux profonds. 
Nous étudions les activations d'état caché des modèles transformateurs dans les tâches de réponse aux questions.
combiner l'apprentissage par renforcement et l'apprentissage par imitation pour résoudre des tâches complexes de manipulation de robots à partir de pixels
Nous avons présenté BatchEnsemble, une méthode efficace d'assemblage et d'apprentissage permanent qui peut être utilisée pour améliorer la précision et l'incertitude de n'importe quel réseau neuronal comme les méthodes d'ensemble typiques.
Estimation des récompenses à partir de vidéos de jeux
Nous proposons une mesure de l'importance des phrases et des algorithmes pour l'explication hiérarchique des prédictions des modèles de séquences neuronales.
Un paramètre de momentum plus élevé $\beta$ permet de sortir plus rapidement des points de selle.
Nous décrivons comment améliorer un modèle de génération d'images en fonction d'un objectif lent ou difficile à évaluer, tel que le feedback humain, qui pourrait avoir de nombreuses applications, comme la réalisation d'images plus esthétiques.
L'algorithme que nous proposons n'utilise pas toutes les données non étiquetées pour l'apprentissage, mais plutôt de manière sélective.
Une nouvelle approche de la génération conditionnelle en contraignant l'espace latent d'un modèle génératif inconditionnel.
Nous quantifions le coût énergétique en termes d'argent (crédits cloud) et d'empreinte carbone de l'entraînement de modèles de réseaux neuronaux récemment réussis pour la PNL. Les coûts sont élevés.
L'élagage VAE est proposé pour rechercher des variables démêlées avec une dimension intrinsèque.
Les modèles de langage récurrents au niveau de l'octet apprennent des représentations du texte de haute qualité et spécifiques au domaine.
Analyse empirique et explication des estimateurs de gradient basés sur des particules pour l'inférence approximative avec des modèles génératifs profonds.
Apprentissage profond multi-étiquettes précis et évolutif avec des millions d'étiquettes.
Il est démontré que les GANs nous fournissent une nouvelle estimation efficace et robuste de la moyenne contre les contaminations agnostiques avec à la fois une optimalité statistique et une tractabilité pratique.
Nous présentons des modèles LSTM d'espace d'état, une combinaison de modèles d'espace d'état et de LSTM, et proposons un algorithme d'inférence basé sur le Monte Carlo séquentiel. 
Nous étendons l'algorithme wake-sleep et l'utilisons pour apprendre des modèles structurés à partir de quelques exemples, 
Protéines, séquences d'acides aminés, apprentissage automatique, apprentissage profond, réseau neuronal récurrent (RNN), mémoire à long terme (LSTM), unité récurrente à déclenchement (GRU), réseaux neuronaux profonds.
Détection de termes parlés, en utilisant la prédiction structurée et les réseaux profonds, en mettant en œuvre une nouvelle fonction de perte qui maximise à la fois l'AUC et le classement en fonction d'un seuil prédéfini.
Nous proposons un nouvel objectif d'optimisation qui encourage l'équité dans les réseaux fédérés hétérogènes, et développons une méthode évolutive pour le résoudre.
Nous proposons un nouveau modèle d'auto-codage avec une perte de reconstruction adversariale augmentée. Nous introduisons une nouvelle métrique pour l'évaluation des reconstructions basée sur le contenu. 
un algorithme d'apprentissage profond bayésien robuste pour inférer des a posteriori complexes avec des variables latentes
Nous avons étendu la décomposition tensorielle espace-temps d'un seul essai basée sur la factorisation de matrices non négatives afin d'écarter efficacement l'activité de base pré-stimulus, ce qui améliore les performances de décodage sur des données avec des lignes de base non négligeables.
Méthode de compression d'images extrêmes basée sur le GAN utilisant moins de la moitié des bits du codec conçu par SOTA tout en préservant la qualité visuelle.
Apprendre à classer en utilisant l'architecture Transformer.
L'article décrit un algorithme d'apprentissage stratégique à motivation intrinsèque qui s'attaque à l'apprentissage de politiques motrices complexes.
Nous utilisons le MCTS pour optimiser davantage une politique bootstrapped pour des espaces d'action continus dans un cadre d'itération de politique.
pourquoi les VAE précédents sur le texte ne peuvent pas apprendre une représentation latente contrôlable comme sur les images, ainsi qu'une solution pour permettre le premier succès vers la génération de texte contrôlé sans supervision.
Un nouveau modèle cortical hiérarchique pour l'encodage de la mémoire spatio-temporelle et la prédiction vidéo
Proposition d'une nouvelle méthodologie basée sur le contrefactuel pour évaluer les hypothèses générées par les cartes de saillance sur le comportement des agents RL profonds. 
La plupart des réseaux neuronaux se rapprochent de la même fonction de classification, même à travers les architectures, à travers toutes les étapes de l'apprentissage.
Représentez chaque entité sur la base de son histogramme de contextes et alors Wasserstein est tout ce dont vous avez besoin !
Méthodologies pour les systèmes de recommandation avec informations secondaires basées sur la régularisation de la norme de trace.
Ce travail présente un agent basé sur l'exploration et l'apprentissage par imitation capable d'atteindre des performances de pointe dans les jeux informatiques basés sur le texte. 
Dans l'élagage des réseaux neuronaux, la mise à zéro des poids élagués est importante, le signe de l'initialisation est essentiel, et le masquage peut être considéré comme un entraînement.
Nous avons proposé SesameBERT, une méthode de réglage fin généralisée qui permet d'extraire des informations globales parmi toutes les couches grâce à Squeeze et Excitation et d'enrichir les informations locales en capturant les contextes voisins via le flou gaussien.
Le façonnage de l'adversaire est une approche puissante de l'apprentissage multi-agents mais peut empêcher la convergence ; notre algorithme SOS résout ce problème avec de fortes garanties dans tous les jeux différentiables.
Nous montrons que la correspondance question-réponse est une tâche de pré-entraînement particulièrement bonne pour la similarité des questions et nous publions un ensemble de données pour la similarité des questions médicales.
Une étude sur l'avantage de partager la représentation dans l'apprentissage par renforcement multi-tâches.
Architectures profondes pour les nuages de points 3D qui sont équivoques par rapport aux rotations SO(3), ainsi qu'aux translations et aux permutations. 
Une comparaison et une analyse détaillée de divers modèles d'intégration de phrases à travers la tâche réelle du résumé automatique.
Nous proposons Value Propagation, un nouveau planificateur de bout en bout qui peut apprendre à résoudre des tâches de navigation en 2D par apprentissage par renforcement, et qui se généralise à des environnements plus vastes et dynamiques.
Proposition d'une méthode pour extraire et exploiter les interprétations des interactions de caractéristiques
Nous montrons qu'il est possible de récupérer les paramètres d'un modèle génératif ReLU à une couche à partir de l'examen d'échantillons générés par celui-ci
Apprenez des représentations vectorielles denses de types arbitraires de caractéristiques dans des ensembles de données étiquetés et non étiquetés.
Les automates finis peuvent être décodés linéairement à partir de RNN reconnaissant les langues à l'aide de fonctions d'abstraction peu grossières et de décodeurs très précis. 
Nous proposons HURRICANE pour relever le défi de la diversité matérielle dans la recherche d'une architecture neuronale à un coup.
Traduction automatique basée sur des phrases neuronales avec un temps de décodage linéaire
Nous proposons un GAN basé sur l'AE qui atténue l'effondrement des modes dans les GAN.
Apprentissage par renforcement et échantillonnage adaptatif pour une compilation optimisée des réseaux neuronaux profonds.
Nous concevons une grammaire apprise dans un cadre contradictoire et l'appliquons à la prédiction du futur dans une vidéo.
Nous proposons la mise en commun de Janossy, une méthode d'apprentissage de fonctions profondes invariantes par permutation conçue pour exploiter les relations au sein de la séquence d'entrée et des stratégies d'inférence réalisables telles qu'une procédure d'optimisation stochastique que nous appelons piSGD.
Un nouveau modèle de méta-apprentissage qui équilibre de manière adaptative l'effet du méta-apprentissage et de l'apprentissage spécifique à la tâche, ainsi que l'apprentissage spécifique à la classe au sein de chaque tâche.
Nous revisitons l'idée de l'architecture maître-esclave dans l'apprentissage par renforcement profond multi-agent et nous surpassons l'état de l'art.
Nous étudions le biais implicite des méthodes de gradient dans la résolution d'un problème de classification binaire avec des modèles ReLU non linéaires.
Une méthode d'élagage de modèle CNN utilisant l'ISTA et l'astuce de remise à l'échelle pour renforcer l'éparpillement des paramètres d'échelle dans la normalisation par lots.
Que pouvons-nous apprendre sur la formation des réseaux neuronaux si nous traitons chaque couche comme un problème de boosting de gradient ?
L'anticipation améliore la convergence de l'apprentissage par renforcement profond.
Nous constatons que le mouvement dans l'espace des fonctions n'est pas proportionnel au mouvement dans l'espace des paramètres pendant l'optimisation. Nous proposons un nouvel optimiseur de type gradient naturel pour résoudre ce problème.
Nous introduisons une famille générale de Lagrangiens qui permettent d'explorer la courbe IB dans tous les scénarios. Lorsque ceux-ci sont utilisés, et que la courbe IB est connue, on peut optimiser directement pour un niveau de performance/compression.
Nous proposons la Neural Logic Machine (NLM), une architecture neuronale-symbolique pour l'apprentissage inductif et le raisonnement logique.
Nous proposons un modèle neuronal de résumé abstrait sensible à la sémantique et un nouveau schéma d'évaluation du résumé automatique qui mesure la capacité d'un modèle à identifier les informations hors sujet à partir d'échantillons adverses.
Imprimez la phrase d'entrée et la phrase de réponse actuelle sur une image et utilisez le modèle ImageNet CNN finement ajusté pour prédire le prochain mot de réponse.
Nous permettons aux CNN ordinaires d'apprendre en quelques coups en exploitant les concepts visuels qui sont des indices visuels interprétables appris dans les CNN.
Appliquer un modèle d'équation différentielle ordinaire sur des données structurées en graphes
Proposition d'une nouvelle tâche, d'ensembles de données et de lignes de base ; la méthode CycleGAN de convoyage 3D préserve les propriétés des objets entre les images ; la structure des lots dans les méthodes au niveau des images est importante.
Un nouveau modèle évolutif et équivariant de groupe pour les réseaux de capsules qui préserve la compositionnalité sous les transformations et qui est empiriquement plus résistant aux transformations que les anciens modèles de réseaux de capsules.
L'article propose une base de référence simple mais efficace pour l'apprentissage avec des étiquettes bruyantes.
Les évaluateurs préfèrent l'adéquation de la traduction humaine à la traduction automatique lorsqu'ils évaluent des documents entiers, mais pas lorsqu'ils évaluent des phrases uniques.
Cet article étend l'apprentissage par imitation adversariale générative multi-agents aux jeux de Markov de forme extensive.
Nous revisitons l'autoformation en tant que méthode d'apprentissage semi-supervisée pour le problème de la génération de séquences neuronales, et nous montrons que l'autoformation peut être tout à fait réussie avec du bruit injecté.
Un modèle de mémoire générative qui combine des réseaux neuronaux à apprentissage lent et un modèle gaussien linéaire à adaptation rapide comme mémoire.
Nous présentons une nouvelle approche, SNIP, qui est simple, polyvalente et interprétable ; elle élague les connexions non pertinentes pour une tâche donnée en une seule fois avant la formation et est applicable à une variété de modèles de réseaux neuronaux sans modifications.
Une technique d'étiquetage automatique de grands ensembles de données non étiquetées afin de pouvoir entraîner des modèles sources pour l'apprentissage par transfert et son évaluation expérimentale. 
Notre article propose un module d'attention qui capture les relations inter-canaux et offre des gains de performance importants.
L'applicabilité de l'apprentissage par renforcement inverse est souvent entravée par le coût de la collecte de démonstrations d'experts ; cet article cherche à élargir son applicabilité en incorporant des informations sur les tâches antérieures grâce au méta-apprentissage.
Une nouvelle architecture neuronale où les couches denses supérieures des architectures convolutionnelles standard sont remplacées par une approximation d'une fonction noyau en s'appuyant sur l'approximation de Nyström.
Il y a des images non consensuelles et pornographiques dans le jeu de données ImageNet.
Cet article propose un nouveau cadre pour l'apprentissage de la similarité des graphes dans un scénario inductif et non supervisé.
Nous montrons comment les modèles de codage neuronal peuvent être entraînés pour capturer à la fois le signal et la variabilité de la stimulation des données de la population neuronale en utilisant les GAN.
Un cadre de regroupement basé sur l'apprentissage faiblement supervisé offre des performances comparables à celles des modèles d'apprentissage entièrement supervisés en exploitant le nombre unique de classes.
Une RL profonde basée sur un modèle qui fonctionne bien.
Nous analysons et déterminons les exigences de précision pour l'entraînement des réseaux neuronaux lorsque tous les tenseurs, y compris les signaux rétro-propagés et les accumulateurs de poids, sont quantifiés au format à virgule fixe.
Nous pouvons identifier des exemples prototypiques et aberrants dans l'apprentissage automatique qui sont quantifiablement très différents, et les utiliser pour améliorer de nombreux aspects des réseaux neuronaux.
Nous proposons d'améliorer le Deep Scattering Network afin d'améliorer le contrôle et la stabilité de tout pipeline d'apprentissage automatique donné en proposant un schéma de seuillage en ondelettes continues.
Regroupement neuronal sans avoir besoin d'un nombre de clusters
Le rapprochement des modèles est un cadre établi pour les explications des régimes, mais il peut être facilement détourné pour produire des mensonges.
Nous considérons de nouvelles variantes d'algorithmes d'optimisation pour la formation de réseaux profonds.
Nous accélérons l'inférence des RNN en réduisant dynamiquement les accès mémoire redondants en utilisant un mélange de modules précis et approximatifs.
Nous lançons une initiative visant à construire des systèmes de reconnaissance des erreurs permettant de reconnaître des milliers de types en fournissant une méthode pour construire automatiquement des ensembles de données appropriés basés sur la hiérarchie des types. 
Cet article propose une théorie de classification des invocations de méthodes par différents niveaux d'abstraction et une approche statistique pour la complétion de code du nom de la méthode à l'invocation de la méthode.
Nous nous concentrons sur la création d'adversaires universels pour tromper les détecteurs d'objets et cacher les objets aux détecteurs. 
Auto-codeur de Wasserstein avec espace latent hyperbolique
Méthode de compression des cartes de caractéristiques qui convertit les activations quantifiées en vecteurs binaires, suivie de couches de réduction de la dimensionnalité non linéaires intégrées dans un DNN.
Obtenir une forte robustesse contre les adversaires, comparable à la formation contre les adversaires sans formation sur des exemples contre les adversaires.
Nous apprenons un algorithme d'apprentissage non supervisé qui produit des représentations utiles à partir d'un ensemble de tâches supervisées. Au moment du test, nous appliquons cet algorithme à de nouvelles tâches sans aucune supervision et montrons des performances comparables à celles d'un VAE.
La sur-paramétrisation en largeur semble aider l'apprentissage par renforcement profond, tout comme l'apprentissage supervisé.
Modèle génératif hiérarchique (hybride de VAE et de GAN) qui apprend une représentation démêlée des données sans compromettre la qualité générative.
Nous introduisons une architecture légère pour la reconnaissance d'entités nommées et effectuons un apprentissage actif incrémentiel, qui est capable d'égaler les performances de l'état de l'art avec seulement 25% des données d'entraînement originales.
Nous formons des réseaux précis entièrement quantifiés en utilisant une fonction de perte maximisant la précision du modèle de pleine précision et minimisant la différence entre le réseau de pleine précision et le réseau quantifié.
Dans cet article, nous avons introduit un algorithme pour apprendre la connectivité des réseaux profonds multi-branches. L'approche est évaluée sur la catégorisation d'images où elle permet d'obtenir des gains de précision constants par rapport aux modèles de pointe qui utilisent une connectivité fixe.
Nous montrons que les unités individuelles dans les représentations CNN apprises dans les tâches NLP sont sélectivement sensibles aux concepts du langage naturel.
Nous proposons un nouveau cadre HRL, dans lequel nous formulons le problème de l'abstraction temporelle comme l'apprentissage d'une représentation latente de la séquence d'action.
Nous présentons les RNN MIST, qui a) présentent des propriétés de gradient de fuite supérieures à celles des LSTM ; b) améliorent considérablement les performances par rapport aux RNN LSTM et Clockwork pour les tâches nécessitant des dépendances à très long terme ; et c) sont beaucoup plus efficaces que les RNN NARX proposés précédemment, avec encore moins de paramètres et d'opérations que les LSTM.
(Version prête pour la caméra) Un module d'entrelacement de caractéristiques permettant de tirer parti des caractéristiques d'un ensemble précis pour faciliter l'apprentissage d'un autre ensemble moins fiable.
Un cadre d'apprentissage continu qui apprend à adapter automatiquement son architecture sur la base d'un algorithme d'inférence variationnelle proposé. 
Nous proposons Noisy-DR-L0-SSC (Noisy Dimension Reduction L0-Sparse Subspace Clustering) pour partitionner efficacement les données bruyantes en fonction de leur structure sous-espace sous-jacente.
Une nouvelle approche utilisant la connectivité des modes dans les paysages de pertes pour atténuer les effets adverses, réparer les modèles altérés et évaluer la robustesse des adversaires.
Un cadre GAN multi-générateurs avec un réseau supplémentaire pour apprendre une priorité sur le bruit d'entrée.
Les BigGAN ne rendent pas compte de la distribution des données d'ImageNet et n'ont qu'un succès modeste pour l'augmentation des données.
Nous présentons Leaf, un cadre d'évaluation modulaire pour l'apprentissage dans les données fédérées, avec des applications aux paradigmes d'apprentissage tels que l'apprentissage fédéré, le méta-apprentissage et l'apprentissage multi-tâches.
Nous introduisons une nouvelle perte d'intégration spatio-temporelle sur les vidéos qui génère une segmentation d'instance vidéo cohérente dans le temps, même avec des occlusions et des détections manquées, en utilisant l'apparence, la géométrie et le contexte temporel.
Cet article propose une méthode avancée d'optimisation des politiques avec l'expérience rétrospective pour l'apprentissage par renforcement à récompense clairsemée.
Nous explorons comment l'utilisation des connaissances de base avec la reformulation des requêtes peut aider à récupérer de meilleures preuves lors de la réponse à des questions scientifiques à choix multiples.
Nous comprimons les CNN profonds en réutilisant une seule couche convolutive de manière itérative, réduisant ainsi le nombre de paramètres par un facteur proportionnel à leur profondeur, tout en laissant leur précision largement inchangée.
Analyse spectrale pour comprendre comment différentes représentations peuvent améliorer l'optimisation et la généralisation.
Nous fournissons un support théorique aux estimations d'incertitude pour l'apprentissage profond obtenues en ajustant des prieurs aléatoires.
Nous proposons un cadre d'imputation de données conditionnées de manière arbitraire, fondé sur des autoencodeurs variationnels et des flux normalisateurs.
Nous développons une attaque contre la confidentialité qui peut récupérer les données d'entrée sensibles d'un réseau profond à partir de sa sortie.
Nous présentons une nouvelle méthode de génération de textes bilingues produisant des phrases parallèles concurrentes dans deux langues.
Nous introduisons l'explication en ligne pour prendre en compte l'exigence cognitive de l'humain pour comprendre l'explication générée par l'agent.
Nous proposons un algorithme d'échange de variables et de recalcul basé sur l'apprentissage par renforcement pour réduire le coût de la mémoire.
Différenciation temporelle itérative avec alignement de rétroaction aléatoire fixe soutenant la plasticité dépendant du temps de pointe dans la rétropropagation de vanille pour l'apprentissage profond.
Cet article propose l'utilisation d'un modèle acoustique génératif profond pour la reconnaissance automatique de la parole, en le combinant naturellement avec d'autres modules profonds de séquence à séquence en utilisant la règle de Bayes.
Nous proposons une nouvelle approche pour générer des exemples adverses basés sur la transformation spatiale, qui produit des exemples perceptivement réalistes par rapport aux attaques existantes. 
Un algorithme hybride DQN et DDPG est proposé pour traiter l'espace d'action hybride discret-continu.
Une nouvelle méthode de modélisation des graphes de connaissances basée sur les distances incorporées et les réseaux neuronaux.
Améliorer la stabilité de l'apprentissage des réseaux adversariens génératifs semi-supervisés avec l'apprentissage collaboratif
Nous montrons comment faire des prédictions à l'aide de réseaux profonds, sans former de réseaux profonds.
Graphon est un bon espace de recherche pour la recherche d'architectures neuronales et produit empiriquement de bons réseaux.
Entraînement adversarial adaptatif à l'instance pour améliorer le compromis robustesse/précision
Nous proposons une approche défensive de protection de la distinction et démontrons la forte capacité de distinction des exemples adverses.
Nous introduisons le NLC, une métrique qui est bon marché à calculer dans l'état initialisé aléatoirement des réseaux et qui est hautement prédictive de la généralisation, au moins dans les réseaux entièrement connectés.
combler les lacunes de l'informatique douce
Cet article présente MarginAttack, une attaque contradictoire sans confiance plus forte et plus rapide.
L'optimisation non supervisée pendant l'inférence donne un retour d'information descendant pour ajuster itérativement la prédiction de la variation d'échelle pour une reconnaissance plus équivariante.
Nous étudions les propriétés du Deep Image Prior récemment introduit (Ulyanov et al, 2017).
Nous proposons une méthodologie d'augmentation des données publiques disponibles pour les études de rumeurs basée sur la parenté samantique entre les données limitées étiquetées et non étiquetées.
Les convolutions dynamiques légères sont compétitives par rapport à l'auto-attention dans les tâches linguistiques.
Nous montrons comment l'inclusion d'une étape de gradient supplémentaire dans les méthodes de formation GAN de premier ordre peut améliorer la stabilité et conduire à de meilleurs résultats de convergence.
La normalisation par lots réduit la robustesse au moment du test aux corruptions courantes et aux exemples adverses.
Nous apprenons un algorithme d'optimisation qui se généralise à des tâches inédites.
Nous prédisons l'erreur de généralisation et spécifions le modèle qui l'atteint à travers les échelles modèle/données.
Méthode d'apprentissage par renforcement non supervisé pour l'apprentissage d'une politique permettant d'atteindre de manière robuste des objectifs spécifiés de manière perceptive.
Modèle de séquence qui ajuste dynamiquement la quantité de calcul pour chaque entrée.
Nous caractérisons les optima globaux problématiques de l'objectif VAE et présentons une nouvelle méthode d'inférence pour éviter ces optima.
Nous proposons un nouvel encastrement non supervisé des mots qui préserve la propriété d'inclusion dans la distribution du contexte et obtenons des résultats de pointe pour la détection non supervisée de l'hypernie.
Une approche basée sur la régularisation pour l'apprentissage continu utilisant des réseaux neuronaux bayésiens pour prédire l'importance des paramètres
Cet article explore l'utilisation d'une technologie d'augmentation sensorielle portable pour faciliter la prise de conscience directe de ce que c'est que d'avoir des moustaches de chat.
Nous donnons quelques limites d'erreur de généralisation des méthodes à gradient bruyant telles que SGLD, dynamique de Langevin, momentum bruyant, etc.
Pour l'apprentissage par renforcement à récompense clairsemée, l'ensemble de modèles dynamiques multiples est utilisé pour générer une récompense intrinsèque conçue comme le minimum de la surprise.
Nous étudions les représentations de la phonologie dans les modèles de réseaux de neurones du langage parlé avec plusieurs variantes de techniques analytiques.
Nous résolvons le problème spécifique de la RS des images JPG de faible qualité par des sous-modèles fonctionnels.
Nous proposons un modèle interprétable pour détecter les mots d'éveil choisis par l'utilisateur qui apprend à partir des exemples de l'utilisateur.
Nous proposons un modèle qui apprend à découvrir des images informatives dans une séquence vidéo future et à représenter la vidéo par ses images clés.
Nous apprenons une représentation profonde en maximisant l'information mutuelle, en tirant parti de la structure de l'objectif, et nous sommes capables de calculer avec des classificateurs entièrement supervisés avec des architectures comparables.
Nous proposons d'abord un estimateur d'importance atomique entièrement automatisé et orienté vers la cible, basé sur les réseaux neuronaux de graphes et un nouveau concept d'auto-attention inverse.
Regroupement spectral non supervisé à l'aide de réseaux neuronaux profonds
Nous constatons que les modèles profonds sont essentiels au fonctionnement de MAML et nous proposons une méthode qui permet un méta-apprentissage efficace dans des modèles plus petits.
La mise en commun est réalisée en utilisant des ondelettes au lieu des approches traditionnelles de voisinage (max, moyenne, etc.).
Nous proposons un nouveau cadre dynamique de covoiturage pour former des trajets qui optimisent à la fois la valeur opérationnelle pour le prestataire de services et la valeur pour les passagers en tenant compte des préférences sociales des utilisateurs dans le processus de prise de décision.
Nous caractérisons les propriétés dimensionnelles des sous-espaces adverses dans le voisinage des exemples adverses via l'utilisation de la dimensionnalité locale intrinsèque (LID).
Nous concevons et analysons un nouvel algorithme d'optimisation stochastique d'ordre zéro, ZO-signSGD, et démontrons sa connexion et son application aux attaques adversariales de type boîte noire dans l'apprentissage profond robuste.
Cet article propose une architecture de réseau neuronal récurrent unifié pour la prévision solaire à court terme et à horizon temporel multiple et valide les gains de performance de la prévision par rapport aux méthodes précédemment rapportées.
La connexion par saut dans ResNet et la normalisation par lots améliorent la capacité de séparation des données et aident à former un réseau neuronal profond.
Nous proposons un modèle génératif qui non seulement produit des données avec les caractéristiques souhaitées à partir de l'espace latent prédéfini, mais qui comprend aussi parfaitement les caractéristiques des données pour créer des caractéristiques qui ne figurent pas dans l'ensemble de données.
Un cadre pour étudier la communication émergente dans une configuration d'apprentissage par renforcement multi-agent en réseau.
Nous étendons les ensembles profonds aux encastrements fonctionnels et aux processus neuronaux pour inclure des membres équivariants de traduction.
Un modèle CNN équivariant de V1 qui surpasse les modèles précédents et suggère des groupements fonctionnels de neurones V1.
Redonner une large classe de procédures d'inférence à partir d'un objectif global de goulot d'étranglement de l'information.
La formation d'agents avec un calcul adaptatif basé sur le goulot d'étranglement de l'information peut promouvoir la généralisation. 
Nous avons utilisé une étude intra-sujet pour évaluer quatre visuels de respiration rythmée courants dans les applications mobiles afin de comprendre lequel est le plus efficace pour guider les exercices de respiration.
Une façon de générer des corpus d'entraînement pour la synthèse de codes neuronaux en utilisant un discriminateur entraîné sur des données non étiquetées.
Nous démontrons la vulnérabilité aux attaques de sous-sensibilité dans les modèles neuronaux de compréhension de la lecture SQuAD2.0 et NewsQA, où le modèle prédit la même réponse avec une confiance accrue à des questions choisies de manière contradictoire, et nous comparons les stratégies de défense.
L'utilisation de techniques de compression pour le codage des mots permet d'accélérer l'apprentissage du CNN et de réduire la dimensionnalité de la représentation.
Un formalisme d'optimisation de politique régularisé par l'entropie subsume un ensemble d'algorithmes d'apprentissage par prédiction de séquence. Un nouvel algorithme d'interpolation avec des résultats améliorés sur la génération de textes et l'apprentissage par imitation de jeux.
Nous proposons un modèle CNN purement convolutif avec un mécanisme d'attention pour prédire les flux d'origine-destination spatio-temporels. 
Nous proposons une nouvelle approche de formation adversariale appelée Robust Local Features for Adversarial Training (RLFAT) qui améliore considérablement la généralisation robuste à l'adversité et la généralisation standard.
Pourquoi et comment contraindre la vérification du modèle de domaine de planification avec des objectifs de planification pour éviter les contre-exemples inatteignables (résultats de vérification faux positifs).
StrokeNet est une nouvelle architecture où l'agent est entraîné à dessiner par traits sur une simulation différentiable de l'environnement, ce qui pourrait exploiter efficacement la puissance de la rétro-propagation.
Nous démontrons comment l'apprentissage automatique est capable de modéliser des expériences en physique quantique.
 un cadre d'apprentissage métrique non supervisé et non linéaire pour améliorer les performances des algorithmes de regroupement.
Face à des modèles complexes, de type boîte noire, le cryptage des données n'est pas aussi utilisable que l'approximation du modèle et son utilisation pour évaluer une transaction potentielle.
Système d'écriture interactif à base de stylet incorporant du son
Nous présentons un cadre d'encodage-décodage pour le transfert de style de langue, qui permet d'utiliser des données non parallèles et des données sources avec divers styles de langue inconnus.
Une nouvelle fonction de perte pour l'ACP avec des autoencodeurs linéaires qui permet d'obtenir des vecteurs propres exacts ordonnés. 
Cet article développe un cadre pour l'intégration des commentaires des utilisateurs en cas d'incertitude sur l'identité dans les bases de connaissances. 
Dans cet article, nous proposons un nouveau modèle génératif pour élaborer des attaques par empoisonnement systématique avec des contraintes de détectabilité contre les classificateurs d'apprentissage automatique, y compris les réseaux profonds. 
C'est l'algorithme quantique pour la maximisation de l'espérance. Il est rapide : le temps d'exécution ne dépend que polylogarithmiquement du nombre d'éléments de l'ensemble de données. 
Un algorithme d'optimisation clairsemé pour les modèles CNN profonds.
Une alternative simple et efficace à l'apprentissage par imitation adversariale : initialiser le tampon de relecture d'expérience avec des démonstrations, fixer leur récompense à +1, fixer la récompense pour toutes les autres données à 0, exécuter Q-learning ou soft actor-critic pour s'entraîner.
Nous présentons une nouvelle architecture profonde, VarPSOM, et son extension aux données de séries temporelles, VarTPSOM, qui permettent d'obtenir des performances de regroupement supérieures aux méthodes actuelles de regroupement profond sur des données statiques et temporelles.
Nous analysons les tâches qu'il est préférable d'apprendre ensemble dans un seul réseau, et celles qu'il est préférable d'apprendre séparément. 
Un cadre sémantique profond pour la recherche de documents dans les moteurs de recherche textuels
Nous proposons un nouvel algorithme basé sur le transport optimal pour entraîner un CNN de manière SSL.
La normalisation par lots réduit la robustesse des adversaires, ainsi que la robustesse générale dans de nombreux cas, notamment aux corruptions dues au bruit.
Apprendre les HGNs, les domaines de la ND
un méta-apprentissage simple basé sur les RNN, qui atteint des performances SOTA sur des repères populaires
Soumis dans EMNLP
Nous présentons un nouvel environnement de football MuJoCo pour la recherche sur l'apprentissage par renforcement multi-agent en continu, et nous montrons que l'entraînement par population d'apprenants par renforcement indépendants peut apprendre des comportements coopératifs.
Utilisation de la grammaire DSL et de l'apprentissage par renforcement pour améliorer la synthèse de programmes avec un flux de contrôle complexe.
Nous proposons un nouveau modèle de série temporelle à espace d'état capable de capturer la structure des points de changement et des points d'anomalie, afin d'obtenir de meilleures performances de prévision lorsqu'il existe des points de changement et des anomalies dans la série temporelle.
Un transformateur multimodal pour l'apprentissage séquentiel multimodal, avec de solides résultats empiriques sur des métriques linguistiques multimodales telles que l'analyse multimodale des sentiments, la reconnaissance des émotions et des traits de personnalité. 
Nous utilisons un coefficient adaptatif en plus du momentum régulier inspiré de l'optimisation géodésique qui accélère considérablement l'apprentissage dans les fonctions convexes et non convexes.
Nous utilisons un codeur transformateur pour effectuer la traduction en l'entraînant dans le style d'un modèle de traduction masqué.
Nous présentons les ensembles locaux, une méthode pour détecter l'extrapolation dans les modèles entraînés, qui approxime la variance d'un ensemble en utilisant des informations locales de second ordre.
La protection de la vie privée peut être envisagée de la même manière que les autres ressources lors de la planification.
apprentissage par représentation démêlée
Nous proposons une approche de formation contradictoire au problème de la génération de questions de clarification qui utilise la réponse à la question pour modéliser la récompense. 
L'utilisation du partitionnement à coût saturé pour sélectionner les motifs est préférable à tous les algorithmes de sélection de motifs existants.
L'utilisation de l'attention ramifiée avec des poids de combinaison appris surpasse le transformateur de base pour les tâches de traduction automatique.
Apprentissage hybride par imitation piloté par la vision et apprentissage par renforcement basé sur un modèle pour la planification, la prévision et le contrôle.
Nous mettons en évidence les problèmes posés par les mesures courantes de l'incertitude dans le domaine et effectuons une étude approfondie des techniques modernes d'assemblage.
Développer un cadre général pour établir la robustesse certifiée des modèles ML contre diverses classes de perturbations adverses.
Nous proposons un modèle génératif à variables latentes pour la décomposition non supervisée de scènes qui fournit une représentation factorisée des objets par objet de premier plan tout en décomposant également les segments d'arrière-plan de morphologie complexe.
Nous proposons une extension de l'auto-codeur variationnel conditionnel qui permet de conditionner un sous-ensemble arbitraire de caractéristiques et d'échantillonner les autres.
Dans cet article, nous proposons une représentation d'architecture hiérarchique dans laquelle la recherche d'architecture aléatoire ou évolutionnaire donne des résultats très compétitifs en utilisant moins de ressources informatiques que l'art antérieur.
Nous proposons la mémoire topologique hallucinante (HTM), un algorithme de planification visuelle capable d'effectuer une planification à horizon long dans de nouveaux environnements. 
Nous proposons d'accélérer la normalisation par lots (BN) en échantillonnant des données moins corrélées pour les opérations de réduction avec un modèle d'exécution régulier, ce qui permet d'atteindre une accélération de 2x et 20% pour la BN elle-même et l'entraînement global, respectivement.
Apprentissage fédéré efficace en termes de communication avec correspondance par couche
Apprendre avec des données de formation limitées en exploitant les instances "utiles" d'une source de données riche.  
un nouvel algorithme d'optimisation sans dérivation dérivé des méthodes de gradient accéléré de Nesterov et de la dynamique hamiltonienne
Back-Propagation binarisée : tout ce dont vous avez besoin pour une formation complètement binarisée est de gonfler la taille du réseau.
Comment choisir efficacement les fonctions d'initialisation et d'activation pour les réseaux neuronaux profonds ?
Nous présentons les décompositions contextuelles, un algorithme d'interprétation pour les LSTM capable d'extraire le score d'importance au niveau des mots, des phrases et des interactions.
Cet article propose une nouvelle méthode de masquage complexe pour l'amélioration de la parole ainsi qu'une fonction de perte pour une estimation efficace de la phase.
Apprendre un comportement émergent en minimisant la surprise bayésienne avec RL dans des environnements naturels avec entropie.
Les représentations profondes combinées à la descente de gradient peuvent se rapprocher de n'importe quel algorithme d'apprentissage.
Nous présentons une interface cerveau-machine en boucle ouverte dont les performances ne sont pas limitées par l'approche traditionnelle du sac de mots.
Nous présentons un encastrement de réseau complet de CNN qui surpasse les encastrements à couche unique pour les tâches d'apprentissage par transfert.
Nous présentons une nouvelle méthode d'élagage du réseau qui permet de trouver la structure éparse optimale pendant le processus de formation avec un seuil d'élagage entraînable.
Nous évaluons la plausibilité biologique des nouveaux algorithmes d'apprentissage ML dans l'abstrait, sur la base des opérations mathématiques nécessaires.
Nous présentons une méthode permettant d'entraîner des modèles dont la robustesse est prouvée par rapport à toutes les normes $l_p$ pour $p\geq 1$ simultanément.
Nous proposons une nouvelle méthode pour gérer les dégradations d'images de différents niveaux en apprenant un temps terminal de diffusion. Notre modèle peut être généralisé à des niveaux de dégradation non vus et à différentes statistiques de bruit.
Nous montrons qu'il est possible d'approximer rapidement le calcul des distances de Wasserstein en trouvant un encastrement approprié où la distance euclidienne émule la distance de Wasserstein.
Nous présentons un nouveau schéma de formation pour obtenir efficacement des représentations de phrases tenant compte de l'ordre.
La paramétrisation récursive des modèles récurrents améliore les performances 
Une étude comparative de modèles génératifs sur des scénarios d'apprentissage continu.
en posant et en résolvant d'abord le problème d'optimisation de l'efficacité de l'échantillon dans l'espace de politique non paramétrée, puis en résolvant un problème de régression supervisée pour trouver une politique paramétrée qui est proche de la politique non paramétrée optimale.
Une approche axée sur les objectifs pour modéliser quatre aires visuelles de la souris (V1, LM, AL, RL), basée sur des réseaux neuronaux profonds entraînés à la reconnaissance statique d'objets, ne dévoile pas une organisation fonctionnelle du cortex visuel, contrairement aux primates.
un modèle de gradient basé sur la transformation généralisée pour l'inférence variationnelle
Nous introduisons un nouveau modèle de langage à contexte élargi qui capture simultanément la syntaxe et la sémantique, ce qui le rend capable de générer des phrases et des paragraphes hautement interprétables.
Nous formons un agent de peinture de médias naturels en utilisant un modèle d'environnement. Sur la base de notre agent de peinture, nous présentons une nouvelle approche pour former un agent de peinture contraint qui suit la commande encodée dans l'observation.
Nous avons développé un cadre de recherche et une pénalité de cohérence pour atténuer le biais de délire.
Le système proposé peut empêcher les usurpateurs de visage d'effectuer une transaction frauduleuse en utilisant un DCNN pré-entraîné.
analyse théorique d'un auto-codeur large non-linéaire
Nous présentons la première approche RL hiérarchique qui réussit à apprendre des hiérarchies à 3 niveaux en parallèle dans des tâches avec des espaces d'état et d'action continus.
Cet article étudie le problème de classification PUbN, où nous incorporons des données négatives biaisées (bN), c'est-à-dire des données négatives qui ne sont pas entièrement représentatives de la véritable distribution négative sous-jacente, dans l'apprentissage positif non étiqueté (PU).
Les pratiques de renforcement des performances de la traduction automatique ne proviennent pas forcément de meilleures prédictions.
Nous entraînons un petit CNN efficace avec les mêmes performances que le Transformer d'OpenAI sur des tâches de classification de texte.
Méthode d'ensemble pour l'apprentissage par renforcement qui pondère les fonctions Q en fonction des erreurs de TD accumulées.
Bsuite est une collection d'expériences soigneusement conçues qui étudient les capacités fondamentales des agents RL.
une préformation améliorée, et l'analyse de la sortie de l'encodeur et de l'attention
Une formulation pour une boîte noire, méthode d'apprentissage par renforcement pour trouver la défaillance la plus probable d'un système agissant dans des scénarios complexes.
Utiliser des algorithmes sans modèle tels que DQN/TRPO pour résoudre des problèmes à court terme (sans modèle) de manière itérative selon un mode d'itération politique/valeur.
Nous montrons que même les méthodes d'apprentissage adversariales les plus solides ne peuvent pas se défendre contre des exemples adversariaux créés sur des images de test légèrement mises à l'échelle et décalées.
Améliorer les activations saturantes (sigmoïde, tanh, htanh, etc.) et le réseau neuronal binarisé avec initialisation du biais.
l'utilisation de réseaux neuronaux profonds et d'algorithmes intelligents pour capturer les concepts visuels mentaux humains
Nous présentons une nouvelle attaque ciblée de type boîte noire qui est capable de tromper la transcription de la parole en texte de l'état de l'art.
Synthèse des mouvements humains sur des tâches interactives à l'aide de données mocap et de RL hiérarchique.
Analyse de la convergence et de l'effondrement des modes en étudiant le processus de formation du GAN comme une minimisation des regrets.
Nous proposons un nouveau cadre pour évaluer l'interprétabilité des réseaux neuronaux.
Un agent RL profond qui apprend les valeurs Q hyperboliques (et autres non exponentielles) et une nouvelle tâche auxiliaire multi-horizon.
Cet article présente la détection des émotions d'une personne envers un stimulus d'image basée sur l'EEG et son applicabilité au neuromarketing.
Approximations variationnelles rapides pour l'approximation de l'état d'un utilisateur et l'apprentissage d'encastrements de produits
Nous présentons une fonction d'évaluation prouvable et facilement calculable qui estime la performance des représentations transférées d'une tâche d'apprentissage à une autre dans l'apprentissage par transfert de tâche.
Nous proposons un schéma d'apprentissage conditionnel contradictoire fiable ainsi qu'un cadre simple, générique mais efficace pour les tâches UDA.
De la distance au noyau et à l'intégration via des caractéristiques aléatoires pour des entrées structurées
Un noyau d'inspiration quantique pour un réseau de convolution, présentant des phénomènes d'interférence, peut être très utile (et comparé à son homologue en valeur réelle).
Une plateforme de jeu de recherche inspirée de MMO pour étudier les comportements émergents de grandes populations dans un environnement complexe
Cet article améliore l'évaluation existante basée sur les échantillons pour les GAN et contient quelques expériences intéressantes.
Les réseaux neuronaux binaires résiduels améliorent considérablement le taux de convergence et la précision d'inférence des réseaux neuronaux binaires.
Méthode non supervisée de détection d'échantillons contradictoires dans l'espace des activations et des erreurs de reconstruction d'un auto-encodeur
Nous proposons d'apprendre des représentations d'entités et de relations connaissables à partir de Bert pour l'intégration de graphes de connaissances.
Un module neuronal différentiable évolutif qui implémente le raisonnement sur des KBs symboliques.
DCEM apprend des domaines latents pour les problèmes d'optimisation et aide à combler le fossé entre la RL basée sur un modèle et la RL sans modèle --- nous créons un contrôleur différentiable et en affinons certaines parties avec PPO.
Nous utilisons des récompenses dynamiques pour entraîner les extracteurs d'événements.
Les GANs bénéficient d'une mise à l'échelle.
L'erreur conjointe est importante pour l'adaptation non supervisée du domaine, surtout lorsque le changement de domaine est important.
Le "Knowledge Flow" forme un réseau profond (l'étudiant) en injectant des informations provenant de plusieurs réseaux (les enseignants). L'étudiant est indépendant de la formation et obtient de très bons résultats sur les tâches apprises, quel que soit le contexte (apprentissage par renforcement ou supervisé).
Une estimation efficace du premier moment gaussien des DNN comme régularisateur pour la formation de réseaux robustes.
Nous proposons des cascades neuronales, une approche simple et trivialement parallélisable de la compréhension de la lecture, composée uniquement de réseaux de type feed-forward et d'attention, qui atteint des performances de pointe sur le jeu de données TriviaQA.
Nous faisons progresser l'état de l'art en matière de compression de modèles en proposant les réseaux de compression atomique (ACN), une nouvelle architecture construite par la répétition récursive d'un petit ensemble de neurones.
Nous démontrons que les modèles génératifs basés sur le flux offrent une approche viable et compétitive de la modélisation générative de la vidéo.
Nous fournissons une analyse théorique et empirique sur le rôle du bruit anisotrope introduit par le gradient stochastique sur l'échappement des minima.
Gradient de politique par rétropropagation dans le temps en utilisant des modèles appris et des fonctions Q. Résultats de SOTA dans des environnements de référence d'apprentissage par renforcement.
Méta-apprentissage sur des distributions de tâches auto-proposées pour accélérer l'apprentissage par renforcement sans distributions de tâches spécifiées par l'homme. 
Une méthode nouvelle et pratiquement efficace pour adapter des réseaux neuronaux pré-entraînés à de nouvelles tâches en réentraînant un nombre minimal (par exemple, moins de 2 %) de paramètres.
Une nouvelle explication théorique de l'existence d'exemples contradictoires
Elastic-InfoGAN est une modification d'InfoGAN qui apprend, sans aucune supervision, des représentations démêlées dans des données déséquilibrées par classe.
un cadre de partage des connaissances basé sur l'espace latent distribué pour l'apprentissage multi-tâches profond
Game Changer est un système qui fournit à la fois des descriptions audio et des ajouts tactiles pour rendre l'état du jeu de société accessible aux joueurs aveugles et malvoyants.
Le couplage de la supervision de règles-exemplaires et d'une perte d'implication permet d'apprendre conjointement à débruiter les règles et à impliquer les étiquettes.
Notre méthode introduit l'apprentissage par renforcement inverse à entropie maximale régularisée par autonomisation pour apprendre des récompenses et des politiques quasi-optimales à partir de démonstrations d'experts.
Les RNN mettent implicitement en œuvre des représentations par produit tensoriel, une méthode fondée sur des principes et interprétable pour représenter des structures symboliques dans un espace continu.
L'augmentation des données apprises inculque des biais inductifs favorables aux algorithmes qui permettent aux RNN d'apprendre des algorithmes de traitement de listes à partir de moins d'exemples.
Nous proposons un problème spécial d'apprentissage multi-labels faiblement supervisé ainsi qu'un algorithme nouvellement adapté qui apprend le classificateur sous-jacent en apprenant à attribuer des pseudo-étiquettes.
Un assistant de recherche conversationnel basé sur l'apprentissage par renforcement qui fournit une assistance contextuelle dans la recherche subjective (comme les biens numériques).
Les réseaux neuronaux convolutifs se comportent comme des plus proches voisins compositionnels !
Factoriser les états LSTM et les matrices de poids LSTM à zéro/liaison selon les biais structurels du monde réel exprimés par des programmes Datalog.
Nous proposons une approche novatrice pour résoudre les problèmes d'optimisation basés sur des modèles axés sur les données dans des contextes passifs et actifs, qui peut s'adapter à des espaces d'entrée à haute dimension.
Dans cet article, nous proposons un nouveau modèle d'encodeur-décodeur basé sur les représentations par produit tensoriel pour la génération de langage naturel à formel, appelé TP-N2F.
Cet article présente un defogger, un modèle qui apprend à prédire les futures informations cachées à partir d'observations partielles, appliqué à un jeu de données StarCraft.
Nous étudions la généralisation des réseaux neuronaux dans le méta-apprentissage basé sur le gradient en analysant diverses propriétés du paysage objectif.
Nous présentons un modèle génératif qui donne des résultats de pointe sur des images en échelle de gris et naturelles.
Nous proposons un nouveau réseau appelé le réseau récurrent d'identité (RIN) qui permet à un réseau récurrent ordinaire de surmonter le problème du gradient de fuite tout en formant des modèles très profonds sans utiliser de portes.
Le document aborde la tolérance aux pannes en cas d'arrêts aléatoires et adversaires.
Nous présentons une nouvelle architecture unifiée qui restaure les images vidéo à partir d'une seule image floue de bout en bout.
Nous proposons une nouvelle technique d'élagage structurée et aveugle aux classes pour produire des réseaux neuronaux hautement compressés.
Nous utilisons des approximations de la somme de Kronecker pour la formation de rangs bas afin de relever les défis de la formation de réseaux neuronaux sur des dispositifs périphériques qui utilisent des technologies de mémoire émergentes.
Examine systématiquement dans quelle mesure nous pouvons expliquer les caractéristiques cachées d'un réseau profond en termes de règles logiques.
Amélioration des estimations de la vraisemblance dans les auto-codeurs variationnels à l'aide de l'apprentissage autogéré des caractéristiques.
Cet article montre que les méthodes de gradient de politique sans modèle peuvent converger vers la solution optimale globale pour les problèmes de contrôle linéarisés non convexes.
Nous utilisons la théorie de la détection comprimée pour prouver que les LSTM peuvent faire au moins aussi bien que les Bag-of-n-Grams pour la classification de textes linéaires.
Nous introduisons de nouvelles couches de convolution ponctuelles équipées de transformées conventionnelles extrêmement rapides dans un réseau neuronal profond.
Nous proposons d'utiliser des treillis pour représenter les objets et prouvons un résultat fondamental sur la façon d'entraîner les réseaux qui les utilisent.
Nous essayons de concevoir et d'entraîner un classificateur dont la robustesse à l'adversité ressemble davantage à la robustesse humaine.
Nous proposons un modèle de GAN de Wasserstein discret (DWGAN) qui est basé sur une double formulation de la distance de Wasserstein entre deux distributions discrètes.
Il s'agit d'une nouvelle architecture AGI pour des performances transsapiennes. Il s'agit d'un aperçu de haut niveau de l'architecture AGI Omega qui est la base d'un système d'automatisation de la science des données. Soumis à un atelier. 
Nous proposons le mécanisme Flow et une architecture de bout en bout, FlowQA, qui permet d'atteindre la SotA sur deux ensembles de données d'AQ conversationnelle et une tâche de compréhension d'instructions séquentielles.
Nous présentons un nouvel algorithme pour résoudre les problèmes d'apprentissage par renforcement et de prédiction structurée par bandit avec un retour de perte très clairsemé.
Nous présentons une modification simple de la méthode SGD alternée, appelée étape de prédiction, qui améliore la stabilité des réseaux adverses.
Cet article présente des compilations indépendantes du domaine des questions des utilisateurs en contraintes pour des explications contrastives.
 Nous intégrons les nœuds d'un graphe sous forme de distributions gaussiennes, ce qui nous permet de saisir l'incertitude quant à leur représentation.
Les méthodes de régularisation Logit permettent d'expliquer et d'améliorer les défenses adversariales de l'état actuel des connaissances.
Nous décrivons un langage modulaire et composable pour décrire des espaces de recherche expressifs sur des architectures et des algorithmes simples de recherche de modèles appliqués à ces espaces de recherche. 
Nous montrons que les techniques de transfert de connaissances peuvent améliorer la précision des réseaux à faible précision et établir un nouvel état de l'art pour la précision ternaire et à 4 bits. 
L'article présente un mécanisme de formation amélioré permettant d'obtenir des réseaux binaires avec une baisse de précision moindre, ce qui permet de combler l'écart avec son homologue de pleine précision.
Cadre unifié pour effectuer des regroupements à l'aide de réseaux neuronaux profonds
HYPE est une métrique d'évaluation humaine fiable pour noter les modèles génératifs, en commençant par la génération de visages humains à travers 4 GANs.
Nous proposons un nouveau modèle de traduction automatique non supervisé qui peut apprendre sans utiliser de corpus parallèles. Les résultats expérimentaux montrent des performances impressionnantes sur plusieurs corpus et paires de langues.
Nous récompensons les agents qui ont une influence causale sur les actions des autres agents, et nous montrons que cela donne lieu à une meilleure coopération et à des protocoles de communication émergents plus significatifs. 
Nous développons un agent que nous appelons l'algorithme Distributional Deterministic Deep Policy Gradient, qui atteint des performances de pointe sur un certain nombre de problèmes de contrôle continu difficiles.
Nous proposons une nouvelle fonction de valeur Q qui permet un meilleur apprentissage des politiques gaussiennes.
Nous présentons KG-A2C, un agent d'apprentissage par renforcement qui construit un graphe de connaissances dynamique tout en explorant et en générant du langage naturel à l'aide d'un espace d'action basé sur des modèles, ce qui lui permet de surpasser tous les agents actuels dans un large éventail de jeux basés sur le texte.
Nous prouvons que les réseaux neuronaux profonds sont exponentiellement plus efficaces que les réseaux peu profonds pour l'approximation des polynômes multivariés épars.
Nous proposons un classement des neurones du CNN avec deux méthodes différentes et montrons leur cohérence pour produire le résultat qui permet d'interpréter ce que le réseau juge important et de compresser le réseau en gardant les nœuds les plus pertinents.
Une approche modulaire et hiérarchique pour apprendre des politiques d'exploration d'environnements 3D.
Une méthode d'adaptation non supervisée du domaine réel au domaine simulé pour la segmentation sémantique utilisant les informations privilégiées d'un simulateur avec une traduction d'image basée sur le GAN.
Le premier diagnostic de rigueur de l'entraînement adversarial à grande échelle sur ImageNet
Attribuer les termes de biais des réseaux neuronaux profonds aux caractéristiques d'entrée par un algorithme de type rétropropagation ; Générer des explications complémentaires et hautement interprétables des DNNs en plus des attributions basées sur le gradient.
Cet article présente une méthode pour trouver de manière autonome de multiples périodicités dans un signal, en utilisant la FFT et l'ACF et en ajoutant trois nouvelles étapes (clustering/filtrage/detrending).
Un système d'apprentissage par imitation simple mais efficace qui encourage l'exploration d'un environnement sans récompense extrinsèque ni démonstration humaine.
 un nouveau cadre utilisant l'espace dual pour générer des images correspondant à des étiquettes multi-classes lorsque le nombre de classes est important
Nous présentons un nouveau ConvNet à graphe à action directe basé sur la généralisation de la transformée de diffusion en ondelettes de Mallat, et nous démontrons son utilité dans les tâches de classification de graphes et d'exploration de données.
Nous présentons un ensemble de données de réception à grande échelle pour les tâches d'analyse syntaxique post-OCR.
Accélération de l'apprentissage du CNN sur un pipeline d'accélérateurs avec des poids statiques
Nous montrons que les réseaux profonds sont non seulement trop sensibles aux changements non pertinents de leur entrée, mais aussi trop invariants à un large éventail de changements pertinents, rendant ainsi de vastes régions de l'espace d'entrée vulnérables aux attaques adverses.
Amélioration de l'entraînement des modèles génératifs actuels basés sur le flux (Glow et RealNVP) sur des repères d'estimation de la densité.
Les réseaux neuronaux profonds formés avec l'augmentation des données ne nécessitent aucune autre régularisation explicite (comme la décroissance et l'abandon des poids) et présentent une plus grande adaptabilité aux changements d'architecture et à la quantité de données de formation.
Cet article améliore la qualité de l'approche AFL (adversarial feature leaning) récemment proposée pour incorporer des contraintes explicites aux représentations, en introduisant le concept de la vulnérabilité de l'adversaire. 
Nous étendons un auto-codeur variationnel récurrent efficace pour les systèmes dynamiques afin de modéliser une instance de hiérarchie de systèmes dynamiques en neurosciences en utilisant la méthode de l'échelle.
Nous introduisons un processus de quantification efficace qui permet d'accélérer les performances sur un accélérateur de réseau neuronal spécialisé en nombres entiers uniquement.
Cet article propose un nouveau modèle CNN qui combine le coût énergétique avec une stratégie de routage dynamique pour permettre une inférence adaptative et économe en énergie.
nous présentons LSH Softmax, une couche d'approximation softmax pour l'apprentissage et l'inférence sub-linéaires avec de fortes garanties théoriques ; nous démontrons à la fois son applicabilité et son efficacité en l'évaluant sur une tâche du monde réel : la modélisation du langage.
RL peut résoudre des problèmes (stochastiques) de multi-robots et d'ordonnancement de manière évolutive et transférable en utilisant l'intégration de graphes.
Nous présentons un nouvel algorithme d'apprentissage par curriculum basé sur la notion de taux de maîtrise qui surpasse les algorithmes précédents.
S'inspirer des processus dendritiques locaux de l'apprentissage néocortical pour rendre l'apprentissage non supervisé à nouveau génial.
Réseaux de mémoire avec inférence plus rapide
En s'inspirant de la linguistique, et plus particulièrement de l'hypothèse de la grammaire universelle, nous apprenons des représentations universelles agnostiques à la langue, que nous pouvons utiliser pour effectuer un apprentissage zéro-temps entre les langues.
Cet article montre que l'objectif de distance de Wasserstein permet l'entraînement de modèles à variables latentes avec des latents discrets dans un cas où l'objectif d'autoencodeur variationnel ne le fait pas.
Un réseau neuronal graphique capable d'apprendre automatiquement et de tirer parti d'une structure graphique interactive dynamique.
Un nouvel algorithme pour la formation de réseaux neuronaux qui se compare favorablement aux méthodes adaptatives populaires.
Souligne les problèmes de la fonction de perte utilisée dans IRGAN, un cadre GAN récemment proposé pour la recherche d'information. En outre, un modèle motivé par la co-formation est proposé, qui permet d'obtenir de meilleures performances.
Nous proposons l'apprentissage par représentation de l'utilisateur fédéré (FURL), un moyen simple, évolutif, préservant la confidentialité et efficace en termes de bande passante d'utiliser les techniques de personnalisation neuronale existantes dans le cadre de l'apprentissage fédéré (FL).
Autoencodeurs pour le texte avec une nouvelle méthode d'utilisation de l'espace latent discret.
Espace latent manifold-structuré pour les modèles génératifs
LoopGAN étend la longueur des cycles dans CycleGAN pour permettre une transformation séquentielle non alignée pour plus de deux pas de temps.
Nous proposons SWAP, un algorithme distribué pour l'entraînement de réseaux neuronaux en grand nombre.
Un nouvel algorithme d'apprentissage à grande échelle basé sur le LARS (Layer-wise Adaptive Rate Scaling) ; à l'aide de LARS, nous avons mis à l'échelle AlexNet et ResNet-50 pour un lot de 16K.
Apprentissage d'opérateurs Koopman compositionnels pour une identification efficace des systèmes et un contrôle basé sur des modèles.
Nous présentons une procédure de calcul du gradient à mémoire constante par le biais de solutions d'équations différentielles stochastiques (EDS) et appliquons la méthode à l'apprentissage de modèles EDS latents.
Apprendre des transformations préservant la confidentialité à partir de données. Une approche collaborative
Nous proposons plusieurs fonctions de récompense intrinsèque pour encourager l'exploration coordonnée dans les problèmes multi-agents, et nous introduisons une approche pour sélectionner dynamiquement la meilleure méthode d'exploration pour une tâche donnée, en ligne.
Nous proposons d'apprendre à synthétiser des classificateurs à quelques coups et des classificateurs à plusieurs coups en utilisant une seule fonction objective pour le GFSL.
Nous combinons la recherche A* avec l'apprentissage par renforcement pour accélérer le code d'apprentissage automatique.
L'apprentissage par renforcement profond, efficace en termes de données, peut être utilisé pour apprendre des politiques d'empilage précises.
paramétrages des politiques et estimateurs sans biais de l'entropie des politiques pour les MDP avec un grand espace d'action discret multidimensionnel
Décomposer les poids pour utiliser moins de FLOPs avec SVD
Convergence asymptotique de la méthode stochastique de sous-gradien avec momentum dans le cadre d'un calcul asynchrone parallèle général pour une optimisation générale non convexe non lisse.
Nous présentons un estimateur à faible biais pour les modèles booléens à variables stochastiques avec de nombreuses couches stochastiques.
Nous proposons une nouvelle méthode pour manipuler des images données en utilisant des descriptions en langage naturel.
Utiliser une méthode basée sur le GAN pour résoudre de manière évolutive le transport optimal.
En exploitant le contrôle comme inférence et les méthodes de Monte Carlo séquentiel, nous avons proposé un algorithme de planification probabiliste.
Une modification simple du GAN qui améliore les performances sur de nombreuses pertes, architectures, schémas de régularisation et ensembles de données. 
Comment estimer le vecteur de probabilité original pour des millions de classes à partir de mesures d'esquisses de comptage - une configuration théorique et pratique.
Vous pouvez corriger le classificateur dans les réseaux neuronaux sans perdre en précision.
Apprendre à détecter des objets sans étiquette d'image à partir de 3 minutes de vidéo
Nous présentons ReClor, un ensemble de données de compréhension de la lecture nécessitant un raisonnement logique, et nous constatons que les modèles actuels de pointe ont du mal à effectuer un véritable raisonnement logique, avec des performances médiocres proches de celles d'une estimation aléatoire.
Entrer seulement le bruit, glaner les sorties du softmax, voler les poids.
Nous proposons une nouvelle forme de modèle d'auto-codage qui incorpore les meilleures propriétés des auto-codeurs variationnels (VAE) et des réseaux adversariens génératifs (GAN).
Nous utilisons la connexion entre le méta-apprentissage basé sur le gradient et les Bayes hiérarchiques pour apprendre un mélange de méta-apprenants qui est approprié pour une distribution de tâches hétérogènes et évolutives.
Nous présentons une nouvelle méthode de routage pour les réseaux Capsule, et ses performances sont équivalentes à celles de ResNet-18 sur CIFAR-10/ CIFAR-100.
Nous présentons Doc2Dial, un cadre de bout en bout pour générer des données conversationnelles fondées sur des documents commerciaux via le crowdsourcing pour former des agents de dialogue automatisés.
Nous présentons un modèle génératif autorégressif pour les spectrogrammes et démontrons des applications à la génération de la parole et de la musique.
Les CNN profonds modernes ne sont pas invariants aux translations, mises à l'échelle et autres transformations réalistes des images, et ce manque d'invariance est lié à l'opération de sous-échantillonnage et aux biais contenus dans les ensembles de données d'images.
Synthétiser des mouvements humains complexes et étendus à l'aide d'un réseau LSTM auto-conditionné
Nous concevons un mécanisme appelé concurrence entre les pixels qui permet aux méthodes de saillance (approximativement) complètes de passer les contrôles de sanité.
Classification d'images par interrogation itérative d'une image de référence d'une classe candidate avec un RNN et utilisation d'un CNN pour la comparer à l'image d'entrée.
nous définissons pour la première fois le problème de l'élagage au niveau du filtre pour les réseaux neuronaux binaires et proposons une méthode pour le résoudre.
Réduction de la complexité de calcul et de mémoire des modèles RNN jusqu'à 100x en utilisant des modules de compression à faible rang clairsemés, formés par distillation des connaissances.
Nous comparons les RNNs à graphes et les ConvNets à graphes, et nous considérons la classe la plus générique de ConvNets à graphes avec résidualité.
Comparaison des perceptrons multicouches à valeurs complexes et réelles en fonction du nombre de paramètres à valeurs réelles.
Un réseau neuronal convolutionnel à graphe spectral avec des propriétés de zoom spectral.
Nous présentons un modèle de segmentation en temps réel découvert automatiquement par un cadre NAS multi-échelle, qui est 30% plus rapide que les modèles de pointe.
Nous présentons R2D3, un agent qui utilise efficacement les démonstrations pour résoudre des problèmes d'exploration difficiles dans des environnements partiellement observables avec des conditions initiales très variables.
Nous étudions comment un réseau neuronal récurrent réussit à apprendre une tâche combinant la mémoire à long terme et le rappel séquentiel.
Nous proposons l'idée d'utiliser la norme de la représentation du successeur comme un bonus d'exploration dans l'apprentissage par renforcement. Dans les jeux d'Atari à exploration difficile, notre algorithme d'apprentissage par renforcement profond atteint les performances des méthodes récentes basées sur le pseudo-comptage.
Factorisation des dimensions en fonction des données dans une architecture multi-échelle basée sur la contribution à la log-vraisemblance totale
Quatre méthodes d'attribution existantes basées sur la rétropropagation sont fondamentalement similaires. Comment les évaluer ?
SGD et Adam sous un modèle à pointes uniques pour l'ACP tensorielle.
Cet article présente une méthode permettant d'expliquer la connaissance encodée dans un réseau de neurones convolutifs (CNN) de manière quantitative et sémantique.
L'article présente une méthodologie d'évaluation dynamique pour la modélisation de séquences adaptatives.
Nous proposons une nouvelle méthode, basée sur la projection, pour incorporer l'information conditionnelle dans le discriminateur des GAN qui respecte le rôle de l'information conditionnelle dans le modèle probabiliste sous-jacent.
La distance de Fréchet entre la distribution du train et celle du test est en corrélation avec le changement de performance pour les fonctions qui ne sont pas invariantes au changement.
Un nouveau système dynamique très simple est introduit, qui génère de jolis motifs ; les propriétés sont prouvées et les possibilités sont explorées.
GMM-UNIT est un modèle de traduction image à image qui fait correspondre une image à plusieurs domaines de manière stochastique.
Nous présentons une nouvelle architecture, basée sur la mémoire dynamique, l'attention et la composition pour la tâche de raisonnement de la machine.
Pour comprendre les informations stockées dans l'espace latent, nous entraînons un décodeur de type GAN contraint de produire des images que le codeur VAE mettra en correspondance avec la même région de l'espace latent.
Deux nouveaux GAN sont construits pour générer des images cérébrales IRMf 3D de haute qualité et des images cérébrales synthétiques qui aident grandement à améliorer les tâches de classification en aval.
Transfert interlinguistique zéro-temps en utilisant la traduction automatique neuronale multilingue 
Nous proposons un algorithme de recherche d'architecture différentiable pour les réseaux convolutifs et récurrents, qui permet d'atteindre des performances compétitives par rapport à l'état de l'art en utilisant des ressources de calcul inférieures de plusieurs ordres de grandeur.
Les systèmes actuels de génération de langage visent une probabilité élevée et se transforment en répétitions génériques, ou bien ils calibrent mal leur stochasticité. Nous fournissons des preuves de ces deux situations et proposons une solution : L'échantillonnage du noyau.
La première méthode de défense contre les textes au niveau des mots, et la méthode améliorée d'attaque basée sur les génériques contre les attaques basées sur la substitution de synonymes.
Vers une affectation efficace des crédits dans les réseaux récurrents sans backpropagation à travers le temps
Nous proposons un nouveau cadre d'apprentissage contradictoire pour la prédiction structurée, dans lequel des modèles discriminants peuvent être utilisés pour affiner les modèles de prédiction structurée au stade de l'inférence. 
Une nouvelle méthodologie pour la détection de la nouveauté en utilisant les valeurs d'activation de l'espace caché obtenues à partir d'un autoencodeur profond.
Apprentissage des préférences sur les traces de plans à l'aide de l'apprentissage actif.
Nous ancrons les commandes du langage dans un environnement visuel à haute dimension en apprenant des récompenses conditionnées par le langage à l'aide de l'apprentissage par renforcement inverse.
Nous plaidons en faveur des caractéristiques aléatoires en tant que théorie des réseaux neuronaux biologiques, en nous concentrant sur les réseaux faiblement connectés.
Nous proposons la méthode Prob2Vec pour l'intégration de problèmes utilisée dans un outil d'apprentissage en ligne personnalisé en plus d'une méthode de classification au niveau des données, appelée préformation négative, pour les cas où l'ensemble de données d'apprentissage est déséquilibré.
Nous présentons CrescendoNet, une architecture CNN profonde par empilement de blocs de construction simples sans connexions résiduelles.
Nous combinons des splines avec des réseaux neuronaux pour obtenir une nouvelle distribution sur les fonctions et l'utiliser pour modéliser les fonctions d'intensité des processus ponctuels.
Nous développons un BERT compressé en fonction de la tâche, qui est 4,3 fois plus petit et 4,0 fois plus rapide que BERT-BASE tout en obtenant des performances compétitives sur GLUE et SQuAD.
Nous montrons que la plupart des variantes des auto-codeurs pondérés par l'importance peuvent être dérivées d'une manière plus raisonnée en tant que cas particuliers des approches d'échantillonnage adaptatif par l'importance, comme l'algorithme de sommeil pondéré par l'importance.
La NUQSGD comble le fossé entre les garanties théoriques de la QSGD et les performances empiriques de la QSGDinf.
Les réseaux neuronaux peuvent être entraînés à modifier leur propre connectivité, améliorant ainsi leurs performances d'apprentissage en ligne sur des tâches difficiles.
Une méthode géométrique basée sur les simplex est proposée pour faire face aux problèmes d'apprentissage en quelques coups.
Nous montrons qu'une entrée de mémoire de travail dans un réseau de réservoirs rend une règle de Hebbian locale modulée par la récompense aussi performante que les moindres carrés récursifs (alias FORCE).
Nous combinons les avantages computationnels des architectures convolutionnelles temporelles avec l'expressivité des variables latentes stochastiques.
Une méthode sans gradient est proposée pour un problème d'optimisation non convexe. 
Nous proposons une nouvelle méthode qui exploite les gradients des simulateurs différentiables pour améliorer les performances de la RL pour le contrôle robotique.
Nous proposons des hyperréseaux bayésiens : un cadre pour l'inférence bayésienne approximative dans les réseaux neuronaux.
La protection de l'innovation profonde permet de faire évoluer de bout en bout des modèles de monde complexes pour des tâches en 3D.
Nous proposons MACER : un algorithme de défense prouvable qui entraîne des modèles robustes en maximisant le rayon certifié. Il n'utilise pas d'entraînement contradictoire mais est plus performant que toutes les défenses l2 prouvables existantes.
Cet article propose une nouvelle méthode d'acteur-critique qui utilise les Hessiens d'un critique pour mettre à jour un acteur.
de classifieurs génératifs à l'échelle sur des ensembles de données complexes, et d'évaluer leur efficacité à rejeter les entrées illégales, y compris les échantillons hors distribution et les exemples adverses.
Une théorie pour l'initialisation et la mise à l'échelle des couches des réseaux neuronaux ReLU
Les sorties des API modernes de traitement automatique des langues sur des textes non sensés fournissent des signaux forts sur les internes du modèle, ce qui permet aux adversaires de voler les API.
Nous présentons SeaRNN, un nouvel algorithme pour l'apprentissage des RNN, inspiré de l'approche de l'apprentissage par la recherche pour la prédiction structurée, afin d'éviter les limites de l'apprentissage MLE.
Une méthode d'apprentissage continu qui utilise la distillation pour combiner les politiques d'experts et l'apprentissage par transfert pour accélérer l'apprentissage de nouvelles compétences.
Modèle d'apprentissage par renforcement explicable utilisant une nouvelle combinaison de mélange d'experts avec des experts d'arbres de décision non-différenciables.
Nous développons et analysons un nouvel algorithme d'optimisation sans dérivation avec momentum et échantillonnage par importance avec des applications au contrôle continu.
Nous proposons une nouvelle méthode d'apprentissage du hachage profond pour la recherche d'images en utilisant uniquement une métrique de distance relationnelle entre les échantillons.
Nous proposons une nouvelle approche pour améliorer un mappage de surface croisée donné par un raffinement local avec une nouvelle méthode itérative pour déformer le maillage afin de répondre aux contraintes de l'utilisateur.
Introduire un point de vue théorique de l'information sur le comportement des processus d'optimisation des réseaux profonds et leurs capacités de généralisation.
La représentation de l'architecture du réseau comme un ensemble d'arbres syntaxiques et l'optimisation de leur structure permettent d'obtenir des modèles de régression précis et concis. 
Étude empirique et théorique des effets de la stagnation dans l'exécution non synchrone sur les algorithmes d'apprentissage automatique.
Ce travail présente un algorithme évolutif pour l'identification de systèmes non linéaires hors ligne à partir d'observations partielles.
Analyse générale des méthodes basées sur les signes (par exemple, signSGD) pour l'optimisation non convexe, fondée sur des limites intuitives des probabilités de succès.
Pour l'apprentissage hors politique avec des rétroactions de bandit, nous proposons un nouvel algorithme d'apprentissage contrefactuel régularisé par la variance, qui a à la fois des fondements théoriques et des performances empiriques supérieures.
Nous combinons des contraintes manuelles dures avec une contrainte faible préalable profonde pour réaliser l'imagerie sismique et récolter des informations sur la distribution "postérieure" en tirant parti de la multiplicité des données.
État de l'art dans l'analyse syntaxique complexe de texte à SQL en combinant le raisonnement relationnel dur et mou dans l'encodage de schémas/questions.
Nous introduisons une configuration d'apprentissage continu basée sur la modélisation du langage où aucun signal explicite de segmentation de la tâche n'est donné et nous proposons un modèle de réseau neuronal avec une mémoire à long terme croissante pour y faire face.
Proposition d'un algorithme basé sur le RNN pour estimer la distribution prédictive dans les prévisions à une et plusieurs étapes dans les problèmes de prédiction de séries chronologiques.
Les LSTM peuvent modéliser plus efficacement la mémoire de travail s'ils sont appris par renforcement, à l'instar du système dopaminergique qui module la mémoire dans le cortex préfrontal.    
Reformuler les non-linéarités des réseaux profonds à partir d'une quantification vectorielle et établir un pont entre les non-linéarités les plus connues.
Nous apprenons à générer de manière conditionnelle des séquences de protéines à partir de structures avec un modèle qui capture les dépendances éparses à longue portée.
Un cadre qui relie les couches profondes du réseau aux algorithmes d'optimisation stochastique ; il peut être utilisé pour améliorer la précision du modèle et informer la conception du réseau.
Une méthode d'apprentissage de la configuration de la quantification pour les réseaux de faible précision qui permet d'atteindre des performances de pointe pour les réseaux quantifiés.
Nous proposons plusieurs stratégies générales de débiaisage pour traiter les biais communs observés dans différents ensembles de données et obtenir une amélioration substantielle des performances hors domaine dans tous les contextes.
Nous présentons un algorithme de reconstruction basé sur l'inférence CNN pour traiter le CT à très faible nombre de vues. 
Nous construisons des agents conversationnels compétents en conditionnant sur Wikipedia + une nouvelle tâche supervisée.
Synthèse des algorithmes GCN et LINUCB pour l'apprentissage en ligne avec rétroactions manquantes
Un bon tagger donne des tags similaires à un article donné et aux articles qu'il cite.
Nous proposons une méthode basée sur la quantification qui régularise les représentations apprises d'un CNN pour qu'elles soient automatiquement alignées avec la matrice des concepts entraînables, ce qui permet de filtrer efficacement les perturbations adverses.
L'article fournit une caractérisation complète des couches linéaires invariantes par permutation et équivariantes pour les données de graphes.
Les modèles partiels causalement corrects n'ont pas besoin de générer l'observation entière pour rester causalement corrects dans des environnements stochastiques.
Un algorithme efficace d'apprentissage tout au long de la vie qui offre un meilleur compromis entre la précision et la complexité temps/mémoire par rapport aux autres algorithmes. 
Nous avons démontré des résultats de formation de pointe en utilisant une représentation en virgule flottante de 8 bits, à travers Resnet, GNMT, Transformer.
Nous proposons l'entropie croisée d'instance (ICE) qui mesure la différence entre une distribution de correspondance estimée au niveau de l'instance et sa distribution de base. 
L'incorporation, dans le modèle, de variables latentes qui codent le contenu futur améliore la précision de la prédiction à long terme, ce qui est essentiel pour une meilleure planification dans la RL basée sur un modèle.
Cadre de détection d'anomalies à base de tenseur intégratif (ITAD) pour un système satellite.
La limitation des informations d'état pour la politique par défaut peut améliorer les performances, dans un cadre de RL régularisé par KL où l'agent et la politique par défaut sont optimisés ensemble.
Nous calculons la saillance en utilisant un modèle génératif fort pour marginaliser efficacement les entrées alternatives plausibles, révélant les zones de pixels concentrés qui préservent les informations de l'étiquette.
Le réseau de variation est un modèle génératif capable d'apprendre des attributs de haut niveau sans supervision, qui peuvent ensuite être utilisés pour la manipulation contrôlée des entrées.
Les humains dans la boucle révisent les documents pour qu'ils correspondent aux étiquettes contrefactuelles, ce qui permet de réduire le recours à des associations fallacieuses.
Nous proposons de nouvelles mesures objectives pour évaluer les explications basées sur la notion de robustesse contradictoire. Les critères d'évaluation nous permettent en outre de dériver de nouvelles explications qui capturent les caractéristiques pertinentes de manière qualitative et quantitative.
Cet article présente un cadre basé sur le GAN pour l'apprentissage de la distribution à partir de données incomplètes à haute dimension.
Nous proposons une nouvelle méthode de compression, l'ILWP (Inter-Layer Weight Prediction) et une méthode de quantification qui quantifie les résidus prédits entre les poids des couches de convolution.
Nous étendons une technique de pointe pour incorporer directement les FLOPs dans l'objectif d'optimisation, et nous montrons que, compte tenu d'une exigence de FLOPs souhaitée, différents réseaux neuronaux sont entraînés avec succès.
Méthode de traduction d'image en image multi-domaine et multimodale à granularité contrôlée
Analyse de l'expressivité et de la généralité des réseaux neuronaux récurrents avec non-linéarités ReLu à l'aide de la décomposition Tensor-Train.
Nous proposons un nouvel algorithme efficace pour construire des exemples contradictoires au moyen de déformations, plutôt que de perturbations additives.
Régularisation de l'apprentissage contradictoire avec un goulot d'étranglement d'information, appliquée à l'apprentissage par imitation, à l'apprentissage par renforcement inverse et aux réseaux contradictoires génératifs.
Une méthode d'augmentation simple permet de surmonter le compromis robustesse/précision observé dans la littérature et ouvre des questions sur l'effet de la distribution de formation sur la généralisation hors distribution.
Nous utilisons des réseaux de densité de mélange pour effectuer une estimation de densité conditionnelle complète pour la régression du décalage spatial et nous l'appliquons à la tâche d'estimation de la pose humaine.
Visualisation des différences entre l'attention régulière et l'attention relative pour Music Transformer.
Trois facteurs (taille du lot, taux d'apprentissage, bruit du gradient) modifient de manière prévisible les propriétés (par exemple la netteté) des minima trouvés par SGD.
Une approche générative simple pour résoudre le problème de l'analogie des mots, qui permet de mieux comprendre les relations entre les mots et les problèmes liés à leur estimation.
Cet article réexamine plusieurs pratiques courantes de définition d'hyperparamètres pour un réglage fin.
amélioration de l'apprentissage profond par transfert avec régularisation en utilisant des cartes de caractéristiques basées sur l'attention
Modèle neuronal prédisant des sentiments multi-aspects et générant simultanément un masque probabiliste multi-dimensionnel. Le modèle est plus performant que les modèles de base et génère des masques qui sont : des prédicteurs de caractéristiques forts, significatifs et interprétables.
Proposer une nouvelle fonction objective pour la génération de séquences neuronales qui intègre les fonctions objectives basées sur ML et RL.
Un réseau de capsules appris par paire qui donne de bons résultats dans les tâches de vérification des visages avec des données étiquetées limitées. 
Reactor combine de multiples contributions algorithmiques et architecturales pour produire un agent avec une efficacité d'échantillonnage plus élevée que le DQN duel priorisé tout en offrant de meilleures performances d'exécution que A3C.
L'article décrit les méthodes de vérification et de reconnaissance des plans HTN par l'analyse syntaxique des grammaires d'attributs.
Nous explorons la recherche d'architecture neuronale pour les tâches de langage. La recherche de cellules récurrentes est difficile pour la NMT, mais la recherche de mécanismes d'attention fonctionne. Le résultat de la recherche d'attention sur la traduction est transférable à la compréhension de la lecture.
Nous proposons un régularisateur qui améliore l'interpolation et les auto-encodeurs et montrons qu'il améliore également la représentation apprise pour les tâches en aval.
Cet article présente une méthode permettant de générer de manière stochastique des images vidéo intermédiaires à partir d'images clés données, en utilisant des convolutions 3D directes.
Cet article étudie l'alignement des graphes de connaissances faiblement supervisé avec des cadres de formation adversaires.
L'apprentissage multi-vues améliore l'apprentissage non supervisé de la représentation des phrases
Nous proposons une approche de méta-apprentissage pour guider les tâches de segmentation visuelle à partir de quantités variables de supervision.
L'optimisation latente améliore la dynamique de formation adversariale. Nous présentons à la fois une analyse théorique et une génération d'images de pointe avec ImageNet 128x128.
Cet article traite des propriétés théoriques du point optimal de premier ordre d'un réseau neuronal à deux couches dans un cas sur-paramétré.
Une architecture permet au CNN entraîné sur les séquences vidéo convergeant rapidement. 
Nous présentons une nouvelle méthode qui combine une attaque adverse de type boîte noire basée sur le transfert et une attaque adverse de type boîte noire notée, améliorant le taux de réussite et l'efficacité de l'interrogation de l'attaque adverse de type boîte noire sur différentes architectures de réseau.
Décrire une technique d'interface neuro-IA pour évaluer les réseaux adversariens génératifs.
En utilisant des méthodes d'échantillonnage adaptatif pour accélérer l'évaluation des probabilités d'événements rares, nous estimons la probabilité d'un accident sous une distribution de base régissant le comportement standard du trafic. 
Une approche dynamique des méthodes de mise en sac pour éviter les transferts négatifs dans l'apprentissage par transfert de réseaux neuronaux en mode "few-shot".
Un nouvel algorithme basé sur l'achèvement de la matrice pour modéliser la progression de la maladie en fonction des événements.
De simples contraintes de similarité, combinées à une traduction automatique multilingue, permettent pour la première fois d'obtenir une traduction de haute qualité entre des paires de langues inconnues.
Le noyau de la tangente neuronale dans un réseau ReLU initialisé de manière aléatoire présente des fluctuations non triviales tant que la profondeur et la largeur sont comparables. 
Nous proposons de nouvelles décompositions tensorielles et des régularisateurs associés pour obtenir des performances de pointe sur la complétion de bases de connaissances temporelles.
Nous avons utilisé une structure de modèle de type CVAE pour apprendre à générer directement des ardoises/pages entières pour les systèmes de recommandation.
En combinant les réseaux neuronaux de graphes et le modèle génératif de graphes RNN, nous proposons une nouvelle architecture capable d'apprendre à partir d'une séquence de graphes en évolution et de prédire l'évolution de la topologie des graphes pour les pas de temps futurs.
Nous proposons un agent d'apprentissage de la décomposition qui aide les personnes répondant à des questions simples à répondre à des questions composées sur un graphe de connaissances.
Modèle basé sur l'énergie apprise avec correspondance des scores
Proposer un modèle RBM général basé sur les tenseurs qui permet de compresser considérablement le modèle tout en conservant une forte capacité d'expression du modèle.
Une approche d'apprentissage par renforcement acteur-critique avec retours multi-étapes appliquée à la conduite autonome avec le simulateur Carla.
Nous proposons de nouvelles méthodes pour évaluer et quantifier la qualité des distributions synthétiques de GAN du point de vue des tâches de classification.
L'objectif du clustering de survie est de répartir les sujets dans des clusters. Sans signaux de fin de vie, c'est une tâche difficile. Pour résoudre cette tâche, nous proposons une nouvelle fonction de perte en modifiant la statistique de Kuiper.
Nous montrons comment l'utilisation d'estimations préalables semi-paramétriques peut accélérer le HPO de manière significative pour tous les ensembles de données et toutes les métriques.
Les procédures de routage ne sont pas nécessaires pour les CapsNets.
En définissant différemment la largeur ou la variance d'initialisation de chaque couche, nous pouvons réellement atténuer les problèmes d'explosion du gradient dans les réseaux résiduels (avec des couches entièrement connectées et sans norme de traitement). Une théorie mathématique est développée qui non seulement vous indique comment le faire, mais qui, de manière surprenante, est capable de prédire, après avoir appliqué ces astuces, à quelle vitesse votre réseau s'entraîne pour atteindre une certaine performance de l'ensemble de test. C'est de la magie noire, et cela s'appelle la "théorie du champ moyen profond".
Communication ciblée dans l'apprentissage par renforcement coopératif multi-agent
Nous avons développé un système d'aide à la gravure latte art qui projette la procédure de réalisation directement sur un cappuccino pour aider les débutants à réaliser une gravure latte art bien équilibrée.
Nous proposons des auto-supervisions temporelles pour l'apprentissage de fonctions temporelles stables avec des GANs.
Classification semi-supervisée de documents translinguistiques
Les HMMs sont-ils un cas particulier des RNNs ? Nous étudions une série de transformations architecturales entre les HMM et les RNN, à la fois par des dérivations théoriques et par une hybridation empirique, et nous fournissons de nouvelles perspectives.
Nous fournissons une analyse théorique et expérimentale de l'état de l'art des auto-codeurs variationnels.
Nous développons les fondements théoriques de la puissance expressive des GNN et concevons un GNN dont la puissance est prouvée.
Un nouvel algorithme pour l'apprentissage multi-tâches en ligne qui apprend sans redémarrage aux frontières des tâches.
Capacité interlinguistique du BERT multilingue : une étude empirique
Un cadre théorique pour le réseau ReLU profond qui peut expliquer de multiples phénomènes déroutants comme la sur-paramétrisation, la régularisation implicite, les billets de loterie, etc. 
Alignement des langues sans la pierre de Rosette : sans données parallèles, nous construisons des dictionnaires bilingues à l'aide d'une formation contradictoire, d'une mise à l'échelle locale inter-domaines et d'un critère de substitution précis pour la validation croisée.
Nous effectuons un comptage pour répondre aux questions visuelles ; notre modèle produit des sorties interprétables en comptant directement à partir des objets détectés.
Nous étudions le problème de la génération de graphes et proposons un puissant modèle génératif profond capable de générer des graphes arbitraires.
Représenter des phrases en les composant avec des Tree-LSTMs selon des arbres d'analyse automatiquement induits.
Trois nouveaux algorithmes avec des études d'ablation pour élaguer le réseau neuronal afin d'optimiser la longueur du câblage, par opposition au nombre de poids restants.
Recherche de moments vidéo à base de texte faiblement supervisé
Comment utiliser la généralisation empilée pour améliorer les performances des algorithmes d'apprentissage par transfert existants lorsque des données étiquetées limitées sont disponibles.
Cet article présente un antécédent physique pour l'apprentissage profond et applique la topologie du réseau qui en résulte à la commande basée sur un modèle.
Nous améliorons les modèles génératifs en proposant un méta-algorithme qui filtre les nouvelles données d'apprentissage des sorties du modèle.
Nous utilisons un simulateur non enroulé comme modèle différentiable de bout en bout de la structure des protéines et nous montrons qu'il peut (parfois) généraliser hiérarchiquement à des topologies de plis inconnues.
Entraînement automatisé de souris pour les neurosciences avec inférence de stratégie latente itérative en ligne pour la prédiction du comportement
Nous analysons les réseaux récurrents entraînés à la classification des sentiments, et nous constatons qu'ils présentent tous une dynamique d'attracteur linéaire approximative lorsqu'ils résolvent cette tâche.
Nous avons construit une simulation physique d'un rongeur, l'avons entraîné à résoudre un ensemble de tâches et avons analysé les réseaux qui en résultent.
Une extension des GANs combinant le transport optimal sous forme primale avec une distance d'énergie définie dans un espace de caractéristiques appris de façon adversariale.
Entraînement d'un agent dans un monde virtuel 2D pour l'acquisition et la généralisation du langage ancré.
Un algorithme RL qui apprend à être robuste aux changements de dynamique
Cet article fournit un schéma d'abstraction basé sur le jeu pour calculer des politiques prouvées solides pour les POMDP.
Un jeu de données jouet basé sur la percolation critique dans un graphe planaire offre une fenêtre analytique sur la dynamique de formation des réseaux neuronaux profonds.  
Nous recadrons le problème de génération comme un problème d'édition de points existants et, par conséquent, nous extrapolons mieux que les GAN traditionnels.
Une nouvelle approche qui apprend une représentation pour décrire des modèles de transition dans des domaines incertains complexes en utilisant des règles relationnelles. 
Nous proposons un réseau de planification différentiable de bout en bout pour les graphes. Ce réseau peut être appliqué à de nombreux problèmes de planification de mouvement
Nous apprenons un débruitage de haute qualité en utilisant uniquement des instances uniques d'images corrompues comme données d'entraînement.
Nous résolvons le problème des récompenses éparses pour les tâches d'interface utilisateur Web en utilisant l'exploration guidée par des démonstrations.
Architecture embarquée pour l'apprentissage profond sur des dispositifs optimisés pour la détection des visages et la reconnaissance des émotions 
L'utilisation de la même intégration pour toutes les covariables n'a pas de sens. Nous montrons qu'un algorithme de décomposition tensorielle permet d'apprendre conjointement et efficacement les intégrations éparses spécifiques aux covariables et les sujets naturellement séparables.
À l'aide de la programmation linéaire, nous montrons que la complexité de l'apprentissage approximatif d'un réseau neuronal profond dépend de façon polynomiale de la taille des données pour plusieurs architectures.
Nous unifions le filtre de Kalman étendu (EKF) et l'approche de l'espace d'état de la propagation de l'espérance de puissance (PEP) en résolvant les intégrales d'appariement de moment intraitables dans la PEP par linéarisation. Ceci conduit à une extension globalement itérée de l'EKF.
Exploration de la capacité d'apprentissage des réseaux neuronaux appris
Nous proposons une méthodologie d'évaluation généralisée pour interpréter les biais du modèle, les biais de l'ensemble des données et leur corrélation.
Les agents sociaux apprennent à se parler en langage naturel pour atteindre un objectif.
Nous montrons que l'effondrement postérieur dans les VAE linéaires est entièrement causé par la log-vraisemblance marginale (et non par ELBO). Des expériences sur des VAE profonds suggèrent qu'un phénomène similaire est en jeu.
Cet article propose un nouveau modèle qui combine des informations à plusieurs échelles pour l'apprentissage de séquence à séquence.
Nous proposons une nouvelle méthode de formation contradictoire certifiée, CROWN-IBP, qui atteint une robustesse de pointe pour les perturbations contradictoires de norme L_inf.
Dans l'élagage des réseaux structurés, l'ajustement fin d'un modèle élagué ne donne que des performances comparables à celles de l'apprentissage à partir de zéro.
Technique interactive pour améliorer le brossage dans des ensembles de données de trajectoires denses en prenant en compte la forme du brossage.
Nous développons une nouvelle approche pour modéliser la composition des objets dans les images dans un cadre GAN.
Discrimination audio adversariale utilisant la dépendance temporelle
 Nous proposons une nouvelle méthode d'apprentissage du GAN en considérant certains faux échantillons comme réels afin d'atténuer l'effondrement des modes et de stabiliser le processus d'apprentissage.
Nous présentons un outil visuel pour explorer de manière interactive l'espace latent d'un auto-encodeur pour les séquences peptidiques et leurs attributs.
Nous présentons des expériences qui démontrent clairement qu'un neurone se comporte comme un classificateur binaire pendant la formation et les tests.
Procédé d'enrichissement et de combinaison de caractéristiques pour améliorer la précision de la classification
Étendre l'architecture GAN pour obtenir le contrôle des emplacements et des identités de plusieurs objets dans les images générées.
Nous proposons un nouveau modèle de bout en bout (SPNet) pour incorporer des échafaudages sémantiques afin d'améliorer le résumé abstrait des dialogues.
Nous présentons un agent RL, MINERVA, qui apprend à se déplacer dans un graphe de connaissances et à répondre à des questions.
Une approximation du flux ventral des primates sous la forme d'un réseau convolutif donne de mauvais résultats en matière de reconnaissance d'objets, et de multiples caractéristiques architecturales y contribuent. 
Nous considérons le problème de l'apprentissage de politiques optimales dans des domaines à temps limité et à temps non limité en utilisant des interactions à temps limité.
Un des problèmes théoriques de l'apprentissage profond
Nous analysons et développons une mise en œuvre efficace sur le plan informatique de la régularisation jacobienne qui augmente les marges de classification des réseaux neuronaux.
Nous sommes les premiers dans ce domaine à montrer comment concevoir un noyau clairsemé efficace sous trois aspects : composition, performance et efficacité.
Un nouveau réseau attentionnel à moyenne marginalisée pour la localisation temporelle de l'action faiblement supervisée. 
Nous proposons un nouvel auto-encodeur incorporé avec une transformée à retardement-embedding multi-voies pour interpréter les images profondes antérieures.
Garantir que les modèles appris de manière fédérée ne révèlent pas la participation d'un client.
Nous montrons comment le pré-entraînement d'un réseau neuronal non entraîné avec seulement 5 à 25 exemples peut améliorer les résultats de reconstruction dans les problèmes de détection comprimée et de récupération sémantique comme la colorisation.
Nous avons proposé l'entraînement coopératif, un nouvel algorithme d'entraînement pour la modélisation générative de données discrètes.
Nous présentons une méthode permettant de calculer une récompense intrinsèque pour la curiosité à l'aide de métriques dérivées de l'échantillonnage d'un modèle de variable latente utilisé pour estimer la dynamique.
Nous présentons un modèle génératif pour les intégrations de mots composites qui capture les relations syntaxiques, et nous fournissons une vérification et une évaluation empiriques.
Nous proposons une approche hybride, basée sur le modèle et sans modèle, qui utilise l'information sémantique pour améliorer la généralisation des LRD dans les environnements artificiels.
Nous utilisons des techniques d'apprentissage profond pour résoudre le problème de la représentation et de la récupération des signaux épars.
Nous présentons Dreamer, un agent qui apprend des comportements à long terme par pure imagination latente en utilisant des gradients de valeur analytiques.
Nous proposons MULTIPOLAR, une méthode de transfert RL qui exploite un ensemble de politiques sources collectées sous diverses dynamiques environnementales inconnues pour apprendre efficacement une politique cible dans une autre dynamique.
Un agent entraîné uniquement par la curiosité, et sans récompense extrinsèque, réussit étonnamment bien dans 54 environnements populaires, dont la suite de jeux Atari, Mario, etc.
pour les transformations spatiales, le minimiseur robuste minimise également la précision standard ; la régularisation induisant l'invariance conduit à une meilleure robustesse que les architectures spécialisées
La notion d'apprentissage par ordre est proposée et appliquée aux problèmes de régression en vision par ordinateur.
Nous montrons que les réseaux neuronaux fonctionnent en changeant la topologie d'un ensemble de données et nous explorons comment les choix architecturaux affectent ce changement.
Nous utilisons les outils empiriques de la connectivité des modes et du SVCCA pour étudier les heuristiques de formation des réseaux neuronaux que sont les redémarrages du taux d'apprentissage, le réchauffement et la distillation des connaissances.
Inférence variationnelle pour déduire une distribution discrète à partir de laquelle un réseau neuronal de faible précision est dérivé
Nous proposons une nouvelle méthode basée sur les tenseurs pour les réseaux convolutifs sur les graphes dynamiques.
"Génération de nouveaux matériaux chimiques à l'aide de nouveaux GAN à domaines croisés".
Nous fournissons un estimateur et un algorithme d'estimation pour une classe de problèmes de régression multi-tâches et fournissons une analyse statistique et computationnelle....
Utilisation de l'apprentissage par renforcement profond pour enseigner aux agents la coordination du style de flotte de covoiturage.
Stabilité des représentations de la transformée de diffusion des données du graphe aux déformations du support du graphe sous-jacent.
Nous proposons une nouvelle architecture de réseau profond qui peut décider dynamiquement de la capacité de son réseau au fur et à mesure qu'il s'entraîne dans un scénario d'apprentissage tout au long de la vie.
Cet article examine différentes méthodes de couplage de la VO avec l'apprentissage profond et propose une prédiction simultanée des corrections et de l'incertitude.
Nous avons introduit le Deep Density Network, un modèle DNN unifié pour estimer l'incertitude pour l'exploration/exploitation dans les systèmes de recommandation.
Nous entraînons des RNN sur des utilisateurs célèbres de Twitter pour déterminer si la population générale de Twitter est plus susceptible de croire au changement climatique après une catastrophe naturelle.
En utilisant une nouvelle représentation des systèmes dynamiques linéaires symétriques avec un état latent, nous formulons le contrôle optimal comme un programme convexe, donnant le premier algorithme en temps polynomial qui résout le contrôle optimal avec une complexité d'échantillon seulement polylogarithmique dans l'horizon temporel.
Nous modélisons le générateur de données (dans le GAN) au moyen d'un polynôme d'ordre élevé représenté par des tenseurs d'ordre élevé.
Nous montrons que les réseaux neuronaux profonds sont capables d'apprendre à partir de données qui ont été diluées par une quantité arbitraire de bruit.
nous proposons une approche de méta-apprentissage pour la traduction automatique neuronale à faibles ressources qui peut apprendre rapidement à traduire dans une nouvelle langue
Une méthode de détection active des anomalies. Nous présentons une nouvelle couche qui peut être attachée à tout modèle d'apprentissage profond conçu pour la détection non supervisée d'anomalies afin de le transformer en une méthode active.
Nous générons des exemples pour expliquer la décision d'un classificateur via des interpolations dans l'espace latent. Le coût du codeur automatique variationnel est étendu avec une fonction du classificateur sur le chemin de l'exemple généré dans l'espace des données.
Présenter une approche permettant aux agents d'apprendre des modèles d'action PPDDL de manière incrémentielle sur plusieurs problèmes de planification dans le cadre de l'apprentissage par renforcement.
Nous proposons un nouvel algorithme DRL hors politique qui atteint des performances de pointe. 
Nous proposons une méthode qui peut utiliser les informations sur les passages multiples pour l'assurance qualité dans un domaine ouvert.
Algorithme de réduction de la dimensionnalité permettant de visualiser des textes contenant des informations de réseau, par exemple un corpus de courriers électroniques ou des co-signatures.
Nous présentons un cadre qui s'appuie sur des simulations informatiques haute-fidélité pour interroger et diagnostiquer les biais dans les classificateurs ML. 
Nous présentons et évaluons des décodeurs de nuages de points basés sur l'échantillonnage qui surpassent l'approche MLP de base en correspondant mieux à la sémantique des nuages de points.
Nous utilisons le RL profond pour apprendre une politique qui dirige la recherche d'un algorithme génétique afin de mieux optimiser le coût d'exécution des graphes de calcul, et nous montrons des résultats améliorés sur des graphes TensorFlow du monde réel.
Nous montrons qu'avec la perte et l'architecture appropriées, l'apprentissage prédictif de la vue améliore la détection des objets en 3D.
un réseau adversarial génératif pour la modélisation du style dans un système texte-parole
Nous montrons dans une tâche d'apprentissage simplifiée que la sur-paramétrisation améliore la généralisation d'un convnet entraîné par descente de gradient.
Méta-apprentissage bayésien utilisant le cadre PAC-Bayes et les distributions préalables implicites
Document de synthèse proposant des explications rebelles et trompeuses pour les agents.
Nous étudions une variante des auto-codeurs variationnels où il existe une superstructure de variables latentes discrètes au-dessus des caractéristiques latentes.
Nous montrons que la clé pour obtenir de bonnes performances avec les IDMs réside dans l'apprentissage de représentations latentes pour encoder les informations partagées entre des expériences équivalentes, de sorte qu'elles puissent être généralisées à des scénarios non vus.
Nous identifions le biais d'angle qui cause le problème de gradient de fuite dans les réseaux profonds et proposons une méthode efficace pour réduire ce biais.
Nous employons des réseaux neuronaux graphiques dans le cadre de l'EM variationnel pour l'inférence et l'apprentissage efficaces des réseaux logiques de Markov.
Une approche de méta-apprentissage par renforcement intégrant un contrôleur de réseau de neurones appliquée à la conduite autonome avec le simulateur Carla.
Déduire un cadre de goulot d'étranglement de l'information dans l'apprentissage par renforcement et quelques théories et outils simples pertinents.
Nous proposons une approche par module neuronal pour l'apprentissage continu en utilisant un environnement visuel unifié avec un large espace d'action.
Nous proposons une méthode d'utilisation des GANs pour générer des justifications visuelles de haute qualité afin d'aider à expliquer les prédictions des modèles. 
Nous proposons un nouvel algorithme qui tire parti de l'expressivité des réseaux neuronaux génératifs pour améliorer les algorithmes de stratégies évolutionnaires.
Nous compressons et accélérons les modèles de reconnaissance vocale sur les dispositifs embarqués grâce à une technique de régularisation de la norme de trace et des noyaux optimisés.
Nous justifions théoriquement le concept d'estimateur direct.
Avec un ensemble de modifications, sous 10 LOC, à A2C, vous obtenez un acteur-critique hors politique qui surpasse A2C et a des performances similaires à ACER. Les modifications sont de grandes tailles de lots, un serrage agressif et un "forçage" de la politique avec un bruit de Gumbel.
Génération de texte à l'aide d'enchâssements de phrases à partir de vecteurs Skip-Thought avec l'aide de réseaux adversariaux génératifs.
nouveau décodeur hors-ordre pour la traduction automatique neuronale
Dans cet article, nous étudions un nouveau problème d'apprentissage des graphes : apprendre à compter les isomorphismes des sous-graphes.
Nous présentons un agent qui utilise un bêta-vae pour extraire les caractéristiques visuelles et un mécanisme d'attention pour ignorer les caractéristiques non pertinentes des observations visuelles afin de permettre un transfert robuste entre les domaines visuels.
Nous proposons le premier algorithme permettant de vérifier la robustesse des transformateurs.
Contrairement à ce que l'on pensait, les performances de formation des réseaux profonds, lorsqu'elles sont mesurées de manière appropriée, permettent de prédire les performances des tests, conformément à la théorie classique de l'apprentissage automatique.
Nous proposons un cadre qui intègre la planification pour une exploration et un apprentissage efficaces dans des environnements complexes.
Notre article analyse l'énorme pouvoir de représentation des réseaux, notamment avec les "connexions sautées", qui peuvent être utilisées comme méthode pour une meilleure généralisation.
Cet article propose une nouvelle fonction objectif pour remplacer le terme KL par une fonction qui émule l'objectif de divergence moyenne maximale (MMD). 
Nous posons que les vraisemblances des modèles génératifs sont excessivement influencées par la complexité de l'entrée, et nous proposons une façon de la compenser lors de la détection des entrées hors distribution.
Nous étudions la convergence d'algorithmes d'optimisation populaires tels que Adam , RMSProp et proposons de nouvelles variantes de ces méthodes qui convergent de manière prouvée vers une solution optimale dans un cadre convexe. 
Nous présentons des défenses efficaces contre les attaques par empoisonnement par étiquette propre. 
MXGNet est une architecture à base de graphes multicouches et multiplex qui obtient de bonnes performances pour diverses tâches de raisonnement diagrammatique.
Nous proposons un nouveau cadre multi-tâches qui apprend la détection des tableaux, la reconnaissance des composants sémantiques et la classification des types de cellules pour les tableaux de tableurs, avec des résultats prometteurs.
Nous proposons des mesures automatiques pour évaluer de manière holistique la génération de dialogues ouverts et elles sont en forte corrélation avec l'évaluation humaine.
Nous concevons une nouvelle convolution graphique séparable en profondeur (DSGC) pour les données du domaine spatial générique, qui est hautement compatible avec la convolution séparable en profondeur.
Nous formons une suite de modèles capables de transcrire, de composer et de synthétiser des formes d'onde audio avec une structure musicale cohérente, grâce au nouvel ensemble de données MAESTRO.
Une étude empirique de l'inférence variationnelle basée sur la minimisation de la divergence du chi carré, montrant que la minimisation du CUBO est plus délicate que la maximisation de l'ELBO.
Nous exploitons la linéarité globale des modèles entraînés par le mélange dans l'inférence pour briser la localité des perturbations adverses.
Le réglage fin de BERT sur des corpus juridiques apporte des améliorations marginales, mais précieuses, aux tâches de TAL dans le domaine juridique.
Nous formulons un modèle probabiliste de séquence latente pour aborder le transfert de style de texte non supervisé, et nous montrons son efficacité dans une série de tâches de transfert de style de texte non supervisé. 
Propose un modèle analytiquement traçable et une procédure d'inférence (régression clairsemée mal paramétrée, inférée en utilisant la pénalité L_1 et étudiée dans la limite de l'interpolation des données) pour étudier les phénomènes liés aux réseaux profonds dans le contexte des problèmes inverses. 
Nous proposons une nouvelle approche de filtrage collaboratif basée sur le hachage variationnel et optimisée pour une nouvelle variante d'auto-masque de la distance de Hamming, qui surpasse l'état de l'art jusqu'à 12% sur NDCG.
Un algorithme d'optimisation qui explore différentes tailles de lot en fonction de la probabilité et exploite automatiquement la taille de lot réussie qui minimise la perte de validation.
Nous avons proposé un cadre unifié de réseaux adversariaux génératifs (GAN) pour apprendre l'intégration de graphes de connaissances tenant compte du bruit.
Un EBM résiduel pour le texte dont la formulation est équivalente à la discrimination entre un texte généré par un humain et un texte généré par une machine. Nous étudions son comportement de généralisation.
Le pseudo-étiquetage s'est révélé être une alternative faible pour l'apprentissage semi-supervisé. A l'inverse, nous démontrons que le traitement du biais de confirmation avec plusieurs régularisations fait du pseudo-étiquetage une approche appropriée.
Nous montrons qu'une fonction spéciale de valeur de condition de but entraînée avec des méthodes sans modèle peut être utilisée dans le cadre de la commande basée sur le modèle, ce qui permet d'obtenir une efficacité et des performances d'échantillonnage nettement meilleures.
Une nouvelle architecture neuronale pour une inférence amortie efficace sur les permutations latentes. 
Nous proposons une nouvelle architecture de modèle à deux tours et à fond partagé pour transférer des connaissances à partir de riches rétroactions implicites afin de prédire la pertinence pour les systèmes de recherche à grande échelle.
Nous abordons la tâche d'exploration et de navigation autonomes à l'aide de cartes d'affordances spatiales qui peuvent être apprises de manière autosupervisée. Ces cartes sont plus performantes que les bases géométriques classiques tout en étant plus efficaces en termes d'échantillonnage que les algorithmes RL contemporains.
