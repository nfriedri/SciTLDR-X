Мы разработали адаптивное масштабирование потерь для улучшения смешанного точного обучения, которое превосходит самые современные результаты.
Предложение для адаптивного метода масштабирования потерь при обратном распространении для обучения с высокой точностью смешивания, где скорость масштабирования определяется автоматически для уменьшения недополнения.
Авторы предлагают метод обучения моделей с точностью FP16, который использует более сложный способ минимизации недополнения в каждом слое одновременно и автоматически.
Мы представляем новый подход для обучения прогнозированию множеств с неизвестной перестановкой и кардинальностью с помощью глубоких нейронных сетей с поступательным движением.
Формулировка для изучения распределения ненаблюдаемых переменных перестановки на основе глубоких сетей для задачи предсказания множества.
Мы сравниваем эффективность распознавания объектов на изображениях, равномерно уменьшенных и с тремя различными схемами фовеации.
Мы разрабатываем методы обучения глубоких нейронных моделей, которые одновременно устойчивы к неблагоприятным возмущениям и устойчивость которых значительно легче проверить.
В статье представлены несколько способов регуляризации простых сетей ReLU для оптимизации устойчивости к неблагоприятным воздействиям, доказуемой устойчивости к неблагоприятным воздействиям и скорости проверки.
В данной работе предлагаются методы обучения устойчивых нейронных сетей, которые могут быть проверены быстрее, с использованием методов обрезки для поощрения разреженности веса и регуляризации для поощрения устойчивости ReLU.
Исследование того, как BatchNorm вызывает уязвимость противника и как ее избежать. 
В данной статье рассматривается уязвимость BatchNorm к неблагоприятным возмущениям, и предлагается альтернатива под названием RobustNorm, использующая минимаксное перемасштабирование вместо нормализации.
В данной статье исследуется причина уязвимости BatchNorm и предлагается Robust Normalization - метод нормализации, который достигает значительно лучших результатов при различных методах атаки.
Наша вариационно-рекуррентная сеть импутации (V-RIN) учитывает коррелированные характеристики, временную динамику и дополнительно использует неопределенность для снижения риска необъективных оценок отсутствующих значений.
Сеть импутации отсутствующих данных для учета корреляции, временных связей и неопределенности данных для решения проблемы нехватки данных в EHR, что позволяет повысить AUC в задачах классификации смертности.
В статье представлен метод, объединяющий VAE и GRU с учетом неопределенности для последовательной интерполяции отсутствующих данных и прогнозирования результатов.
Адаптивный метод квантования нейронных сетей с фиксированной точкой, основанный на теоретическом анализе, а не на эвристике. 
Предлагает метод квантования нейронных сетей, который позволяет квантовать веса с разной точностью в зависимости от их важности с учетом потерь.
В статье предлагается метод квантования весов нейронной сети с битовой глубиной/точностью, варьируемой по каждому параметру.
Основываясь на теории нечетких множеств, мы предлагаем модель, которая, учитывая только размеры симметричных разностей между парами множеств, обучается представлениям таких множеств и их элементов.
В данной статье предлагается новая задача обучения множеств, предсказывающая размер симметричной разности между множествами, и дается метод решения этой задачи, основанный на теории нечетких множеств.
В данной статье предлагается метод глубокого обучения для получения достоверных образцов от незаинтересованных агентов. 
Авторы предлагают схему элекции образцов для проблемы элекции достоверных образцов от агентов для сложных распределений, предполагают, что глубокие нейронные фреймворки могут быть применены в этой схеме, и связывают элекцию образцов и f-GAN.
В данной работе исследуется проблема отбора образцов, предлагается подход глубокого обучения, основанный на двойственном выражении f-дивергенции, которая записывается как максимум над множеством функций t.
Обучение графа последовательности с помощью нейронных сетей, основанных на внимании
Архитектура graph2seq, объединяющая графовый кодер, сочетающий компоненты GGNN и GCN, с кодером последовательности внимания, и демонстрирующая улучшения по сравнению с базовыми моделями.
В данной работе предлагаются сквозные модели кодировщика графов и декодера последовательности с механизмом внимания между ними.
Система сегментации с нулевым снимком для сегментации частей 3D-объекта. Моделирование сегментации как процесса принятия решений и решение как контекстуальной проблемы бандита.
Метод сегментации 3D облаков точек объектов на составные части, ориентированный на обобщение группировок частей для новых категорий объектов, не замеченных во время обучения, который демонстрирует высокую производительность по сравнению с базовыми методами.
В данной статье предлагается метод сегментации частей в облаках точек объектов.
Новый взгляд на то, как собирать корреляцию между узлами на основе свойств диффузии.
Новая операция диффузии для графовых нейронных сетей, которая не требует вычисления собственных значений и может распространяться экспоненциально быстрее по сравнению с традиционными графовыми нейронными сетями.
В статье предлагается справиться с проблемой скорости распространения путем введения баллистической прогулки.
Мы предлагаем обучающий конвейер со слабым контролем на основе структуры программирования данных для задач ранжирования, в котором мы обучаем модель ранжирования на основе BERT и создаем новую SOTA.
Авторы предлагают сочетание BERT и системы слабого надзора для решения проблемы ранжирования отрывков, получая результаты лучше, чем современное решение с полным надзором.
В реальных задачах мы обнаружили, что в процессе обучения ДНК часто подгоняют целевые функции от низких к высоким частотам.
В данной работе анализируется потеря нейронных сетей в области Фурье и обнаруживается, что ДНС имеют тенденцию к обучению низкочастотных компонентов перед высокочастотными.
В статье изучается процесс обучения NNs с помощью Фурье-анализа, делается вывод, что NNs обучаются низкочастотным компонентам раньше, чем высокочастотным.
Мы предлагаем многоразрешающий, иерархически связанный кодер-декодер для перевода графов в графы.
Иерархическая модель трансляции графов в графы для создания молекулярных графов с использованием химических подструктур в качестве строительных блоков, которая является полностью авторегрессионной и обучается когерентным представлениям с несколькими разрешениями, превосходя предыдущие модели.
Авторы представляют метод иерархической трансляции графов в графы для генерации новых органических молекул.
Мы используем внимание, чтобы ограничить эквивариантные нейронные сети набором или совпадающими преобразованиями в данных. 
В данной работе внимание сочетается с групповой эквивариантностью, в частности, рассматривается группа p4m вращений, переводов и переворотов, и выводится форма самовнимания, которая не разрушает свойство эквивариантности.
Авторы предлагают механизм самовнимания для вращательно-эквивариантных нейронных сетей, который улучшает эффективность классификации по сравнению с обычными вращательно-эквивариантными сетями.
Мы обучаем GAN генерировать и восстанавливать полноатомные белковые основы, и показываем, что в некоторых случаях мы можем восстановить сгенерированные белки после разработки последовательности и ab initio форвард-фолдинга.
Генеративная модель для белковой основы, использующая GAN, автоэнкодер-подобную сеть и процесс уточнения, а также набор качественных оценок, свидетельствующих о положительных результатах.
В данной статье представлен сквозной подход для генерации белковых основ с использованием генеративных состязательных сетей.
Meta Learning for Few Shot learning предполагает, что учебные задания и тестовые задания взяты из одного и того же распределения. Что делать, если это не так? Мета-обучение с адаптацией домена на уровне задач!
В данной работе предлагается модель, объединяющая неконтролируемую адаптацию к домену с прототипическими сетями, которая показывает лучшие результаты, чем базовые модели обучения с несколькими выстрелами, в задачах обучения с несколькими выстрелами и сменой домена.
Авторы предложили адаптацию мета-домена для решения проблемы смены домена в мета-обучении, продемонстрировав улучшение производительности в нескольких экспериментах.
Divide, Conquer, and Combine - это новая схема вывода, которая может быть выполнена для вероятностных программ со стохастической поддержкой, т.е. само существование переменных является стохастическим.
Алгоритм встраивания узлов с сохранением сообществ, который приводит к более эффективному обнаружению сообществ с кластеризацией на пространстве встраивания
Модель глубокого обучения с авторегрессией для генерации разнообразных облаков точек.
Подход для создания трехмерных фигур в виде облаков точек, который учитывает лексикографическое упорядочивание точек по координатам и обучает модель предсказывать точки по порядку.
В статье представлена генеративная модель для облаков точек, использующая пиксельную авторегрессионную модель типа RNN и модель внимания для обработки взаимодействий на больших расстояниях.
Описывает ряд методов объяснения, примененных к простому нейросетевому контроллеру, используемому для навигации.
В данной статье представлены идеи и объяснения проблемы предоставления объяснений для многослойного перцептрона, используемого в качестве инверсного контроллера для движения ровера, а также идеи о том, как объяснить модель "черного ящика".
Мы предлагаем самоконтролирующегося агента для решения задачи навигации с помощью зрения и языка.
Метод навигации "зрение+язык", который отслеживает прогресс в выполнении инструкций с помощью монитора прогресса и визуально-текстового модуля совместного обоснования и демонстрирует высокие результаты в стандартных тестах.
В данной статье описывается модель зрительно-языковой навигации с панорамным зрительным вниманием и вспомогательной потерей контроля прогресса, дающая самые современные результаты.
обнаружение событий для представления истории агента в RL
Авторы изучают проблему RL в условиях частичного наблюдения и предлагают решение, которое использует FFNN, но обеспечивает представление истории, превосходя PPO.
В данной статье предлагается новый способ представления прошлой истории в качестве входных данных для RL-агента, который показал, что он работает лучше, чем PPO и RNN-вариант PPO.
Мы показываем, что авторегрессионные модели могут генерировать изображения высокой точности. 
Архитектура, использующая компоненты декодера, декодера увеличения размера и декодера увеличения глубины для решения проблемы обучения дальних зависимостей в изображениях с целью получения изображений с высокой точностью.
В данной работе рассматривается проблема генерации изображений с высокой точностью, успешно демонстрируя убедительные образцы Imagenet с разрешением 128x128 для модели плотности вероятности.
Глубокая иерархическая модель пространства состояний, в которой переходы состояний коррелирующих объектов координируются графовыми нейронными сетями.
Иерархическая модель латентных переменных для последовательных динамических процессов нескольких объектов, когда каждый объект проявляет значительную стохастичность.
В статье представлена реляционная модель пространства состояний, которая имитирует совместные переходы состояний коррелированных объектов, иерархически согласованных в графовой структуре.
Мы представляем новое индуктивное смещение, которое объединяет древовидные структуры в рекуррентных нейронных сетях.
В данной работе предлагается ON-LSTM, новый блок РНС, который интегрирует структуру латентного дерева в рекуррентные модели и показывает хорошие результаты при моделировании языка, несамостоятельном синтаксическом разборе, целевой синтаксической оценке и логическом выводе.
Дегенеративные многообразия, возникающие из-за неидентифицируемости модели, замедляют обучение в глубоких сетях; пропускные соединения помогают, разрушая вырождения.
Авторы показывают, что сингулярности устранения и перекрытия препятствуют обучению в глубоких нейронных сетях, и демонстрируют, что пропускные соединения могут уменьшить распространенность этих сингулярностей, ускоряя обучение.
В статье рассматривается использование пропускных соединений в глубоких сетях как способ смягчения сингулярностей в матрице Гессиана во время обучения.
Обучение представлениям состояния, которые отражают факторы, необходимые для управления
Подход к обучению представлений в контексте обучения с подкреплением, который функционально различает два этапа с точки зрения действий, необходимых для их достижения.
В статье представлен метод обучения представлениям, в которых близость на евклидовом расстоянии представляет состояния, достигаемые с помощью схожих политик.
Мы изучаем поведение CNN, когда она осваивает новые задачи, сохраняя при этом навыки для ранее изученных задач.
Morty обновляет предварительные вкрапления слов, чтобы: (a) улучшить общую производительность встраивания (для многозадачных установок) или улучшить производительность однозадачных установок, требуя при этом минимальных усилий.
Выборочное дополнение трудно классифицируемых точек приводит к эффективному обучению.
Авторы исследуют проблему определения стратегий подвыборки для дополнения данных и предлагают стратегии, основанные на влиянии и потерях модели, а также эмпирический бенчмаркинг предложенных методов.
Авторы предлагают использовать методы, основанные на влиянии или потерях, для выбора подмножества точек для использования в дополнении наборов данных для обучения моделей, где потери аддитивны по точкам данных.
Глубокая генеративная модель для органических молекул, которая сначала генерирует строительные блоки реактивов, а затем объединяет их с помощью предиктора реакций.
Молекулярная генеративная модель, которая генерирует молекулы с помощью двухэтапного процесса и предоставляет маршруты синтеза генерируемых молекул, позволяя пользователям исследовать синтетическую доступность генерируемых соединений.
Улучшение устойчивости и энергоэффективности глубокой нейронной сети с помощью скрытых представлений.
Данная работа направлена на уменьшение ошибочных классификаций глубоких нейронных сетей энергоэффективным способом путем добавления вспомогательных ячеек на основе релевантных признаков после одного или нескольких скрытых слоев для принятия решения о досрочном завершении классификации.
Понимание структуры представления графа знаний с помощью вкраплений слов.
В данной работе предпринята попытка понять скрытую структуру, лежащую в основе методов встраивания графов знаний, и показано, что способность модели представлять тип отношения зависит от ограничений архитектуры модели в отношении условий отношения.
В данной статье предлагается подробное исследование объяснимости моделей предсказания связей (LP) с использованием новейшей интерпретации вкраплений слов для обеспечения лучшего понимания производительности моделей LP.
Новый механизм самонаблюдения для многомерной интерполяции временных рядов с географическими метками.
В данной работе предлагается проблема применения трансформаторной сети к пространственно-временным данным эффективным с точки зрения вычислений способом, а также исследуются способы реализации трехмерного внимания.
В данной работе эмпирически исследуется эффективность трансформаторных моделей для вменения данных временных рядов в зависимости от размерности входных данных.
Мы разработали и протестировали REDNET (ResNet Encoder-Decoder) с 8 пропусками соединений для удаления шума из документов, включая размытие и водяные знаки, в результате чего была создана высокопроизводительная глубокая сеть для очистки изображений документов. 
Мы определили семейство методов защиты и показали, что как детерминированное сжатие с потерями, так и случайные возмущения на входе приводят к схожему повышению устойчивости.
В данной статье обсуждаются способы дестабилизации данной состязательной атаки, что делает состязательные образы неустойчивыми, и возможно ли злоумышленникам использовать универсальную модель возмущений, чтобы сделать свои состязательные примеры устойчивыми к таким возмущениям.
В статье исследуется устойчивость атак противника к преобразованиям входных данных.
Мы предлагаем метод сравнительной оценки оптимизаторов, учитывающий процесс настройки гиперпараметров.
Введение новой метрики для определения настраиваемости оптимизатора и всестороннее эмпирическое сравнение оптимизаторов глубокого обучения при различных объемах настройки гиперпараметров. 
В данной работе вводится простая мера настраиваемости, которая позволяет сравнивать оптимизаторы при ограничении ресурсов, и обнаруживается, что настройка скорости обучения оптимизаторов Адама легче всего позволяет найти хорошо работающие конфигурации гиперпараметров.
Мы представляем полусамоуправляемую глубокую нейронную сеть для аппроксимации решения фазовой задачи в электронной микроскопии
Word2net - это новый метод обучения нейросетевых представлений слов, который может использовать синтаксическую информацию для изучения лучших семантических характеристик.
Данная работа расширяет SGNS, меняя архитектуру с модели "мешок слов" на модель с фидфорвардом, и предлагает новую форму регуляризации, связывая подмножество слоев между различными ассоциированными сетями.
Метод использования нелинейной комбинации контекстных векторов для обучения векторному представлению слов, где основная идея заключается в замене встраивания каждого слова нейронной сетью.
Используя 10-секундное окно фМРТ-сигналов, наша модель GCN определила 21 различное условие задачи из набора данных HCP с точностью теста 89%.
Эффективное индуцирование низкоранговых глубоких нейронных сетей с помощью SVD-обучения с разреженными сингулярными значениями и ортогональными сингулярными векторами.
В данной работе представлен подход к сжатию сети путем поощрения весовой матрицы в каждом слое иметь низкий ранг и явного факторизации весовых матриц в SVD-подобную факторизацию для обработки в качестве новых параметров.
Предложение параметризировать каждый слой глубокой нейронной сети перед обучением с помощью разложения матрицы с низким рангом, соответственно заменить свертки двумя последовательными свертками, а затем обучить разложенный метод.
Мы предлагаем модель обучения с несколькими выстрелами, специально разработанную для задач регрессии
В данной статье предлагается новый метод дробного обучения для решения задач регрессии на малых выборках.
Метод, который обучает регрессионную модель на нескольких выборках и превосходит другие методы.
Мы представляем новый подход для обнаружения нераспределенных пикселей при семантической сегментации.
В данной статье рассматривается вопрос обнаружения нераспределенных участков для помощи процессу сегментации, и предлагается подход обучения бинарного классификатора, который отличает участки изображения из известного набора классов от неизвестных.
Целью данной работы является обнаружение пикселей вне распределения для семантической сегментации, и в этой работе используются данные из других областей для обнаружения неопределенных классов, чтобы лучше моделировать неопределенность.
Точная, быстрая и автоматизированная квантование нейронной сети со смешанной точностью с помощью иерархического глубокого обучения с усилением
Метод квантования весов и активаций нейронной сети, который использует глубокое обучение с подкреплением для выбора битовой ширины для отдельных ядер в слое и который достигает лучшей производительности или задержки, чем предыдущие подходы.
В данной работе предлагается автоматический поиск схем квантования для каждого ядра в нейронной сети, используя иерархическую RL для управления поиском. 
Gaggle, интерактивная система визуального анализа, помогающая пользователям интерактивно ориентироваться в пространстве моделей для задач классификации и ранжирования.
Новая визуальная аналитическая система, цель которой - дать возможность неэкспертным пользователям интерактивно ориентироваться в пространстве моделей, используя подход, основанный на демонстрации.
Система визуальной аналитики, которая помогает начинающим аналитикам ориентироваться в пространстве моделей при выполнении задач классификации и ранжирования.
Мы предлагаем новую сеть внимания с кодировщиком hybird для решения проблемы представления текста при классификации китайских текстов, особенно языковых феноменов произношения, таких как полифон и омофон.
В данной работе предлагается модель, основанная на внимании, состоящая из кодировщика слов и кодировщика пиньинь для задачи классификации китайского текста, и расширяется архитектура для кодировщика пиньиньских иероглифов.
Предложение для сети внимания, в которой для представления китайского языка учитываются как слово, так и пиньинь, с улучшенными результатами, показанными в нескольких наборах данных для классификации текстов.
мультимодальное обучение имитации на основе неструктурированных демонстраций с использованием стохастического нейросетевого моделирования намерения. 
Новый подход на основе выборки для вывода в моделях латентных переменных, который применим к мультимодальному обучению имитации и работает лучше, чем детерминированные нейронные сети и стохастические нейронные сети для реальной задачи визуальной робототехники.
В данной работе показано, как обучиться нескольким модальностям с помощью имитационного обучения на основе визуальных данных с использованием стохастических нейронных сетей, а также метод обучения на демонстрациях, где дается несколько модальностей одной и той же задачи.
Новый подход к построению иерархических объяснений для классификации текстов путем обнаружения взаимодействия признаков.
Новый метод предоставления объяснений для предсказаний, сделанных текстовыми классификаторами, который превосходит базовые показатели по оценке важности на уровне слов, а также новую метрику, потери связности, для оценки важности на уровне пролета.
Метод интерпретации, основанный на взаимодействии признаков и оценке важности признаков по сравнению с независимыми вкладами признаков.
Мы заставляем конволюционные слои работать быстрее, динамически усиливая и подавляя каналы при вычислении признаков.
Метод усиления и подавления признаков для динамической обрезки каналов, который предсказывает важность каждого канала, а затем использует аффинную функцию для усиления/подавления важности канала.
Предложение по методу обрезки каналов для динамического выбора каналов во время тестирования.
Нейронные сети могут быть предварительно определены так, чтобы иметь разреженную связь без ухудшения производительности.
В данной работе рассматриваются разреженные схемы связей в верхних слоях конволюционных сетей классификации изображений, а также вводятся эвристики для распределения связей между окнами/группами и мера под названием scatter для построения масок связности.
Предложение по уменьшению количества параметров, изучаемых глубокой сетью, путем установки разреженных весов связей в классификационных слоях и введения понятия "разброс".
Мы предлагаем комплексный, строгий и последовательный эталон для оценки устойчивости моделей глубокого обучения к неблагоприятным факторам.
В данной статье представлена оценка различных видов моделей классификации при различных методах атаки противника.
Крупномасштабное эмпирическое исследование, сравнивающее различные методы атаки и защиты, а также использование кривых "точность против бюджета возмущений" и "точность против силы атаки" для оценки атак и защиты.
Мы предлагаем модификацию традиционных искусственных нейронных сетей, основанную на биологии нейронов, чтобы форма функции активации зависела от контекста.
Метод масштабирования активаций слоя нейронов в ИНС в зависимости от входов в этот слой, который показывает улучшения выше базовых значений.
Введение изменения архитектуры для базовых нейронов в нейронной сети и идея умножения выхода линейной комбинации нейронов на модулятор перед подачей его в функцию активации.
Мы выявили проблему забывания при точной настройке предварительно обученных моделей NLG и предложили стратегию mix-review для ее решения.
В данной статье анализируется проблема забывания в рамках предварительного обучения-финетунинга с точки зрения чувствительности к контексту и передачи знаний, а также предлагается стратегия тонкой настройки, которая превосходит метод снижения веса.
Исследование проблемы забывания в системе предварительного обучения-финетуны, в частности, в задачах генерации диалоговых ответов, и предложение стратегии микс-рецензирования для облегчения проблемы забывания.
Улучшенное моделирование сложных систем использует гибридную композицию нейронных/доменных моделей, новые функции потерь декорреляции и экстраполяционные тестовые наборы 
В данной работе проводятся эксперименты по сравнению экстраполяционных прогнозов различных гибридных моделей, состоящих из физических моделей, нейронных сетей и стохастических моделей, и решается проблема немоделируемой динамики как узкого места.
В данной статье представлены подходы к объединению нейронных сетей с не-NNN моделями для прогнозирования поведения сложных физических систем.
Мы изучаем плотные оценки и модель динамики в качестве приор из данных разведки и используем их, чтобы вызвать хорошую политику в новых задачах в условиях нулевого выстрела.
В данной статье рассматривается обобщение нулевого выстрела на новые среды и предлагается подход с результатами на примере Grid-World, Super Mario Bros и 3D Robotics.
Метод, нацеленный на изучение диагностических приоритетов задачи для обобщения нулевого выстрела, с идеей использования подхода моделирования поверх основы RL, основанной на моделях.
Исследовать механизмы, лежащие в основе дисперсионного коллапса SVGD в высоких измерениях.
Переосмысление обобщения требует пересмотра старых идей: подходы статистической механики и сложное обучающее поведение
Авторы предполагают, что идеи статистической механики помогут понять обобщающие свойства глубоких нейронных сетей, и предлагают подход, который обеспечивает сильные качественные описания эмпирических результатов, касающихся глубоких нейронных сетей и алгоритмов обучения.
Набор идей, связанных с теоретическим пониманием обобщающих свойств многослойных нейронных сетей, и качественная аналогия между поведением в глубоком обучении и результатами количественного статистического анализа физики одно- и двухслойных нейронных сетей.
Мы представляем дважды разреженный softmax, разреженную смесь разреженных экспертов, для повышения эффективности вывода softmax за счет использования двухуровневой перекрывающейся иерархии. 
В данной статье предлагается быстрая аппроксимация вычисления softmax, когда количество классов очень велико.
В данной работе предлагается смесь разреженных экспертов, которая обучается двухуровневой иерархии классов для эффективного вывода softmax.
Мы исследуем использование пассивно собранных данных слежения за глазами, чтобы уменьшить количество маркированных данных, необходимых во время обучения.
Метод использования информации о взгляде для уменьшения сложности выборки модели и необходимых усилий по маркировке для получения целевой производительности, с улучшенными результатами в выборках среднего размера и более трудных задачах.
Метод включения сигналов взгляда в стандартные CNN для классификации изображений, добавляя член функции потерь, основанный на разнице между картой активации класса модели и картой, построенной на основе информации о слежении за глазами.
Мы применяем коррекцию потерь в графовых нейронных сетях для обучения более устойчивой к шуму модели.
В данной статье представлена коррекция потерь для графовых нейронных сетей для борьбы с симметричным шумом меток графа, сфокусированная на задаче классификации графов.
В данной работе предлагается использование потери коррекции шума в контексте графовых нейронных сетей для работы с зашумленными метками.
Мы используем совместное внимание графов в системе обучения парных графов для классификации и регрессии графов.
В данной работе в GCN вводится механизм совместного присутствия нескольких голов, который позволяет одному лекарству присутствовать в другом лекарстве во время предсказания побочного действия лекарства.
Метод расширения обучения на основе графов с помощью ко-аттенционального слоя, который превосходит другие предыдущие методы в задаче парной классификации графов.
Создание подписей к изображениям как условное обучение GAN с использованием новых архитектур, также изучаются два дискретных метода обучения GAN. 
Улучшенная модель GAN для создания подписей к изображениям, которая предлагает контекстно-зависимый LSTM-картинщик, вводит более сильный коаттентивный дискриминатор с лучшей производительностью и использует SCST для обучения GAN.
Использование кривизны для того, чтобы методы MCMC сходились быстрее, чем современные.
Keras для бесконечных нейронных сетей.
Мы предлагаем новую функцию потерь, которая достигает лучших результатов в обнаружении нераспределенности с помощью функции Outlier Exposure как в задачах классификации изображений, так и текстов.
В данной работе решаются проблемы обнаружения нераспределенности и калибровки модели путем адаптации функции потерь метода Outlier Exposure. Результаты демонстрируют более высокую производительность по сравнению с OE на эталонах зрения и текста и улучшенную калибровку модели.
Предложение новой функции потерь для обучения сети с выделением выбросов, которая приводит к лучшему обнаружению OOD по сравнению с простыми функциями потерь, использующими дивергенцию KL.
Предварительное обучение, не зависящее от задачи, может формировать аттракторный ландшафт РНС и формировать различные индуктивные предубеждения для различных навигационных задач   
В данной работе изучаются внутренние представления рекуррентных нейронных сетей, обученных на навигационных задачах, и обнаруживается, что РНС, предварительно обученные для использования интеграции путей, содержат двумерные непрерывные аттракторы, в то время как РНС, предварительно обученные для запоминания ориентиров, содержат дискретные аттракторы.
В данной работе исследуется, как предварительное обучение рекуррентных сетей на различные навигационные цели дает различные преимущества для решения последующих задач, и показывается, как различное предварительное обучение проявляется в виде различных динамических структур в сетях после предварительного обучения.
Нейросетевая верификация для темпоральных свойств и моделей генерации последовательностей
Данная работа расширяет распространение границ интервалов на рекуррентные вычисления и авторегрессионные модели, вводит и расширяет сигнальную темпоральную логику для задания временных ограничений, а также предоставляет доказательство того, что STL с распространением границ может обеспечить соответствие нейронных моделей временной спецификации.
Способ верифицируемого обучения регрессоров временных рядов относительно набора правил, определяемых сигнальной временной логикой, и работа по выведению правил распространения границ для языка STL.
Мы предлагаем универсальное нейросетевое решение для автоматического вывода эффективных архитектур NN для табличных данных.
Новая процедура обучения нейронной сети, разработанная для табличных данных, которая направлена на использование кластеров признаков, извлеченных из GBDT.
Предложение для гибридного алгоритма машинного обучения с использованием Gradient Boosted Decision Trees и Deep Neural Networks, с предполагаемым направлением исследования на табличных данных.
Система обучения вероятностным правилам с использованием приподнятого вывода
Модель вероятностного обучения правилам для автоматизации заполнения вероятностных баз данных, использующая AMIE+ и поднятый вывод для повышения эффективности вычислений.
Мы предлагаем первую неавторегрессионную нейронную модель для отслеживания состояния диалога (DST), достигая точности SOTA (49,04%) на эталоне MultiWOZ2.1 и уменьшая время ожидания вывода на порядок.
Новая модель для задачи DST, которая снижает сложность времени вывода с помощью неавторегрессионного декодера, обеспечивает конкурентоспособную точность DST и демонстрирует улучшения по сравнению с другими базовыми моделями.
Предложение для модели, способной отслеживать состояния диалога нерекурсивным способом.
Новая сетевая архитектура для выполнения глубокого 3D-зума или крупного плана.
Метод создания "увеличенного изображения" для заданного входного изображения, и новая потеря реконструкции обратной проекции, которая позволяет сети изучать лежащую в основе 3D структуру и сохранять естественный вид.
Алгоритм синтеза поведения 3D-зума при движении камеры вперед, сетевая структура, включающая оценку диспаратности в рамках GANs для синтеза новых представлений, и предложенная новая задача компьютерного зрения.
Количественное уточнение универсальной теоремы аппроксимации с помощью алгебраического подхода.
Авторы выводят доказательства универсального свойства аппроксимации алгебраически и утверждают, что результаты являются общими для других видов нейронных сетей и аналогичных обучающих устройств.
Новое доказательство версии Лешно универсального свойства аппроксимации для нейронных сетей, а также новое понимание универсального свойства аппроксимации.
Модульная структура для классификации документов и техника агрегации данных для придания структуре устойчивости к различным искажениям и шумам и фокусировки только на важных словах. 
Авторы рассматривают обучение классификации текста на основе РНС в условиях ограничения ресурсов на предсказание во время тестирования и предлагают подход, использующий механизм маскировки для уменьшения количества слов/фраз/предложений, используемых в предсказании, а затем классификатор для обработки этих компонентов.
Разрешение частичного соединения каналов в суперсетях для регуляризации и ускорения поиска дифференцируемой архитектуры
Расширение метода поиска нейронной архитектуры DARTS, которое устраняет его недостаток - огромные затраты памяти - за счет использования случайного подмножества каналов и метода нормализации ребер.
В данной работе предлагается улучшить DARTS с точки зрения эффективности обучения, от больших накладных расходов на память и вычисления, и предлагается частично связанный DARTS с частичным соединением каналов и нормализацией краев.
Агенты взаимодействуют (говорят, действуют) и могут достигать целей в богатом мире с разнообразным языком, преодолевая разрыв между болтовней и диалогом, ориентированным на достижение цели.
В данной работе изучается задача мультиагентного диалога, в которой обучающийся агент стремится генерировать действия на естественном языке, вызывающие определенное действие со стороны другого агента, и показано, что RL-агенты могут достичь более высоких уровней выполнения задачи, чем базовые модели имитационного обучения.
В данной работе исследуется постановка диалогов, ориентированных на цель, с помощью обучения с подкреплением в фэнтезийной текстовой приключенческой игре, и отмечается, что RL-подходы превосходят модели контролируемого обучения.
Новый метод с частичной диагностикой политики для оценки политики вне политики в бесконечном горизонте с несколькими известными или неизвестными политиками поведения.
Оценка смешанной политики, которая заимствует идеи из оценщиков бесконечного горизонта оценки внеполитической политики и регрессионной выборки важности для веса важности, и распространяет их на множество политик и неизвестные политики.
Алгоритм для решения проблемы оценки политики с бесконечным горизонтом при множественной политике поведения путем оценки смешанной политики с помощью регрессии, и теоретическое доказательство того, что оценочное отношение политики может уменьшить дисперсию.
Мы представляем более эффективную нейронную архитектуру для амортизированного вывода, которая объединяет непрерывные и условные нормализующие потоки, используя принципиальный выбор структуры разреженности.
Мы показываем, что ENAS с ES-оптимизацией в RL обладает высокой масштабируемостью, и используем его для уплотнения нейросетевых политик путем разделения весов.
Авторы строят политики обучения с подкреплением с очень малым количеством параметров, сжимая нейронную сеть с прямой передачей, заставляя ее разделять веса и используя метод обучения с подкреплением для обучения отображению разделяемых весов.
В данной работе объединены идеи методов ENAS и ES для оптимизации, а также представлена архитектура хроматической сети, которая разбивает веса сети RL на связанные подгруппы.
Мы представляем Deep SAD, глубокий метод для общего полунаблюдаемого обнаружения аномалий, который особенно использует преимущества меченых аномалий.
Новый метод поиска аномальных данных, когда даны некоторые помеченные аномалии, который применяет потери, выведенные теорией информации, основанные на том, что нормальные данные обычно имеют более низкую энтропию, чем аномальные данные.
Предложение структуры обнаружения аномалий в условиях, когда доступны немеченые данные, меченые положительные данные и меченые отрицательные данные, и предложение подхода к полусамостоятельному AD с точки зрения теории информации.
В данной статье анализируется динамика обучения и критические точки обучения глубокой сети ReLU с помощью SGD в режиме "учитель-ученик". 
Исследование перепараметризации в многослойных ReLU-сетях "ученик-учитель", теоретическая часть о критических точках SGD для множества "учитель-ученик", эвристическая и эмпирическая часть о динамике алгоритма SDG как функции сетей учителей.
При определенных условиях на входные и выходные линейные преобразования, как GD, так и SGD могут достичь глобальной сходимости для обучения глубоких линейных ResNets.
Авторы исследуют сходимость градиентного спуска при обучении глубоких линейных остаточных сетей и устанавливают глобальную сходимость GD/SGD и линейные скорости сходимости SG/SGD.
Исследование свойств сходимости GD и SGD на глубоких линейных сетках и доказательство того, что при определенных условиях на входные и выходные преобразования и при нулевой инициализации GD и SGD сходятся к глобальным минимумам.
Мы анализируем процесс обучения глубоких сетей и показываем, что они начинают с быстрого обучения неглубоких классифицируемых примеров и медленно обобщают их на более сложные точки данных.
Обучение глубоких латентных переменных MRF с целью в седловой точке, полученной из аппроксимации функции разбиения Бете.
Метод обучения глубокой латентно-переменной MRF с целью оптимизации, использующей свободную энергию Бете, который также решает основные ограничения оптимизации свободной энергии Бете.
Цель для обучения MRF с латентными переменными, основанная на свободной энергии Бете и амортизированном выводе, отличная от оптимизации стандартного ELBO.
Общая структура для создания объяснений с помощью логики.
В данной статье исследуется генерация объяснений с точки зрения КР и проводятся эксперименты по измерению размера объяснения и времени выполнения на случайных формулах и формулах из экземпляра Blocksworld.
Данная работа представляет перспективу объяснений между двумя базами знаний и идет параллельно с работой по согласованию моделей в литературе по планированию.
Глубокие и узкие нейронные сети с высокой вероятностью сходятся к ошибочным средним или медианным состояниям целевой функции в зависимости от потерь.
В данной работе изучаются режимы отказа глубоких и узких сетей, фокусируясь на как можно меньших моделях, для которых возникает нежелательное поведение.
В данной работе показано, что обучение глубоких нейронных сетей ReLU будет сходиться к постоянному классификатору с высокой вероятностью по сравнению со случайной инициализацией, если ширина скрытого слоя слишком мала.
Мы предлагаем обучение MMA для прямой максимизации маржи входного пространства, чтобы улучшить устойчивость к воздействию противника, прежде всего, за счет устранения требования задавать фиксированную границу искажения.
Подход к обучению устойчивых ДНС на основе адаптивной маржи, максимизирующий кратчайший запас между входами и границей принятия решения, что делает возможным обучение с большими возмущениями.
Предложен метод робастного обучения против атак противника, в котором непосредственно максимизируется маржа входного пространства, а также softmax-вариант max-margin.
Мы предлагаем метод обнаружения аномалий с помощью GANs путем поиска в латентном пространстве генератора хороших представлений образцов.
Авторы предлагают использовать GAN для обнаружения аномалий, метод на основе градиентного спуска для итеративного обновления латентных представлений и новое обновление параметров генераторов.
Подход на основе GAN к обнаружению аномалий для данных изображений, где латентное пространство генератора исследуется для поиска представления тестового изображения.
Переходное поведение градиентных алгоритмов MCMC и алгоритмов вариационного вывода более схоже, чем можно подумать, что ставит под сомнение утверждение о том, что вариационный вывод быстрее MCMC.
Графовая конволюционная структура на основе композиции для многосвязных графов.
Авторы разрабатывают GCN на многосвязных графах и предлагают CompGCN, который использует знания из вкраплений графов знаний и обучается представлениям узлов и связей для облегчения проблемы избыточной параметризации.
В данной работе представлена структура GCN для мультиреляционных графов и обобщены несколько существующих подходов к встраиванию графов знаний в единую структуру.
Мы полностью квантуем трансформатор до 8 бит и улучшаем качество перевода по сравнению с моделью полной точности.
Метод 8-битного квантования для квантования модели машинного перевода Transformer, предлагающий использовать равномерное минимаксное квантование во время вывода и взвешивание перед квантованием для уменьшения ошибки квантования.
Метод уменьшения требуемого объема памяти с помощью техники квантования, ориентированный на уменьшение для архитектуры Transformer.
Latent Embedding Optimization (LEO) - это новый метаобучающий инструмент на основе градиента, который показал самые высокие результаты в сложных задачах классификации 5-полосной 1-снимковой и 5-снимковой miniImageNet и tieredImageNet.
Новая система метаобучения, которая изучает латентное пространство, зависящее от данных, выполняет быструю адаптацию в латентном пространстве, эффективна для обучения в несколько выстрелов, имеет зависящую от задачи инициализацию для адаптации и хорошо работает при мультимодальном распределении задач.
В данной статье предлагается метод оптимизации латентного встраивания для мета-обучения, и утверждается, что его вклад заключается в том, чтобы отделить методы мета-обучения на основе оптимизации от высокоразмерного пространства параметров модели.
Реляционные индуктивные предубеждения улучшают способность к обобщению вне распределения в агентах обучения с подкреплением без моделей
Архитектура общей реляционной сети для параметризации сети акторов и критиков, ориентированная на распределенные алгоритмы актор-критик с преимуществами, которая усиливает безмодельные методы глубокого подкрепления с реляционными знаниями об окружающей среде, чтобы агенты могли изучать интерпретируемые представления состояния.
Количественный и качественный анализ и оценка механизма самовнимания в сочетании с сетью отношений в контексте безмодельного RL.
Мы предлагаем простую генеративную модель для перевода изображений без наблюдения и обнаружения салиента.
Мы определяем концепцию послойных модельно-параллельных глубоких нейронных сетей, для которых слои работают параллельно, и предоставляем инструментарий для проектирования, обучения, оценки и онлайн-взаимодействия с этими сетями.
Ускоренный на GPU инструментарий для параллельного обновления нейронов, написанный на языке Theano, который поддерживает различные порядки обновления в рекуррентных сетях и сетях с соединениями, пропускающими слои. 
Новый инструментарий для обучения и оценки глубоких нейронных сетей, а также предложение по переходу от послойно-последовательных сетей к послойно-параллельным.
Метод защиты от состязательности, объединяющий устойчивость глубоких нейронных сетей с устойчивостью по Ляпунову
Авторы формулируют обучение ИНС как поиск оптимального регулятора для дискретной динамической системы, что позволяет им использовать метод последовательных приближений для обучения ИНС таким образом, чтобы он был более устойчив к атакам противника.
В данной работе используется теоретический взгляд на нейронную сеть как на дискретизированную ОДУ для разработки теории робастного управления, направленной на обучение сети с обеспечением робастности.
Мы предлагаем простую, но эффективную схему перевзвешивания для GCNs, теоретически подкрепленную теорией среднего поля.
Метод, известный как DrGCN, для перевзвешивания различных измерений представлений узлов в графовых сверточных сетях путем уменьшения дисперсии между измерениями.
Наш подход является первой попыткой использовать последовательную модель латентных переменных для выбора знаний в многооборотном диалоге, основанном на знаниях. Он достиг новой современной производительности на эталоне Wizard of Wikipedia.
Модель последовательных латентных переменных для выбора знаний при генерации диалога, которая расширяет модель апостериорного внимания на проблему выбора латентных знаний и достигает более высоких показателей, чем предыдущие современные модели.
Новая архитектура для выбора многооборотных диалогов, основанных на знаниях, которая показывает лучшие результаты на соответствующих эталонных наборах данных, а также более высокие результаты при оценке человеком.
Мы предлагаем метод мета-обучения, который эффективно амортизирует иерархический вариационный вывод по эпизодам обучения.
Адаптация к моделям типа MAML, учитывающая апостериорную неопределенность в латентных переменных, специфичных для задачи, путем использования вариационного вывода для специфичных для задачи параметров в иерархическом байесовском представлении MAML.
Авторы рассматривают мета-обучение для получения предварительного значения весов нейронной сети, выполняемое с помощью амортизированного вариационного вывода.
Представление/дистилляция знаний путем максимизации взаимной информации между учителем и учеником
В данной работе сочетается контрастная задача измерения взаимной информации между представлениями, полученными сетями учителя и ученика, для дистилляции моделей, и предлагается модель с улучшением по сравнению с существующими альтернативами в задачах дистилляции.
Сети, которые обучаются с помощью связей обратной связи и правил локальной пластичности, могут быть оптимизированы для использования мета-обучения.
CNN с биологически вдохновленными боковыми связями, обученными несамостоятельным образом, более устойчивы к шумным входным данным. 
Целью данной работы является разработка подхода к представлению тензорных продуктов для приложений обработки естественного языка на основе глубокого обучения.
Мы изучаем сертифицированную устойчивость для прогнозов top-k с помощью рандомизированного сглаживания при гауссовском шуме и выводим жесткую границу устойчивости в норме L_2.
Данная статья расширяет работу по выведению сертифицированного радиуса с использованием рандомизированного сглаживания и показывает радиус, при котором сглаженный классификатор при гауссовских возмущениях сертифицирован для k лучших предсказаний.
Данная работа основана на технике случайного сглаживания для предсказания топ-1 и направлена на предоставление сертификации по предсказанию топ-к.
Мы представляем структурированные приоритеты для неконтролируемого обучения распутанных представлений в VAEs, которые значительно смягчают компромисс между распутыванием и потерями при реконструкции.
Общая схема использования семейства L^p-вложенных распределений в качестве приоритета для кодового вектора VAE, демонстрирующая более высокую MIG.
Авторы указывают на проблемы в существующих подходах VAE и предлагают новый взгляд на компромисс между реконструкцией и ортогонализацией для VAE, beta-VAE и beta-TCVAE.
Мы обобщаем остаточные блоки до тандемных блоков, которые используют произвольные линейные карты вместо ярлыков, и улучшаем производительность по сравнению с ResNets.
В данной статье проводится анализ коротких связей в ResNet-подобных архитектурах, и предлагается заменить тождественные короткие связи альтернативными конволюционными, называемыми тандемным блоком.
В данной работе исследуется эффект замены идентичных пропускных соединений на обучаемые конволюционные пропускные соединения в ResNet и обнаруживается, что производительность улучшается.
Мы представляем новую структуру для адаптации методов типа Adam, а именно AdamT, для включения информации о тенденции при обновлении параметров с адаптивным размером шага и градиентами.
Новый тип варианта Адама, который использует линейный метод Холта для вычисления сглаженного импульса первого и второго порядка вместо использования экспоненциального взвешенного среднего.
Метод объяснения классификатора путем создания визуального возмущения изображения, преувеличивая или уменьшая семантические признаки, которые классификатор связывает с целевой меткой.
Модель, которая при поступлении запроса в "черный ящик" стремится объяснить результат, предоставляя правдоподобные и прогрессивные вариации запроса, которые могут привести к изменению результата.
Метод объяснения выходных данных классификации изображений с помощью черного ящика, который генерирует постепенное возмущение выходных данных в ответ на постепенно возмущаемые входные запросы.
Мы представляем подход к построению объяснений поведения глубоких конволюционных сетей, ориентированный на влияние, и показываем, как он может быть использован для ответа на широкий круг вопросов, которые не могли быть решены в предыдущих работах.
Способ измерения влияния, удовлетворяющий определенным аксиомам, и понятие влияния, которое может быть использовано для определения того, какая часть входного сигнала является наиболее влиятельной для выхода нейрона в глубокой нейронной сети.
В данной работе предлагается измерить влияние отдельных нейронов на интересующую величину, представленную другим нейроном.
Мы рассказываем о методе, с помощью которого системы обработки естественного языка могут узнавать новое слово из контекста, что позволяет им быть гораздо более гибкими.
Техника использования предыдущих знаний для изучения представлений вкраплений для новых слов с минимальными данными.
Архитектура памяти, поддерживающая инференциальные рассуждения.
В данной статье предлагаются изменения в архитектуре сети памяти End2End, вводится новая задача парного ассоциативного вывода, которую большинство существующих моделей решают с трудом, и показывается, что предложенная ими архитектура решает эту задачу лучше.
Новая задача (парное ассоциативное умозаключение), взятая из когнитивной психологии, и предложение новой архитектуры памяти с характеристиками, позволяющими лучше справляться с задачей парного ассоциативного умозаключения.
Глубинные сепарабельные свертки улучшают нейронный машинный перевод: чем больше сепарабельность, тем лучше.
В данной статье предлагается использовать разделяемые по глубине сверточные слои в полностью сверточной нейронной модели машинного перевода, а также вводится новый суперразделяемый сверточный слой, который еще больше снижает вычислительные затраты.
Обучение GAN без насыщения эффективно минимизирует обратную KL-подобную f-дивергенцию.
В данной работе предлагается полезное выражение класса f-дивергенций, исследуются теоретические свойства популярных f-дивергенций с помощью недавно разработанных инструментов, а также исследуются GAN с ненасыщающей схемой обучения.
Мы представляем новый метод представления текста, который позволяет применять классификаторы изображений для решения задач классификации текста, и применяем этот метод для разотождествления имен изобретателей.
Метод отображения пары текстовой информации в двумерное RGB-изображение, которое может быть подано на двумерные сверточные нейронные сети (классификаторы изображений).
Авторы рассматривают проблему однозначной идентификации имен изобретателей в патентах и предлагают построить страничное представление двух строк имен для сравнения и применить классификатор изображений.
Мы предложили модель "Difference-Seeking Generative Adversarial Network" (DSGAN) для изучения целевого распределения, для которого трудно собрать обучающие данные.
В данной статье представлен DS-GAN, предназначенный для изучения разницы между любыми двумя распределениями, выборки которых трудно или невозможно собрать, и показана его эффективность в задачах полунаблюдаемого обучения и обучения в условиях состязательности.
В данной статье рассматривается проблема обучения GAN для захвата целевого распределения при наличии лишь очень небольшого количества обучающих выборок из этого распределения.
Общий метод, улучшающий производительность перевода изображений в рамках GAN с помощью встроенного дискриминатора внимания
Механизм обратной связи в системе GAN, который улучшает качество генерируемых изображений при переводе от изображения к изображению, и чей дискриминатор выводит карту, указывающую, где генератор должен сосредоточиться, чтобы сделать свои результаты более убедительными.
Предложение для GAN с основанным на внимании дискриминатором для перевода I2I, который обеспечивает вероятность реального/поддельного и карту внимания, которая отражает соленость для генерации изображения.
Мы предлагаем новый набор данных для исследования проблемы энтитета в условиях полуструктурированной таблицы в качестве предпосылки
В данной статье предлагается новый набор данных для проверки фактов на основе таблиц и представлены методы для решения этой задачи.
Авторы предлагают проблему проверки фактов с полуструктурированными источниками данных, такими как таблицы, создают новый набор данных и оценивают базовые модели с вариациями.
Мы разработали архитектуру глубокого сопоставления графов, которая уточняет исходные соответствия для достижения консенсуса соседей.
Система для ответа на вопросы о соответствии графов, состоящая из локальных вкраплений узлов с шагом уточнения по передаче сообщений.
Двухэтапная архитектура на основе GNN для установления соответствий между двумя графами, которая хорошо справляется с реальными задачами сопоставления изображений и выравнивания сущностей графов знаний.
Данная работа расширяет доказательство плотности нейронных сетей в пространстве непрерывных (или даже измеримых) функций на евклидовых пространствах на функции на компактных множествах вероятностных мер. 
В данной работе исследуются аппроксимационные свойства семейства нейронных сетей, разработанных для решения задач обучения по нескольким фактам, и показано, что результаты для стандартных однослойных архитектур распространяются и на эти модели.
Данная работа обобщает универсальную теорему аппроксимации на вещественные функции на пространстве мер.
Новая структура для контекстно-зависимых и бесконтекстных объяснений предсказаний
Авторы расширяют линейный метод локальной атрибуции LIME для интерпретации моделей "черного ящика" и предлагают метод различения контекстно-зависимых и бесконтекстных взаимодействий.
Метод, который может предоставить иерархические объяснения для модели, включая как контекстно-зависимые, так и бесконтекстные объяснения с помощью алгоритма локальной интерпретации.
Тонкая настройка после квантования соответствует или превосходит современные сети с полной точностью как при 8-, так и при 4-битовом квантовании.
В данной статье предлагается улучшить производительность низкоточных моделей путем квантования на предварительно обученных моделях, использования большого размера партий и использования отжига с надлежащей скоростью обучения при более длительном времени обучения.
Метод квантования с малым количеством битов, позволяющий проводить выводы на эффективном аппаратном обеспечении, достигающий полной точности на ResNet50 с 4-битными весами и активациями, основанный на наблюдениях, что тонкая настройка с низкой точностью вносит шум в градиент.
Два метода, основанные на анализе репрезентативного сходства (RSA) и древовидных ядрах (TK), которые непосредственно количественно определяют, насколько сильно информация, закодированная в паттернах нейронной активации, соответствует информации, представленной символическими структурами.
В данной статье представлена структура для эффективного с точки зрения данных обучения представлений путем адаптивной выборки в латентном пространстве.
Метод последовательного и адаптивного отбора обучающих примеров для представления алгоритму обучения, где отбор происходит в латентном пространстве на основе выбора примеров в направлении градиента потерь.
Метод эффективного отбора жестких выборок во время обучения нейронной сети, достигаемый с помощью вариационного автокодера, который кодирует выборки в латентное пространство.
Метод состязательного обучения для разделения двух взаимодополняющих наборов вариаций в наборе данных, где маркирована только одна из них, проверен на примере стиля и содержания в иллюстрациях аниме.
Метод генерации изображений, объединяющий условные GAN и условные VAE, который генерирует высокоточные изображения аниме с различными стилями от различных художников. 
Предложение по методу изучения рассогласованных представлений стиля (художника) и содержания в аниме.
Мы вводим регуляризацию гладкости для конволюционных ядер CNN, которая может помочь улучшить устойчивость к неблагоприятным воздействиям и привести к перцептивно выровненным градиентам.
В данной статье предлагается новая схема регуляризации, которая поощряет конволюционные ядра быть более гладкими, утверждая, что снижение зависимости нейронной сети от высокочастотных компонентов способствует устойчивости к неблагоприятным примерам. 
Авторы предлагают метод обучения более гладким конволюционным ядрам, в частности, регуляризатор, штрафующий большие изменения между последовательными пикселями ядра с интуицией штрафа за использование высокочастотных входных компонентов.
Мы исследовали поведение оценок Q-значений на больших выборках и предложили эффективную стратегию поиска, которая основывается на оценке относительных расхождений между оценками Q. 
Мы обучаем вкрапления слов на основе энтитета, а не сходства, успешно предсказывая лексический энтитет.
В статье представлен алгоритм встраивания слов для лексической эвентуальности, который следует работе Хендерсона и Попы (ACL, 2016).
Неконтролируемое обучение для обучения с подкреплением с использованием автоматической программы самовоспроизведения
Новая формулировка для исследования окружающей среды без наблюдения для последующего выполнения конкретной задачи, когда один агент предлагает все более сложные задачи, а обучающийся агент пытается их выполнить.
Модель самостоятельной игры, в которой один агент учится предлагать задания, которые легки для него, но трудны для соперника, создавая движущуюся цель целей самостоятельной игры и учебной программы. 
Эксплуатация богатых структурных деталей в граф-структурированных данных с помощью адаптивных "структурных отпечатков".
Методология, основанная на графовой структуре, для расширения механизма внимания графовых нейронных сетей, с основной идеей исследования взаимодействия между различными типами узлов локальной окрестности корневого узла.
Данная работа расширяет идею самонаблюдения в графовых ЯП, которая обычно основывается на сходстве признаков между узлами, на структурное сходство.
Мы предлагаем масштабируемый алгоритм Bayesian Reinforcement Learning, который обучается байесовской коррекции над ансамблем ясновидящих экспертов для решения задач со сложными скрытыми вознаграждениями и динамикой.
В данной работе рассматривается проблема байесовского обучения с усилением над латентными марковскими процессами принятия решений (MDP) путем принятия решений с экспертами.
В этой статье авторы мотивируют и предлагают алгоритм обучения, названный Байесовской оптимизацией остаточной политики (BRPO), для Байесовских проблем обучения с подкреплением.
Мы доказываем, что градиентный спуск достигает нулевых потерь при обучении с линейной скоростью на чрезмерно параметризованных нейронных сетях.
В данной работе рассматривается оптимизация двухслойной перепараметризованной сети ReLU с квадратичными потерями и с учетом набора данных с произвольными метками.
В данной работе исследуются нейронные сети с одним скрытым слоем и квадратичными потерями, где показано, что в чрезмерно параметризованной настройке случайная инициализация и градиентный спуск приводят к нулевым потерям.
Анализ обратных задач с помощью инвертируемых нейронных сетей
Автор предлагает использовать инвертируемые сети для решения неоднозначных обратных задач и предлагает обучать не только прямую модель, но и обратную модель с помощью MMD-критики.
В научной статье предлагается инвертируемая сеть с наблюдениями для апостериорной вероятности сложных входных распределений с теоретически обоснованной схемой двунаправленного обучения.
Показатели эффективности - это неполные характеристики; цель не всегда оправдывает средства.
Авторы показывают, как мета-обучение выявляет скрытые стимулы для сдвига распределения и предлагают подход, основанный на переключении обучающихся между средами, чтобы уменьшить самопроизвольный сдвиг распределения.
В статье обобщается присущий обучающемуся стимул к победе путем облегчения задачи в мета-обучении на более широкий класс проблем.
Мы предлагаем подход к обнаружению аномалий, который сочетает моделирование класса переднего плана с помощью нескольких локальных плотностей с обучением по принципу состязательности.
В статье предлагается методика, позволяющая сделать генеративные модели более надежными путем приведения их в соответствие с локальной плотностью.
Мы предлагаем вариант GAN, который учится генерировать облака точек. Были проведены различные исследования, включая более жесткую оценку расстояния Вассерштейна, условное генерирование, обобщение на невидимые облака точек и переход от изображения к облаку точек.
В данной статье предлагается использовать GAN для генерации 3D облака точек и вводится задача сэндвичинга, усредняя верхнюю и нижнюю границы расстояния Вассерштейна между распределениями.
В данной статье предлагается новая генеративная модель для неупорядоченных данных, с особым применением к облакам точек, которая включает метод вывода и новую целевую функцию. 
В статье представлен новый подход к изучению аттенционных механизмов, который может принести пользу целому ряду задач, таких как машинный перевод и создание подписей к изображениям.
Данная работа расширяет существующие модели внимания с уровня слова на комбинацию соседних слов, применяя модели к элементам, составленным из объединенных соседних слов.
Мы выявили феномен - нейронное промывание мозгов - и ввели статистически обоснованное снижение пластичности веса для его преодоления.
В данной статье рассматривается явление "нейронного промывания мозгов", которое заключается в том, что на производительность одной модели влияет другая модель, обмениваясь параметрами модели.
В данной статье представлен Morpho-MNIST, набор метрик формы и возмущений, что является шагом к количественной оценке обучения представлений.
В данной статье рассматривается проблема оценки и диагностики репрезентаций, полученных с помощью генеративной модели.
Авторы представляют набор критериев для классификации дигистов MNISt и набор интересных возмущений для модификации набора данных MNIST.
структурированная разведка в глубоком обучении с подкреплением через несамостоятельное обнаружение и управление визуальными абстракциями
В статье представлены визуальные абстракции, которые используются для обучения с подкреплением, где алгоритм учится "управлять" каждой абстракцией, а также выбирать варианты для достижения общей задачи.
Новый политико-градиентный алгоритм, разработанный для решения комбинаторных задач оптимизации "черного ящика". Алгоритм полагается только на оценки функций и возвращает локально оптимальные решения с высокой вероятностью.
В статье предлагается подход к построению суррогатных целей для применения градиентных методов политики в комбинаторной оптимизации с целью уменьшения необходимости настройки гиперпараметров.
В статье предлагается заменить член вознаграждения в алгоритме градиента политики на его центрированное эмпирическое кумулятивное распределение. 
Быстрая калиброванная оценка неопределенности для нейронных сетей без выборки
В данной работе предлагается новый подход к оценке достоверности прогнозов в условиях регрессии, что открывает двери для онлайн-приложений с полностью интегрированными оценками неопределенности.
В данной работе предложена глубокая доказательная регрессия - метод обучения нейронных сетей не только для оценки выходных данных, но и сопутствующих доказательств в поддержку этих данных.
Мы предлагаем новый алгоритм, который быстро находит выигрышные билеты в нейронных сетях.
В данной работе предлагается новая целевая функция, которая может быть использована для совместной оптимизации задачи классификации при одновременном стимулировании разрежения в сети, которая работает с высокой точностью.
В данной работе предлагается новый итеративный метод обрезки под названием Continuous Sparsification, который непрерывно обрезает текущий вес, пока он не достигнет целевого соотношения.
Ввести формальную настройку для бюджетного обучения и предложить линейный график скорости обучения с учетом бюджета
В данной работе представлена методика настройки скорости обучения для обучения нейронной сети при фиксированном количестве эпох.
В данной работе анализируется, какой график скорости обучения следует использовать, когда число итераций ограничено, с помощью введенной концепции BAS (Budget-Aware Schedule).
Мы проводим исследование, используя внутреннее вознаграждение, которое основано на взвешенном расстоянии ближайших соседей в репрезентативном пространстве.
В данной работе предлагается метод эффективного исследования в табличных MDP, а также простой среды управления, используя детерминированные кодеры для изучения низкоразмерного представления динамики среды.
В данной работе предлагается метод выборочной эффективной разведки для агента RL, использующий комбинацию подходов на основе модели и без модели с метрикой новизны.
Показатели робастности обученных моделей PGD чувствительны к семантико-сохраняющему преобразованию наборов данных изображений, что подразумевает хитрость оценки робастных алгоритмов обучения на практике.
Мы предлагаем градиент политики ранжирования, который учит оптимальному рангу действий для максимизации прибыли. Мы предлагаем общую схему обучения вне политики со свойствами сохранения оптимальности, уменьшения дисперсии и эффективности выборки.
В данной работе предлагается перепараметризация политики с использованием формы ранжирования для преобразования задачи RL в задачу контролируемого обучения.
В данной статье представлен новый взгляд на градиентные методы политики с точки зрения ранжирования. 
Объединив классификацию и поиск изображений в архитектуре нейронной сети, мы получаем улучшение для обеих задач.
В данной статье предлагается единое вложение для классификации изображений и поиска экземпляров для повышения эффективности выполнения обеих задач.
В статье предлагается совместное обучение глубокой нейронной сети для классификации изображений, распознавания экземпляров и копий.
Мы исследуем отображение гипонимических отношений сети слов на векторы признаков
В данной работе изучается, как гипонимия между словами может быть отображена в представлениях признаков.
В данной статье исследуется понятие гипонимии в векторных представлениях слов и описывается метод организации отношений WordNet в древовидную структуру для определения гипонимии.
Мы создаем более мощный генератор естественного языка путем дискриминационного обучения функций оценки, которые ранжируют поколения кандидатов по различным качествам хорошего письма.
В данной работе предлагается объединить несколько индуктивных предубеждений, которые надеются исправить несоответствия в декодировании последовательности, и предлагается оптимизировать параметры заранее определенной комбинации различных подцелей. 
В данной работе языковая модель RNN сочетается с несколькими дискриминационно обученными моделями для улучшения генерации языка.
В данной статье предлагается улучшить генерацию языковых моделей РНС с помощью дополненных целей, вдохновленных максимами общения Грайса.
Масштабируемое и низко коммуникационное решение по балансировке нагрузки для гетерогенных серверных мультидиспетчерских систем с сильными теоретическими гарантиями и многообещающими эмпирическими результатами. 
Количественная мера для прогнозирования производительности моделей глубоких нейронных сетей.
В статье предлагается новая величина, подсчитывающая количество путей в нейронной сети, которая предсказывает производительность нейронных сетей с одинаковым количеством параметров.
В статье представлен метод подсчета путей в глубоких нейронных сетях, который, возможно, может быть использован для измерения производительности сети.
В данной работе представлено строгое исследование того, почему практически используемые графики скорости обучения (при заданном вычислительном бюджете) дают значительные преимущества, даже если эти схемы не поддерживаются классической теорией стохастического приближения.
В данной работе представлено теоретическое исследование различных графиков скорости обучения, в результате которого были получены статистические минимаксные нижние границы для полиномиальных схем и схем с постоянными и вырезанными значениями.
В статье исследуется влияние выбора скорости обучения для стохастической оптимизации, фокусируясь на наименьших среднеквадратичных значениях с убывающими шагами.
Мы представляем планировщики на основе конветов, которые являются эффективными с точки зрения выборки и обобщаются на более крупные экземпляры задач навигации и поиска пути.
Предлагает методы, которые можно рассматривать как модификации Value Iteration Networks (VIN), с некоторыми улучшениями, направленными на повышение эффективности выборки и обобщение на большие размеры среды.
В статье представлено расширение оригинальных стоимостных итерационных сетей (VIN) путем рассмотрения функции перехода, зависящей от состояния.
обучение лучшим вкраплениям доменов через непрерывное обучение и мета-обучение
Представляет метод непрерывного обучения для изучения вкраплений слов.
В данной работе предлагается подход к обучению вкраплений в новых областях, который значительно превосходит базовый подход в задаче извлечения аспектов. 
 мы предлагаем новый метод обрезки на основе регуляризации (названный IncReg) для постепенного назначения различных факторов регуляризации различным весовым группам на основе их относительной важности.
В данной работе предлагается метод обрезки на основе регуляризации для постепенного назначения различных факторов регуляризации различным весовым группам на основе их относительной важности.
Существующие схемы импульса/ускорения, такие как метод тяжелого шара и ускорение Нестерова, используемые со стохастическими градиентами, не улучшаются по сравнению с ванильным стохастическим градиентным спуском, особенно при использовании малых размеров партии.
Мы показываем, что задачи планирования переподписки могут быть решены с помощью A*, и представляем новые чувствительные к ограничениям эвристики для задач планирования переподписки.
Представлен подход к оптимальному решению задач планирования по переподписке (OSP) с помощью перевода к классическому планированию с множественными функциями затрат.
В статье предлагаются модификации допустимых эвристик, чтобы сделать их более обоснованными в многокритериальной среде, где.
Мы разрабатываем методы метаобучения для устойчивого к неблагоприятным условиям обучения с несколькими выстрелами.
В данной статье представлен метод, повышающий устойчивость обучения с несколькими выстрелами путем введения атаки на данные запроса в фазе тонкой настройки внутренней задачи алгоритма метаобучения.
Авторы данной статьи предлагают новый подход для обучения надежной модели с несколькими выстрелами. 
Мы обнаружили, что объединение само по себе не определяет устойчивость к деформации в CNN и что гладкость фильтра играет важную роль в определении устойчивости. 
Мы предлагаем самособирающуюся структуру для обучения более надежных моделей глубокого обучения в условиях зашумленных помеченных наборов данных.
В данной работе предложена "самосогласованная фильтрация меток" для обучения с зашумленными метками, где шум меток не зависит от экземпляра, что дает более точную идентификацию противоречивых предсказаний. 
В данной статье предлагается алгоритм обучения на данных с зашумленными метками, который чередует обновление модели и удаление образцов, которые выглядят так, как будто они имеют зашумленные метки.
Мы исследуем обрезку ДНС перед обучением и даем ответ на вопрос, какую топологию следует использовать для обучения априорно разреженных сетей.
Авторы предлагают заменить плотные слои линейными слоями с разреженной связью и подход к поиску наилучшей топологии путем измерения того, насколько хорошо разреженные слои аппроксимируют случайные веса своих плотных аналогов.
В статье предложена разреженная каскадная архитектура, представляющая собой умножение нескольких разреженных матриц и определенный шаблон связности, который превосходит другие представленные соображения.
Мы представляем Multitask Neural Model Search - метаобучающий инструмент, который может разрабатывать модели для нескольких задач одновременно и переносить обучение на невидимые задачи.
Данная статья расширяет нейронную архитектуру поиска на проблему многозадачного обучения, когда контроллер поиска модели, обусловленный задачей, изучается для одновременного решения нескольких задач.
В этой статье авторы подводят итоги своей работы по созданию структуры, названной контроллером поиска многозадачной нейронной модели, для автоматизированного построения нейронных сетей в нескольких задачах одновременно.
Мы моделируем нелинейные визуальные процессы как авторегрессионный шум с помощью генеративного глубокого обучения.
Предлагает новый метод, который моделирует нелинейный визуальный процесс с помощью глубокой версии линейного процесса (процесса Маркова).
В данной работе предлагается новая глубокая генеративная модель для последовательностей, в частности, последовательностей изображений и видео, которая использует линейную структуру в части модели.
В данной статье предлагается новая сеть с прямой передачей, называемая PDE-Net, для обучения PDE на основе данных. 
В статье показано использование механизмов глубокого обучения для идентификации динамических систем, заданных PDE.
В статье предлагается алгоритм на основе нейронной сети для обучения на данных, возникающих из динамических систем с управляющими уравнениями, которые могут быть записаны как уравнения в частных дифференциальных уравнениях.
В данной работе рассматривается моделирование сложных динамических систем с помощью непараметрических дифференциальных уравнений с использованием нейронных архитектур, при этом наиболее важной идеей папье (PDE-сети) является обучение как дифференциальных операторов, так и функции, управляющей PDE.
Мы даем быструю процедуру выборки типа "нормализация-поток" для дискретных моделей латентных переменных.
В данной работе используется вариационная аппроксимация авторегрессионной фильтрации для оценки параметров дискретных динамических систем с помощью итераций с фиксированной точкой.
Авторы предлагают общее семейство авторегрессионных постеров для дискретных переменных или их непрерывных релаксаций. 
Данная работа имеет два основных вклада: она расширяет нормализующие потоки на дискретные параметры и представляет приближенное правило обновления с фиксированной точкой для авторегрессионных временных рядов, которое может использовать параллелизм GPU. 
Мы предлагаем схему, которая учит кодировать знания символически и генерировать программы для рассуждения о закодированных знаниях.
Авторы предлагают машину N-Gram для ответов на вопросы по длинным документам.
В данной статье представлена машина n-грамм, модель, которая кодирует предложения в простые символьные представления, которые можно эффективно запрашивать.
В данной работе предлагается мета-цель обучения, основанная на скорости адаптации к распределению переноса для обнаружения модульной декомпозиции и причинных переменных.
В статье показано, что модель с правильной базовой структурой быстрее адаптируется к причинному вмешательству, чем модель с неправильной структурой.
В данной работе авторы предложили общую и систематическую схему мета-трансферной цели, включающую обучение причинно-следственной структуры при неизвестных вмешательствах.
Другой взгляд на катастрофическое забывание
В данной работе представлена схема борьбы с катастрофической забывчивостью, основанная на изменении термина потерь для минимизации изменений в вероятности классификатора, полученной с помощью аппроксимации ряда Тейлора.
В данной статье делается попытка решить проблему непрерывного обучения, сосредоточившись на подходах регуляризации, и предлагается стратегия L_1 для смягчения этой проблемы.
Мы предлагаем подход к построению реалистичных 3D морфируемых моделей лица (3DMM), который позволяет интуитивно понятный рабочий процесс редактирования атрибутов лица путем выбора лучших наборов собственных векторов и антропометрических измерений.
Предлагает кусочно-морфируемую модель для сеток человеческого лица, а также предлагает отображение между антропометрическими измерениями лица и параметрами модели для синтеза и редактирования лиц с желаемыми атрибутами. 
В данной статье описывается метод морфируемой модели лица на основе частей, позволяющий локализовать управление пользователем.
Два алгоритма превзошли восемь других в эксперименте с BCI на основе ЭЭГ
Мы учим агентов вести переговоры, используя только обучение с подкреплением; эгоистичные агенты могут это делать, но только используя надежный канал связи, а просоциальные агенты могут вести переговоры, используя дешевые разговоры.
Авторы описывают вариант игры в переговоры с учетом вторичного канала коммуникации для дешевых разговоров, обнаруживая, что вторичный канал улучшает результаты переговоров.
В данной работе исследуется, как агенты могут научиться общаться для решения задачи переговоров, и обнаруживается, что просоциальные агенты способны научиться обосновывать символы с помощью RL, а корыстные агенты - нет.
Изучает проблемы того, как агенты могут использовать коммуникацию для максимизации своего вознаграждения в простой переговорной игре.
Мы предлагаем новую систему метаобучения для трансдуктивного вывода, которая классифицирует весь набор тестов сразу, чтобы облегчить проблему малого количества данных.
В данной работе предлагается решить проблему обучения по нескольким снимкам трансдуктивным способом, изучая модель распространения меток сквозным образом. В этой работе впервые было изучено распространение меток для трансдуктивного обучения по нескольким снимкам и получены эффективные эмпирические результаты. 
В данной статье предлагается мета-система обучения, которая использует немаркированные данные, обучаясь сквозному распространению меток на основе графа.
Изучение обучения на нескольких хостах в трансдуктивной среде: использование метаобучения для обучения распространению меток от обучающих выборок к тестовым. 
Мы описываем использование автоматизированной системы планирования для разработки политики наблюдений и планирования операций миссии НАСА ECOSTRESS.
В данной статье представлена адаптация автоматизированной системы планирования CLASP для проведения эксперимента по ЭО (ECOSTRESS) на МКС. 
Гибридное хранение и представление усвоенных знаний может быть причиной появления неблагоприятных примеров.
Новые эксперименты и теория для Q-обучения на основе Адама
В данной статье приводится результат сходимости для традиционного Q-обучения с аппроксимацией линейной функции при использовании Адамоподобного обновления. 
В данной статье описывается метод улучшения алгоритма AltQ с помощью комбинации оптимизатора Adam и регулярного перезапуска внутренних параметров оптимизатора Adam.
Новая сеть капсул, которая быстрее сходится в наших экспериментах с эталонами в области здравоохранения.
Представлен вариант капсульных сетей, в котором вместо EM-маршрутизации используется линейное подпространство, охватываемое доминирующим собственным вектором матрицы взвешенных голосов предыдущей капсулы.
В статье предлагается улучшенный метод маршрутизации, который использует инструменты эйгендекомпозиции для поиска активации капсулы и ее позы.
Мы предлагаем метод распределенной тонкой настройки языковых моделей на пользовательских устройствах без сбора приватных данных
В данной работе рассматривается улучшение языковых моделей на мобильном оборудовании на основе небольшой части текста, введенного пользователем, путем использования линейно интерполированных целей между текстом, специфичным для пользователя, и общим английским языком. 
В данной работе используется анализ потерь Липшица на ограниченном пространстве гипотез для получения новых алгоритмов типа ERM с сильными гарантиями производительности, которые могут быть применены к несопряженной разреженной модели GP.
Мы предлагаем метод регуляризации для нейронной сети и метод анализа шума
В данной статье предлагается новый метод регуляризации для смягчения проблемы переподгонки глубоких нейронных сетей путем вращения признаков с помощью случайной матрицы вращения для уменьшения совместной адаптации.
В данной статье предлагается новый метод регуляризации для обучения нейронных сетей, который добавляет шумовые нейроны взаимозависимым образом.
Вероятностная основа для многоагентного обучения с усилением
В данной работе предлагается новый алгоритм Multi-Agent Soft Actor-Critic (MA-SAC), основанный на алгоритме критики акторов Soft Actor-Critic (SAC), основанном на неполитическом максимально-энтропийном алгоритме критики акторов.
Мы предоставляем непрерывную релаксацию оператора сортировки, позволяющую проводить сквозную стохастическую оптимизацию на основе градиента.
В статье рассматривается вопрос о том, как отсортировать ряд элементов без явного изучения их фактических значений или ценностей, и предлагается метод оптимизации с помощью непрерывной релаксации.
Данная работа основана на тождестве sum(top k) для получения дифференцируемого по пути сэмплера "унимодальных стохастических рядов" матриц.
Представляет непрерывную релаксацию оператора сортировки для построения сквозной оптимизации на основе градиента и вводит стохастическое расширение своего метода с использованием распределений Плакета-Люса и Монте-Карло.
Мы проводим эффективное и гибкое обучение переносу в рамках байесовской оптимизации с помощью метаобучаемых функций нейронного приобретения.
Авторы представляют MetaBO, который использует обучение с подкреплением для мета-обучения функции приобретения для Байесовской оптимизации, демонстрируя возрастающую эффективность выборки на новых задачах.
Авторы предлагают альтернативу стандартным функциям приобретения (AF), основанную на метаобучении, при котором предварительно обученная нейронная сеть выводит значения приобретения как функцию выбранных вручную характеристик.
Детерминированные глубокие нейронные сети не отбрасывают информацию, но они кластеризуют свои входы.
В данной работе представлен принципиальный способ исследования фразы сжатия в глубоких нейронных сетях путем предоставления теоретически обоснованного энтропийного оценщика для оценки взаимной информации. 
Мы предлагаем задачи регуляризации для многоагентных RL-алгоритмов, которые способствуют координации в кооперативных задачах.
В данной работе предлагаются два метода, позволяющие направить агентов на обучение скоординированному поведению, и проводится строгая оценка обоих методов в многоагентных областях подходящей сложности.
В данной статье предлагаются два метода, основанные на MADDPG, для поощрения сотрудничества между децентрализованными агентами MARL.
Мы представляем модель, которая обучается надежным совместным представлениям путем выполнения иерархических циклических переводов между несколькими модальностями.
В данной статье представлена сеть мультимодального циклического перевода (MCTN) и проведена ее оценка для мультимодального анализа настроений.
Понимание собственных значений гессиана нейронной сети в условиях порождающего распределения данных.
В данной работе анализируется спектр матрицы Гессиана больших нейронных сетей, с анализом макс/минус собственных значений и визуализацией спектров с помощью квадратурного подхода Ланцоша.
В данной работе используется теория случайных матриц для изучения спектрального распределения эмпирического гессиана и истинного гессиана для глубокого обучения, а также предлагаются эффективные методы визуализации спектра.
Один простой прием для улучшения моделей последовательности: Скомпонуйте их с графовой моделью
В данной статье представлена модель структурного обобщения с кодировщиком на основе графа, расширенным из RNN.
Данная работа сочетает в себе графовые нейронные сети и последовательный подход к абстрактному обобщению, эффективный во всех наборах данных по сравнению с внешними базовыми показателями.
Разреженный классификатор на основе дискриминационной модели гауссовой смеси, который также может быть встроен в нейронную сеть.
В статье представлена модель гауссовской смеси, обучаемая с помощью аргументов градиентного спуска, которая позволяет вызвать разреженность и уменьшить параметры обучаемого слоя модели.
В данной статье предлагается классификатор, названный SDGM, основанный на дискриминационной гауссовской смеси и оценке ее разреженных параметров.
Инициализируйте веса, используя готовые кодовые книги Грассманиана, ускорьте обучение и повысьте точность.
Неконтролируемый подход к адаптации домена, который адаптируется как на уровне пикселей, так и на уровне признаков
В данной работе предлагается подход к адаптации домена путем расширения CycleGAN функциями потерь, специфичными для конкретной задачи, и потерями, налагаемыми как на пиксели, так и на признаки. 
В данной работе предлагается использование CycleGANs для адаптации домена
В данной работе сделано новое расширение предыдущей работы по CycleGAN путем соединения его с подходами к адаптации к состязательности, включая новую функцию и семантические потери в общую цель CycleGAN, с очевидными преимуществами.
Amharic Light Stemmer предназначен для улучшения производительности Amharic Sentiment Classification.
В данной работе исследуется стемминг для морфологически богатых языков с помощью легкого стеммера, который удаляет аффиксы только в той степени, в которой сохраняется исходная семантическая информация в слове.
В данной статье предлагается метод стеблирования амхарского языка с использованием каскада преобразований, которые стандартизируют форму, удаляют суффиксы, префиксы и инфиксы.
Мы исследовали, обладают ли простые глубокие сети искусственными нейронами, похожими на ячейки решетки, при извлечении памяти в изученном концептуальном пространстве.
Плюсы и минусы компьютерного зрения на основе саккад с точки зрения предиктивного кодирования
Представляет вычислительную схему для проблемы активного зрения и объясняет, как политика управления может быть выучена для уменьшения энтропии апостериорного убеждения.
Мы теоретически исследуем согласованность спектра Лапласиана и используем его для встраивания в целые графы.
В данной статье рассматривается спектр лапласиана графа как средство создания представления, которое можно использовать для сравнения графов и их классификации.
В данной работе предлагается использовать спектр Graph Laplacian для изучения представления графов.
Обучение на основе FGSM с рандомизацией работает так же хорошо, как и обучение на основе PGD: мы можем использовать это для обучения надежного классификатора за 6 минут на CIFAR10 и за 12 часов на ImageNet на одной машине.
В данной работе рассматривается метод Random+FGSM для обучения надежных моделей против сильных атак уклонения PGD быстрее, чем предыдущие методы.
Основное утверждение данной работы заключается в том, что простая стратегия рандомизации плюс аверсивное обучение методом быстрого градиентного знака (FGSM) позволяет получить надежные нейронные сети.
Мы предлагаем почти везде дифференцируемые и масштабно-инвариантные регуляризаторы для обрезки ДНК, которые могут привести к сверхпредельной разреженности с помощью стандартного обучения SGD.
В статье предлагается масштабно-инвариантный регуляризатор (DeepHoyer), вдохновленный мерой Хойера, для обеспечения разреженности в нейронных сетях. 
Мы показываем, что дополнительные немаркированные данные не являются обязательными для вспомогательных задач с самоконтролем, чтобы быть полезными для классификации временных рядов, и представляем новые и эффективные вспомогательные задачи.
В данной статье предлагается метод самоконтроля для обучения на основе данных временных рядов в здравоохранении путем разработки вспомогательных задач на основе внутренней структуры данных для создания более маркированных вспомогательных учебных задач.
В данной работе предлагается подход для самоконтролируемого обучения на временных рядах.
Собственные значения сопряженного (он же NNGP) и нейронного касательного ядра могут быть вычислены в замкнутой форме над булевым кубом и показывают влияние гиперпараметров на индуктивное смещение нейронной сети, обучение и обобщение.
В данной работе проводится спектральный анализ сопряженного ядра нейронных сетей и нейронного касательного ядра на булевом кубе, чтобы выяснить, почему глубокие сети предвзято относятся к простым функциям.
Все функциональные парцелляции мозга ошибочны, но некоторые из них полезны
Имитация из пикселей, с редким или отсутствующим вознаграждением, с использованием неполитической RL и крошечной функции вознаграждения с неблагоприятным обучением.
В статье предлагается использовать "минимального противника" в генеративном состязательном обучении имитации в высокоразмерных визуальных пространствах.
Данная работа направлена на решение проблемы оценки разреженных вознаграждений в условиях высокой размерности входных данных.
Мы показываем стратегии, позволяющие легко идентифицировать поддельные образцы, созданные с помощью генеративной адверсариальной сети.
Показать, что поддельные образцы, созданные с помощью распространенных реализаций генеративной адверсивной сети (GAN), легко идентифицируются с помощью различных статистических методов. 
В статье предлагается статистика для выявления фальшивых данных, генерируемых с помощью GANs, основанная на простой маргинальной статистике или формальных спецификациях, автоматически генерируемых на основе реальных данных.
Мы представляем аналитическую схему для определения требований к битовой ширине накопления во всех трех обучающих GEMM глубокого обучения и проверяем обоснованность и строгость нашего метода с помощью сравнительных экспериментов.
Авторы предлагают аналитический метод для прогнозирования количества битов мантиссы, необходимых для частичного суммирования для конволюционных и полностью связанных слоев.
Авторы проводят тщательный анализ числовой точности, необходимой для операций накопления при обучении нейронных сетей, и показывают теоретическое влияние уменьшения количества битов в накопителе с плавающей запятой.
Новая теория неконтролируемой адаптации домена для метрического обучения на расстоянии и ее применение для распознавания лиц с различными этническими вариациями.
Предлагается новая сеть передачи признаков, которая оптимизирует потери на состязательность доменов и потери на разделение доменов.
Мы предлагаем сходящийся стохастический алгоритм градиентного спуска проксимального типа для ограниченных негладких невыпуклых задач оптимизации
В данной работе предлагается Prox-SGD, теоретическая основа для алгоритмов стохастической оптимизации, которые сходятся асимптотически к стационарности для гладких невыпуклых потерь + выпуклого ограничения/регуляризатора.
В статье предлагается новый градиентный алгоритм стохастической оптимизации с усреднением градиента путем адаптации теории проксимальных алгоритмов к невыпуклой постановке.
Мы даем ограничение для NNs на выходную ошибку в случае случайных весовых сбоев, используя разложение Тейлора в непрерывном пределе, когда близлежащие нейроны схожи.
В данной статье рассматривается проблема отсева нейронов из нейронной сети, показано, что если цель состоит в том, чтобы стать устойчивым к случайному отсеву нейронов во время оценки, то достаточно просто тренироваться с отсевом.
В данном материале изучается влияние удаления случайных нейронов на точность предсказания обученной архитектуры, с приложением к анализу отказов и специфическому контексту нейроморфного оборудования.
Мы исследуем и изучаем синергию между звуком и действием.
В данной работе исследуются связи между действием и звуком путем создания набора данных "звук-действие-зрение" с помощью наклоняющегося робота.
В данной работе изучается роль звука в восприятии объектов и действий, а также то, как слуховая информация может помочь в обучении моделей прямой и обратной динамики.
Мы предлагаем иерархическое объектное обучение с дополнением - новую парадигму обучения, позволяющую эффективно использовать иерархию категорий в пространстве меток как для классификации изображений, так и для семантической сегментации.
Метод, регуляризирующий энтропию апостериорного распределения по классам, который может быть полезен для задач классификации и сегментации изображений
Наша статья определяет проблему существующего подхода к распределению веса в поиске нейронной архитектуры и предлагает практический метод, достигающий высоких результатов.
Автор выявляет проблему NAS, называемую задним затуханием, и представляет Posterior Convergent NAS для смягчения этого эффекта
Мы предлагаем новый двухфазный подход к обучению, основанный на "ранней остановке", для надежного обучения на зашумленных метках.
В статье предлагается изучить, как ранняя остановка в оптимизации помогает найти уверенные примеры
В данной статье предлагается двухфазный метод обучения для обучения с шумом меток.
Мы представляем IC3Net, единую сеть, которую можно использовать для обучения агентов в кооперативных, конкурентных и смешанных сценариях. Мы также показываем, что агенты могут научиться общаться, используя нашу модель.
Автор предлагает новую архитектуру для мультиагентного обучения с подкреплением, которая использует несколько LSTM-контроллеров с привязанными весами, которые передают друг другу непрерывный вектор
Авторы предлагают интересную схему развязки, позволяющую агентам общаться в многоагентной среде RL. 
Мы представляем первую нейронную модель абстрактного резюмирования, способную настраивать сгенерированные резюме.
Мы предлагаем программную основу, основанную на идеях алгоритма Learning-Compression, которая позволяет сжимать любую нейронную сеть с помощью различных механизмов сжатия (обрезка, квантование, низкий ранг и т.д.).
В данной статье представлена разработка программной библиотеки, которая облегчает пользователю сжатие сетей, скрывая детали методов сжатия.
В данной статье предлагается метод сквозной мультимодальной генерации человеческого лица из речи на основе самоконтролируемого обучения.
В данной работе представлена мультимодальная система обучения, которая связывает этап вывода и этап генерации для поиска возможности генерации человеческого лица исключительно по голосу.
Данная работа направлена на создание одной условной системы формирования изображения лица из аудиосигнала. 
Представлен нисходящий подход к рекурсивному представлению пропозициональных формул с помощью нейронных сетей.
В данной статье представлена новая нейросетевая модель логических формул, которая собирает информацию о данной формуле, обходя ее дерево разбора сверху вниз.
В статье рассматривается путь древовидной сети, изоморфной дереву разбора формулы пропозиционального исчисления, но с передачей информации сверху вниз, а не снизу вверх.
Ape-X DQfD = распределенный (много актеров + один ученик + приоритетное воспроизведение) DQN с демонстрациями, оптимизирующими нескладируемый 0,999-дисконтированный доход на Atari.
В статье предлагаются три расширения (обновление Беллмана, потеря временной согласованности и демонстрация эксперта) для DQN, чтобы улучшить эффективность обучения на играх Atari, достигая превосходства над современными результатами для игр Atari. 
В данной статье предлагается преобразованный оператор Беллмана, который направлен на решение проблем чувствительности к неполученному вознаграждению, устойчивости к значению коэффициента дисконтирования и проблемы разведки.
Метод обучения, позволяющий накладывать строгие ограничения на выученные вкрапления во время контролируемого обучения. Применяется для визуального ответа на вопросы.
Авторы предлагают структуру для включения дополнительных семантических предварительных знаний в традиционное обучение моделей глубокого обучения для регуляризации пространства встраивания вместо пространства параметров.
В статье приводится аргумент в пользу кодирования внешних знаний в слое лингвистического встраивания мультимодальной нейронной сети в виде набора жестких ограничений.
Решение обратных задач с помощью гладких аппроксимаций прямых алгоритмов для обучения обратных моделей.
Метод глубокого обучения для точечной локализации со слабым контролем, который обучается, используя только метки на уровне изображения. Он опирается на условную энтропию для локализации релевантных и нерелевантных областей, стремясь минимизировать количество ложноположительных областей.
В данной работе исследуется проблема WSL с использованием новой конструкции регуляризационных условий и рекурсивного алгоритма стирания.
В данной статье представлен новый слабо контролируемый подход для обучения сегментации объектов с метками классов на уровне изображения.
Получение состояний из высокочастотной области для управления поиском в Dyna.
Авторы предлагают делать выборку в высокочастотной области для повышения эффективности выборки
В данной статье предлагается новый способ выбора состояний, из которых осуществляются переходы в алгоритме dyna.
Мы представляем систему распределенного исходного кодирования на основе распределенного рекуррентного автокодирования для масштабируемого сжатия изображений (DRASIC).
В статье предложен распределенный рекуррентный автокодер для сжатия изображений, который использует ConvLSTM для обучения двоичных кодов, которые постепенно строятся из остатков ранее закодированной информации.
Авторы предлагают метод обучения моделей сжатия изображений на нескольких источниках, с отдельным кодером на каждом источнике и общим декодером. 
Гейты выполняют всю тяжелую работу в LSTM, вычисляя взвешенные суммы по элементам, и удаление внутренней простой RNN не ухудшает производительность модели.
В данной работе предлагаются упрощенные варианты LSTM путем устранения нелинейности элементов содержимого и выходных ворот.
В данной работе представлен анализ LSTMS, показывающий, что они имеют форму, в которой содержимое ячейки памяти на каждом шаге является взвешенной комбинацией значений "обновления содержимого", вычисляемых на каждом временном шаге, и предлагается упрощение LSTMs, которые вычисляют значение, на которое изменяется ячейка памяти на каждом временном шаге в терминах детерминированной функции входа, а не функции входа и текущего контекста.
В статье предлагается новый подход к LSTM, в котором ядром является взвешенная сумма по элементам, и утверждается, что LSTM избыточна, если для вычисления весов использовать только входные ворота и ворота забывания.
Проанализировав более 300 докладов на последних конференциях по машинному обучению, мы обнаружили, что приложения машинного обучения для здравоохранения (ML4H) отстают от других областей машинного обучения по показателям воспроизводимости.
В данной статье проведен количественный и качественный обзор состояния воспроизводимости в области применения ML в здравоохранении и предложены рекомендации по повышению воспроизводимости исследований.
Мы обучаем множество небольших сетей, каждая из которых предназначена для выполнения определенной операции, затем они объединяются для выполнения сложных операций
В данной работе предлагается использовать нейронные сети для оценки математических выражений путем проектирования 8 небольших строительных блоков для 8 фундаментальных операций, например, сложения, вычитания и т.д., а затем проектирования многозначного умножения и деления с использованием этих небольших блоков.
В статье предлагается метод разработки механизма оценки математических выражений на основе NN.
Улучшение качества и стабильности ГАНов с помощью релятивистского дискриминатора; ГАНы IPM (такие как WGAN-GP) являются особым случаем.
В статье предлагается "релятивистский дискриминатор", который помогает в некоторых ситуациях, хотя и немного чувствителен к гиперпараметрам, архитектурам и наборам данных.
В данной работе авторы рассматривают вариацию GAN путем одновременного уменьшения вероятности того, что реальные данные являются реальными для генератора.
Версия MPO, основанная на функции состояния-значения, которая достигает хороших результатов в широком спектре задач дискретного и непрерывного управления.
В данной работе представлен алгоритм обучения с подкреплением на основе политики, который может работать с непрерывным/дискретным управлением, однозадачным/многозадачным обучением и использовать как низкоразмерные состояния, так и пиксели.
В статье предлагается онлайн вариант MPO, V-MPO, который обучается V-функции и обновляет непараметрическое распределение в направлении преимуществ.
Мы предлагаем нейронные двигатели выполнения (NEE), которые используют выученную маску и контролируемые следы выполнения для имитации функциональности подпрограмм и демонстрируют сильную обобщенность.
В данной работе исследуется проблема построения механизма выполнения программ с помощью нейронных сетей, предлагается модель на основе трансформатора для обучения базовым подпрограммам и применяется в нескольких стандартных алгоритмах.
В данной статье рассматривается проблема проектирования архитектур нейронных сетей, которые могут обучаться и реализовывать общие программы.
Байесовское определение точек изменения позволяет проводить мета-обучение непосредственно по данным временных рядов.
В статье рассматривается мета-обучение в задаче без сегментации и применяется байесовское онлайн-определение точек изменения с мета-обучением.
Эта статья продвигает мета-обучение в сторону задач без сегментов, где в рамках MOCA используется байесовская схема оценки точек изменения для обнаружения изменения задачи.
Подход на основе глубокого обучения для обнаружения фрикативных фонем с нулевой задержкой
В данной работе применяются методы контролируемого глубокого обучения для определения точной длительности фрикативной фонемы с целью улучшения практического алгоритма понижения частоты.
Онлайновый механизм внимания с линейным временем, который выполняет мягкое внимание над адаптивно расположенными фрагментами входной последовательности.
В данной работе предлагается небольшая модификация монотонного внимания в [1] путем добавления мягкого внимания к сегменту, предсказанному монотонным вниманием.
В статье предлагается расширение предыдущей модели монотонного внимания (Raffel et al 2017), чтобы посещать окно фиксированного размера до позиции выравнивания.
Разработка новых методов, основанных на переупорядочивании патчей, для детального анализа взаимосвязи набора данных с результатами обучения и обобщения.
Мы создаем агентов обучения с подкреплением, которые хорошо обобщаются для широкого спектра сред, используя новую технику регуляризации.
В статье представлена проблема политики высокой дисперсии в рандомизации доменов для обучения с подкреплением, и основное внимание уделяется проблеме визуальной рандомизации, когда различные рандомизированные домены отличаются только в пространстве состояний, а лежащие в основе вознаграждения и динамика одинаковы.
Для улучшения обобщающей способности агентов глубокой RL для задач с различными визуальными паттернами в данной работе предложена простая техника регуляризации для рандомизации домена.
Мы исследуем пересечение сетевой нейронауки и глубокого обучения. 
В данной статье представлена система для бесконтрольного высокоточного построения базы знаний с использованием вероятностной программы для определения процесса преобразования фактов базы знаний в неструктурированный текст.
Обзор существующей базы знаний, построенной с помощью вероятностной модели, с оценкой подхода к построению базы знаний в сравнении с другими подходами к базам знаний YAGO2, NELL, Knowledge Vault и DeepDive.
В данной работе используется вероятностная программа, описывающая процесс, посредством которого факты, описывающие сущности, могут быть реализованы в тексте и большом количестве веб-страниц, чтобы научиться выполнять извлечение фактов о людях, используя один начальный факт.
Новый метод извлечения сигнала в области Фурье
Улучшение масштабируемости графовых нейронных сетей для обучения имитации и прогнозирования движения роя
В статье предлагается новая модель временного ряда для изучения последовательности графов.
В данной работе рассматриваются проблемы предсказания последовательности в многоагентной системе.
Мы предлагаем схему квантования дифференцируемых продуктов, которая позволяет уменьшить размер слоя встраивания при сквозном обучении без затрат на производительность.
В данной статье рассматриваются методы сжатия слоев вкрапления для выводов с малым объемом памяти, где сжатые вкрапления изучаются вместе с моделями, специфичными для конкретной задачи, дифференцируемым сквозным способом.
Мы представляем простой и новый алгоритм модальной регрессии, который легко масштабируется на большие задачи. 
В статье предлагается подход неявной функции для обучения режимам мультимодальной регрессии.
В данной работе предлагается параметрический подход к оценке условной моды с использованием теоремы о неявной функции для мультимодальных распределений. 
Выборочная эффективная мета-РЛ путем объединения вариационного вывода вероятностных переменных задачи с внеполитической РЛ 
В данной статье предлагается использовать РЛ без политики во время мета-обучения, чтобы значительно повысить эффективность выборки методов мета-РЛ.
Данная работа посвящена определению высококачественных веб-источников для промышленной системы пополнения базы знаний.
Мы исследуем достоинства использования нейронных сетей в задаче предсказания соответствия, где требуется оценить вероятность того, что группа из M предметов будет предпочтительнее другой, на основе данных частичного сравнения групп.
В данной статье предлагается решение проблемы ранжирования множеств с помощью глубокой нейронной сети и разрабатывается архитектура для этой задачи, вдохновленная предыдущими алгоритмами, разработанными вручную.
В данной статье представлена методика решения проблемы прогнозирования матчей с использованием архитектуры глубокого обучения.
Новый подход к поддержанию ортогональных рекуррентных весовых матриц в РНС.
Представляет схему обучения рекуррентной матрицы параметров в нейронной сети, которая использует преобразование Кейли и масштабную весовую матрицу. 
В данной работе предлагается репараметризация РНС с помощью перекососимметричной матрицы с использованием преобразования Кейли для сохранения ортогональности матрицы весов рекуррентных сигналов.
Новая параметризация РНС позволяет относительно легко представлять ортогональные весовые матрицы.
Мы используем единую модель для решения множества задач анализа естественного языка, формулируя их в едином формате span-relation.
В данной работе широкий спектр задач обработки естественного языка обобщен в виде единого фреймворка на основе span и предложена общая архитектура для решения всех этих задач.
В данной работе представлена единая формулировка различных задач НЛП на уровне фраз и лексем.
Мы представляем вариационную нижнюю границу для моделей GP, которая может быть оптимизирована без вычисления дорогостоящих матричных операций, таких как инверсии, обеспечивая при этом те же гарантии, что и существующие вариационные приближения.
Вариационные автокодировщики с латентными пространствами, моделируемыми как произведения римановых многообразий постоянной кривизны, улучшают реконструкцию изображений по сравнению с вариантами с одним многообразием.
В данной работе представлена общая формулировка понятия VAE с латентным пространством, состоящим из криволинейного многообразия.
Эта статья посвящена разработке VAE в неевклидовых пространствах.
Мы представляем алгоритм "черного ящика" для многократной оптимизации соединений с использованием переводной рамки.
Авторы представляют оптимизацию молекул как проблему последовательности и расширяют существующие методы для улучшения молекул, показывая, что это выгодно для оптимизации logP, но не QED.
Работа основана на существующих моделях трансляции, разработанных для молекулярной оптимизации, с итеративным использованием моделей трансляции от последовательности к последовательности или от графа к графу.
Предложение первой системы водяных знаков для встраивания и извлечения многобитных подписей с использованием выходов ДНК. 
Предлагает метод многобитного водяного знака для нейронных сетей в условиях "черного ящика" и демонстрирует, что предсказания существующих моделей могут нести многобитную строку, которая впоследствии может быть использована для проверки права собственности.
В статье предлагается подход к водяному знаку модели, где водяной знак представляет собой битовую строку, встроенную в модель как часть процедуры тонкой настройки.
Не знаете, как оптимизировать? Тогда просто научитесь оптимизировать!
В данной статье предлагается способ обучения моделей классификации изображений, устойчивых к атакам с возмущением L-бесконечности.
В данной работе предлагается использовать схему обучения для изучения злоумышленника.
Простой и легко обучаемый метод для мультимодального прогнозирования во временных рядах. 
В данной работе представлена модель прогнозирования временных рядов, которая обучается детерминированному отображению и тренирует другую сеть для прогнозирования будущих кадров, учитывая входные данные и остаточную ошибку первой сети.
В статье предлагается модель для прогнозирования в условиях неопределенности, в которой разделяются детерминированное прогнозирование компонентов и неопределенное прогнозирование компонентов.
Эта статья представляет и мотивирует simple_rl, новую библиотеку с открытым исходным кодом для проведения экспериментов по обучению с подкреплением в Python 2 и 3 с акцентом на простоту.
В данной работе рассматривается устойчивость простой градиентной штрафной $\mu$-WGAN оптимизации путем введения понятия дифференцирования, оцениваемого мерой.
Исследуется РГАН с квадратичным нулевым центрированным градиентным штрафным членом по отношению к общей мере.
Характеризует сходимость градиентно-пенализированного GAN Вассерштейна.
Современный метод обучения бинарных и тернарных весовых сетей, основанный на попеременной оптимизации произвольно расслабленных весовых разделов
В статье предлагается новая схема обучения для оптимизации троичной нейронной сети.
Авторы предлагают RPR, способ случайного разбиения и квантования весов и обучения оставшихся параметров с последующей релаксацией в чередующихся циклах для обучения квантованных моделей.
Мы заменяем некоторые пути градиентов в иерархических РНС вспомогательными потерями. Мы показываем, что это позволяет снизить затраты памяти при сохранении производительности.
В статье представлена иерархическая архитектура РНК, которая может быть обучена с большей эффективностью использования памяти.
В предлагаемой работе предлагается развязать различные уровни иерархии в RNN с помощью вспомогательных потерь.
Нейронные сети, которые хорошо справляются с классификацией, проектируют точки в более сферические формы, прежде чем сжать их в меньшее количество измерений.
Мы предлагаем новый метод обучения для глубокого распознавания звуков, названный BC learning.
Авторы определили новую задачу обучения, которая требует от ДНС предсказать соотношение смешивания между звуками из двух разных классов, чтобы увеличить дискриминационную способность окончательно обученной сети.
Предлагается метод улучшения производительности общего метода обучения путем создания обучающих выборок "между классами" и излагается основная интуиция и необходимость предложенной техники.
Мы предлагаем метод, позволяющий определить изменяющийся во времени уровень качества данных для пространственно-временного прогнозирования без явно заданных меток.
Представляет новое определение качества данных, которое опирается на понятие локальной вариации, определенное в (Zhou and Scholkopf), и расширяет его на множественные гетерогенные источники данных.
В данной работе предложен новый способ оценки качества различных источников данных с помощью модели изменяющегося во времени графа, при этом уровень качества используется в качестве регуляризирующего члена в объективной функции
Мы предлагаем программы 3D-фигур, структурированное, композиционное представление фигур. Наша модель учится находить и выполнять программы для объяснения 3D-фигур.
Подход к выводу программ формы с учетом 3D моделей, с архитектурой, состоящей из рекуррентной сети, которая кодирует 3D форму и выдает инструкции, и второго модуля, который визуализирует программу в 3D.
В данной статье представлено высокоуровневое семантическое описание трехмерных фигур, представленное программой ShapeProgram.
Мы показываем, что обычные методы регуляризации (например, $L_2$, выпадение), которые в основном игнорировались в методах RL, могут быть очень эффективными при оптимизации политики.
Авторы изучают набор существующих методов оптимизации прямой политики в области обучения с подкреплением и проводят детальное исследование влияния правил на производительность и поведение агентов, следующих этим методам.
В данной работе представлено исследование влияния регуляризации на производительность в обучающих средах в методах оптимизации политики в задачах множественного непрерывного управления.
Мы представляем набор данных вопросов-ответов FigureQA в качестве первого шага к разработке моделей, способных интуитивно распознавать закономерности из визуальных представлений данных.
В данной работе представлена база данных шаблонизированных ответов на вопросы о фигурах, включающая рассуждения об элементах фигур.
В статье представлен новый набор данных для визуальных рассуждений под названием Figure-QA, состоящий из 140K изображений рисунков и 1,55M пар QA, который может помочь в разработке моделей, способных извлекать полезную информацию из визуальных представлений данных.
В этом позиционном документе анализируются различные типы самообъяснений, которые могут возникать в системах планирования и смежных системах. 
Обсуждает различные аспекты объяснений, особенно в контексте последовательного принятия решений. 
Первый подход глубокого обучения к MFSR для решения задач регистрации, слияния, апсемплинга в сквозном режиме.
В данной работе предлагается сквозной алгоритм многокадрового сверхразрешения, основанный на парной совместной регистрации и блоках слияния (сверточные остаточные блоки), встроенных в сеть кодера-декодера "HighRes-net", которая оценивает изображение со сверхразрешением.
В данной работе предлагается схема, включающая рекурсивное слияние с учетом потерь при корегистрации, для решения проблемы, когда результаты сверхразрешения и метки высокого разрешения не совпадают по пикселям.
Для распределенного обучения в сетях с высокой задержкой используйте приблизительное распределенное усреднение на основе сплетен вместо точного распределенного усреднения, как в AllReduce.
Авторы предлагают использовать алгоритмы сплетен в качестве общего метода вычисления приблизительного среднего по множеству работников приблизительно
В статье доказана сходимость SGP для невыпуклых гладких функций и показано, что SGP может достичь значительного ускорения в среде с низкой задержкой без ущерба для предсказательной производительности. 
В данной работе разрабатывается система обучения на основе состязательности для нейронных моделей разговора с персоналиями.
В данной работе предлагается расширение hredGAN для одновременного обучения набору вкраплений атрибутов, которые представляют личность каждого говорящего, и генерирования ответов на основе личности.
Биоинспирированные искусственные нейронные сети, состоящие из нейронов, расположенных в двумерном пространстве, способны формировать независимые группы для выполнения различных задач.
Дискретный трансформатор, использующий жесткое внимание для обеспечения того, что каждый шаг зависит только от фиксированного контекста.
В данной статье представлены модификации стандартной архитектуры трансформатора с целью улучшения интерпретируемости при сохранении производительности в задачах НЛП.
В данной работе предлагаются три дискретных трансформатора: дискретный и стохастический модуль внимания на основе Gumbel-softmax, двухпоточный синтаксический и семантический трансформатор и регуляризация разреженности.
Мы демонстрируем эмпирические доказательства того, что модели предиктивного кодирования дают представления, более коррелирующие с данными мозга, чем модели распознавания образов под наблюдением.
Общая структура для обработки переноса и многозадачного обучения с использованием пар автоэнкодеров с весами, специфичными для конкретной задачи и общими весами.
Предлагает общую структуру для сквозного трансферного обучения/доменной адаптации с помощью глубоких нейронных сетей. 
В данной статье предлагается модель, позволяющая архитектурам глубоких нейронных сетей совместно использовать параметры в различных наборах данных, и она применяется для трансферного обучения.
Работа посвящена изучению общих признаков на основе данных из нескольких доменов и завершается разработкой общей архитектуры для многозадачного, полусамостоятельного и трансфертного обучения.
Мы предлагаем схему объединения деревьев решений и нейронных сетей и показываем на задачах классификации изображений, что она обладает дополнительными преимуществами этих двух подходов, одновременно устраняя ограничения предыдущих работ.
Авторы предложили новую модель, Adaptive Neural Trees, объединив обучение представлений и градиентную оптимизацию нейронных сетей с обучением архитектуры деревьев решений.
В данной статье предлагается подход Adaptive Neural Trees, позволяющий объединить две парадигмы обучения - глубокие нейронные сети и деревья решений.
Перевод части входных данных во время обучения может улучшить межъязыковую производительность.
В статье предлагается метод дополнения межъязыковых данных для улучшения задач языкового вывода и ответов на вопросы.
В данной работе предлагается дополнить межъязыковые данные эвристическими обменами с использованием согласованных переводов, как это делают двуязычные люди при переключении кодов.
Мы предлагаем условный вариационный автоэнкодер, который смягчает апостериорный коллапс в сценариях, когда условный сигнал достаточно силен, чтобы выразительный декодер мог генерировать из него правдоподобный выход.
В данной работе рассматриваются сильно обусловленные генеративные модели, и предлагается целевая функция и параметризация вариационного распределения таким образом, чтобы латентные переменные явно зависели от входных условий.
В данной работе утверждается, что когда декодер обусловлен конкатенацией латентных переменных и вспомогательной информации, то апостериорный коллапс более вероятен, чем в ванильной VAE.
Мы предлагаем исследование устойчивости нескольких алгоритмов обучения с несколькими выстрелами при вариациях гиперпараметров и схем оптимизации при контроле случайного семени.
В данной работе изучается воспроизводимость для обучения с помощью нескольких снимков.
Мы переводим ограничение на неоптимальность представлений в практическую задачу обучения в контексте иерархического обучения с подкреплением.
Авторы предлагают новый подход к обучению представления для HRL и указывают на интригующую связь между обучением представления и ограничением неоптимальности, что приводит к градиентному алгоритму.
В данной работе предлагается способ обработки субоптимальности в контексте обучающих представлений, которые относятся к субоптимальности иерархического многообразия по отношению к вознаграждению за выполнение задачи.
Метарассуждения в ситуативном временном планировщике
В данной статье рассматривается проблема временного планирования, предлагая дальнейшее упрощение жадных стратегий, ранее предложенных Шпербергом.
Показатели робастности обученных моделей PGD чувствительны к семантико-сохраняющему преобразованию наборов данных изображений, что подразумевает хитрость оценки робастных алгоритмов обучения на практике.
В статье разъясняется разница между чистой и робастной точностью и показано, что изменение маргинального распределения входных данных P(x) при сохранении их семантики P(y|x) влияет на робастность модели.
В данной работе исследуется происхождение недостаточной устойчивости классификаторов к возмущениям неблагоприятных входов при l-inf ограниченных возмущениях.
Сопоставление предложений путем изучения структур латентного дерева конституентов с помощью варианта алгоритма inside-outside, встроенного в слой нейронной сети.
В данной работе представлены механизмы структурированного внимания для вычисления оценок выравнивания среди всех возможных пролетов в двух заданных предложениях.
В данной статье предлагается модель структурированных выравниваний между предложениями как средство сравнения предложений путем сопоставления их скрытых структур.
Изучение представления рассогласования без наблюдения.
Авторы представляют схему, в которой автокодер (E, D) регуляризируется таким образом, чтобы его латентное представление разделяло взаимную информацию со сгенерированным представлением латентного пространства.
Условные GAN, обученные генерировать дополненные данными образцы своих условных входов, используются для улучшения ванильной классификации и систем однократного обучения, таких как сети соответствия и пиксельное расстояние.
Авторы предлагают метод дополнения данных, при котором межклассовые преобразования отображаются на низкоразмерное латентное пространство с помощью условного GAN.
Мы разработали простой метод выбора признаков, основанный на регрессии и диагностике модели, для интерпретации процессов генерации данных с контролем FDR и превзошли несколько популярных базовых методов на нескольких симуляционных, медицинских и изобразительных наборах данных.
В данной статье предлагается практическое улучшение теста на условную рандомизацию и новая тестовая статистика, доказывается, что f-дивергенция является одним из возможных вариантов, и показывается, что KL-дивергенция отменяет некоторые условные распределения.
В данной работе рассматривается проблема поиска полезных характеристик в исходных данных, которые зависят от переменной отклика даже при условии, что все остальные входные переменные являются условными.
Метод, не зависящий от модели, позволяющий интерпретировать влияние входных характеристик на отклик модели машинного уровня вплоть до уровня экземпляра, и соответствующая тестовая статистика для выбора характеристик, не зависящих от модели.
Новый подход для обучения модели на основе шумных аннотаций краудсорсинга.
В данной статье предлагается метод обучения на шумных метках, сфокусированный на случае, когда данные не имеют избыточных меток, с теоретической и экспериментальной проверкой.
Эта статья посвящена проблеме обучения из толпы, где совместное обновление весов классификаторов и матриц путаницы работников может помочь в решении проблемы оценки с редкими метками, полученными из толпы.
Предлагает алгоритм контролируемого обучения для моделирования качества меток и работников и использует алгоритм для изучения того, сколько избыточности требуется в краудсорсинге и приводит ли низкая избыточность с большим количеством шумовых примеров к лучшим меткам.
Новый способ объяснить, почему нейронная сеть неправильно классифицировала изображение
В данной статье предлагается метод объяснения ошибок классификации нейронных сетей. 
Нацелен на лучшее понимание классификации нейронных сетей и исследует латентное пространство вариационного автокодировщика и рассматривает возмущения латентного пространства для получения правильной классификации.
Метод автоматического построения разветвленных многозадачных сетей с сильной экспериментальной оценкой на различных многозадачных наборах данных.
В данной работе предлагается новая система многозадачного обучения с мягким разделением параметров, основанная на древовидной структуре.
В данной статье представлен метод вывода архитектуры многозадачных сетей для определения того, какая часть сети должна быть разделена между различными задачами.
Можно заменить весовую матрицу в конволюционном слое, чтобы обучить его как структурированный эффективный слой, работающий так же хорошо, как и низкоранговое разложение.
Данная работа применяет предыдущие структурированные эффективные линейные слои к слоям conv и предлагает структурированные эффективные конволюционные слои в качестве замены оригинальных слоев conv.
Мы представляем SVDocNet - сквозную обучаемую пространственную рекуррентную нейронную сеть (РНС) на основе U-Net для слепого размытия документов.
Мы расширяем билинейное разреженное кодирование и используем видеопоследовательности для обучения динамическим фильтрам.
Мы предлагаем новый детектор OOD, который использует размытые изображения в качестве неблагоприятных примеров. Наша модель достигает значительной эффективности обнаружения ООД в различных областях.
В данной статье представлена идея использования размытых изображений в качестве регуляризирующих примеров для повышения эффективности обнаружения нераспределенных объектов на основе метода случайной сетевой дистилляции.
В данной работе решается проблема распределения данных вне данных с помощью RND, применяемого к дополнениям данных, путем обучения модели для согласования выходов случайной сети с дополнением в качестве входа.
Быстрый оптимизатор для общих приложений и обучения больших партий.
В данной работе авторы провели исследование по крупносерийному обучению для BERT и успешно обучили модель BERT за 76 минут.
В данной работе разработана стратегия послойной адаптации, которая позволяет обучать модели BERT с большими 32k мини-батчами против базовых 512.
Мы проанализировали роль двух скоростей обучения в метаобучении с диагностикой модели при сходимости.
Авторы решили проблему нестабильности оптимизации в MAML, исследуя две скорости обучения.
В данной работе исследуется метод, позволяющий настроить две скорости обучения, используемые в алгоритме обучения MAML.
Независимая от задачи нейронная модель для обучения ассоциациям между взаимосвязанными группами слов.
В статье предложен метод обучения векторов слов, специфичных для функций, в котором каждое слово представлено тремя векторами, каждый из которых относится к отдельной категории (субъект-глагол-объект).
В данной статье предлагается нейронная сеть для обучения представлениям работы, специфичным для конкретной функции, и демонстрируется ее преимущество перед альтернативными вариантами.
Использование метода глубокого обучения для проведения автоматического измерения изображений SEM в полупроводниковой промышленности
В данной статье описываются и анализируются три метода планирования работ с нефиксированной продолжительностью при наличии потребляемых ресурсов.
В статье представлены три подхода к бортовому планированию работ в планетарном ровере в условиях ограничений на пластовые ресурсы.
Описание заявки на конкурс NeurIPS2019 Disentanglement Challenge на основе гиперсферических вариационных автоэнкодеров
Обнаружение аномалий, которое: использует классификацию со случайным преобразованием для обобщения на данные, не относящиеся к изображениям.
В данной работе предлагается глубокий метод обнаружения аномалий, который объединяет недавно разработанные глубокие подходы одноклассовой классификации и классификации на основе преобразований.
В данной статье предлагается подход к обнаружению аномалий на основе классификации для общих данных с использованием аффинного преобразования y = Wx+b.
Мы уменьшаем предубеждения в отношении настроений на основе контрфактической оценки генерации текста с помощью языковых моделей.
В данной работе измеряется смещение настроений в языковых моделях, отражаемое текстом, генерируемым моделями, и добавляются другие объективные условия к обычной цели языкового моделирования для уменьшения смещения.
В данной работе предлагается оценить смещение предварительно обученных языковых моделей с помощью фиксированной системы настроений и тестируется несколько различных префиксных шаблонов.
Метод, основанный на семантическом сходстве, и метод, основанный на сходстве настроений, для дебайеризации нейронных языковых моделей, обученных на основе больших наборов данных.
Байесовская непараметрическая тематическая модель с вариационными автокодировщиками, которая достигает современного уровня на публичных эталонах в плане недоумения, согласованности тем и задач поиска.
В данной работе построена бесконечная тематическая модель с вариационными автоэнкодерами путем объединения вариационного автоэнкодера Nalisnick & Smith, разбивающего палочки, с латентным распределением Дирихле и несколькими методами вывода, используемыми в Miao.
Мы представляем новую структуру дистилляции знаний, используя образцы сверстников в качестве учителя.
Предлагается метод повышения эффективности дистилляции знаний путем смягчения используемых меток и использования набора данных вместо одной выборки.
В данной статье предлагается решить проблему дополнительных вычислительных затрат на обучение с помощью дистилляции знаний, основываясь на недавно предложенной технике Snapshot Distillation.
обучение иерархическим под-политикам путем сквозного обучения на распределении задач
Авторы рассматривают проблему обучения полезному набору "подполитик", которые могут быть распределены между задачами, чтобы начать обучение на новых задачах, взятых из распределения задач. 
В данной статье предлагается новый метод создания временной иерархической структуры в специализированной многозадачной среде.
Модель конволюционной нейронной сети для неконтролируемого встраивания документов.
Представляет новую модель для общей задачи индуцирования представлений документов (вкраплений), которая использует архитектуру CNN для повышения вычислительной эффективности.
В данной работе предлагается использовать CNNs с целью, подобной пропускной программе, в качестве быстрого способа вывода вкраплений документов.
Мы доказываем границы обобщения для конволюционных нейронных сетей, которые учитывают привязку к весу
Исследует обобщающую способность CNNs и улучшает верхние границы ошибок обобщения, показывая корреляцию между ошибкой обобщения обученных CNNs и доминирующим членом верхней границы.
В данной работе представлена граница обобщения для сверточных нейронных сетей, основанная на количестве параметров, константе Липшица и расстоянии конечных весов от инициализации.
Двукратная экономия размера модели, 28% снижение энергопотребления для MobileNets на ImageNet без потери точности при использовании гибридных слоев, состоящих из обычных полноточных фильтров и троичных фильтров
Фокусируется на квантовании архитектуры MobileNets до троичных значений, уменьшая требуемое пространство и вычисления, чтобы сделать нейронные сети более энергоэффективными.
В статье предлагается послойный гибридный банк фильтров, который квантует только часть конволюционных фильтров в троичные значения для архитектуры MobileNets.
Мы создали эталон контролируемого реального шума и выявили несколько интересных результатов, касающихся реальных зашумленных данных.
В данной работе сравниваются 6 существующих методов обучения по шумным меткам в двух вариантах обучения: с нуля и доработки.
Авторы создали большой набор данных и эталон контролируемого шума реального мира для проведения контролируемых экспериментов на зашумленных данных в глубоком обучении.
Мы научимся решать задачу проектирования РНК с помощью обучения с подкреплением, используя подходы метаобучения и autoML.
Использование градиентной оптимизации политики для генерации последовательностей РНК, которые складываются в целевую вторичную структуру, привело к значительному повышению точности и времени работы. 
Обучение небольших сетей побеждает обрезку, но обрезка позволяет найти хорошие небольшие сети, которые легко скопировать.
Мы изучаем проблему обучения предсказанию лежащего в основе разнообразия убеждений, присутствующих в областях обучения под наблюдением.
Мы представили стратегию, которая позволяет проводить инпайтинг моделей на наборах данных различных размеров
Помощь в инпайтинге изображений с помощью GANs, используя сравнительный аугментирующий фильтр и добавляя случайный шум к каждому пикселю.
Мы обнаружили доказательства того, что минимизация расхождений не является точной характеристикой обучения GAN.
Цель работы - представить эмпирические доказательства того, что теория минимизации расхождений является скорее инструментом для понимания результатов обучения GAN, чем необходимым условием, которое должно соблюдаться в процессе обучения.
В данной работе исследуются ненасыщающие GAN и влияние двух подходов с пенализацией градиента, рассматривается несколько мысленных экспериментов для демонстрации наблюдений и их проверка на реальных данных.
Новый и практичный статистический тест зависимости с использованием нейронных сетей, проверенный на синтетическом и реальном наборе данных фМРТ.
Предлагается нейросетевая оценка взаимной информации, которая может надежно работать с небольшими наборами данных, уменьшая сложность выборки за счет разделения проблемы обучения сети и проблемы оценки.
Создание подписей к изображениям с помощью двумерного встраивания слов.
LEAP объединяет силу адаптивной выборки с силой мини-пакетного онлайн-обучения и адаптивного обучения представлений, чтобы сформулировать репрезентативную стратегию самообучения в сквозном протоколе обучения ДНК. 
Представляет метод создания мини-партий для студенческой сети с помощью второго обучаемого пространства представлений для динамического отбора примеров по их "простоте и истинному разнообразию".
Эксперименты по точности классификации на наборах данных MNIST, FashionMNIST и CIFAR-10 для изучения представления с выбором минипакетов в стиле обучения по учебному плану в сквозной структуре.
Мы предлагаем строить макродействия с помощью генетического алгоритма, который устраняет зависимость процедуры выведения макродействий от прошлых политик агента.
В данной работе предлагается общий алгоритм построения макродействий для глубокого обучения с подкреплением путем добавления макродействий к пространству примитивных действий.
Мы предлагаем расширение LFADS, способное вычислять последовательности спайков для реконструкции следов флуоресценции кальция с помощью иерархических VAE.
Мы представляем первый успешный метод обучения нейронного машинного перевода без контроля, используя только моноязычные корпорации.
Авторы представляют модель для несамостоятельного NMT, которая не требует параллельных корпораций между двумя интересующими языками. 
Это статья о неконтролируемом МТ, в которой стандартная архитектура, использующая вкрапления слов в общем пространстве вкраплений, обучается только с помощью двуязычных словников и кодера-декодера, обученного на одноязычных данных.
Мы обучаем генеративные адверсарные сети в прогрессивном режиме, что позволяет нам генерировать изображения высокого разрешения с высоким качеством.
Представляет прогрессивный рост и простую функцию сводной статистики минипартий без параметров для использования в обучении GAN для синтеза изображений высокого разрешения.
Сферическая CNN на основе графа, которая обеспечивает интересный баланс компромиссов для широкого спектра приложений.
Объединяет существующие структуры CNN, основанные на дискретизации сферы в виде графа, чтобы показать результат сходимости, который связан с эквивалентностью вращения на сфере.
Авторы используют существующую формулировку графовой CNN и стратегию объединения, которая использует иерархические пикселизации сферы для обучения на дискретизированной сфере.
Мы доказываем соотношения флуктуация-диссипация для SGD, которые могут быть использованы для (i) адаптивной установки скорости обучения и (ii) зондирования поверхностей потерь.
Концепции Paper работают в формализме дискретного времени, используют основное уравнение и устраняют зависимость от локально квадратичной аппроксимации функции потерь или от любых гауссовских предположений о шуме SGD. 
Авторы выводят соотношения стационарных флуктуаций-диссипаций, которые связывают измеряемые величины и гиперпараметры в SGD, и используют эти соотношения для адаптивной настройки графика обучения и анализа ландшафта функции потерь.
Мы предлагаем механизм деноизации внутреннего состояния РНС для улучшения эффективности обобщения.
Для сред, частично диктуемых внешними входными процессами, мы выводим зависимую от входа базовую линию, которая доказательно уменьшает дисперсию для градиентных методов политики и улучшает эффективность политики в широком диапазоне задач РЛ.
Авторы рассматривают проблему обучения в средах, управляемых входными данными, показывают, как теорема PG по-прежнему применима для критика с учетом входных данных, и показывают, что исходные данные, зависящие от входных данных, являются наилучшими для использования в догадках с таким критиком.
В данной работе вводится понятие входно-зависимых базовых линий в политико-градиентных методах в RL, и предлагаются различные методы обучения входно-зависимой базовой функции, чтобы помочь очистить дисперсию от возмущений внешних факторов.
Дополнение верхнего слоя сети классификатора памятью стилей позволяет ей быть генеративной.
В данной работе предлагается обучать нейронную сеть-классификатор не только классифицировать, но и реконструировать представление своего входа, чтобы факторизовать информацию о классе из внешнего вида.
В статье предлагается обучение автоэнкодера таким образом, что представление среднего слоя состоит из метки класса на входе и представления скрытого вектора
Модели маршрутизации на основе отдельных примеров выигрывают от архитектурного разнообразия, но все же с трудом масштабируются на большое количество решений по маршрутизации.
Добавляет разнообразие к типу архитектурного блока, доступного маршрутизатору при каждом решении, и масштабируется на более глубокие сети, достигая современной производительности на Omniglot. 
Эта работа расширяет сети маршрутизации для использования различных архитектур между маршрутизируемыми модулями
Мы представляем РНС для обучения суррогатных моделей PDE, где ограничения согласованности обеспечивают физическую значимость решений, даже если при обучении используются гораздо меньшие области, чем те, к которым применяется обученная модель.
Мы предлагаем использование оптимистического зеркального приличия для решения проблем цикличности при обучении GAN. Мы также представляем оптимистический алгоритм Адама
В данной работе предлагается использовать оптимистический зеркальный спуск для обучения WGAN.
В статье предлагается использовать оптимистический градиентный спуск для обучения GAN, который позволяет избежать циклического поведения, наблюдаемого в SGD и его вариантах, и обеспечивает многообещающие результаты в обучении GAN.
В данной статье предлагается простая модификация стандартного градиентного спуска, претендующая на улучшение сходимости GAN и других задач минимаксной оптимизации.
Простое расширение обобщенной матричной факторизации может превзойти самые современные подходы для рекомендаций.
В работе представлена матричная факторизация для усиления эффекта исторических данных при изучении предпочтений пользователей в условиях коллаборативной фильтрации.
Метод построения представлений последовательных данных и их динамики с помощью генеративных моделей с активным процессом
Комбинирует нейронные сети и гауссовские распределения для создания архитектуры и генеративной модели для изображений и видео, которая минимизирует ошибку между сгенерированными и предоставленными изображениями.
В статье предлагается модель байесовской сети, реализованная в виде нейронной сети, которая обучается различным данным в форме линейной динамической системы
В качестве функций активации мы предлагаем полином.
Авторы вводят обучаемые функции активации, которые параметризуются полиномиальными функциями, и показывают результаты немного лучше, чем ReLU.
Простой метод внутренней мотивации с использованием модели ошибки в пространстве признаков политики.
Мы показываем, что распутанные VAE более устойчивы, чем ванильные VAE, к атакам противника, направленным на то, чтобы заставить их декодировать входные данные противника в выбранную цель. Затем мы разработали еще более надежный иерархический распутанный VAE, Seatbelt-VAE.
Авторы предлагают новую модель VAE под названием seatbelt-VAE, которая оказалась более устойчивой к латентным атакам, чем эталонные модели.
Мы демонстрируем, что изменение функции обратного распространения эквивалентно неявной скорости обучения
Подход к обучению с подкреплением для передачи стиля текста
Представляет метод на основе RL, который использует предварительно обученную языковую модель для передачи стиля текста без цели распутывания, используя при этом поколения передачи стиля из другой модели.
Авторы предлагают комбинированную награду, состоящую из беглости, содержания и стиля, для передачи стиля текста.
Мы показываем, что высокоструктурированная семантическая иерархия возникает в глубоких генеративных представлениях как результат для синтеза сцен.
В статье исследуются аспекты, закодированные латентными переменными, вводимыми в различные слои StyleGAN.
В статье представлена визуальная интерпретация активаций сверточных слоев в генераторе StyleGAN по макету, категории сцены, атрибутам сцены и цвету.
Мы объединяем сообщения между несколькими SMILES-строками одной молекулы для передачи информации по всем путям через молекулярный граф, создавая скрытые представления, которые значительно превосходят современные в различных задачах.
Метод использует несколько входных строк SMILES, объединение признаков по символам в этих строках и обучение сети с помощью нескольких выходных целей строк SMILES, создавая надежное латентное представление фиксированной длины, не зависящее от вариаций SMILES.  
Авторы описывают новый метод вариационного автоэнкодера для молекул, который кодирует молекулы как строки, чтобы уменьшить количество операций, необходимых для обмена информацией между атомами в молекуле.
Мы предлагаем простой и общий подход, позволяющий избежать проблемы коллапса режимов в различных условных GAN.
В статье предлагается термин регуляризации для условной цели GAN, чтобы способствовать разнообразной мультимодальной генерации и предотвратить разрушение режима.
В статье предлагается метод генерации разнообразных выходов для различных условных GAN-систем, включая перевод изображений в изображения, рисование изображений и предсказание видео, который может быть применен к различным условным синтезирующим системам для различных задач. 
Оснащение модели трансформатора короткими путями к слою встраивания освобождает возможности модели для изучения новой информации.
Мы исследуем связь между значениями плотности вероятности и содержанием изображения в неинвертируемых GAN.
Авторы пытаются оценить распределение вероятностей изображения с помощью GAN и разработать правильное приближение к PDF в латентном пространстве.
Мы предлагаем пространственно-перемешанную свертку, при которой обычная свертка включает в себя информацию, поступающую из-за пределов рецептивного поля.
Предлагается SS свертка, которая использует информацию за пределами своего RF, показывая улучшенные результаты при тестировании на нескольких моделях CNN.
Авторы предложили стратегию перестановки слоев свертки в слоях свертки в сверточных нейронных сетях.
Метод моделирования генеративного распределения последовательностей, поступающих от сущностей, связанных графом.
Авторы предлагают метод моделирования последовательных данных из нескольких взаимосвязанных источников с помощью смеси общего пула HMM.
Наша работа применяет мета-обучение к мультиагентному обучению с усилением, чтобы помочь нашему агенту эффективно адаптироваться к новым наступающим противникам.
Данная работа посвящена быстрой адаптации к новому поведению других агентов среды с помощью метода, основанного на MAML.
В статье представлен подход к обучению мультиагентов, основанный на концепции метаобучения с диагностикой модели для задачи моделирования оппонентов для мультиагентных RL.
Мы характеризуем сингулярные значения линейного преобразования, связанного со стандартным двумерным многоканальным сверточным слоем, что позволяет эффективно их вычислять. 
Статья посвящена вычислению сингулярных значений конволюционных слоев
Выводит точные формулы для вычисления сингулярных значений сверточных слоев глубоких нейронных сетей и показывает, что вычисление сингулярных значений может быть выполнено гораздо быстрее, чем вычисление полной SVD матрицы свертки, путем обращения к быстрым преобразованиям БПФ.
VariBAD открывает путь к трактируемому приближенному Байес-оптимальному исследованию для глубокого РЛ, используя идеи метаобучения, Байесовского РЛ и приближенного вариационного вывода.
В данной статье представлен новый метод глубокого обучения с подкреплением, который может эффективно сочетать исследование и эксплуатацию, объединяющий метаобучение, вариационный вывод и байесовский RL.
Мы показываем, что метрическое обучение может помочь уменьшить катастрофическую забывчивость
В данной работе применяется метрическое обучение для уменьшения катастрофического забывания в нейронных сетях путем улучшения выразительности последнего слоя, что приводит к лучшим результатам при непрерывном обучении.
Мы представляем NormCo, модель глубокой связности, которая учитывает семантику упоминания сущности, а также тематическую связность упоминаний в пределах одного документа для выполнения нормализации сущности болезни.
Использует автоэнкодер GRU для представления "контекста" (связанных с данным заболеванием особенностей в пределах предложения), решая задачу BioNLP со значительным улучшением по сравнению с наиболее известными методами.
Мы исследуем роль мультипликативного взаимодействия как объединяющей основы для описания ряда классических и современных архитектурных мотивов нейронных сетей, таких как гейтинг, слои внимания, гиперсети, динамические свертки и др.
Представляет мультипликативное взаимодействие как единую характеристику для представления широко используемых компонентов проектирования архитектуры модели, демонстрируя эмпирическое доказательство превосходной производительности в таких задачах, как RL и моделирование последовательности.
В статье исследуются различные типы мультипликативных взаимодействий и обнаруживается, что модели MI способны достичь самых современных результатов в задачах языкового моделирования и обучения с подкреплением.
Эффективная система GAN с текстовыми условиями для создания видео из текста
В данной работе представлен метод генерации видео на основе GAN, основанный на текстовом описании, с новым методом кондиционирования, который генерирует фильтры свертки из закодированного текста и использует их для свертки в дискриминаторе.
В данной статье предлагаются условные модели GAN для синтеза текста в видео: разработка фильтров CNN, обусловленных текстовыми характеристиками, и построение набора данных движущихся фигур с улучшенной производительностью при генерации видео/изображений.
SplitLBI применяется к глубокому обучению для изучения структурной разреженности модели, достигая лучших результатов в ImageNet-2012 и раскрывая эффективную архитектуру подсетей.
Предлагается оптимизационный алгоритм для поиска важных разреженных структур крупномасштабных нейронных сетей путем объединения обучения весовой матрицы и ограничений разреженности, обеспечивающий гарантированную сходимость для невыпуклых задач оптимизации.
Мы предлагаем механизмы управления, улучшающие выученный ISTA для разреженного кодирования, с теоретическими гарантиями превосходства метода. 
Предлагает расширения LISTA, которые решают проблему недооценки, вводя "ворота усиления" и включая импульс с "воротами проскакивания", демонстрируя улучшенную скорость сходимости.
Данная статья посвящена решению проблем разреженного кодирования с использованием сетей типа LISTA путем предложения "функции усиления" для смягчения слабости предположения "отсутствие ложных срабатываний".
Мы представляем эффективную и адаптивную структуру для сравнения классификаторов изображений с целью максимизации расхождений между классификаторами, вместо сравнения на фиксированных тестовых наборах.
Механизм выявления ошибок, который сравнивает классификаторы изображений путем выборки их "наиболее несогласованного" тестового набора, измеряя несогласие с помощью семантически-ориентированного расстояния, полученного из онтологии WordNet.
Мы предлагаем метод, который изменяет структуру CNN для повышения устойчивости при сохранении высокой точности тестирования, и ставим под сомнение целесообразность текущего определения неблагоприятных примеров, генерируя неблагоприятные примеры, способные обмануть человека.
В данной статье предлагается простая техника для повышения устойчивости нейронных сетей к атакам "черного ящика".
Авторы предлагают простой метод повышения устойчивости конволюционных нейронных сетей к неблагоприятным примерам, который дает удивительно хорошие результаты.
Мы предлагаем сравнить полунаблюдаемое и надежное обучение для зашумленных меток в общей настройке
Авторы предлагают стратегию, основанную на смешивании, для обучения модели в формальной среде, которая включает задачи полунаблюдения и надежного обучения в качестве частных случаев.
В данной работе экспериментально продемонстрировано благотворное влияние нисходящих связей в алгоритме Hierarchical Sparse Coding.
В данной работе представлено исследование, в котором сравниваются методы иерархического разреженного кодирования, показано, что термин "сверху вниз" выгоден для снижения ошибки предсказания и может обучаться быстрее.
Подход "черного ящика" для объяснения предсказаний модели сходства изображений.
Представляет метод объяснения модели сходства изображений, который определяет атрибуты, вносящие положительный вклад в оценку сходства, и сопоставляет их со сгенерированной картой салиентации.
В статье предлагается механизм объяснения, который сопрягает типичные области карты салиента с атрибутами для глубоких нейронных сетей, сопоставляющих сходство.
Как следует оценивать атаки противников на seq2seq
Авторы исследуют способы генерации состязательных примеров, показывая, что состязательное обучение с атакой, наиболее соответствующей введенным критериям сохранения смысла, приводит к улучшению устойчивости к этому типу атак без ухудшения в не состязательной среде.
Статья посвящена сохраняющим смысл неблагоприятным возмущениям в контексте моделей Seq2Seq.
Метод нормализации, альтернативный пакетной нормализации
Представляет технику нормализации, которая нормализует веса конволюционных слоев. 
В данной рукописи представлено новое послойное преобразование EquiNorm для улучшения пакетной нормализации, которое изменяет не входы в слои, а веса слоев.
Представьте каждую сущность как распределение вероятности по контекстам, встроенным в пространство земли.
Предлагает строить вкрапления слов на основе гистограммы над контекстными словами, а не в виде точечных векторов, что позволяет измерять расстояния между двумя словами в терминах оптимального переноса между гистограммами с помощью метода, который расширяет представление сущности от стандартной "точки в векторном пространстве" до гистограммы с бинами, расположенными в некоторых точках этого векторного пространства. 
Небольших возмущений следует ожидать, учитывая наблюдаемые коэффициенты ошибок моделей за пределами естественного распределения данных.
В данной работе предлагается альтернативный взгляд на состязательные примеры в пространствах высокой размерности путем рассмотрения "коэффициента ошибок" в гауссовском распределении, сосредоточенном в каждой тестовой точке.
Изучает взаимодействие самоконтролируемого обучения и дистилляции знаний в контексте построения компактных моделей.
Исследует обучение компактных предварительно обученных языковых моделей с помощью дистилляции и показывает, что использование учителя для дистилляции компактной модели студента работает лучше, чем прямое предварительное обучение модели.
Это представление показывает, что предварительное обучение студента непосредственно моделированию языка по маске лучше, чем дистилляция, и лучше всего объединить оба способа и дистилляцию из этой предварительно обученной студенческой модели.
Мы представляем универсальную схему сжатия глубоких нейронных сетей, которая универсально применима для сжатия любых моделей и может работать практически оптимально независимо от распределения их веса.
Представляет конвейер для сжатия сетей, который похож на глубокое сжатие и использует рандомизированное решетчатое квантование вместо классического векторного квантования, а также использует универсальное исходное кодирование (bzip2) вместо кодирования Хаффмана.
В данной работе предпринята попытка предварительного теоретического рассмотрения проблемы распутывания в идеалистической ситуации и практического рассмотрения с точки зрения моделирования шума в реалистическом случае.
Исследует важность моделирования шума в гауссовском VAE и предлагает обучать шум с помощью метода эмпирического Бэйеса.
Изменение того, как учитываются факторы шума при разработке моделей VAE
Мы исследуем регуляризацию с уменьшением веса для различных оптимизаторов и выявляем три различных механизма, с помощью которых уменьшение веса улучшает обобщение.
Обсуждается влияние уменьшения веса на обучение моделей глубоких сетей с нормализацией партии и без нее, а также при использовании методов оптимизации первого/второго порядка и выдвигается гипотеза, что большая скорость обучения оказывает эффект регуляризации.
Самый первый свободно распространяемый набор данных адаптации домена для обнаружения звуковых событий.
Оценщик взаимной информации на основе неэкстенсивной статистической механики
В данной работе делается попытка установить новые вариационные нижние границы для взаимной информации, вводя параметр q и определяя q-алгебру, показывая, что нижние границы имеют меньшую дисперсию и достигают высоких значений.
Мы показываем, что стохастический градиентный спуск сходится к глобальному оптимуму для WGAN с однослойной генераторной сетью.
Попытка доказать, что стохастический градиентный спуск может сходиться к глобальному решению для min-max задачи WGAN.
Мы эмпирически показываем, что состязательное обучение эффективно для устранения универсальных возмущений, делает состязательные примеры менее устойчивыми к трансформациям изображения и оставляет их пригодными для обнаружения.
Анализируется обучение противника и его влияние на универсальные примеры противника, а также на стандартные (базовая итерация) примеры противника и то, как обучение противника влияет на обнаружение. 
Авторы показывают, что состязательное обучение эффективно для защиты от "общих" состязательных возмущений, в частности, от универсальных возмущений, но менее эффективно для защиты от единичных возмущений.
Мы представляем методы обучения одной универсальной сети, которая подходит для многих аппаратных платформ.
Результатом метода является сеть, из которой можно извлечь подсети для различных ограничений ресурсов (задержка, память), которые работают хорошо без необходимости переобучения.
В данной работе предпринята попытка решить проблему поиска наилучших архитектур для специализированных сценариев развертывания с ограниченными ресурсами с помощью метода NAS, основанного на прогнозировании.
Предложите подход для усиления генеративных моделей путем каскадирования моделей скрытых переменных
В данной работе предложен новый подход каскадного бустинга для бустинга генеративных моделей, который позволяет обучать каждую мета-модель отдельно и жадно.
Мы исследуем структуру предложения в ELMo и связанных с ним моделях контекстуального встраивания. Мы обнаружили, что существующие модели эффективно кодируют синтаксис и демонстрируют наличие дальних зависимостей, но предлагают лишь небольшие улучшения при решении семантических задач.
Предлагает метод "edge probing" и фокусируется на отношениях между диапазонами, а не отдельными словами, что позволяет авторам рассмотреть синтаксическую составляющую, зависимости, метки сущностей и маркировку семантических ролей.
Предоставляет новое понимание того, что такое контекстуальные вкрапления слов, путем составления набора задач "зондирования краев". 
Мы представляем DPFRL, схему для обучения с усилением при частичных и сложных наблюдениях с полностью дифференцируемым дискриминационным фильтром частиц.
Представляет идеи для обучения агентов DLR с латентными переменными состояния, смоделированными как распределение убеждений, чтобы они могли работать с частично наблюдаемой средой.
В данной работе представлен принципиальный метод для POMDP RL: Discriminative Particle Filter Reinforcement Learning, который позволяет рассуждать с частичными наблюдениями на нескольких временных шагах, достигая лучших результатов на эталонных тестах.
Задачи Монте-Карло анализируются с помощью вариационного вывода вспомогательных переменных, что позволяет провести новый анализ CPC и NCE, а также построить новую генеративную модель.
Предлагает другой взгляд на улучшение вариационных границ с помощью вспомогательных моделей латентных переменных и исследует использование этих моделей в генеративной модели.
Мы улучшаем работу всех существующих алгоритмов градиентного спуска.
Авторы предлагают отбирать стохастические градиенты из монотонной функции, пропорциональной величине градиента, с помощью LSH. 
Рассматривает SGD над задачей в виде суммы примеров квадратичной потери.
Ограничения современного ИИ общепризнанны, но меньше людей знают, что мы понимаем достаточно о мозге, чтобы сразу предложить новые формулировки ИИ.
Мы используем вопрос-ответ для оценки того, сколько знаний об окружающей среде могут получить агенты с помощью самонаблюдаемого предсказания.
Предлагает QA как инструмент для исследования того, о чем агенты узнают в мире, утверждая, что это интуитивный метод для людей, который допускает произвольную сложность.
Авторы предлагают структуру для оценки представлений, построенных прогностическими моделями, которые содержат достаточно информации для ответов на вопросы об окружающей среде, на которой они обучаются, и показывают, что представления SimCore содержат достаточно информации для того, чтобы LSTM точно отвечал на вопросы.
Мы разработали новый метод для несбалансированной классификации с использованием неблагоприятных примеров
Предлагает новую задачу оптимизации, которая генерирует синтетические выборки путем перевыбора классов большинства вместо классов меньшинств, решая проблему переподбора классов меньшинств.
Авторы предлагают решать проблему несбалансированной классификации с помощью методов повторной выборки, показывая, что неблагоприятные примеры в классе меньшинства помогут обучить новую модель, которая лучше обобщает.
Интересное применение CNN в экспериментах по физике мягкой конденсированной материи.
Авторы демонстрируют, что подход глубокого обучения позволяет повысить точность идентификации и скорость выявления дефектов нематических жидких кристаллов.
Примените известную нейронную модель (YOLO) для обнаружения ограничивающих границ объектов на изображениях.
Анализ влияния композиционности и локальности на обучение представлений для обучения с нулевым результатом.
Предлагается система оценки для ZSL, в которой модель не подлежит предварительному обучению, а вместо этого параметры модели инициализируются случайным образом для лучшего понимания того, что происходит в ZSL.
Ошибка состязательности имеет схожую форму силового закона для всех изученных наборов данных и моделей, и архитектура имеет значение.
Мы представляем формулировку любопытства как проблемы обучения визуальным представлениям и показываем, что она позволяет получить хорошие визуальные представления у агентов.
В данной работе обучение RL на основе любопытства формулируется как обучение модели визуального представления, утверждая, что фокусирование на лучшем LR и максимизация потерь модели для новых сцен позволит получить лучшую общую производительность.
Из неполного RGB-D сканирования сцены мы стремимся обнаружить отдельные объекты, составляющие сцену, и определить их полную геометрию.
Предлагается сквозная структура 3D CNN, которая объединяет цветовые характеристики и 3D характеристики для предсказания недостающей 3D структуры сцены по RGB-D сканам.
Авторы предлагают новую сквозную 3D-конволюционную сеть, которая предсказывает завершение 3D-семантических экземпляров в виде ограничивающих объектов, меток классов и полной геометрии объекта.
XGAN - это модель перевода изображений на уровне признаков, не требующая контроля, применяемая для решения задач семантического переноса стиля, таких как задача "лицо - карикатура", для которой мы представляем новый набор данных.
В данной работе предлагается новая модель на основе GAN для непарного перевода изображений с одного изображения на другое, аналогичная DTN
Рабочие посылают знаки градиента на сервер, и решение об обновлении принимается большинством голосов. Мы показываем, что этот алгоритм сходится, эффективен в общении и устойчив к сбоям как в теории, так и на практике.
Представляет распределенную реализацию signSGD с мажоритарным голосованием в качестве агрегации.
Мы исправляем неприятные вариации для вкраплений изображений в различных областях, сохраняя только релевантную информацию.
Обсуждается метод корректировки вкраплений изображений для того, чтобы отделить технические вариации от биологического сигнала.
Авторы представляют метод удаления информации, специфичной для конкретной области, при сохранении релевантной биологической информации путем обучения сети, которая минимизирует расстояние Вассерштейна между распределениями.
Масштабируемый по размеру выборки и размерности оценщик взаимной информации.
Новая комбинация обучения с подкреплением и контролируемого обучения, резко снижающая количество необходимых образцов для обучения на видео
В данной работе предлагается использовать маркированные контролируемые данные для ускорения обучения политики управления на основе подкрепления.
Быстрое обучение через эпизодическую память, подтвержденное биологически правдоподобной схемой префронтальной коры-базальных ганглиев-гиппокампа (ПФК-БГ)
В этой работе мы указываем на новую связь между выразительностью ДНС и теоремой Шарковского из динамических систем, которая позволяет нам охарактеризовать компромисс между глубиной и шириной сетей ReLU. 
Показывает, как выразительная сила NN зависит от ее глубины и ширины, углубляя понимание преимущества глубоких сетей для представления определенных классов функций.
Авторы выводят условия компромисса между глубиной и шириной для того, когда сети relu способны представлять периодические функции, используя анализ динамических систем.
Мы исследуем обучение с учетом квантования в очень низкоразрядных квантованных устройствах поиска ключевых слов для снижения стоимости поиска ключевых слов на устройстве.
В данной работе предлагается сочетание низкоранговой декомпозиции и кванитизации для сжатия моделей DNN для поиска ключевых слов.
Новая система обработки графовых сигналов для количественной оценки влияния экспериментальных возмущений в одноклеточных биомедицинских данных.
В данной статье представлены несколько методов обработки результатов экспериментов с биологическими клетками и предложен алгоритм MELD, отображающий жесткие групповые назначения на мягкие, что позволяет кластеризовать соответствующие группы клеток.
Мы предлагаем класс пользовательских моделей, основанных на использовании гауссовских процессов, применяемых к преобразованному пространству, определенному правилами принятия решений
Мы предлагаем оптимальный алгоритм байесовской оптимизации для настройки гиперпараметров с использованием дешевых приближений.
Изучает оптимизацию гиперпараметров с помощью байесовской оптимизации, используя систему Knowledge Gradient и позволяя байесовскому оптимизатору настраивать верность в зависимости от затрат.
Мы эффективно проверяем робастность глубоких нейронных моделей с помощью более 100 000 ReLU, сертифицируя больше образцов, чем самые современные, и находя больше неблагоприятных примеров, чем сильная атака первого порядка.
Проводит тщательное исследование подходов смешанного целочисленного линейного программирования для проверки устойчивости нейронных сетей к неблагоприятным возмущениям и предлагает три усовершенствования формулировок MILP для проверки нейронных сетей.
Набор методов для получения оценки неопределенности любой заданной модели без ее перепроектирования, переобучения или тонкой настройки.
Описывает несколько подходов для измерения неопределенности в произвольных нейронных сетях при отсутствии искажений во время обучения.
Предлагаемая операция высшего порядка для контекстного обучения
Предлагается новый 3D-конволюционный блок, который свертывает входное видео с его контекстом, основываясь на предположении, что соответствующий контекст присутствует вокруг объекта изображения.
Модели на основе согласованности для полунаблюдаемого обучения не сходятся к одной точке, а продолжают исследовать разнообразный набор правдоподобных решений по периметру плоской области. Усреднение весов помогает улучшить эффективность обобщения.
В статье предлагается применить стохастическое усреднение веса в контексте полусамостоятельного обучения, утверждая, что полусамостоятельные модели MT/Pi особенно хорошо поддаются SWA, и предлагая быстрое SWA для ускорения обучения.
Мы успешно преобразовали популярный детектор RPN в хорошо работающий трекер с точки зрения функции потерь.
Нейронная архитектура для оценки и ранжирования кандидатов на ремонт программы для выполнения семантического ремонта программы статически без доступа к модульным тестам.
Представляет архитектуру нейронной сети, состоящую из частей share, specialize и compete, для ремонта кода в четырех случаях.
Возможно ли совместное проектирование точности, надежности и эффективности моделей для достижения их тройного выигрыша? Да!
Использует адаптивные к входу множественные ранние выходы для области атак и защиты от противника, снижая среднюю сложность выводов без противоречия предположению о большей емкости.
Мы показываем, что отдельные единицы в представлениях CNN, изучаемых в задачах НЛП, избирательно реагируют на конкретные понятия естественного языка.
Использует грамматические единицы естественного языка, которые сохраняют значения, чтобы показать, что единицы глубоких CNN, изученные в задачах NLP, могут действовать как детектор понятий естественного языка.
Это в основном теоретическая статья, в которой описываются проблемы, связанные с расчленением факторов вариации с использованием автоэнкодеров и GAN.
В данной статье рассматривается разделение факторов вариации изображений, показано, что в общем случае, без дополнительных предположений, невозможно различить два разных фактора вариации, и предложена новая архитектура AE+GAN для попытки разделения факторов вариации.
В данной работе исследуются проблемы, связанные с разделением независимых факторов вариации в условиях слабо маркированных данных, и вводится термин "неоднозначность ссылок" для отображения точек данных.
обучение ранжированию с несколькими вкраплениями и вниманием
Предлагает использовать внимание для объединения нескольких входных представлений для запроса и результатов поиска в задаче обучения ранжированию.
Мы разработали алгоритм, который принимает на вход записи нейронной активности и возвращает кластеры нейронов по типу клеток и модели нейронной активности, ограниченные этими кластерами.
Мы управляем графовыми нейронными сетями для имитации промежуточных и пошаговых выходов классических графовых алгоритмов, получая весьма благоприятные результаты.
Предлагает обучать нейронные сети подражать графовым алгоритмам, изучая примитивы и подпрограммы, а не конечный результат.
Мы описываем архитектуру для генерации различных гипотез о промежуточных целях во время выполнения роботизированных манипуляционных задач.
Оценивает качество предложенной генеративной прогностической модели для генерации планов выполнения роботов.
В данной статье предлагается метод обучения высокоуровневой функции перехода, полезной для планирования задач.
В данной статье представлен новый анализ адаптивных градиентных алгоритмов для решения невыпуклых невогнутых min-max задач в виде GAN, а также объясняется причина, по которой адаптивные градиентные методы превосходят свои неадаптивные аналоги на основе эмпирических исследований.
Разрабатывает алгоритмы решения вариационных неравенств в стохастической постановке, предлагая вариацию экстраградиентного метода.
Мы изучаем сохпистические траектории объекта исключительно по пикселям с помощью набора данных видео игрушек, используя структуру VAE с предварительным гауссовским процессом.
Мы исследуем нейронную основу вспоминания снов, используя методы конволюционной нейронной сети и визуализации признаков, такие как tSNE и управляемое обратное распространение.
В данной статье предлагается новая формулировка и новый протокол связи для сетевых многоагентных задач управления
Рассматриваются N-MARL, в которых агенты обновляют свою политику, основываясь только на сообщениях от соседних узлов, показывая, что введение пространственного коэффициента дисконтирования стабилизирует обучение.
Mean field VB использует вдвое больше параметров; мы связываем параметры дисперсии в mean field VB без потерь в ELBO, выигрывая в скорости и меньших градиентах дисперсии.
Мы эффективно используем несколько ключевых слов в качестве слабого контроля для обучения нейронных сетей для извлечения аспектов.
Обсуждается вариант дистилляции знаний, в котором используется "учитель", основанный на классификаторе "мешок слов" с затравочными словами, и "ученик", представляющий собой нейронную сеть на основе встраивания.
Горизонтальные и нисходящие обратные связи отвечают за взаимодополняющие стратегии перцептивной группировки в биологических и рекуррентных зрительных системах.
Используя нейронные сети в качестве вычислительной модели мозга, изучает эффективность различных стратегий для решения двух визуальных задач.
Мы представляем GAN-TTS, генеративную адверсариальную сеть для преобразования текста в речь, которая достигла средней оценки мнения (MOS) 4,2.
Решает проблему GAN в синтезе необработанных форм сигнала и начинает сокращать существующий разрыв в производительности между авторегрессионными моделями и GAN для необработанных аудиофайлов.
мы предлагаем алгоритм обучения обрезке сети путем применения штрафов за разреженность структуры
В данной статье представлен подход к обрезке при обучении сети с использованием лассо и расщепленных штрафов LBI.
Мы представляем непрерывное обучение без надзора (UCL) и нейроинспирированную архитектуру, которая решает проблему UCL.
Предлагает использовать иерархии модулей STAM для решения проблемы UCL, предоставляя доказательства того, что представления, которые изучают модули, хорошо подходят для классификации по нескольким снимкам.
Новый метод извлечения сигнала в области Фурье
Вносит комплексно-значную конволюционную версию Feature-Wise Linear Modulation, которая позволяет оптимизировать параметры и разрабатывает потери, учитывающие величину и фазу.
Мы представляем новую структуру для обучения рассогласованному представлению содержания и стиля в полностью несамостоятельной манере. 
Предложена модель на основе автоэнкодера для разделения представления объекта, результаты показывают, что модель может создавать представления, передающие содержание и стиль.
Мы разработали стратегию оценки CATE, которая использует некоторые интригующие свойства нейронных сетей. 
Показывает усовершенствования X-learner путем моделирования функции ответа на лечение, функции ответа на контроль и отображения от вмененного эффекта лечения к условному среднему эффекту лечения в виде нейронных сетей.
Авторы предлагают Y-learner для оценки условного среднего эффекта лечения (CATE), который одновременно обновляет параметры функций исхода и оценщика CATE.
Выполнение встроенного программного обеспечения, не зависящего от устройства
Архитектура для табличных данных, которая эмулирует ветви деревьев решений и использует плотную остаточную связность 
В данной статье предлагается глубокий нейронный лес, алгоритм, который нацелен на табличные данные и объединяет сильные стороны градиентного усиления деревьев решений.
Новая архитектура нейронной сети, имитирующая работу леса решений, для решения общей проблемы обучения глубоких моделей для табличных данных и демонстрирующая эффективность наравне с GBDT.
YellowFin - это оптимизатор на основе SGD с адаптацией по импульсу и скорости обучения.
Предлагается метод автоматической настройки параметра импульса в импульсных SGD методах, который позволяет достичь лучших результатов и быстрой скорости сходимости по сравнению с современным алгоритмом Адама.
Адверсионные атаки на латентное пространство вариационных автоэнкодеров для изменения семантического смысла входных данных
Данная статья посвящена безопасности и машинному обучению и предлагает атаку "человек посередине", которая изменяет VAE-кодировку входных данных таким образом, что декодированные выходные данные будут неправильно классифицированы.
Эмпирическое исследование, изучающее эффективность различных комбинаций кодера и декодера для задачи разбора зависимостей
Эмпирический анализ различных кодировщиков, декодировщиков и их зависимостей для разбора зависимостей на основе графов.
Учитель, который обучает метаобучающихся, как людей
Мы представляем подход с использованием пространства вложений для ограничения распределения вероятностей на выходе нейронной сети.
В данной статье представлен метод полусамостоятельного обучения с помощью глубоких нейронных сетей, и модель достигает относительно высокой точности при небольшом объеме обучения.
В данной работе распределение меток включается в процесс обучения модели при ограниченном количестве обучающих примеров, и предлагаются два метода решения проблемы неправильного распределения выходных меток.
Мы представляем новый тип глубокого контекстуализированного представления слов, который значительно улучшает современное состояние дел для ряда сложных задач НЛП.
В данной работе представлена новая функция потерь для надежного обучения ДНК временной локализации в присутствии несоответствующих меток.
Новая потеря для обучения моделей, предсказывающих, где происходят события в обучающей последовательности с зашумленными метками, путем сравнения сглаженных меток и предсказанной последовательности.
Мы вводим понятие смешанных тензорных разложений и используем его для доказательства того, что объединение расширенных конволюционных сетей увеличивает их выразительные возможности.
В данной работе теоретически обосновано, что объединение сетей с различными расширениями может привести к выразительной эффективности при использовании смешанного тензорного разложения.
Авторы исследуют расширенные сверточные сети и показывают, что переплетение двух расширенных сверточных сетей A и B на различных этапах более выразительно, чем отсутствие переплетения.
Показывает, что структурное предположение WaveNet о единственном совершенном бинарном дереве мешает его производительности, и что WaveNet-подобные архитектуры с более сложными смешанными структурами деревьев работают лучше.
многозадачное обучение работает 
В данной работе представлена многозадачная нейронная сеть для классификации на MNIST-подобных наборах данных
Мы предлагаем принципиальный, основанный на оптимизации новый взгляд на понятие состязательных примеров и разрабатываем методы, позволяющие создавать модели, устойчивые к широкому кругу состязательных факторов.
Исследует минимаксную формулировку обучения глубоких сетей для повышения их устойчивости, используя проецируемый градиентный спуск в качестве основного противника. 
В данной статье предлагается рассмотреть вопрос о том, как сделать нейронные сети устойчивыми к неблагоприятным потерям с помощью задач о седловой точке. 
Многие наборы данных классификации графов содержат дубликаты, что ставит вопросы о способности к обобщению и справедливом сравнении моделей. 
Авторы обсуждают смещение изоморфизма в наборах данных графов, эффект избыточной подгонки при обучении сетей, когда в модель включаются признаки изоморфизма графов, теоретически аналогичный эффекту утечки данных.
Мы вводим понятие консервативно-экстраполированных функций ценности, которые доказательно приводят к политикам, которые могут самокорректироваться, чтобы оставаться близкими к демонстрационным состояниям, и обучаем их с помощью новой техники отрицательной выборки.
Алгоритм, называемый ценностной итерацией с отрицательной выборкой, для решения проблемы сдвига ковариаты в имитационном обучении.
Контрастно обученные структурированные модели мира (C-SWM) изучают объектно-ориентированные представления состояний и реляционную модель окружения на основе исходного пиксельного ввода.
Авторы преодолевают проблему использования потерь на основе пикселей при построении и обучении структурированных моделей мира, используя контрастное латентное пространство.
Методы без наблюдения для поиска, анализа и контроля важных нейронов в НМТ
В данной работе предлагается найти "значимые" нейроны в моделях нейромашинного перевода путем ранжирования на основе корреляции между парами моделей, разными эпохами или разными наборами данных, а также предлагается механизм управления моделями.
Мы представляем дважды разреженный softmax, разреженную смесь разреженных экспертов, для повышения эффективности вывода softmax за счет использования двухуровневой перекрывающейся иерархии. 
В статье предлагается новая реализация алгоритма Softmax с двумя иерархическими уровнями разреженности, которая ускоряет работу при моделировании языка.
В данной работе представлены эмпирические данные, подтверждающие открытие индикатора обобщения: изменение в процессе обучения косинусного расстояния между весовым вектором каждого слоя и его инициализацией.
Модели исходного кода, сочетающие глобальные и структурные особенности, позволяют получить более мощные представления программ.
Новый метод моделирования исходного кода для задачи исправления ошибок с использованием многослойной модели типа [RNN GNN RNN], которая значительно улучшает точность локализации и исправления.
Инкрементные РНС решают проблему взрыва/исчезающего градиента путем обновления векторов состояния на основе разницы между предыдущим состоянием и состоянием, предсказанным ODE.
Авторы решают проблему распространения сигнала в рекуррентных нейронных сетях, строя аттракторную систему для перехода сигнала и проверяя, сходится ли она к равновесию. 
Мы приводим доказательства против классических утверждений о компромиссе между смещением и дисперсией и предлагаем новое разложение для дисперсии.
Мы предложили новую систему классификации изображений на основе глубокого обучения, которая может одновременно точно классифицировать изображения и защищать конфиденциальность пользователей.
В данной работе предлагается структура, которая сохраняет частную информацию в изображении и не ставит под угрозу удобство использования изображения.
В настоящей работе предлагается использовать адверсивные сети для обфускации изображений, что позволяет собирать их без опасений за конфиденциальность и использовать для обучения моделей машинного обучения.
модель 2vec для графов криптовалютных транзакций
В статье предлагается использовать автоэнкодер, networkX и node2Vec для предсказания того, станет ли адрес Биткойна пустым через год, но результаты оказались хуже, чем существующий базовый показатель.
Доказательство сходимости метода стохастических подградиентов и его вариаций на выпукло-вогнутых минимаксных задачах
Анализ одновременного стохастического субградиента, одновременного градиента с оптимизмом и одновременного градиента с привязкой в контексте минимаксных выпукло-вогнутых игр.
В данной работе анализируется динамика стохастического градиентного спуска в применении к выпукло-вогнутым играм, а также GD с оптимизмом и новый алгоритм GD с якорем, который сходится при более слабых предположениях, чем SGD или SGD с оптимизмом.
Мы предлагаем алгоритмическую основу для планирования созвездий малых космических аппаратов с возможностью 3-DOF переориентации, объединенных в сеть межспутниковых связей.
В данной статье предлагается коммуникационный модуль для оптимизации расписания связи для проблемы созвездий космических аппаратов, и проводится сравнение алгоритма в распределенной и централизованной настройках.
Мы предложили новый сжатый алгоритм выборки важности с ядрами.
Мы изучаем структуру гребневой регрессии в асимптотических рамках высокой размерности и получаем представление о перекрестной проверке и эскизировании.
Теоретическое исследование гребневой регрессии с использованием новой асимптотической характеристики оценщика гребневой регрессии.
Мы анализируем ландшафт потерь нейронных сетей с вниманием и объясняем, почему внимание полезно при обучении нейронных сетей для достижения хорошей производительности.
В данной работе с теоретической точки зрения доказывается, что сети внимания могут обобщать лучше, чем базовые сети невнимания, для фиксированного внимания (однослойного и многослойного) и самовнимания в однослойных условиях.
Смешанная модель для нейронного распутывания
Мы разработали надежные оценки взаимной информации для ДНС и использовали их для наблюдения сжатия в сетях с ненасыщающими функциями активации
В данной статье изучается популярное мнение о том, что глубокие нейронные сети выполняют сжатие информации для задач с наблюдением.
В данной работе предлагается метод оценки взаимной информации для сетей с неограниченными функциями активации и использование L2 регуляризации для большего сжатия.
Мы представляем TimbreTron, конвейер для высококачественной передачи тембра на музыкальных волновых формах с использованием передачи стиля CQT-домена.
Метод преобразования записей определенного музыкального инструмента в другой путем применения CycleGAN, разработанного для передачи стиля изображения, для передачи спектрограмм.
Авторы используют несколько методов/инструментов для нейронной передачи тембра (преобразование музыки с одного инструмента на другой) без парных обучающих примеров. 
Описывается модель передачи музыкального тембра, результаты которой показывают, что предложенная система эффективна для передачи высоты и темпа, а также для адаптации тембра.
В статье представлен алгоритм Deep Rewiring, который может быть использован для обучения глубоких нейронных сетей, когда связность сети сильно ограничена во время обучения.
Подход к реализации глубокого обучения непосредственно на разреженных связных графах, позволяющий эффективно обучать сети в режиме онлайн и обеспечивающий быстрое и гибкое обучение.
Авторы предлагают простой алгоритм, способный обучаться при ограниченной памяти
Существующие методы обрезки не работают, когда применяются к GAN, решающим сложные задачи, поэтому мы представляем простой и надежный метод обрезки генераторов, который хорошо работает для широкого спектра сетей и задач.
Авторы предлагают модификацию классического метода дистилляции для задачи сжатия сети, чтобы устранить неудачу предыдущих решений при применении к генеративным адверсивным сетям.
мы обнаружили, что 99,9% градиентного обмена в распределенной SGD является избыточным; мы уменьшаем пропускную способность связи на два порядка без потери точности. 
В данной работе предлагается дополнительное улучшение по сравнению с градиентным падением для повышения эффективности связи
Мы предлагаем сеть Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT), которая обуславливает процесс перевода образцовым изображением в целевой области.
Обсуждается основной недостаток и необходимость моделей перевода I2I.
В статье рассматривается идея о том, что изображение состоит из двух компонентов, и применяется модель внимания, в которой маски признаков, управляющие процессом перевода, не требуют семантических меток.
Наложение графовой структуры на слои нейронной сети для улучшения визуальной интерпретируемости.
Новый регуляризатор для наложения графовой структуры на скрытые слои нейронной сети для улучшения интерпретируемости скрытых представлений.
Подчеркивает вклад спектрального регуляризатора графа в интерпретируемость нейронных сетей.
Мы показываем, что модели на основе энергии, обученные на остатках авторегрессионной языковой модели, могут быть эффективно и качественно использованы для генерации текста. 
Предложенная модель на основе остаточной энергии (EBM) для генерации текста, которая работает на уровне предложений и поэтому может использовать BERT, достигает более низкой степени запутанности и является предпочтительной по результатам человеческой оценки.
систематическое исследование крупномасштабных моделей распознавания образов на основе кэша, уделяя особое внимание их свойствам устойчивости
В этой статье было предложено использовать кэш-память для повышения устойчивости к неблагоприятным примерам изображений, и был сделан вывод, что использование большого постоянного кэша не превосходит жесткое внимание.
В статье описывается гибкая структура для построения CNN, эквивариантных к большому классу групп преобразований.
Концепция построения групповой CNN с произвольной группой Ли G, которая демонстрирует превосходство над CNN в классификации опухолей и локализации ориентиров. 
Сравнительный анализ девяти репрезентативных схем глобального объединения показывает некоторые интересные результаты.
Для задач тонкой классификации в данной работе было подтверждено, что maxpooling способствует созданию более редких карт признаков и превосходит avgpooling. 
Самоконтроль улучшает распознавание нескольких снимков на небольших и сложных наборах данных без использования дополнительных данных; дополнительные данные помогают только тогда, когда они из той же или похожей области.
Эмпирическое исследование различных методов самоконтролируемого обучения (SSL), показывающее, что SSL помогает больше, когда набор данных сложнее, что домен имеет значение для обучения, и метод выбора образцов из немаркированного набора данных. 
На основе опыта мы создаем абстрактные модели окружающей среды и используем их для более быстрого обучения новым задачам.
Методология, использующая идею гомоморфизмов MDP для преобразования сложной MDP с непрерывным пространством состояний в более простую.
Мы расширяем сетевую диссекцию для включения интерпретации действий и изучаем интерпретируемые пути признаков, чтобы понять концептуальную иерархию, используемую для классификации действий.
Мы предлагаем новую модель для представления нот и их свойств, которая может улучшить автоматическую генерацию мелодий.
В данной работе предлагается генеративная модель символической (MIDI) мелодии в западной популярной музыке, которая совместно кодирует нотные символы с информацией о времени и длительности для формирования музыкальных "слов".
В статье предлагается облегчить генерацию мелодии, представляя ноты как "слова", отражающие все свойства ноты и, таким образом, позволяющие генерировать музыкальные "предложения".
Метод, который автоматически наращивает слои в нейронных сетях для определения оптимальной глубины.
Структура для чередования обучения более мелкой сети и добавления новых слоев, которая дает представление о парадигме "растущих сетей".
Исследование обучения внутридоменным представлениям для наборов данных дистанционного зондирования.
В этой работе было представлено несколько стандартизированных наборов данных дистанционного зондирования и показано, что внутридоменное представление может дать лучшие базовые результаты для дистанционного зондирования по сравнению с точной настройкой на ImageNet или обучением с нуля.
Избегайте генерирования ответов по одному слову за раз, используя слабый контроль для обучения классификатора выбору полного ответа.
Способ генерации ответов для медицинского диалога с использованием классификатора для выбора из ответов, подготовленных экспертами, на основе контекста разговора.
CNN с конечной шириной SGD-обучения против CNN с бесконечной шириной, полностью байесовских. Кто побеждает?
В статье устанавливается связь между бесконечной канальной байесовской конволюционной нейронной сетью и гауссовскими процессами.
Мы масштабируем байесовский вывод для классификации ImageNet и добиваемся конкурентоспособных результатов точности и калибровки неопределенности.
Адаптивный шумовой MCMC-алгоритм для классификации изображений, который динамически регулирует импульс и шум, применяемые при каждом обновлении параметров, устойчив к переборке и обеспечивает меру неопределенности с предсказаниями. 
Эмпирическое исследование поддельных изображений показало, что текстура является важным признаком, по которому поддельные изображения отличаются от настоящих. Наша улучшенная модель, учитывающая глобальную статистику текстуры, показывает лучшую эффективность обнаружения поддельных изображений с помощью кросс-ГАН.
В статье предлагается способ улучшить производительность модели для обнаружения поддельных лиц на изображениях, генерируемых GAN, чтобы сделать ее более обобщенной на основе информации о текстуре.
Расстояние Вассерштейна трудно минимизировать с помощью стохастического градиентного спуска, в то время как расстояние Крамера можно легко оптимизировать, и оно работает так же хорошо.
В рукописи предлагается использовать расстояние Крамера в качестве потери при оптимизации объективной функции с помощью стохастического градиентного спуска, поскольку оно имеет несмещенные выборочные градиенты.
Вклад статьи связан с критериями эффективности, в частности с метрикой Вассерштейна/Мэллоуза
Мы изучаем стрелу времени для MDP и используем ее для измерения достижимости, обнаружения побочных эффектов и получения сигнала вознаграждения за любопытство. 
В данной работе предлагается h-потенциал в качестве решения задачи, которая измеряет асимметрию переходов между состояниями в MDP.
Мы сформулировали SGD как задачу байесовской фильтрации и показали, что это позволяет получить RMSprop, Adam, AdamW, NAG и другие характеристики современных адаптивных методов.
В статье анализируется стохастический градиентный спуск через байесовскую фильтрацию в качестве основы для анализа адаптивных методов.
Авторы пытаются объединить существующие адаптивные градиентные методы в рамках байесовской фильтрации с динамическим приоритетом.
Мы внедряем идею состязательного обучения в автоматическое дополнение данных для улучшения обобщения сети targe.
Техника под названием Adversarial AutoAugment, которая динамически обучается хорошим политикам дополнения данных во время обучения, используя состязательный подход.
В исследовании представлены два подхода для улучшения обобщения мета-обучения первого порядка и дана эмпирическая оценка на классификации изображений с несколькими снимками.
В статье представлено эмпирическое исследование алгоритма метаобучения первого порядка Reptile, исследуется предложенная техника регуляризации и более глубокие сети.
В данной статье предлагается использовать матричную факторизацию во время обучения для нейронного машинного перевода, что позволяет уменьшить размер модели и сократить время обучения без ущерба для производительности.
В данной статье предлагается сжимать модели с помощью матричной факторизации во время обучения глубоких нейронных сетей машинного перевода.
Различные методы анализа BERT позволяют сделать разные (но совместимые) выводы на примере исследования NPI.
В этой работе мы представляем V1Net - новую рекуррентную нейронную сеть, моделирующую горизонтальные связи в коре головного мозга, которые приводят к созданию надежных визуальных представлений посредством перцептивной группировки.
Авторы предлагают модифицировать конволюционный вариант LSTM для включения горизонтальных связей, вдохновленных известными взаимодействиями в зрительной коре.
Мы предлагаем связь между эквивариантностью перестановок и композиционным обобщением, а также предоставляем эквивариантные языковые модели
Данная работа посвящена обучению локально эквивариантных представлений и функций над входными/выходными словами для целей задачи SCAN.
В статье предлагается алгоритм для повышения гибкости вариационного апостериорного в байесовских нейронных сетях путем итеративной оптимизации.
Метод обучения гибких вариационных апостериорных распределений, применяемый к байесовским нейронным сетям для выполнения вариационного вывода (ВИ) по весам.
Новая современная система восстановления изображений
В статье предлагается архитектура конволюционной нейронной сети, включающая блоки для локальных и нелокальных механизмов внимания, которые, как утверждается, отвечают за достижение отличных результатов в четырех приложениях по восстановлению изображений.
В данной работе предлагается остаточная нелокальная сеть внимания для восстановления изображений
Гибридный подход к приобретению модели, который компенсирует недостаток доступных данных знаниями о конкретной области, предоставляемыми экспертами
Подход к приобретению домена, который рассматривает использование другого представления для частичной модели домена, используя схематические мьютексные отношения вместо условий "до/после".
Мы публикуем набор данных, созданный на основе данных однопроводной ЭКГ 11 000 пациентов, которым было назначено использование устройства {DEVICENAME}(TM).
В данной статье описывается крупномасштабный набор данных ЭКГ, который авторы собираются опубликовать, а также обеспечивается анализ и визуализация этого набора данных без наблюдения.
Новый метод Context-Gated Convolution, который включает глобальную контекстную информацию в CNNs путем явной модуляции ядер свертки, и таким образом захватывает более представительные локальные паттерны и извлекает дискриминационные признаки.
В данной работе используется глобальный контекст для модуляции весов конволюционных слоев и помогает CNN улавливать более дискриминационные признаки с высокой производительностью и меньшим количеством параметров, чем модуляция карты признаков.
Мы анализируем компромисс между шумом квантования и искажением клиппирования в сетях низкой точности и показываем заметные улучшения по сравнению со стандартными схемами квантования, которые обычно позволяют избежать клиппирования.
Выводит формулу для нахождения минимального и максимального значений обрезания для равномерного квантования, которые минимизируют квадратичную ошибку, возникающую в результате квантования, для распределения Лапласа или Гаусса над предварительно квантованным значением.
Мы предлагаем новый метод нормализации для обработки случаев с малым размером партии.
Метод решения проблемы малого размера партии в BN, который применяет операцию скользящего среднего без излишних накладных расходов и уменьшает количество статистик BN для лучшей стабильности.
Доказательство разделения глубин ReLU MLP с помощью гемотерических аргументов
Доказательство того, что для семейства задач более глубоким сетям требуется меньше единиц, чем более мелким. 
Новый алгоритм обучения на основе GAN с несколькими выстрелами путем синтеза разнообразных и дискриминационных признаков
Метод мета-обучения, который обучает генеративной модели, способной дополнить набор поддержки обучающегося с несколькими выстрелами, который оптимизирует комбинацию потерь.
Мы демонстрируем, как структура наборов данных влияет на нейронные сети, и представляем генеративную модель для синтетических наборов данных, которая воспроизводит это влияние.
В статье исследуется, как различные настройки структуры данных влияют на обучение нейронных сетей и как имитировать поведение на реальных наборах данных при обучении на синтетических.
Мы обучаем глубокие нейронные сети на основе диагональных и циркулярных матриц и показываем, что сети этого типа компактны и точны в реальных приложениях.
Авторы проводят теоретический анализ выразительных возможностей диагонально-циркуляционных нейронных сетей (DCNN) и предлагают схему инициализации для глубоких DCNN.
Мы предлагаем использовать дистилляцию моделей для обучения глобальным аддитивным объяснениям в виде форм признаков (которые более выразительны, чем атрибуции признаков) для таких моделей, как нейронные сети, обученные на табличных данных.
В данной работе используются обобщенные аддитивные модели (GAM) с дистилляцией моделей для обеспечения глобального объяснения нейронных сетей.
Крупномасштабная система многозадачного обучения с различными целями обучения для изучения представлений предложений фиксированной длины
Данная статья посвящена изучению вкраплений предложений путем объединения нескольких обучающих сигналов: пропуск мыслей, предсказание перевода, классификация отношений энтитета и предсказание составного разбора.
Мы предлагаем нейронный аннотатор предвзятости для проверки моделей на их устойчивость к предвзятым текстовым массивам данных.
Метод создания предвзятых наборов данных для NLP, основанный на условном автоэнкодере с негативной регуляризацией (CARA).
Мы предлагаем супервизию тематических моделей в стиле VAE путем разумной корректировки приоритета на основе каждого документа. Мы обнаружили, что логит-нормальный апостериор обеспечивает наилучшую производительность.
Гибкий метод слабого супервизора тематической модели для достижения лучшего соответствия интуиции пользователя.
Первый комплексный анализ информационной плоскости крупномасштабных глубоких нейронных сетей с использованием энтропии на основе матрицы и тензорных ядер.
Авторы предлагают тензорно-ядерный оценщик для оценки взаимной информации между высокоразмерными слоями в нейронной сети.
Мы предлагаем модульную структуру, которая может выполнять задачи, заданные программами, и достигать обобщения на более сложные задачи.
В данной работе исследуется обучение агентов RL с инструкциями и декомпозициями задач, формализованными в виде программ, предлагается модель для агента, управляемого программой, который интерпретирует программу и предлагает подцели модулю действий.
Мы доказываем, что случайно инициализированный (стохастический) градиентный спуск обучает конволюционный фильтр за полиномиальное время.
Изучает проблему обучения одного конволюционного фильтра с помощью SGD и показывает, что при определенных условиях SGD обучает один конволюционный фильтр.
В данной работе предположение о гауссовском распределении расширяется до более общего предположения об угловой гладкости, которое охватывает более широкое семейство входных распределений
Первый метод дополнения данных, специально разработанный для улучшения общей устойчивости DNN без каких-либо гипотез об атакующих алгоритмах.
Предлагается метод обучения с дополнением данных для повышения устойчивости модели к неблагоприятным возмущениям путем дополнения равномерно случайных выборок из сферы с фиксированным радиусом, сосредоточенной на обучающих данных. 
Использование Wasserstein-GANs для генерации реалистичной нейронной активности и обнаружения наиболее значимых особенностей, присутствующих в паттернах нейронной популяции.
Метод моделирования спайк-трейнов от популяций нейронов, соответствующих эмпирическим данным, с использованием полуконволюционной GAN.
В статье предлагается использовать GAN для синтеза реалистичных моделей нейронной активности
Градиентные оценки с двойным перепараметрированием обеспечивают несмещенное уменьшение дисперсии, что приводит к улучшению производительности.
Автор экспериментально обнаружил, что оценщик существующей работы (STL) является смещенным и предлагает уменьшить смещение для улучшения градиентного оценщика ELBO.
Безградиентный спуск - это доказательно эффективный алгоритм без градиента, монотонно-инвариантный и быстрый для высокоразмерной оптимизации нулевого порядка.
В данной статье предлагаются устойчивые алгоритмы безградиентного спуска (GLD), которые не полагаются на оценку градиента.
Мы предлагаем новый класс визуальных генеративных моделей: предикторы, обусловленные целью. Мы экспериментально показываем, что обусловленность целью позволяет уменьшить неопределенность и производить предсказания на гораздо более длинные горизонты.
В данной работе проблема предсказания видео переформулируется в интерполяцию вместо экстраполяции, обуславливая предсказание начальным и конечным (целевым) кадром, что приводит к более качественному предсказанию.
Мы предлагаем глубокую систему Multi Instance Learning на основе рекуррентных нейронных сетей, которая использует функции объединения и механизмы внимания для задач аннотирования понятий.
В статье рассматривается классификация медицинских временных рядов данных и предлагается моделировать временные отношения между экземплярами в каждом ряду с помощью архитектуры рекуррентной нейронной сети. 
Предлагается новая формула обучения множественных инстанций (MIL) под названием Relation MIL (RMIL), обсуждается ряд ее вариантов с LSTM, Bi-LSTM, S2S и т.д., исследуется интеграция RMIL с различными механизмами внимания и демонстрируется ее использование для предсказания медицинских концепций по данным временных рядов. 
Слои встраивания факторизуются с помощью разложения Tensor Train для уменьшения занимаемой ими памяти.
В данной статье предлагается модель тензорного разложения с низким рангом для параметризации матрицы встраивания при обработке естественного языка (NLP), которая сжимает сеть и иногда повышает точность тестирования.
Регуляризация разложения веса в адаптивных градиентных методах, таких как Адам
Предлагается идея отвязки убывания веса от количества шагов, выполняемых процессом оптимизации.
В статье представлен альтернативный способ реализации снижения веса в Адаме с использованием эмпирических результатов.
Исследует проблемы снижения веса, возникающие в вариантах SGD, и предлагает метод развязки между снижением веса и обновлением на основе градиента.
Пожизненное обучение распределению с помощью архитектуры "ученик-учитель" в сочетании с кросс-модельным регуляризатором апостериорных данных.
Глубокие автоэнкодеры для обучения хорошему представлению для геометрических 3D данных облака точек; генеративные модели для облаков точек.
Подходы к обучению генеративных моделей типа GAN с использованием архитектуры PointNet и латентно-пространственной GAN.
Мы предлагаем новый метод подавления уязвимости латентного пространства признаков для достижения надежных и компактных сетей.
В данной работе предлагается метод "состязательной нейронной обрезки", заключающийся в обучении маски обрезки и новой потери подавления уязвимостей для повышения точности и устойчивости к состязаниям.
Мы предложили две модификации VAE, учитывающие негативные примеры данных, и использовали их для полунаблюдаемого обнаружения аномалий.
В статье предлагаются два метода VAE-подобных подходов для полунаблюдаемого обнаружения новизны - MML-VAE и DP-VAE.
Новое понимание динамики обучения и метрики трудности запоминания приводят к эффективному и доказуемому обучению учебной программы.
В данной работе DIH формулируется как проблема обучения учебной программы, которая позволяет более эффективно использовать данные для обучения ДНК, и выводится теория о границе аппроксимации.
История параллельного развития законов обновления и концепций между адаптивным управлением и оптимизацией в машинном обучении.
Рекуррентная свертка для сжатия модели и трюк для ее обучения, то есть обучение независимых слоев BN по шагам.
Автор модифицирует рекуррентную сверточную нейронную сеть (RCNN) с независимой пакетной нормализацией, причем экспериментальные результаты по RCNN совместимы с архитектурой нейронной сети ResNet, когда она содержит одинаковое количество слоев.
Динамические рецептивные поля с пространственной гауссовой структурой являются точными и эффективными.
В данной работе предлагается структурированный оператор свертки для моделирования деформаций локальных областей изображения, что позволило значительно сократить количество параметров.
Трюк с неблагоприятными выборками, чтобы неправильно классифицированные метки были незаметны в пространстве меток для человеческих наблюдателей
Метод построения состязательных атак, менее обнаруживаемых человеком, без затрат в пространстве изображений путем изменения целевого класса, чтобы он был похож на исходный класс изображения.
В данной статье представлена классификация по типу/положению шума различных ударных шумов, возникающих в здании, что является серьезной конфликтной проблемой в многоквартирных комплексах
В данной работе описывается использование сверточных нейронных сетей в новой прикладной области классификации типа и положения шума в здании. 
Рекуррентные нейронные сети учатся увеличивать и уменьшать размерность своего внутреннего представления таким образом, чтобы соответствовать задаче, в зависимости от динамики исходной сети.
Вместо строгого выравнивания распределений в традиционных задачах адаптации глубоких доменов, которое не работает при смещении распределения целевых меток, мы предлагаем оптимизировать расслабленную задачу с помощью нового анализа, новых алгоритмов и экспериментальной проверки.
В данной статье предлагаются расслабленные метрики для адаптации домена, которые дают новые теоретические границы для целевой ошибки.
мы исследуем задачу генерации резюме к статье и предлагаем иерархическую схему генерации вместе с совместной сквозной системой обучения с усилением для обучения иерархической модели.
Для решения проблемы вырождения при генерации резюме к статье в данной работе предлагается иерархический подход к генерации, который сначала генерирует промежуточный набросок статьи, а затем полную статью.
Мы предлагаем контрфактическую регуляризацию для защиты от неблагоприятных доменных сдвигов, возникающих из-за изменений в распределении латентных "стилевых особенностей" изображений.
В статье рассматриваются способы защиты от неблагоприятных изменений в домене с помощью контрфактической регуляризации путем обучения классификатора, инвариантного к поверхностным изменениям (или "стилевым" особенностям) в образах.
Данная работа направлена на надежную классификацию изображений против неблагоприятных сдвигов в домене, и цель достигается путем отказа от использования изменяющихся стилевых признаков.
Мы предлагаем мета-обучалку для быстрой адаптации к нескольким задачам даже на одном шаге в режиме нескольких кадров.
В данной работе предлагается метод метаобучения модуля градиентной коррекции, в котором предусловие параметризуется нейронной сетью и встраивается в двухэтапный процесс обновления градиента во время адаптации. 
Модели ответов на вопросы, которые моделируют совместное распределение вопросов и ответов, могут обучаться лучше, чем дискриминационные модели
В данной работе предлагается генеративный подход к текстовым и визуальным QA, при котором изучается совместное распределение по пространству вопросов и ответов с учетом контекста, что позволяет уловить более сложные взаимосвязи.
В данной статье представлена генеративная модель для ответов на вопросы и предлагается моделировать p(q,a|c), факторизованную как p(a|c) * p(q|a,c). 
Авторы предлагают генеративную модель QA, которая совместно оптимизирует распределение вопросов и ответов, заданных документом/контекстом. 
Предложена новая функция активации под названием Displaced Rectifier Linear Unit. Показано, что она повышает эффективность обучения и вывода данных пакетных нормализованных сверточных нейронных сетей.
В статье приводится сравнение и предложение против использования пакетной нормализации после использования линейных блоков выпрямителя
В данной статье предлагается функция активации, названная смещенной ReLU, для улучшения производительности CNN, использующих пакетную нормализацию.
Мы строим масштабно-эквивариантные конволюционные нейронные сети в наиболее общей форме, обладающие как вычислительной эффективностью, так и доказанной устойчивостью к деформациям.
Авторы предлагают архитектуру CNN, которая теоретически эквивариантна к изотропным масштабированиям и переводам путем добавления дополнительного масштабного измерения к тензорам активации.
Мы диагностируем глубокие нейронные сети для обработки 3D облаков точек, чтобы исследовать полезность различных архитектур сетей. 
В статье исследуются различные архитектуры нейронных сетей для обработки 3D облаков точек и предлагаются метрики для устойчивости к неблагоприятным факторам, устойчивости к вращению и согласованности с соседями.
Использование структуры распределений улучшает полупростые вариационные выводы
Самоимитационное обучение разнообразным траекториям с политикой, обусловленной траекторией
В данной работе рассматриваются трудные задачи разведки путем применения самостимуляции к разнообразному выбору траекторий из прошлого опыта для более эффективной разведки в задачах с разреженным вознаграждением и достижения результатов SOTA.
Метод обучения нейронных сетей большой емкости со значительно улучшенной точностью и меньшими динамическими вычислительными затратами
Метод обучения сети с большой емкостью, только часть которой используется во время вывода в зависимости от входных данных, с использованием мелкозернистого условного отбора и нового метода регуляризации, "пакетного формирования".
Мы представляем сквозную дифференцируемую архитектуру, которая учится сопоставлять пиксели с предикатами, и оцениваем ее на наборе простых задач реляционного рассуждения.
Сетевая архитектура на основе многоголового модуля самовнимания для обучения новой форме реляционных представлений, которая улучшает эффективность данных и способность к обобщению при обучении по учебным программам.
Мы используем нейронные сети для проецирования поверхностной информации для выводов на естественном языке, определяя и идентифицируя поверхностную информацию с точки зрения логики первого порядка.
В данной работе предпринята попытка уменьшить количество поверхностной информации в выводах на естественном языке, чтобы предотвратить перебор, и представлена графовая нейронная сеть для моделирования связи между предпосылками и гипотезами. 
Подход к обработке выводов на естественном языке с помощью логики первого порядка и наполнение моделей NLI логической информацией для повышения надежности выводов.
Алгоритм для обучения индивидуально справедливого классификатора с использованием состязательной устойчивости
В данной работе предлагается новое определение алгоритмической справедливости и алгоритм для доказательного нахождения модели ML, удовлетворяющей условию справедливости.
Разве посев и наращивание - это все, что нужно для классификации цифр в любом языке?
В данной работе представлены новые наборы данных для пяти языков и предложена новая структура (SAT) для создания наборов данных изображений шрифтов для универсальной классификации цифр.
Успех MAML основан на повторном использовании функций из метаинициализации, что также дает естественное упрощение алгоритма, с удалением внутреннего цикла для тела сети, а также другие идеи по голове и телу.
В статье показано, что повторное использование функций является доминирующим фактором успеха MAML, и предложены новые алгоритмы, которые тратят гораздо меньше вычислений, чем MAML.
Мы предлагаем алгоритм, не зависящий от метода, для принятия решения о том, когда проводить инкрементное обучение, а когда полное, и он обеспечивает значительное ускорение по сравнению с полным обучением и позволяет избежать катастрофической забывчивости.
В данной статье предлагается подход к принятию решения о том, когда следует проводить постепенное, а когда полное переобучение модели в условиях итеративного развития модели в задачах заполнения слотов.
Мы разработали теоретическую основу для определения того, какие задачи рассуждения нейронная сеть может хорошо усвоить.
В статье предлагается мера классов алгоритмического соответствия, которая измеряет, насколько "близки" нейронные сети к известным алгоритмам, доказывая связь между несколькими классами известных алгоритмов и архитектурами нейронных сетей.
Мы исследуем взаимодействие клеток с клетками в контексте опухолевой среды, наблюдаемое на изображениях с высоким мультиплексированием, путем синтеза изображений с использованием новой архитектуры GAN, основанной на внимании.
Новый метод моделирования данных, полученных с помощью мультиплексной ионно-лучевой визуализации с временным прохождением света (MIBI-TOF), путем изучения сопоставления "многие-ко-многим" между типами клеток и уровнями экспрессии белковых маркеров.
Двухэтапный подход, состоящий из отбора предложений с последующим отбором диапазонов, может быть более устойчив к атакам противника по сравнению с одноэтапной моделью, обученной на полном контексте.
В данной работе исследуется существующая модель и обнаруживается, что двухэтапный обученный метод QA не является более устойчивым к атакам противника по сравнению с другими методами.
Верификация модели водителя-человека на основе когнитивной архитектуры и синтез на ее основе корректной по конструкции системы ADAS.
Новый гибридный подход глубокого обучения обеспечивает наилучшее решение проблемы ограниченных данных (что важно для сохранения гавайского языка).
Мы количественно изучили обнаружение нераспределенности в условиях нескольких снимков, установили базовые результаты с помощью ProtoNet, MAML, ABML и улучшили их.
В статье предлагаются две новые доверительные оценки, которые больше подходят для обнаружения нераспределенности при классификации по нескольким снимкам, и показано, что подход на основе метрики расстояния улучшает производительность.
В данной работе представлена прогрессивная дистилляция знаний для обучения генеративных моделей, ориентированных на задачи распознавания.
В данной работе демонстрируется обучение по принципу "легкий-трудный" для обучения генеративной модели с целью улучшения классификации по нескольким снимкам.
Мы предлагаем новый метод повышения переносимости неблагоприятных примеров с помощью градиента с пониженным уровнем шума.
В данной работе постулируется, что возмущение состоит из специфического для модели и специфического для данных компонента, и что усиление последнего лучше всего подходит для атак противника.
Данная работа посвящена повышению переносимости состязательных примеров из одной модели в другую.
Мы представляем итеративный двухпроходный поток CP-декомпозиции для эффективного ускорения существующих сверточных нейронных сетей (CNN).
В статье предлагается новый рабочий процесс для ускорения и сжатия CNN, а также способ определения целевого ранга каждого слоя с учетом целевого общего ускорения. 
В данной работе рассматривается проблема обучения операции тензорного фильтра низкого ранга для фильтрующих слоев в глубоких нейронных сетях (ГНС). 
Верхние границы константы Липшица нейронных сетей на основе ЛП
Авторы исследуют проблему оценки константы Липшица глубокой нейронной сети с функцией активации ELO, формулируя ее как полиномиальную оптимизационную задачу.
Мы решаем проблему многодоменной классификации по нескольким снимкам путем построения нескольких моделей для коллективного представления этого сложного распределения задач и упрощения адаптации к конкретной задаче как проблемы выбора из этих предварительно обученных моделей.
В данной работе решается проблема классификации по нескольким снимкам в различных областях путем построения пула моделей встраивания, позволяющих улавливать инвариантные и специфические для данной области особенности без значительного увеличения числа параметров.
Нейронное удаление чернильных артефактов документов (подчеркиваний, пятен и т.д.) без использования аннотированных вручную обучающих данных
Мы предлагаем эффективную с точки зрения запросов атаку "черного ящика", которая использует байесовскую оптимизацию в сочетании с байесовским выбором модели для оптимизации возмущения противника и оптимальной степени уменьшения размерности пространства поиска. 
Авторы предлагают использовать байесовскую оптимизацию с суррогатом GP для генерации аверсивных изображений, используя аддитивную структуру и применяя байесовский выбор модели для определения оптимального сокращения размерности.
Мы предлагаем модель для обучения факторизованным мультимодальным представлениям, которые являются дискриминационными, генеративными и интерпретируемыми.
В данной работе представлена "Модель мультимодальной факторизации", которая факторизует представления в общие мультимодальные дискриминационные факторы и специфические для модальности генеративные факторы. 
Мы разработали иерархический, акторно-критический алгоритм для композиционной передачи путем совместного использования компонентов политики и продемонстрировали специализацию компонентов и связанные с этим прямые преимущества в многозадачных областях, а также его адаптацию для одиночных задач.
Сочетание различных методов обучения для получения структуры и обучения с асимметричными данными, используемое для обучения политики HRL.
Авторы представляют иерархическую структуру политики для использования как в однозадачном, так и в многозадачном обучении с подкреплением, и оценивают ее полезность в сложных робототехнических задачах.
Мы эмпирически подсчитываем количество линейных областей выпрямительных сетей и уточняем верхнюю и нижнюю границы.
В данной работе представлены улучшенные границы для подсчета количества линейных областей в сетях ReLU.
Мы анализируем свойства запоминания коннетом обучающего набора и предлагаем несколько примеров использования, когда мы можем извлечь некоторую информацию об обучающем наборе. 
Освещает свойства обобщения/памяти больших и глубоких ConvNet и пытается разработать процедуры, связанные с определением того, действительно ли входные данные для обученной ConvNet были использованы для обучения сети.
В принципе, GAN могут эффективно изучать распределения по выборке, если класс дискриминаторов компактен и обладает сильной отличительной способностью от конкретного класса генераторов.
Предлагает понятие ограниченной аппроксимируемости и обеспечивает ограничение сложности выборки, полиномиальное по размерности, что полезно при исследовании отсутствия разнообразия в GAN.
Анализируется, что интегральная метрика вероятности может быть хорошим приближением расстояния Вассерштейна при некоторых мягких предположениях.
На ранней стадии обучения глубоких нейронных сетей существует "точка безубыточности", которая определяет свойства всей траектории оптимизации.
В данной работе анализируется оптимизация глубоких нейронных сетей путем рассмотрения того, как гиперпараметры размера партии и размера шага изменяют траектории обучения.
Мы предлагаем HWGCN, чтобы смешивать соответствующую информацию о соседях в разных порядках для лучшего изучения представлений узлов.
Авторы предлагают вариант GCN, HWGCN, для рассмотрения свертки за пределами 1-шаговых соседей, что сравнимо с современными методами.
Мы вводим новую меру плоскостности в локальных минимумах поверхности потерь глубоких нейронных сетей, которая инвариантна относительно послойных перепараметризаций, и связываем плоскостность с робастностью и обобщением признаков.
Авторы предлагают понятие робастности признака, которое инвариантно по отношению к изменению веса, и обсуждают связь этого понятия с обобщением.
В данной работе определяется понятие робастности признака и объединяется с эпсилон-репрезентативностью функции для описания связи между плоскостью минимумов и обобщением в глубоких нейронных сетях.
Мы предлагаем спарсифицировать преактивации ворот и поток информации в LSTM, чтобы сделать их постоянными и повысить уровень разреженности нейронов.
В данной работе предложен метод спарсификации рекуррентных нейронных сетей путем исключения нейронов с нулевыми преактивациями для получения компактных сетей.
Мы представляем нейросетевой подход для помощи решателям дифференциальных уравнений.
Цель авторов - повысить точность численных решателей путем обучения нейронной сети на смоделированных эталонных данных, которая корректирует численный решатель.
метод конфедеративного обучения, который обучает модель на основе горизонтально и вертикально разделенных медицинских данных 
Метод машинного обучения "конфедерации", который обучается через разделы в медицинских данных, разделенных как по горизонтали, так и по вертикали.
В данной работе предлагается стохастическая квантованная активация, которая решает проблемы переподбора в FGSM adversarial training и быстро достигает устойчивости, сравнимой с многоэтапным обучением.
В статье предлагается модель для улучшения состязательного обучения путем введения случайных возмущений в активации одного из скрытых слоев
Мы изучили структуру шума в мозге и обнаружили, что он может способствовать обобщению, перемещая представления по вариациям стимулов в классе.
Мы представляем новую конструкцию, т.е. самособирающиеся с категорией-агностическими кластерами, для адаптации как к закрытому, так и к открытому набору доменов.
Новый подход к адаптации домена открытого набора, когда категории исходного домена содержатся в категориях целевого домена, чтобы отфильтровать категории-аутсайдеры и обеспечить адаптацию в рамках общих классов.
Мы показываем, как изучать спектральные разложения линейных операторов с помощью глубокого обучения, и используем его для обучения без надзора без генеративной модели.
Авторы предлагают использовать механизм глубокого обучения для решения задачи вычисления наибольших собственных векторов.
В данной работе представлена схема изучения собственных функций с помощью стохастического процесса и предлагается решить проблему вычисления собственных функций в крупномасштабном контексте путем их аппроксимации с помощью двухфазного процесса стохастической оптимизации.
Применение алгоритма Riemannian SGD (RSGD) для обучения Tensor-Train RNN для дальнейшего уменьшения параметров модели.
В статье предлагается использовать римановский стохастический градиентный алгоритм для обучения низкоранговых тензорных поездов в глубоких сетях.
Предлагается алгоритм оптимизации нейронных сетей, параметризованных разложением тензорного поезда, основанный на римановой оптимизации и адаптации ранга, и проектируется двунаправленная архитектура TT LSTM.
Мы предлагаем новый алгоритм, который обучает политикам, удовлетворяющим ограничениям, а также проводим теоретический анализ и эмпирическую демонстрацию в контексте обучения подкреплению с ограничениями.
В данной работе представлен алгоритм оптимизации политик с ограничениями, использующий двухэтапный процесс оптимизации, в котором политики, не удовлетворяющие ограничениям, могут быть спроецированы обратно в набор ограничений.
Мы предлагаем представление на основе градиента для характеристики информации, которую глубокие сети не усвоили.
Авторы представляют создание представлений на основе градиентов относительно весов для дополнения информации, отсутствующей в наборе данных для обучения глубоких сетей.
Мы представляем систему "Zero-Shot" для уменьшения артефактов медицинских изображений, которая использует возможности глубокого обучения, но без использования общих предварительно обученных сетей или каких-либо чистых эталонов изображений. 
Мы применяем концепцию информационного узкого места к атрибуции.
В статье предлагается новый метод на основе возмущений для вычисления карт атрибуции/салиентации для глубоких нейронных сетей, основанных на классификаторах изображений, путем введения искусственного шума в ранний слой сети.
Мы показываем, что РНС можно подрезать, чтобы вызвать разреженность блоков, что повышает скорость выполнения разреженных операций на существующем оборудовании.
Авторы предлагают подход блочной обрезки разреженности для сжатия РНС, используя групповую LASSO для повышения разреженности и обрезки, но с очень специализированным расписанием в отношении обрезки и веса обрезки.
Мы предлагаем усовершенствование сетей итерации значений с применением к планированию пути планетарного ровера.
В данной работе функция вознаграждения, основанная на траекториях экспертов, изучается с помощью модуля итерации значений, чтобы сделать шаг планирования дифференцируемым.
Новый слой внимания, сочетающий в себе самовнимание и подслои трансформерных сетей.
В данной работе предлагается модификация модели Transformer путем включения внимания к векторам "постоянной" памяти в слой самовнимания, что позволяет достичь производительности на уровне существующих моделей при использовании меньшего количества параметров.
Мы эффективно находим подмножество изображений, которые имеют более высокие, чем ожидалось, активации для некоторого подмножества узлов.  Эти изображения кажутся более аномальными, и их легче обнаружить, если рассматривать их как группу. 
В статье предложена схема обнаружения наличия аномальных входов, основанная на подходе "сканирования подмножества" для обнаружения аномальных активаций в сети глубокого обучения.
Стабильные рекуррентные модели могут быть аппроксимированы сетями с прямолинейным движением и эмпирически работают не хуже нестабильных моделей на эталонных задачах.
Изучение устойчивости РНС и исследование спектральной нормализации для последовательных предсказаний.
Исследовал роль распределения веса в нейронных сетях с помощью хэш-функций, обнаружил, что сбалансированная и детерминированная хэш-функция способствует повышению производительности сети.
Предложение ArbNets для более систематического изучения разделения веса путем определения функции разделения веса как хэш-функции.
 Мы представляем систему статистического реляционного обучения, которая заимствует идеи из логики Маркова, но обучается неявному представлению правил в виде нейронной сети.
В статье предлагается расширение логических сетей Маркова путем устранения их зависимости от предопределенных правил логики первого порядка для моделирования большего числа доменов в задачах завершения баз знаний.
Масштабируемый метод обучения экспрессивной предварительной оценки нейронных сетей для множества задач.
В статье представлен метод обучения вероятностной модели для Multitasks Transfer Learning путем введения латентной переменной для каждой задачи, чтобы отразить общность в экземплярах задач.
В работе предлагается вариационный подход к метаобучению, который использует латентные переменные, соответствующие специфическим для конкретной задачи наборам данных.
Цель - выучить предварительные оценки нейронных сетей для нескольких задач. 
МОДЕЛИ РАССОГЛАСОВАННОГО ПРОСТРАНСТВА СОСТОЯНИЙ
В статье представлена генеративная модель пространства состояний, использующая глобальную латентную переменную E для отражения информации, специфичной для окружающей среды.
Обучение по дивергенции Брегмана для обучения по нескольким выстрелам. 
Мы представляем структуру сети, которая может изменять свою структуру во время обучения, и показываем, что она может сходиться к различным архетипам ML сетей, таким как MLPs и LCNs. 
Дополнение данных, ориентированное на домен, обеспечивает надежный и стабильный метод обобщения домена
В данной работе предлагается подход к обобщению домена путем дополнения данных в зависимости от домена.
Авторы представляют метод CrossGrad, который обучает как задаче классификации меток, так и задаче классификации домена.
Мы исследуем альтернативные традиционным подходы к моделированию пиксельных изображений и предлагаем генеративную модель для векторных изображений.
В данной статье представлена архитектура нейронной сети для создания эскизных рисунков, вдохновленная вариационным автоэнкодером.
Мы приводим исследование, пытающееся увидеть, как недавняя адаптация скорости онлайн-обучения расширяет выводы, сделанные в Wilson et al. 2018 об адаптивных градиентных методах, наряду со сравнением и анализом чувствительности.
Сообщает о результатах тестирования нескольких методов, связанных с корректировкой размера шага, включая ванильную SGD, SGD с импульсом Несерова и ADAM, и сравнивает эти методы с гиперградиентом и без него. 
Мы исследовали поведение оценок Q-значений на больших выборках и предложили эффективную стратегию поиска, которая основывается на оценке относительных расхождений между оценками Q. 
В данной работе представлен чисто поисковый алгоритм для обучения с подкреплением, основанный на асимптотическом анализе Q-значений и их сходимости к центральному предельному распределению, превосходящий эталонные поисковые алгоритмы.
Мы обучаем сеть трансляции изображения в изображение, которая принимает на вход исходное изображение и выборку из предварительного распределения для создания выборки из целевого распределения.
В данной работе формализована проблема перевода без контроля и предложена расширенная система GAN, которая использует взаимную информацию для предотвращения вырожденного случая.
В данной статье формулируется проблема неконтролируемого перевода изображений "один ко многим" и решается она путем минимизации взаимной информации. 
Обучение извлечению различимых ключевых точек из прокси-задачи, отбраковка выбросов.
Данная статья посвящена самоконтролируемому обучению локальных признаков с использованием Neural Guided RANSAC в качестве дополнительного вспомогательного поставщика потерь для улучшения интерполяции дескрипторов.
Мы предлагаем формулировку внутренней мотивации, которая подходит для использования в качестве предубеждения при исследовании в многоагентных синергетических задачах с редким вознаграждением, побуждая агентов влиять на мир таким образом, который не был бы достигнут, если бы они действовали индивидуально.
Статья посвящена использованию внутренней мотивации для улучшения процесса исследования агентов обучения с подкреплением в задачах, для решения которых требуется участие нескольких агентов.
Алгоритм вероятностного вывода, управляемый нейронной сетью, для граф-структурированных моделей
В данной статье представлена нейронная сеть с механизмом вывода, которая назначает сообщения на ребра рекуррентным образом, демонстрируя конкурентоспособную производительность в задачах визуального рассуждения.
Мы показываем, как можно повысить производительность многозадачной сети путем настройки адаптивной многозадачной функции потерь, которая обучается путем прямого уравновешивания градиентов сети.
В данной работе предлагается схема динамического обновления весов, которая обновляет веса для потерь различных задач во время обучения, используя коэффициенты потерь различных задач.
ДНС для сегментации изображений могут реализовать решения проблемы внутренности, но только некоторые рекуррентные сети могут обучиться им при определенном типе наблюдения.
В этой статье представлена инсайдерская информация для изучения семантической сегментации в эпоху глубокого обучения, а полученные результаты могут помочь моделям лучше обобщать.
Учитывая предварительно обученную модель, мы исследовали градиенты параметров модели на выборку относительно специфической для задачи потери и построили линейную модель, которая объединяет градиенты параметров модели и активацию модели.
В данной работе предлагается использовать градиенты определенных слоев конволюционных сетей в качестве характеристик в линеаризованной модели для трансферного обучения и быстрой адаптации.
Мы обучаем нашу модель реконструкции лица с аверсивными потерями полунаблюдательным способом на гибридных партиях немаркированных и маркированных изображений лиц, чтобы использовать ценность большого количества немаркированных изображений лиц из неограниченных коллекций фотографий.
В данной работе предлагается полунаблюдаемый и состязательный процесс обучения для точного нелинейного рассогласованного представления изображения лица с функциями потерь, что позволяет достичь передовых результатов в реконструкции лица.
В данной статье представлен ConceptFlow, который явно моделирует поток разговоров в графе знаний для более эффективной генерации разговоров.
В статье предлагается система генерации однооборотных ответов на размещенное высказывание в диалоге с открытым доменом, использующая диффузию в соседи обоснованных понятий.
Мы рассматриваем гипотезу о том, что энтропия пространства решений для ограничений на синаптические веса ("гибкость" ограничений) может служить в качестве функции стоимости для развития нейронных цепей.
Бесконечные ансамбли бесконечно широких нейронных сетей представляют собой интересное семейство моделей с точки зрения теории информации.
Мы проводим сравнительное исследование методов кросс-языкового выравнивания и совместного обучения и объединяем эти две ранее эксклюзивные парадигмы в новой структуре. 
В данной статье сравниваются подходы к индукции двуязычного лексикона и показывается, какой метод лучше справляется с задачами лексики, индукции, а также NER и MT.
Комбинирование ортогональных методов сжатия модели позволяет значительно уменьшить размер модели и количество флопов, требуемых при выводе.
В данной работе предлагается объединить разложение Такера с обрезкой фильтра.
Представляет JAUNE: методологию замены BLEU и ROUGE на многомерные, основанные на моделях оценщики для оценки резюме
В данной статье предлагается новая метрика JAUNE для оценки систем машинного перевода и резюмирования текстов, показывающая, что их модель лучше соответствует меткам сходства, чем BLEU.
новый формализм GNN + обширные эксперименты; показано, что различия между GGNN/GCN/GAT меньше, чем считалось ранее
В статье предлагается новая архитектура графовой нейронной сети, которая использует линейную модуляцию с учетом особенностей (Feature-wise Linear Modulation), чтобы обусловить передачу сообщений от источника к целевому узлу на основе представления целевого узла.
В данной работе предлагается новая схема разложения матрицы для одновременного встраивания и кластеризации приписанных сетевых данных.
В данной статье предлагается алгоритм для совместного выполнения встраивания сети атрибутов и кластеризации.
Мы предлагаем обучаемую технику рендеринга, ориентированную на изображение, которая объединяет преимущества рендеринга на основе изображения и синтеза изображения на основе GAN, учитывая при этом эффекты, зависящие от вида.
В данной работе предлагается метод обработки эффектов, зависящих от вида, в нейронном рендеринге, который повышает устойчивость существующих методов нейронного рендеринга.
GAN оцениваются на синтетических наборах данных
Мы предлагаем эффективный и действенный метод адаптации размера шага для градиентных методов.
Новая адаптация размера шага в градиентных методах первого порядка, которая ставит новую задачу оптимизации с разложением функции потерь первого порядка и регуляризацией, где размер шага рассматривается как переменная.
Мы показали, что широкий класс многообразий может быть сгенерирован сетями ReLU и сигмоидными сетями с произвольной точностью.
Данная работа дает определенные базовые гарантии того, когда многообразия могут быть записаны как образ карты, аппроксимируемой нейронной сетью, и сшивает вместе теоремы из геометрии многообразий и стандартные универсальные результаты аппроксимации.
В данной работе теоретически показано, что генеративные модели на основе нейронных сетей могут аппроксимировать многообразия данных, и доказано, что при умеренных предположениях нейронные сети могут отображать латентное пространство на множество, близкое к заданному многообразию данных в пределах небольшого хаусдорфова расстояния.
Мы разработали алгоритмы обучения с подкреплением на основе модели с теоретическими гарантиями и достигли передовых результатов на эталонных задачах Mujuco, когда разрешено использовать один миллион или меньше образцов.
В статье предложена структура для разработки модельных алгоритмов RL на основе OFU, которые достигают производительности SOTA в задачах MuJoCo.
Мы представляем дополнительные методы использования дистилляции знаний для сжатия U-сети более чем в 1000 раз.
Авторы представили модифицированную стратегию дистилляции для сжатия архитектуры U-сети более чем в 1000 раз при сохранении точности, близкой к исходной U-сети.
В данной работе предлагается подход к решению проблемы катастрофической забывчивости с помощью безгессианных оценок кривизны
В статье предлагается приближенный метод Лапласа для обучения нейронных сетей в условиях непрерывного обучения с низкой пространственной сложностью.
Метод улучшения работы простых моделей с учетом (точной) сложной модели.
В статье предлагается способ улучшения прогнозов модели с низкой пропускной способностью, который демонстрирует преимущества по сравнению с существующими подходами.
Простой и практичный алгоритм обучения инвариантного по переводу или сферически симметричного ядра на основе обучающих данных с использованием инструментов анализа Фурье и минимизации сожалений.
В статье предлагается выучить инвариантное к переводу или повороту ядро в представлении Фурье, чтобы максимизировать маржу SVM.
Авторы предлагают интересный алгоритм для совместного обучения l1-SVM и представленного ядра Фурье
Авторы рассматривают возможность обучения непосредственно Фурье-представлений инвариантных кернелов сдвига/перемещения для приложений машинного обучения с выравниванием кернела по данным в качестве объективной функции для оптимизации.
Вероятностное программирование с естественной поддержкой каузальных и контрфактических выводов
Вывод модели игры со средним полем (MFG) поведения большой популяции с помощью синтеза MFG и марковских процессов принятия решений.
Авторы решают проблему вывода в моделях коллективного поведения, используя обратное обучение с подкреплением для изучения функций вознаграждения агентов в модели.
Мы сочетаем глубокие генеративные модели с программным слабым контролем для создания скоординированных траекторий движения мультиагентов, качество которых значительно выше, чем у предыдущих базовых моделей.
Предлагает многоагентные последовательные генеративные модели.
В статье предлагается обучение генеративных моделей, которые создают траектории движения мультиагентов, используя эвристические функции, которые маркируют переменные, которые в противном случае были бы скрыты в обучающих данных.
Научиться ранжировать кривые обучения, чтобы на ранней стадии прекратить бесперспективные задания на обучение. Новизна: использование парных потерь при ранжировании для прямого моделирования вероятности улучшения и переноса обучения между наборами данных с целью сокращения требуемых данных для обучения.
В статье предлагается метод ранжирования кривых обучения нейронных сетей, который позволяет моделировать кривые обучения на различных наборах данных, достигая более высокого ускорения при решении задач классификации изображений.
Мы показываем, что в условиях непрерывного обучения катастрофического забывания можно избежать, применяя внеполитическую RL к смеси нового и повторного опыта, с поведенческим клонированием потерь.
Предлагает особый вариант воспроизведения опыта с клонированием поведения как метод непрерывного обучения.
Мы представляем метод, который учит интегрировать временную информацию и неоднозначную визуальную информацию в контексте взаимодействующих агентов.
Авторы предлагают Graph VRNN, который моделирует взаимодействие нескольких агентов путем развертывания VRNN для каждого агента.
В данной работе представлена архитектура на основе графовой нейронной сети, которая обучена определять местоположение и моделировать взаимодействие агентов в среде непосредственно по пикселям, и показано преимущество модели для отслеживания задач и прогнозирования местоположения агентов.
Мы рассматриваем упрощенную модель глубокой конволюционной нейронной сети. Мы показываем, что все слои этой сети могут быть приблизительно выучены при правильном применении тензорного разложения.
Предоставляет теоретические гарантии для обучения глубоких сверточных нейронных сетей с использованием рангового тензорного разложения.
В данной работе предлагается метод обучения для ограниченного случая глубоких конволюционных сетей, где слои ограничены случаем непересечения и имеют только один выходной канал на слой
Анализирует проблему обучения очень специального класса CNN: каждый слой состоит из одного фильтра, применяемого к непересекающимся участкам входного сигнала.
Фидфорвардные нейронные сети, у которых веса могут быть обрезаны после обучения, могли бы иметь те же веса, обрезанные до обучения
Показывает, что существуют разреженные подсети, которые могут быть обучены с нуля с хорошими показателями обобщения, и предлагает нерасщепленные, случайно инициализированные NNs содержат подсети, которые могут быть обучены с нуля с аналогичной точностью обобщения.
В статье рассматривается гипотеза о том, что нейронные сети со случайной инициализацией содержат подсети, которые сходятся одинаково быстро или быстрее и могут достигать такой же или лучшей точности классификации.
В этой статье мы подчеркиваем сложность обучения разреженных нейронных сетей, проводя эксперименты по интерполяции в энергетическом ландшафте. 
Весопространственная симметрия в ландшафтах нейронных сетей порождает множество седловин и плоских высокоразмерных подпространств.
В статье представлен метод исследования функции потерь относительно параметров в нейронной сети с точки зрения симметрии весового пространства.
Теория распространения сигналов применяется к непрерывным суррогатам бинарных сетей; интуитивно понятная инициализация; трюк с перепараметризацией не помогает
Авторы исследуют динамику обучения бинарных нейронных сетей при использовании непрерывных суррогатов, изучают, какими свойствами должны обладать сети при инициализации для наилучшего обучения, и дают конкретные рекомендации по стохастическим весам при инициализации.
Углубленное исследование стохастических бинарных сетей, непрерывных суррогатов и динамики их обучения, с пониманием того, как инициализировать веса для достижения наилучшей производительности.
Мы предлагаем подход к полусамостоятельному обучению семантических синтаксических анализаторов зависимостей на основе CRF-автоэнкодера.
Данная статья посвящена полусупервизированному разбору семантических зависимостей с использованием CRF-автоэнкодера для обучения модели в полусупервизированном стиле, что свидетельствует об эффективности на задачах с небольшими ресурсами меченых данных.
DeFINE использует глубокую, иерархическую, разреженную сеть с новыми пропусками связей для эффективного обучения лучшим вкраплениям слов. 
В данной работе описывается новый метод эффективного обучения глубоким представлениям на уровне слов с помощью иерархической структуры с пропусками связей для использования входных и выходных слоев низкой размерности.
Мы успешно воспроизводим и приводим замечания по сравнению с базовыми версиями подхода мета-обучения для классификации по нескольким снимкам, который работает путем обратного распространения через решение замкнутой формы.
Динамическое перераспределение параметров обеспечивает успешное прямое обучение компактных разреженных сетей, и оно играет незаменимую роль даже тогда, когда мы знаем оптимальную разреженную сеть a-priori.
3 направления, служащие ступеньками для экспериментального обучения роботов модулю зрения
Исследует производительность существующих классификаторов изображений и детекторов объектов. 
Все акустические модели на основе CNNs, за исключением первых двух слоев, продемонстрировали некоторую степень языковой специфики, но обучение с замораживанием позволило успешно переносить их с одного языка на другой.
В статье измеряется переносимость признаков для каждого слоя в акустических моделях на основе CNN между языками, и делается вывод, что АМ, обученные с помощью метода "замороженного обучения", превосходят другие перенесенные модели.
Связь энтропийных градиентов политики области Вассерштейна-доверия и уравнения тепла.
В статье исследуются связи между обучением с подкреплением и теорией квадратичного оптимального транспорта
Авторы исследовали градиент политики со сменой политик, ограниченных доверительной областью с расстоянием Вассерштейна в условиях многорукого бандита, показав, что в пределе малых шагов динамика политики управляется уравнением тепла (уравнением Фоккера-Планка).
Дискриминационная способность softmax для обучения векторов признаков объектов эффективно усиливается благодаря изотропной нормализации на глобальном распределении точек данных.
Мы адаптируем Q-обучение с бонусом UCB-исследования к бесконечно-горизонтной MDP с дисконтированными вознаграждениями без доступа к генеративной модели и улучшаем ранее известный результат.
В данной работе рассматривается алгоритм Q-обучения с политикой разведки UCB для MDP с бесконечным горизонтом.
Возмущения могут быть использованы для обучения весов обратной связи в полносвязных и конволюционных нейронных сетях
В данной работе предлагается метод, который решает проблему "переноса веса" путем оценки весов для обратного прохода с использованием оценщика на основе шума. 
Мы выявили некоторые универсальные закономерности (т.е. сохраняющиеся в разных архитектурах) в поведении различных суррогатных потерь (CE, MSE, 0-1 потери) при обучении нейронных сетей и представили подтверждающие эмпирические доказательства.
