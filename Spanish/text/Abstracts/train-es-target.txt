Proporcionamos formas analíticas necesarias y suficientes para los puntos críticos de las funciones de pérdida cuadradas para varias redes neuronales, y explotamos las formas analíticas para caracterizar las propiedades del paisaje para las funciones de pérdida de estas redes neuronales.
Los algoritmos de aprendizaje biológicamente plausibles, en particular la simetría de signos, funcionan bien en ImageNet
Introducimos el Transformador 2-simplicial y mostramos que esta arquitectura es un sesgo inductivo útil para el razonamiento lógico en el contexto del aprendizaje profundo por refuerzo.
Previsiones precisas en horizontes temporales muy largos mediante RNNs con entrenamiento tensorial
Proponemos un algoritmo variacional de paso de mensajes para modelos que contienen tanto el modelo profundo como el modelo gráfico probabilístico.
Una sencilla modificación de la factorización de bajo rango que mejora el rendimiento (tanto en tareas de imagen como de lenguaje) sin dejar de ser compacta.
Proponemos un formato de datos simple, general y eficiente en términos de espacio para acelerar el entrenamiento del aprendizaje profundo permitiendo que la fidelidad de la muestra sea seleccionada dinámicamente en el momento del entrenamiento
APRENDIZAJE ROBUSTO DE LA REPRESENTACIÓN DISCRIMINATIVA MEDIANTE EL REESCALADO DEL GRADIENTE: UNA PERSPECTIVA DE REGULARIZACIÓN DEL ÉNFASIS
¿Los GANs tienen éxito debido al entrenamiento adversarial o al uso de ConvNets? Demostramos que un generador de ConvNet entrenado con una pérdida de reconstrucción simple y vectores de ruido aprendibles lleva muchas de las propiedades deseables de un GAN.
Equipar los GAN de MMD con un nuevo núcleo de bosque aleatorio.
Un método para estimar críticas más precisas en el aprendizaje por refuerzo.
Introducimos un marco sistemático para cuantificar la robustez de los clasificadores ante las perturbaciones naturales de las imágenes que se encuentran en los vídeos.
Aprendizaje profundo para el aprendizaje automático de datos tabulares estructurados utilizando un modelo CNN preentrenado a partir de ImageNet.
La decodificación de píxeles puede seguir funcionando para el aprendizaje de la representación en imágenes
AdaGrad/Adam de matriz completa, rápido y verdaderamente escalable, con teoría para la optimización estocástica adaptativa no convexa
En este trabajo, proponemos aprender un sistema de diálogo que parametriza de forma independiente diferentes habilidades de diálogo, y aprende a seleccionar y combinar cada una de ellas a través de la Atención sobre Parámetros (AoP). 
Proponemos destilar un gran conjunto de datos en un pequeño conjunto de datos sintéticos que puedan entrenar redes cercanas al rendimiento original. 
Proponemos un método de subgradiente primal-dual para el entrenamiento de GANs y este método alivia eficazmente el colapso del modo.
Descubrimos que la irracionalidad de un demostrador experto puede ayudar a un alumno a inferir sus preferencias. 
Comparamos la robustez de los modelos de 4 tareas populares de PNL: Q&A, NLI, NER y Análisis de Sentimientos probando su rendimiento en entradas perturbadas.
Se propone un novedoso algoritmo de aprendizaje curricular basado en clusters para resolver el entrenamiento robusto de modelos generativos.
Proponemos un novedoso ataque de puerta trasera distribuida contra el aprendizaje federado y demostramos que no sólo es más eficaz en comparación con los ataques centralizados estándar, sino que también es más difícil de defender por los métodos robustos existentes de FL
Red neuronal para el aprendizaje semisupervisado basado en grafos; revisa los clásicos y propaga *etiquetas* en lugar de representaciones de características
Arquitectura neuronal Búsqueda de una serie de tareas de comprensión del lenguaje natural. Diseñar el espacio de búsqueda para las tareas de NLU. Y Aplicar la búsqueda de arquitectura diferenciable para descubrir nuevos modelos.
En este trabajo presentamos EvalNE, una caja de herramientas de Python para automatizar la evaluación de los métodos de incrustación de redes en la predicción de enlaces y garantizar la reproducibilidad de los resultados.
Garantía de recuperación del descenso de gradiente estocástico con inicialización aleatoria para el aprendizaje de una red neuronal de dos capas con dos nodos ocultos, pesos de norma unitaria, funciones de activación ReLU y entradas gaussianas.
Jumpout aplica tres modificaciones sencillas pero efectivas al abandono, basadas en nuevos conocimientos sobre el rendimiento de generalización de las DNN con ReLU en regiones locales.
Estudiamos la aparición natural de la dispersión en las activaciones y gradientes de algunas capas de un modelo de lenguaje LSTM denso, a lo largo del entrenamiento.
Las redes de memoria convencionales generan muchos vectores latentes redundantes, lo que da lugar a un exceso de ajuste y a la necesidad de memorias más grandes. Introducimos el abandono de la memoria como una técnica automática que fomenta la diversidad en el espacio latente.
Derivamos el método de Nesterov surge como una discretización directa de una EDO diferente a la de Su-Boyd-Candes y probamos la aceleración el caso estocástico
Proponemos el aprendizaje por transferencia (L2TL) para mejorar el aprendizaje por transferencia en un conjunto de datos de destino mediante la extracción juiciosa de información de un conjunto de datos de origen.
En Deep RL, las funciones invariantes de orden pueden utilizarse junto con los módulos de memoria estándar para mejorar el decaimiento del gradiente y la resistencia al ruido.
Este trabajo introduce un algoritmo para manejar un problema de optimización con múltiples restricciones bajo la visión de un colector.
Un método para realizar el aprendizaje Q en espacios de acción continuos mediante la predicción de una secuencia de acciones 1-D discretizadas.
Nuestro método incorpora el WGAN para lograr la coincidencia de la medida de ocupación para el aprendizaje de la transición.
La normalización gaussiana realiza un ajuste por mínimos cuadrados durante la retropropagación, que centra en cero y descorrelaciona las derivadas parciales de las activaciones normalizadas.
Ofrecemos un análisis teórico de la capacidad de la normalización por lotes para ajustar automáticamente las tasas de aprendizaje, en el contexto de la búsqueda de puntos estacionarios para un objetivo de aprendizaje profundo.
Proponemos DVD-GAN, un modelo generativo de vídeo de gran tamaño que está a la vanguardia en varias tareas y produce vídeos muy complejos cuando se entrena con grandes conjuntos de datos del mundo real.
Proponemos una nueva arquitectura de memoria recurrente que puede seguir los cambios de estado de las entidades en sentido común simulando los efectos causales de las acciones.
Investigamos la eficiencia espacial de las redes neuronales con memoria aumentada cuando aprenden la pertenencia a un conjunto.
Construimos una aproximación de Laplace factorizada por Kronecker para redes neuronales que conduce a una distribución normal matricial eficiente sobre los pesos.
La regularización de los gráficos obliga a la incrustación espectral a centrarse en los clusters más grandes, lo que hace que la representación sea menos sensible al ruido. 
Demostramos que el sesgo de exposición podría ser mucho menos grave de lo que se supone actualmente para el entrenamiento MLE LM.
Un estudio controlado del papel de los entornos con respecto a las propiedades en los protocolos de comunicación emergentes.
Representación de documentos basada en cuadrículas con vectores de incrustación contextualizados para documentos con diseños 2D
Las políticas de RL profunda pueden ser atacadas por otros agentes que realicen acciones para crear observaciones naturales que sean adversas.
Presentamos un novedoso algoritmo iterativo basado en modelos generalizados de bajo rango para calcular e interpretar modelos de incrustación de palabras.
Aprendemos un flujo autorregresivo condicional para proponer perturbaciones que no induzcan al fracaso del simulador, mejorando el rendimiento de la inferencia.
Mejoramos la respuesta a las preguntas que requieren un razonamiento multi-salto extrayendo una cadena intermedia de frases.
Desarrollamos un nuevo método para la estimación de la constante de normalización (evidencia bayesiana) utilizando el Muestreo Puente Óptimo y un novedoso Flujo de Normalización, que se demuestra que supera a los métodos existentes en términos de precisión y tiempo computacional.
Comprobamos los modelos DNN para el olvido catastrófico utilizando un nuevo esquema de evaluación que refleja las condiciones típicas de aplicación, con resultados sorprendentes.
El Promedio Federado ya es un algoritmo de Meta Aprendizaje, mientras que los métodos entrenados en el centro de datos son significativamente más difíciles de personalizar.
Identificamos el downsampling como un mecanismo de memorización en los autocodificadores convolucionales.
Proponemos un algoritmo de aprendizaje de refuerzo inverso adversarial capaz de aprender funciones de recompensa que pueden transferirse a nuevos entornos no vistos.
La generalización está fuertemente correlacionada con la evidencia bayesiana, y el ruido de gradiente conduce al SGD hacia los mínimos cuya evidencia es grande.
redes adversariales, mecanismo de atención, imágenes de positrones, escasez de datos
 Inspirado en la investigación neurocientífica, resuelve tres puntos débiles clave del muy citado modelo de atención recurrente simplemente añadiendo dos términos en la función objetivo.
Este artículo presenta un algoritmo de aprendizaje activo basado en clustering sobre grafos.
Proponemos la InfoCNF, una CNF condicional eficiente que emplea redes de compuerta para aprender las tolerancias de error de los solucionadores de ODE  
Un método de aprendizaje no supervisado que utiliza el meta-aprendizaje para permitir el aprendizaje eficiente de las tareas de clasificación de imágenes posteriores, superando los métodos del estado de la técnica.
VAE condicional sobre espacios latentes de modelos generativos preentrenados que permite la transferencia entre dominios drásticamente diferentes preservando la localidad y la alineación semántica.
Un novedoso método de aprendizaje inductivo de transferencia que emplea el aprendizaje adversarial y el aprendizaje multitarea para abordar la discrepancia en el espacio de entrada y salida
Una nueva arquitectura de alto rendimiento para el reconocimiento de entidades con nombre y la extracción de relaciones de extremo a extremo que es rápida de entrenar.
 Esquema de Bayes variable para redes neuronales recurrentes
Estudio de caso sobre el modelo óptimo de aprendizaje profundo para vehículos aéreos no tripulados
Mostramos el primer uso exitoso de Transformer en la generación de música que exhibe una estructura a largo plazo. 
Proponemos un nuevo algoritmo Monte Carlo Tree Search / rollout que se basa en la búsqueda basada en la anchura para construir un lookahead.
Proponemos una nueva capa de red neuronal profunda para normalizar la covarianza dentro de la clase de una representación interna en una red neuronal que resulta en una mejora significativa de la generalización de las representaciones aprendidas.
La adición de un criterio de diversidad inspirado en DPP en el objetivo del GAN evita el colapso del modo y conduce a mejores generaciones. 
Sugerimos un límite de generalización que podría explicar en parte la mejora de la generalización con la sobreparametrización.
Introducimos tres bloques genéricos de procesamiento de nubes de puntos que mejoran tanto la precisión como el consumo de memoria de múltiples redes de última generación, permitiendo así diseñar redes más profundas y precisas.
Métodos para aprender incrustaciones de palabras acústicas contextuales a partir de un modelo de reconocimiento del habla de extremo a extremo que rinden de forma competitiva con las incrustaciones de palabras basadas en el texto.
Este trabajo propone un método de máscara que resuelve los resultados borrosos anteriores de la estimación de profundidad monocular no supervisada causada por la oclusión
Introducimos una forma novedosa de representar los grafos como estructuras de imagen multicanal que permite que sean manejados por CNNs 2D.
Proponemos una medida de la memoria a largo plazo y demostramos que las redes recurrentes profundas son mucho más adecuadas para modelar las dependencias temporales a largo plazo que las superficiales.
Comparamos las representaciones perceptivas, neuronales y modeladas de la comunicación animal utilizando el aprendizaje automático, el comportamiento y la fisiología. 
El principio del cuello de botella de la información aplicado a las ResNets, utilizando modelos PixelCNN++ para decodificar la información mutua y generar condicionalmente imágenes para la ilustración de la información
La adaptación de un agente de RL en un entorno objetivo con una dinámica desconocida es rápida y segura cuando transferimos la experiencia previa en una variedad de entornos y luego seleccionamos acciones con aversión al riesgo durante la adaptación.
Proponemos el Neuro-Symbolic Concept Learner (NS-CL), un modelo que aprende conceptos visuales, palabras y parsing semántico de frases sin supervisión explícita sobre ninguno de ellos.
Introducimos una Prioridad de Proceso Gaussiano sobre los pesos en una red neuronal y exploramos su capacidad para modelar pesos dependientes de la entrada con beneficios para varias tareas, incluyendo la estimación de la incertidumbre y la generalización en el entorno de baja muestra.
Realizamos una investigación en profundidad de la idoneidad de los modelos de autoatención para la traducción automática neural a nivel de caracteres.
presentamos el estado del arte del uso de redes neuronales para diagnosticar radiografías de tórax
Demostramos la utilidad de una reciente técnica de explicabilidad de la IA mediante la visualización de las características aprendidas de una CNN entrenada en la clasificación binaria de los movimientos del pez cebra.
Las restricciones de consistencia interna mejoran la capacidad de los agentes para desarrollar protocolos emergentes que se generalizan a través de los roles comunicativos.
Presentamos una nueva técnica de análisis que descubre la estructura compositiva interpretable en redes neuronales recurrentes notoriamente difíciles de interpretar.
Reproducimos las representaciones neuronales encontradas en los sistemas visuales biológicos simulando sus restricciones de recursos neuronales en un modelo convolucional profundo.
una teoría que relaciona el hessiano de la solución y el poder de generalización del modelo
Introducimos la maximización de la entropía en los GAN, lo que lleva a una reinterpretación del crítico como función de energía.
Presentamos un algoritmo de transferencia de estilo de audio musical de larga escala temporal que sintetiza el audio en el dominio del tiempo, pero utiliza representaciones de tiempo-frecuencia del audio.
Proponemos una tarea de referencia repetida y un enfoque de aprendizaje continuo regularizado para la comunicación adaptativa con humanos en dominios desconocidos
Ordenar en el codificador y deshacer la ordenación en el decodificador para evitar el problema de la responsabilidad en los autocodificadores establecidos
Presentamos un marco de aprendizaje jerárquico para la navegación en un entorno de aprendizaje encarnado
La atribución a veces puede ser engañosa
Transformador eficiente con hashing sensible a la localidad y capas reversibles
Demostramos que la comprensión del lenguaje a través de la lectura es una forma prometedora de aprender políticas que se generalizan a nuevos entornos.
Proponemos una hipótesis de por qué el descenso de gradiente se generaliza en base a cómo los gradientes por ejemplo interactúan entre sí.
Novedosa arquitectura para la síntesis de vistas estereoscópicas con desplazamientos arbitrarios de la cámara utilizando núcleos adaptativos en forma de T con dilataciones adaptativas.
Este trabajo propone la teoría fundamental y los algoritmos óptimos para el entrenamiento de las DNN, que reducen hasta el 80% de la memoria de entrenamiento para las DNN populares.
Este trabajo demuestra la aproximabilidad universal de las redes neuronales ReLU cuantificadas y presenta el límite de complejidad dado un error arbitrario.
Un marco general de aprendizaje por refuerzo basado en valores para el control continuo
El entrenamiento de redes adversariales generativas es un problema de aprendizaje continuo.
Un marco unificado para el aprendizaje de pocos disparos y el aprendizaje de cero disparos basado en la reparametrización de la red
GraphQA es un método basado en grafos para la evaluación de la calidad de las proteínas que mejora el estado del arte de los enfoques de ingeniería manual y de aprendizaje de la representación
Abordamos el aprendizaje activo en un entorno de lotes con oráculos ruidosos y utilizamos la incertidumbre del modelo para codificar la calidad de la decisión del algoritmo de aprendizaje activo durante la adquisición.
Transferencia de estilo estocástico con características ajustables. 
Proponemos AGILE, un marco de trabajo para entrenar a los agentes para que ejecuten instrucciones a partir de ejemplos de estados meta respectivos.
En Hierarchical RL, introducimos la noción de una opción "suave", es decir, adaptable, y mostramos que esto ayuda al aprendizaje en entornos multitarea.
Aprendizaje de un modelo generativo controlable realizando un aprendizaje de desentrañamiento de la representación latente.
Mejorar el modelo lingüístico para la tarea de aprendizaje supervisado 
generar dinámicamente filtros condicionados a la imagen de entrada para las CNN en cada pase de avance 
Proponemos una nueva red neuronal de cualquier tiempo que permite la evaluación parcial mediante subredes con diferentes anchuras y profundidades.
Proponemos un nuevo modelo para hacer predicciones de reacciones retrosintéticas generalizables y diversas.
Disentanglement-PyTorch es una biblioteca para el aprendizaje de representaciones variacionales
Ampliamos los conocimientos recientes relacionados con la consistencia de softmax para lograr resultados de vanguardia en el control continuo.
Adaptamos una familia de juegos combinatorios con dificultad sintonizable y una política óptima expresable como red lineal, desarrollándola como un entorno rico para el aprendizaje por refuerzo, mostrando contrastes en el rendimiento con el aprendizaje supervisado, y analizando el aprendizaje y la generalización multiagente. 
Un método complementario de aprendizaje profundo para detectar valores atípicos durante la predicción
Se utiliza una arquitectura totalmente conectada para producir incrustaciones de palabras a partir de representaciones de caracteres, superando las incrustaciones tradicionales y proporcionando una visión de la dispersión y el abandono.
Llevamos a cabo ataques adversarios contra redes neuronales binarizadas y demostramos que reducimos el impacto de los ataques más fuertes, manteniendo una precisión comparable en un entorno de caja negra
Una investigación empírica de la alineación basada en GAN de espacios de vectores de palabras, centrándose en los casos en los que las transformaciones lineales existen de forma demostrable, pero el entrenamiento es inestable.
Nuestro objetivo en este trabajo es proponer un nuevo enfoque para abordar el problema del aprendizaje de transferencia de proyectos de software etiquetados a no etiquetados en el contexto de la SVD, con el fin de resolver el problema de colapso de modo al que se enfrentan los enfoques anteriores.
Un método más rápido para generar incrustaciones de nodos que emplea un número de permutaciones sobre la vecindad inmediata de un nodo como contexto para generar su representación.
Mostramos cómo inicializar arquitecturas recurrentes con la solución de forma cerrada de un autoencoder lineal para secuencias. Mostramos las ventajas de este enfoque en comparación con las RNN ortogonales.
Proporcionamos una comprensión profunda de la NER de etiquetado de secuencias y proponemos utilizar dos tipos de estructuras cruzadas, que aportan mejoras teóricas y empíricas.
Presentamos un modelo generativo teóricamente probado de incrustación de grafos de conocimiento. 
Estudiamos empíricamente lo difícil que es recuperar las partes perdidas de los modelos entrenados
Este trabajo propone la adaptación de dominio variacional, un marco uniﬁcado, escalable y sencillo para el aprendizaje de múltiples distribuciones a través de la inferencia variacional
Proponemos una novedosa combinación de entrenamiento adversarial y defensas demostrables que produce un modelo con una precisión de vanguardia y una robustez certificada en CIFAR-10. 
Los programas tienen una estructura que puede representarse como grafos, y las redes neuronales de grafos pueden aprender a encontrar errores en dichos grafos
Introducimos y analizamos varios criterios para detectar el sobreajuste.
Desarrollamos un solucionador de iteración de valores basado en puntos para POMDPs con tareas de percepción y planificación activas.
Introducimos una red neuronal profunda, no convolutiva y simple que puede, sin entrenamiento, representar eficazmente imágenes naturales y resolver competitivamente tareas de procesamiento de imágenes como la compresión y la eliminación de ruido.
Este trabajo 1) caracteriza las funciones representables por las DNNs ReLU, 2) estudia formalmente el beneficio de la profundidad en dichas arquitecturas, 3) da un algoritmo para implementar la minimización del riesgo empírico hasta la optimización global para redes ReLU de dos capas.
Puntos de referencia para algoritmos de aprendizaje biológicamente plausibles en conjuntos de datos y arquitecturas complejas
Hemos propuesto utilizar el reciente regularizador GrOWL para la dispersión de parámetros y la vinculación simultánea en el aprendizaje de las DNN. 
Un análisis de las estructuras de aprendizaje y optimización de la búsqueda de arquitectura en las redes neuronales y más allá.
Realizamos una compresión sin pérdidas de grandes conjuntos de datos de imágenes utilizando un VAE, superando los algoritmos de compresión existentes.
Optimización bayesiana basada en la optimización de hiperparámetros en línea.
En este trabajo, proponemos la Red de Reformulación de Preguntas Latentes (LQR-net), una red atenta, multisalto y paralela, diseñada para tareas de respuesta a preguntas que requieren capacidades de razonamiento.
Explicación de los modelos de series temporales multivariantes mediante la búsqueda de observaciones importantes en el tiempo utilizando contrafactuales
Utilizamos la autosupervisión en ambos dominios para alinearlos para la adaptación de dominios sin supervisión.
El mínimo de un conjunto de hashes distribuidos exponencialmente tiene una probabilidad de colisión muy útil que generaliza el índice de Jaccard a las distribuciones de probabilidad.
Un modelo de red neuronal de grafos con parámetros generados a partir de lenguajes naturales, que puede realizar un razonamiento multi-salto. 
Presentamos Meta-Critic, un módulo de crítica auxiliar para los métodos de actor-crítica fuera de política que puede ser meta-aprendido en línea durante el aprendizaje de una sola tarea.
Obtenemos límites de generalización no vacíos en redes neuronales profundas a escala de ImageNet mediante la combinación de un límite original de PAC-Bayes y un método de compresión de redes neuronales disponible.
Proponemos una medida alternativa para determinar la eficacia de los ataques adversarios en los modelos de PNL según un método basado en la medida de distancia como la ganancia incremental L2 en la teoría de control.
Proponemos la Red Residual Warped utilizando un operador warp paralelizable para la propagación hacia delante y hacia atrás a capas distantes que se entrena más rápido que la red neuronal residual original. 
Proponemos un conjunto de métricas que captan las propiedades deseadas de los algoritmos de explicabilidad y lo utilizamos para comparar y evaluar objetivamente dichos métodos
Un reciente método de detección de fuera de la distribución ayuda a medir la confianza de las predicciones de las RNN para algunas tareas de PNL
separación profundidad-2-vs-3 para redes neuronales sigmoidales sobre distribuciones generales
Proponemos un método escalable para aproximar los vectores propios del Laplaciano en el contexto del aprendizaje por refuerzo y mostramos que las representaciones aprendidas pueden mejorar el rendimiento de un agente RL.
Traducción de simulación a imágenes reales y generación de vídeo
Proponemos PocketFlow, un marco automatizado para la compresión y aceleración de modelos, para facilitar el despliegue de modelos de aprendizaje profundo en dispositivos móviles.
Cómo aprender GANs a partir de observaciones parciales, distorsionadas y con ruido
Véase el resumen.  (Para la revisión, el documento es idéntico, excepto por un Material Suplementario de 59 páginas, que puede servir como versión de informe técnico del documento).
Introducimos un mecanismo de atención para mejorar la extracción de características para el aprendizaje activo profundo (AL) en el entorno semi-supervisado.
Aplicamos formas canónicas de complejos de gradiente (códigos de barras) para explorar las superficies de pérdida de las redes neuronales.
Uso de actualizaciones de gradiente asíncronas para acelerar el entrenamiento de redes neuronales dinámicas
Estudiamos el problema de diseño de recompensas en MARL cooperativo basado en entornos de enrutamiento de paquetes. Los resultados experimentales nos recuerdan que hay que tener cuidado al diseñar las recompensas, ya que son realmente importantes para guiar el comportamiento del agente.
Las redes de Neumann son un enfoque de aprendizaje de extremo a extremo y eficiente desde el punto de vista de la muestra para resolver problemas inversos lineales en imagen que son compatibles con el enfoque óptimo de MSE y admiten una extensión al aprendizaje basado en parches.
GLMP: Se propone un codificador de memoria global (RNN de contexto, puntero global) y un decodificador de memoria local (RNN de boceto, puntero local) que comparten el conocimiento externo (MemNN) para reforzar la generación de respuestas en el diálogo orientado a tareas.
Proponemos un novedoso módulo aritificial checkerboard enhancer (ACE) que guía los ataques a un espacio de píxeles preestablecido y lo defiende con éxito con una simple operación de relleno.
Analizamos sistemáticamente el comportamiento de convergencia de algoritmos de gradiente populares para resolver juegos bilineales, con actualizaciones simultáneas y alternas.
Utilizamos los VAE para aprender una incrustación de espacio latente compartida entre las características y los atributos de la imagen y, por lo tanto, logramos resultados de vanguardia en el aprendizaje generalizado de disparo cero.
La información espacial de las últimas capas no es necesaria para una buena precisión de la clasificación.
Utilizamos las redes siamesas para guiar y desentrañar el proceso de generación en GANs sin datos etiquetados.
Presentamos Predicted Variables, un enfoque para hacer del aprendizaje automático un ciudadano de primera clase en los lenguajes de programación.
Mostramos formas de entrenar un modelo de predicción de vídeo jerárquico sin necesidad de etiquetas de pose.
En este trabajo, estudiamos el problema del aprendizaje de representaciones para identificar objetos nuevos mediante la exploración de objetos utilizando la detección táctil. El punto clave aquí es que la consulta se proporciona en el dominio de la imagen.
Empleamos esquemas de compresión homomórfica lineal para representar la estadística suficiente de un modelo de campo aleatorio condicional de la coreferencia y esto nos permite escalar la inferencia y mejorar la velocidad en un orden de magnitud.
Damos un análisis teórico de la medición y optimización de la información mutua.
Rompiendo la jerarquía de capas, proponemos un enfoque de 3 pasos para la construcción de redes de jerarquía neuronal que superan a NAS, SMASH y la representación jerárquica con menos parámetros y menor tiempo de búsqueda.
Proponemos un algoritmo que ajusta automáticamente los parámetros de un motor de simulación para generar datos de entrenamiento para una red neuronal de forma que se maximice la precisión de la validación.
Un esquema de regularización agnóstica del modelo para la estimación de la densidad condicional basada en redes neuronales.
Una formulación de cuello de botella basada en parches en un marco VAE que aprende representaciones no supervisadas más adecuadas para el reconocimiento visual.
Para resolver los problemas de desvanecimiento/explosión del gradiente, proponemos una parametrización eficiente de la matriz de transición de la RNN que no pierde poder expresivo, converge más rápido y tiene una buena generalización.
Un artículo que sugiere un método para transformar el estilo de las imágenes utilizando redes neuronales profundas.
Mejoramos los sistemas de diálogo existentes para responder a las personas que comparten historias personales, incorporando representaciones de predicción de emociones, y también publicamos un nuevo punto de referencia y un conjunto de datos de diálogos empáticos.
Una nueva arquitectura de red neuronal recurrente para detectar la causalidad de Granger entre series temporales que no interactúan linealmente. 
Un algoritmo de entrenamiento estocástico basado en variantes de control para redes convolucionales de grafos que el campo receptivo puede ser de sólo dos vecinos por nodo.
Métodos de Monte Carlo para cuantificar los modelos preentrenados sin ningún tipo de entrenamiento adicional.
Enfoque teórico de la información para el aprendizaje no supervisado de un híbrido de representaciones discretas y continuas, 
Es importante considerar la optimización en el espacio de la función, no sólo en el espacio de los parámetros. Introducimos una regla de aprendizaje que reduce la distancia recorrida en el espacio de funciones, al igual que el SGD limita la distancia recorrida en el espacio de parámetros.
Teoría de convergencia para estimadores de gradiente sesgados (pero consistentes) en optimización estocástica y aplicación a redes convolucionales de grafos
Utilizamos instantáneas del proceso de entrenamiento para mejorar cualquier método de estimación de la incertidumbre de un clasificador DNN.
Un nuevo conjunto de datos de imágenes faciales para equilibrar la raza, el sexo y la edad que puede utilizarse para medir y mitigar los prejuicios
Intentamos modelar el proceso de dibujo de las fuentes construyendo modelos generativos secuenciales de gráficos vectoriales (SVG), una representación altamente estructurada de los caracteres de las fuentes.
Desarrollamos la "inferencia relacional neuronal dinámica", un modelo de autocodificador variacional que puede representar de forma explícita e interpretable las relaciones dinámicas ocultas entre las neuronas.
Hasta donde sabemos, DeePa es el primer marco de aprendizaje profundo que controla y optimiza el paralelismo de las CNN en todas las dimensiones paralizables en la granularidad de cada capa.
Combinamos el método kernel con los modelos conexionistas y demostramos que las arquitecturas profundas resultantes pueden entrenarse por capas y tienen una dinámica de aprendizaje más transparente. 
Proponemos un método para optimizar estocásticamente las penalizaciones de segundo orden y mostramos cómo puede aplicarse al entrenamiento de clasificadores con conciencia de equidad.
Demostramos que las derivadas de las redes de aprendizaje profundo tienen una estructura de bajo rango, y esta estructura nos permite utilizar la información de las derivadas de segundo orden para calcular las tasas de aprendizaje de forma adaptativa y de manera computacionalmente factible.
Un marco unificado de optimización min-max para el ataque y la defensa adversarial
reducción de la dimensionalidad para los casos en que los ejemplos pueden representarse como distribuciones de probabilidad suaves
Proponemos una novedosa arquitectura de Exploración de Metas Intrínsecamente Motivada con aprendizaje no supervisado de representaciones del espacio de metas, y evaluamos cómo varias implementaciones permiten el descubrimiento de una diversidad de políticas.
Proponemos un paso adicional de entrenamiento, llamado post-entrenamiento, que calcula los pesos óptimos para la última capa de la red.
Comprimiendo las incrustaciones de palabras en más de un 94% sin perjudicar el rendimiento.
OE enseña a los detectores de anomalías a aprender heurística para detectar anomalías no vistas; los experimentos son en clasificación, estimación de densidad y calibración en entornos de PNL y visión; no afinamos en muestras de distribución de prueba, a diferencia de trabajos anteriores
Un método para aprender una transformación entre un par de conjuntos de datos de origen/destino y aplicarla a otro conjunto de datos de origen para el que no existe un conjunto de datos de destino
Combinar el aprendizaje por imitación y el aprendizaje por refuerzo para aprender a superar al experto
Un enfoque de aprendizaje no supervisado para separar dos señales estructuradas a partir de su superposición
Exploramos la relación entre los flujos normalizadores y los autocodificadores variacionales y de denostación, y proponemos un nuevo modelo que los generaliza.
Utilizamos el aprendizaje por refuerzo para la reformulación de consultas en dos tareas y, sorprendentemente, descubrimos que cuando se entrenan varios agentes la diversidad de las reformulaciones es más importante que la especialización.
Un marco general para incorporar restricciones de seguridad a largo plazo en el aprendizaje por refuerzo basado en políticas
Evaluación de las redes generativas a través de su capacidad de aumento de datos en modelos discriminativos.
Novedad: aplicación de la modelización seq2seq a la automatización del periodismo científico; conjunto de datos muy abstracto; trucos de aprendizaje de transferencia; medida de evaluación automática.
Presentamos un enfoque para rediseñar el entorno de forma que se minimicen o eliminen los comportamientos no interpretables de los agentes.
Proponemos una nueva clase de modelos de inferencia que codifican iterativamente los gradientes para estimar distribuciones posteriores aproximadas.
Presentamos una regla de aprendizaje para los pesos de retroalimentación en una red neuronal spiking que aborda el problema de transporte de pesos.
Combinamos la inferencia variacional y el aprendizaje de la matriz (específicamente VAE y mapas de difusión) para construir un modelo generativo basado en un paseo aleatorio de difusión en una matriz de datos; generamos muestras extrayendo de la distribución estacionaria del paseo.
Desarrollamos un enfoque sencillo y general para evitar la interferencia entre gradientes de diferentes tareas, que mejora el rendimiento del aprendizaje multitarea tanto en los dominios de aprendizaje supervisado como de refuerzo.
Aprender a muestrear a través de la limitación inferior de la tasa de aceptación del algoritmo Metropolis-Hastings
BERT generalizado para entradas continuas y multimodales; representaciones de vídeo autosupervisadas de última generación.
Una arquitectura dinámica genérica que emplea un mecanismo de bifurcación diferenciable específico del problema para codificar supuestos de estructuras de datos difíciles. Se aplica a CLEVR VQA y a la evaluación de expresiones.
Unificamos la estimación del soporte con la familia de algoritmos de Aprendizaje de Imitación Adversarial en el Aprendizaje de Imitación Adversarial Guiado por Soporte, un marco de aprendizaje de imitación más robusto y estable.
Aplicamos el meta-aprendizaje basado en el gradiente al dominio de los gráficos e introducimos una nueva función de transferencia específica de los gráficos para reforzar el proceso.
Proponemos un nuevo método para entrenar incrementalmente un modelo generativo de mezcla para aproximar la proyección de información de la distribución de datos reales.
Recuperar vídeos a partir de mediciones compresivas mediante el aprendizaje de una representación de baja dimensión (de bajo rango) directamente a partir de las mediciones mientras se entrena un generador profundo. 
Estudiamos una generalización multicapa de la poda basada en la magnitud.
Introducimos la maximización del hipervolumen para el entrenamiento de GANs con múltiples discriminadores, mostrando mejoras en el rendimiento en términos de calidad y diversidad de la muestra. 
Un nuevo estado de la técnica en Imagenet para la configuración móvil
Un marco de desarrollo de algoritmos y simulación robótica de alto rendimiento.
Un nuevo paradigma de adaptación de dominio no supervisado: realizar la adaptación sin acceder a los datos de origen ("sin fuente") y sin ninguna suposición sobre la brecha de categoría fuente-destino ("universal").
Dejar que un metaaprendiz decida la tarea en la que se entrena un agente en un entorno multitarea mejora sustancialmente la capacidad multitarea
Proponemos la Generación de Oraciones con Respuestas (ASGen), un novedoso método de pre-entrenamiento para generar datos sintéticos para la comprensión lectora automática.
Enfoque de cuantificación suave para aprender representaciones puras de punto fijo de redes neuronales profundas
Presentamos una novedosa arquitectura de red para el aprendizaje de redes neuronales profundas compactas y eficientes
Estudiamos por primera vez los ataques de aprendizaje automático adversario contra los mecanismos de seguimiento de objetos múltiples. 
Acoplar el aprendizaje semisupervisado con el autosupervisado y modelar explícitamente la tarea autosupervisada condicionada a la semisupervisada
Una arquitectura de red de punteros para la reclasificación de artículos, aprendida a partir de los registros de clics.
El método de gradiente estocástico con impulso se generaliza.
Aprender a imitar a un experto en ausencia de acciones óptimas aprendiendo un modelo de dinámica mientras se explora el entorno.
Mostramos la posibilidad de podar para encontrar una pequeña subred con una tasa de convergencia significativamente mayor que la del modelo completo.
Proponemos un enfoque basado en la inferencia variacional para fomentar la inferencia de latentes desentrañadas. También proponemos una nueva métrica para cuantificar el desentrañamiento. 
Nuestra propuesta de ASN caracteriza la influencia de diferentes acciones sobre otros agentes utilizando redes neuronales basadas en la semántica de la acción entre ellos.
 Demostramos una red neuronal recurrente asíncrona con picos que corresponde a una unidad LSTM.
Clasificación eficiente de vídeos mediante un módulo de gating condicional basado en fotogramas para seleccionar los fotogramas más dominantes, seguido de un modelado temporal y un clasificador.
Programación dinámica diferenciable sobre pesos de entrada perturbados con aplicación a la VAE semisupervisada
Sin aprendizaje, es imposible explicar las decisiones de un modelo de aprendizaje automático.
Red neuronal gráfica simple y eficaz con mezcla de pasos de paseo aleatorio y atención
Presentamos una reconstrucción de aprendizaje profundo no supervisada para problemas inversos de imágenes que combina redes neuronales con restricciones basadas en modelos.
Introducimos una tarea de diagnóstico que es una variación del aprendizaje de pocos disparos e introducimos un conjunto de datos para ello.
Presentamos el uso de un codificador-decodificador secundario como función de pérdida para ayudar a entrenar un resumidor.
Un marco de traducción de vídeo a vídeo no supervisado, consistente en el tiempo y flexible en cuanto a la modalidad, entrenado de forma autosupervisada.
Los marcos de argumentación se utilizan para representar la causalidad de los planes/modelos que se utilizarán para las explicaciones.
Proponemos un enfoque de red neuronal generativa para nubes de puntos temporalmente coherentes.
Presentamos una visión unificadora de los ataques adversarios de caja negra como un problema de estimación de gradiente, y a continuación presentamos un marco (basado en la optimización de bandidos) para integrar los priores en la estimación de gradiente, lo que conduce a un rendimiento significativamente mayor.
Mejora de la eficacia de las etiquetas mediante el aprendizaje multitarea en datos auditivos
El artículo presenta dos técnicas para incorporar la estructura de alto nivel en la generación de texto procesal a partir de una secuencia de imágenes.
Introducimos un novedoso estimador de gradiente utilizando el método de Stein, y lo comparamos con otros métodos de aprendizaje de modelos implícitos para la inferencia aproximada y la generación de imágenes.
Metodología ideal para inyectar ruido a los datos de entrada durante el entrenamiento de la CNN
Proponemos modelar explícitamente las distribuciones de características profundas de los datos de origen y destino como distribuciones de mezcla gaussiana para la adaptación de dominio no supervisada (UDA) y lograr resultados superiores en múltiples tareas de UDA que los métodos del estado de la técnica.
Aprendemos una abstracción del grafo del mundo del entorno independiente de la tarea y mostramos cómo su uso para la exploración estructurada puede acelerar significativamente la RL específica de la tarea.
Representamos un programa de ordenador mediante un conjunto de programas más sencillos y utilizamos esta representación para mejorar las técnicas de síntesis de programas.
¿Cómo podemos construir agentes artificiales que resuelvan dilemas sociales (situaciones en las que los individuos se enfrentan a la tentación de aumentar sus beneficios a costa del bienestar total)?
Proponemos un nuevo modelo de gradiente basado en la transformación generalizada y proponemos un estimador de gradiente basado en polinomios basado en el modelo.
aprendizaje semi-supervisado y de transferencia en la clasificación del flujo de paquetes, mediante un sistema de bloques neuronales cooperativos o adversarios
Nuestro trabajo presenta una factorización de Kronecker de las matrices de pesos recurrentes para obtener redes neuronales recurrentes eficientes y bien condicionadas.
Proponemos un método para calcular representaciones adversamente robustas de forma totalmente no supervisada.
Proponemos un nuevo enfoque basado en la puntuación para el aprendizaje estructural/causal aprovechando las redes neuronales y una reciente formulación continua restringida para este problema
El artículo analiza el problema del diseño de ataques adversarios contra clasificadores múltiples, introduciendo algoritmos que son óptimos para clasificadores lineales y que proporcionan resultados del estado del arte para el aprendizaje profundo.
Presentamos un análisis general de bucle cerrado para los juegos de potencial de Markov y mostramos que el aprendizaje por refuerzo profundo puede utilizarse para aprender un equilibrio de Nash de bucle cerrado aproximado.
Aumentamos la compresión sin pérdidas con variables latentes, superando los enfoques existentes en imágenes ImageNet de tamaño completo.
Nuestra hipótesis es que la vulnerabilidad de los modelos de imagen a pequeñas perturbaciones adversarias es un resultado natural de la geometría de alta dimensión de la matriz de datos. Exploramos y demostramos teóricamente esta hipótesis para un conjunto de datos sintético sencillo.
Presentamos Variational Intrinsic Successor FeatuRes (VISR), un novedoso algoritmo que aprende características controlables que pueden ser aprovechadas para proporcionar una rápida inferencia de tareas a través del marco de las características de sucesión.
Un método de adaptación de dominio para la salida estructurada mediante el aprendizaje de representaciones de características discriminativas a nivel de parche
Un nuevo ataque adversario que puede atacar directamente modelos de aprendizaje automático de caja negra del mundo real sin transferencia.
La privacidad diferencial a nivel de usuario para los modelos lingüísticos de redes neuronales recurrentes es posible con un conjunto de datos suficientemente grande.
El entrenamiento de las redes de convección con un tamaño de imagen mixto puede mejorar los resultados a través de múltiples tamaños en la evaluación
El artículo introduce un método de entrenamiento de redes recurrentes generativas que ayuda a planificar el futuro. Ejecutamos una segunda RNN en sentido inverso y hacemos una restricción suave entre los estados cotemporales hacia adelante y hacia atrás.
Proponemos estructurar el generador de un GAN para que considere explícitamente los objetos y sus relaciones, y genere imágenes mediante la composición
Conseguimos que emerja la comunicación con agentes egoístas, en contra de la visión actual en ML
proponemos un nuevo marco para la regularización de las DNN dependientes de los datos que puede evitar que las DNN se ajusten en exceso a los datos aleatorios o a las etiquetas aleatorias.
El aprendizaje multitarea mejora el reconocimiento del habla a nivel de palabras y caracteres interpolando los sesgos de preferencia de sus componentes: preferencia de frecuencia y longitud de palabra.
Aprendemos una red neuronal que uniformiza la distribución de entrada, lo que conduce a un rendimiento de indexación competitivo en un espacio de alta dimensión
Este trabajo proporciona un estudio riguroso del aprendizaje de la TD de varianza reducida y caracteriza su ventaja sobre el aprendizaje de la TD de vainilla
Una Red Multiflow es una arquitectura dinámica para la adaptación de dominios que aprende grafos computacionales potencialmente diferentes por dominio, con el fin de mapearlos en una representación común donde la inferencia puede realizarse de forma agnóstica al dominio.
IMPACT ayuda a los agentes de RL a entrenar más rápido, reduciendo el tiempo de entrenamiento en la pared y aumentando la eficiencia de la muestra simultáneamente.
Este trabajo introduce un esquema de coloreado para la desambiguación de nodos en redes neuronales de grafos basado en la separabilidad, que ha demostrado ser una extensión universal de MPNN.
Representando las melodías como imágenes con unidades semánticas alineadas podemos generarlas utilizando un DCGAN sin componentes recurrentes.
Introducimos y analizamos el fenómeno de las "alucinaciones" en NMT, o traducciones espurias no relacionadas con el texto de origen, y proponemos métodos para reducir su frecuencia.
Un marco de evaluación basado en una red neuronal del mundo real para los métodos explicativos post-hoc
Presentamos un método inspirado en la neurociencia y basado en redes neuronales para la búsqueda de espacios latentes
Al introducir la noción de un espacio de representación óptimo, proporcionamos un argumento teórico y la validación experimental de que un modelo no supervisado para oraciones puede tener un buen rendimiento tanto en las tareas de similitud supervisada como en las de transferencia no supervisada.
Un conjunto de datos de pruebas cloze diseñadas por profesores para evaluar el dominio del idioma
Las redes neuronales artificiales entrenadas con descenso de gradiente son capaces de recapitular tanto la actividad neuronal realista como la organización anatómica de un circuito biológico.
Prune y ReLU en el dominio de Winograd para una red neuronal convolucional eficiente
Un nuevo algoritmo para entrenar redes neuronales profundas. Probado en funciones de optimización y MNIST.
Introducimos el flipout, un método eficiente para descorrelacionar los gradientes calculados por los pesos de las redes neuronales estocásticas dentro de un minilote mediante el muestreo implícito de perturbaciones de peso pseudoindependientes para cada ejemplo.
Se propone un nuevo modelo de autoencoder latentemente invertible para resolver el problema de la inferencia variacional en VAE utilizando la red invertible y el entrenamiento adversarial en dos etapas.
Introducimos el modelo PHP para la representación jerárquica de programas neuronales, y un algoritmo para el aprendizaje de PHPs a partir de una mezcla de supervisión fuerte y débil.
Proponemos un método de transferencia de conocimientos entre tareas de RL relacionadas utilizando mapeos visuales, y demostramos su eficacia en variantes visuales del juego Atari Breakout y en diferentes niveles de Road Fighter, un juego de conducción de coches de Nintendo.
Los métodos de gradiente adaptativo, cuando se hacen bien, no incurren en una penalización de generalización. 
Introducimos un modelo que generaliza rápidamente a partir de pocas observaciones almacenando información sorprendente y atendiendo a los datos más relevantes en cada momento.
Desarrollamos un enfoque entrenable de principio a fin para la ojeada, la relectura y la detención temprana aplicable a las tareas de clasificación. 
Consideramos la exploración en RL como un problema de adecuación de una distribución marginal sobre los estados.
Introducimos G-HexaConv, una red neuronal convolucional equivariante de grupo en celosías hexagonales.
Proponiendo un novedoso enfoque de localización(detección) de objetos basado en la interpretación de la CNN profunda utilizando la representación interna y los pensamientos de la red
Las redes Trellis son una nueva arquitectura de modelado de secuencias que tiende un puente entre los modelos recurrentes y convolucionales y establece un nuevo estado del arte en el modelado del lenguaje a nivel de palabras y caracteres.
Se puede obtener una alta precisión en la detección de objetos entrenando modelos compactos específicos del dominio y el entrenamiento puede ser muy corto.
Comparamos los algoritmos de RL basados en modelos profundos y sin modelos estudiando la aproximabilidad de las funciones $Q$, las políticas y la dinámica mediante redes neuronales. 
Introducimos un novedoso enfoque de razonamiento físico de sentido común que aprende a descubrir objetos y a modelar sus interacciones físicas a partir de imágenes visuales sin procesar de una manera puramente no supervisada
Se observa un sesgo muy fuerte hacia las salidas simples en muchos mapas simples de entrada-salida. El mapa parámetro-función de las redes profundas presenta el mismo sesgo.
En este artículo, proponemos modelos imitativos para combinar las ventajas de la IL y la planificación dirigida a objetivos: modelos predictivos probabilísticos de comportamiento deseable capaces de planificar trayectorias interpretables como las de los expertos para alcanzar objetivos específicos.
Novedosa arquitectura del mecanismo de atención basado en la memoria para la comunicación entre agentes múltiples.
Este trabajo refuerza la dinámica hamiltoniana con el control para aprender los modelos del sistema a partir de los datos de posición y velocidad incrustados, y explota esta dinámica físicamente consistente para sintetizar el control basado en el modelo mediante la conformación de la energía.
Investigamos las razones internas de nuestras observaciones, la disminución de los efectos de los conocidos métodos de optimización de hiperparámetros en el aprendizaje federado a partir de datos descentralizados no IID.
Un nuevo ataque de imitación adversarial para engañar a los modelos de aprendizaje automático.
Entrenamiento de grandes lotes mediante formación adversarial e información de segundo orden
primera red neuronal profunda para modelar la memoria espacial egocéntrica inspirada en los descubrimientos neurofisiológicos de las células de navegación en el cerebro de los mamíferos
Probamos la generalización de las DNNs añadiendo un término de regularización de Lipschitz a la pérdida de entrenamiento. Resolvemos una cuestión planteada en Zhang et al. (2016).
Entrenamos redes de residuos amplios que pueden desplegarse inmediatamente utilizando sólo un bit para cada peso convolucional, con una precisión significativamente mejor que los métodos anteriores.
Visualización inmersiva de los espacios clásicos no euclidianos mediante el trazado de rayos en tiempo real.
Proponemos el autoencoder de conjuntos, un modelo de aprendizaje de representación no supervisado para conjuntos de elementos.
Proponemos un método autónomo para el aprendizaje por refuerzo seguro y eficiente que aprende simultáneamente una política hacia adelante y otra hacia atrás, con la política hacia atrás restableciendo el entorno para un intento posterior.
Presentamos pruebas de que los LM captan el sentido común con resultados de vanguardia tanto en el Desafío de Esquemas de Winograd como en la Minería del Conocimiento con Sentido Común.
Un algoritmo en línea para la adquisición y predicción de rasgos que tienen en cuenta los costes
Sostenemos que las redes convolucionales deberían considerarse el punto de partida por defecto para las tareas de modelado de secuencias.
Entrenamiento de DNNs para interconectar funciones de caja negra con etiquetas intermedias utilizando una subred estimadora que puede ser reemplazada por la caja negra después del entrenamiento
Proponemos el algoritmo Actor-Crítico Dual, que se deriva de una forma principial de la forma dual Lagrangiana de la ecuación de optimalidad de Bellman. El algoritmo alcanza el estado del arte en varios puntos de referencia.
Una adaptación robusta del dominio empleando una pérdida específica de la tarea en el aprendizaje adversarial cíclico
Optimización de la política mediante el uso de buenas tiradas anteriores del agente; aprendizaje de recompensas con forma mediante la minimización de la divergencia; SVPG con JS-kernel para la exploración basada en la población.
Estudiamos el funcionamiento de los autocodificadores en un entorno sencillo y aconsejamos nuevas estrategias para su regularización con el fin de obtener una mejor generalización pensando en la interpolación latente para la síntesis de imágenes. 
Presentamos una idea sencilla que permite grabar a un hablante en un idioma determinado y sintetizar su voz en otros idiomas que tal vez no conozca.
En este trabajo, proponemos un algoritmo de IL sin modelo y sin política para el control continuo. Los resultados experimentales mostraron que nuestro algoritmo logra resultados competitivos con GAIL mientras que reduce significativamente las interacciones del entorno.
Un sistema de reescritura de texto condicionado a múltiples atributos controlables
Desarrollamos un nuevo enfoque de optimización para la RNN basada en ReLU de vainilla que permite la memoria a corto plazo y la identificación de sistemas dinámicos no lineales arbitrarios con escalas de tiempo muy diferentes.
Proponer un marco mejorado para los WGAN y demostrar su mejor rendimiento en la teoría y la práctica.
Las operaciones en el espacio latente del GAN pueden inducir un desajuste de la distribución en comparación con la distribución de entrenamiento, y lo abordamos utilizando un transporte óptimo para igualar las distribuciones. 
Una nueva forma de aprender la incrustación semántica de programas
Proponemos una extensión de la normalización por lotes, mostramos un análisis de convergencia por primera vez para esta extensión y demostramos en experimentos numéricos que tiene un mejor rendimiento que la normalización por lotes original.
Proponemos un marco para modificar las operaciones del espacio latente de forma que se elimine por completo el desajuste de la distribución entre las salidas resultantes y la distribución previa con la que se entrenó el modelo generativo.
Este artículo proporciona un enfoque de extremo a extremo para aprender incrustaciones unificadas para los pares de pregunta-respuesta en los sistemas de diálogo aprovechando la información contextual, sintáctica, semántica y externa.
Técnicas para combinar políticas generalizadas con algoritmos de búsqueda para explotar los puntos fuertes y superar las debilidades de cada uno al resolver problemas de planificación probabilística
Obtenemos el estado del arte en cuanto a la robustez frente a los cambios de datos, y mantenemos la calibración bajo el cambio de datos aunque aunque la precisión caiga
Extraemos automáticamente la información de la digitación de los vídeos de las interpretaciones de piano, para utilizarla en los modelos de predicción automática de la digitación.
SOTA en la adaptación de dominios sin supervisión aprovechando la hipótesis de los clusters.
Modelos generativos de gráficos basados en la generalización del paso de mensajes a tiempo continuo mediante ecuaciones diferenciales ordinarias 
Demostramos que varias afirmaciones de la teoría del cuello de botella de información del aprendizaje profundo no son ciertas en el caso general.
Las redes neuronales tienen grandes gradientes por diseño; eso las hace adversamente vulnerables.
Introducimos la optimización proximal amortizada (APO), un método para adaptar una variedad de hiperparámetros de optimización en línea durante el entrenamiento, incluyendo las tasas de aprendizaje, los coeficientes de amortiguación y los exponentes de varianza del gradiente.
Sin requerir ninguna restricción o post-procesamiento, mostramos que las dimensiones salientes de los vectores de palabras pueden interpretarse como características semánticas. 
estrategia para reparar redes neuronales dañadas
Generación automática de preguntas a partir de párrafos mediante modelos jerárquicos
La consulta de una red neuronal de caja negra revela mucha información sobre ella; proponemos novedosos "metamodelos" para extraer eficazmente la información de una caja negra.
Uso de un marco de modelado de variables latentes supervisado para determinar la recompensa en una tarea de aprendizaje por refuerzo inverso
Este trabajo combina la búsqueda en árbol de Monte Carlo con la búsqueda local de 2 opciones en un modo de vecindad variable para resolver el TSP de forma efectiva.
Aplicación de la síntesis de programas a las tareas de finalización y generación de imágenes en un marco de aprendizaje profundo
Este artículo presenta un modelo computacional para la adaptación eficiente del control postural humano basado en funciones de adquisición jerárquicas con características bien conocidas. 
Estudiamos el problema de los agentes de control continuo en RL profunda con ataques adversarios y propusimos un algoritmo de dos pasos basado en la dinámica del modelo aprendido. 
Estudiamos el sesgo que induce la dispersión de los modelos profundos, causado por su dinámica de aprendizaje.
Las divergencias paramétricas adversariales definen implícitamente pérdidas de tareas más significativas para el modelado generativo, hacemos un paralelismo con la predicción estructurada para estudiar las propiedades de estas divergencias y su capacidad para codificar la tarea de interés.
Proporcionamos una comparación rigurosa de diferentes redes neuronales gráficas para la clasificación de grafos.
Aprendizaje automático de aumento de datos mediante una arquitectura basada en GAN para mejorar un clasificador de imágenes
Nueva clase de autocodificadores con arquitectura pseudoinvertible
Explotamos un esquema de inversión para redes neuronales profundas arbitrarias para desarrollar un nuevo marco de aprendizaje semi-supervisado aplicable a muchas topologías.
Comparación de redes neuronales siamesas, GANs y VAT para el aprendizaje de pocos disparos. 
Proponemos una mejora ligera para la atención y una arquitectura neural, FusionNet, para lograr SotA en SQuAD y SQuAD adversarial.
Modelo generativo jerárquico entrenado adversarialmente con representación latente robusta y aprendida semánticamente.
Observamos que los solucionadores numéricos de las EDP pueden considerarse procesos de desición de Markov, y proponemos utilizar el aprendizaje por refuerzo para resolver leyes de conservación escalares de 1D
Introducimos una arquitectura de representación neuronal que ayuda a las VAE a aprender representaciones latentes desentrañadas.
Los déficits sensoriales en las primeras fases de entrenamiento pueden conducir a una pérdida irreversible de rendimiento tanto en las redes artificiales como en las neuronales, lo que sugiere que los fenómenos de información son la causa común, y señalan la importancia del transitorio inicial y del olvido.
Proponemos un método para aprender incrementalmente un espacio de incrustación sobre el dominio de las arquitecturas de red, para permitir la selección cuidadosa de arquitecturas para la evaluación durante la búsqueda de arquitecturas comprimidas.
Mejora del rendimiento de un agente RL en el dominio de la acción continua y el espacio de estado mediante el uso de la repetición de la experiencia priorizada y el ruido de los parámetros.
mostrar el peso de la atención multicanal contiene la característica semántica para resolver la tarea de inferencia del lenguaje natural.
Aproximamos los Procesos Puntuales Determinantes con redes neuronales; justificamos nuestro modelo teórica y empíricamente.
Este artículo presenta una arquitectura de red para resolver el problema de estructura a partir del movimiento (SfM) mediante el ajuste del conjunto de características (BA)
Demostramos que añadir una restricción a las actualizaciones de TD estabiliza el aprendizaje y permite el aprendizaje Q profundo sin una red objetivo
Proponemos DuoRC, un novedoso conjunto de datos para la Comprensión Lectora (CR) que contiene 186.089 pares de GC generados por humanos y creados a partir de una colección de 7680 pares de tramas de películas paralelas, e introducimos una tarea de CR consistente en leer una versión de la trama y responder a preguntas creadas a partir de la otra versión; así, por diseño, se requiere un razonamiento complejo y una comprensión lingüística más profunda para superar el escaso solapamiento léxico entre la trama y la pregunta.
Un componente de planificación basado en modelos mejora el análisis semántico basado en RL sobre WikiTableQuestions.
Una nueva forma de cuantificar la activación de las redes neuronales profundas a través del recorte parametrizado que optimiza la escala de cuantificación a través del descenso de gradiente estocástico.
Demostramos que los métodos de poda que introducen una mayor inestabilidad en la pérdida también confieren una mejor generalización, y exploramos los mecanismos subyacentes a este efecto.
Las redes neuronales profundas menos inverosímiles y entrenadas sin transporte de pesos pueden ser más difíciles de engañar.
Un modelo generativo para la predicción de reacciones que aprende los pasos electrónicos mecanísticos de una reacción directamente a partir de los datos brutos de la misma.
Incorporar la capacidad de decir "no sé" puede mejorar la imparcialidad de un clasificador sin sacrificar demasiado la precisión, y esta mejora se magnifica cuando el clasificador tiene conocimiento de la toma de decisiones posterior.
Un enfoque para realizar la planificación HTN utilizando procedimientos externos para evaluar predicados en tiempo de ejecución (anexos semánticos).
Los vectores de palabras de máxima agrupación con similitud de conjuntos difusos de Jaccard son una línea de base extremadamente competitiva para la similitud semántica; proponemos una variante dinámica simple que se desempeña aún mejor.
El objetivo general de este trabajo es permitir la imitación eficiente de muestras a partir de demostraciones de expertos, tanto con la provisión de etiquetas de acción de expertos como sin ella, mediante el uso de divergencias f.
Con una interfaz cognitiva cerebro-máquina, mostramos una relación directa entre los efectos atencionales en la precisión perceptiva y la ganancia neural en la potencia EEG-SSVEP, en el cerebro humano.
Un marco general y fácil de usar que mejora la robustez adversarial de los modelos de clasificación profunda a través de la regularización de incrustación.
Proponemos un algoritmo de clustering de tareas basado en el completamiento de matrices para el aprendizaje profundo multitarea y de pocos disparos en los entornos con un gran número de tareas diversas.
Este enfoque supera los problemas de escalabilidad e implica nuevas conexiones matemáticas entre la física cuántica de muchos cuerpos, la teoría de la información cuántica y el aprendizaje automático.
Entrenamos una combinación de redes neuronales para predecir las trayectorias óptimas de sistemas físicos complejos.
Proporcionamos una garantía de generalización basada en PAC-Bayes para redes profundas deterministas sin comprimir, generalizando la resistencia al ruido de la red en los datos de entrenamiento a los datos de prueba.
Demostramos que para una gran clase de funciones f existe una red robusta certificada por intervalos que aproxima f hasta una precisión arbitraria.
Se trata de un trabajo que pretende potenciar todo el método de poda e imitación existente.
Introducimos un objetivo gaussiano a priori dependiente de los datos para aumentar el entrenamiento MLE actual, que está diseñado para capturar el conocimiento previo en los datos de la verdad.
Proponemos un enfoque interactivo para clasificar las consultas en lenguaje natural pidiendo a los usuarios información adicional utilizando la ganancia de información y un controlador de políticas de aprendizaje por refuerzo.
Autocodificadores convolucionales generalizados a superficies de malla para codificar y reconstruir expresiones faciales 3D extremas.
Jiffy es un enfoque convolucional para el aprendizaje de una métrica de distancia para series temporales multivariantes que supera a los métodos existentes en términos de precisión de clasificación del vecino más cercano.
Se propone una arquitectura modular ampliable para el desarrollo de una variedad de comportamientos de agentes en DQN.
Aislamos un factor de la generalización de la RL analizando el caso en que el agente sólo se adapta a las observaciones. Demostramos que en este régimen se producen regularizaciones implícitas arquitectónicas.
En este trabajo, proponemos un nuevo modelo neural del lenguaje, llamado Parsing-Reading-Predict Networks (PRPN), que puede inducir simultáneamente la estructura sintáctica de oraciones no anotadas y aprovechar la estructura inferida para aprender un mejor modelo del lenguaje.
Hemos propuesto un enfoque integral para el aprendizaje de incrustación no supervisado sobre la base del algoritmo AND.
Proponemos un método de aprendizaje débilmente supervisado para la clasificación y localización de cánceres en imágenes de portaobjetos completos de histopatología de muy alta resolución, utilizando únicamente etiquetas de toda la imagen.
 Proponemos un nuevo método para utilizar la información de la ontología para mejorar el rendimiento en los problemas de predicción/clasificación masiva multietiqueta.
Aplicamos una asignación codiciosa en las muestras proyectadas en lugar de ordenarlas para aproximar la distancia Wasserstein
En este trabajo se estudian las interacciones entre los modelos de aprendizaje rápido y de predicción lenta y se demuestra cómo dichas interacciones pueden mejorar la capacidad de la máquina para resolver los problemas conjuntos de aprendizaje de por vida y de pocos disparos.
El primer método de inicialización de pesos por principios para las hiperredes
Un novedoso marco de aprendizaje profundo bayesiano que captura y relaciona conceptos semánticos y visuales jerárquicos, con un buen rendimiento en una variedad de tareas de modelado y generación de imágenes y textos.
Este artículo introduce la conexión a tierra parcial para abordar el problema que surge cuando el proceso de conexión a tierra completo, es decir, la traducción de una tarea de entrada PDDL a una representación a tierra como STRIPS, es inviable debido a las limitaciones de memoria o tiempo.
Presentación del método de caracterización de la respuesta para interpretar la dinámica de las células en las redes de memoria a corto plazo aprendidas (LSTM). 
Hasta donde sabemos, este es el primer estudio que muestra cómo las representaciones neuronales del espacio, incluidas las células tipo rejilla y las células de borde, tal y como se observan en el cerebro, podrían surgir del entrenamiento de una red neuronal recurrente para realizar tareas de navegación.
Comparamos el rendimiento del modelo basado en el espectrograma con un modelo entrenado de principio a fin en el dominio de la forma de onda
Proporcionamos una solución escalable para la evaluación multiagente con una complejidad de tasa lineal tanto en tiempo como en memoria en función del número de agentes
Proponemos un novedoso enfoque de aprendizaje semisupervisado con rendimiento SOTA para combatir el aprendizaje con etiquetas ruidosas.
Diseñamos un método de entrenamiento adversarial para las redes neuronales bayesianas, mostrando una defensa mucho más fuerte ante los ataques adversariales de caja blanca
Ataques efectivos de envenenamiento de modelos en el aprendizaje federado capaces de causar una clasificación errónea dirigida de alta confianza de las entradas deseadas
 En este trabajo, planteamos la hipótesis de que los puntos de datos perturbados superficialmente no deberían limitarse a asignarse a la misma clase, sino que deberían asignarse a la misma representación.
modelo acústico armónico
Abordar la compensación causada por la dependencia de las clases en los dominios mediante la mejora de las redes adversarias de los dominios
Proponemos la FVD: una nueva métrica para los modelos generativos de vídeo basada en la FID. Un estudio en humanos a gran escala confirma que la FVD se correlaciona bien con el juicio humano cualitativo de los vídeos generados.
Una arquitectura de memoria dual inspirada en el cerebro humano para aprender tareas entrantes de forma secuencial y evitar el olvido catastrófico.
Modelización del lenguaje para el aprendizaje de idiomas a lo largo de la vida.
Utilizamos ideas de la computación cuántica para proponer incrustaciones de palabras que utilizan muchos menos parámetros entrenables.
Entrenamos a agentes de redes neuronales para que desarrollen un lenguaje con propiedades compositivas a partir de la entrada de píxeles en bruto.
Aprendemos una función de muestreo de diversidad con DPP para obtener un conjunto diverso de muestras de un modelo generativo.
Las representaciones de los modelos lingüísticos obtienen sistemáticamente mejores resultados que los codificadores de traducción en las tareas de predicción de auxiliares sintácticos.
Proponemos el muestreo Langevin restringido basado en sustitutos con aplicación en el diseño de configuraciones de materiales nanoporosos.
Mejora de los modelos de incrustación jerárquica mediante el suavizado del núcleo
Enfoque de bootstrapping aumentado que combina la información de un conjunto de referencia con refinamientos iterativos de etiquetas blandas para mejorar el reconocimiento de entidades de nombre a partir de la literatura biomédica.
Ampliamos las SVM cuánticas a un entorno semi-supervisado, para hacer frente al probable problema de muchas etiquetas de clase perdidas en conjuntos de datos enormes.
Este artículo une las arquitecturas de las redes profundas con las ecuaciones diferenciales numéricas (estocásticas). Esta nueva perspectiva permite nuevos diseños de redes neuronales profundas más eficaces.
CNN y LSTM para generar un código similar al de las marcas que describen las imágenes de la interfaz gráfica de usuario.
Demostramos que las incrustaciones hiperbólicas son útiles para las tareas de visión por ordenador de alto nivel, especialmente para la clasificación de pocos disparos.
Presentamos un método para aprender representaciones interpretables de las series temporales utilizando ideas de los autocodificadores variacionales, los mapas autoorganizativos y los modelos probabilísticos.
Arquitectura convolucional para el aprendizaje de pesos dependientes de los datos para la previsión autorregresiva de series temporales.
Presentamos una nueva interpretación de MixUp como perteneciente a una clase altamente análoga al entrenamiento adversarial, y sobre esta base introducimos una simple generalización que supera a MixUp
Manejo de la incertidumbre en la percepción visual para el reconocimiento de planes
Acceso multi-salto diferenciable a una base de conocimiento textual de representaciones contextuales indexadas
Algoritmo de factorización de propósito general escalable: también ayuda a evitar el problema del arranque en frío.
Presentamos un sistema de autoría de tutoriales de montaje de medios mixtos que agiliza la creación de vídeos, imágenes, textos e instrucciones dinámicas in situ.
Demostramos que el uso de notas clínicas junto con los datos de los instrumentos de la UCI mejora el rendimiento en las tareas de referencia de la gestión de la UCI
Proponemos un gradiente de política basado en eventos para entrenar al líder y un gradiente de política de abstracción de acciones para entrenar a los seguidores en el juego de Markov líder-seguidor.
Utilizamos la transmisión cultural para fomentar la composicionalidad en los lenguajes que surgen de las interacciones entre los agentes neuronales.
Proponemos un método basado en la SVD para explorar la dimensión local del colector de activación en redes neuronales profundas.
La inferencia en grandes Transformers es costosa debido a la autoatención en múltiples capas. Demostramos que una sencilla técnica de descomposición puede dar lugar a un modelo más rápido y de bajo consumo de memoria que es igual de preciso que los modelos originales.
Una adaptación del aprendizaje profundo de la iteración aleatoria del valor de los mínimos cuadrados
Los parámetros de una red neuronal entrenada pueden permutarse para producir un modelo completamente distinto para una tarea diferente, lo que permite incrustar redes de caballo de Troya dentro de otra red.
Introducimos un diseño alternativo de GAN basado en rutas aleatorias en el generador, que puede servir como herramienta para la interpretabilidad de los modelos generativos.
Presentamos un marco teórico y experimental para definir, comprender y lograr la generalización, y como resultado la robustez, en el aprendizaje profundo, basándonos en la teoría de la información algorítmica y la teoría de la codificación.
Planteamos el descubrimiento de la estructura causal como una selección de modelos bayesianos de forma que nos permita discriminar entre los grafos equivalentes de Markov para identificar el único grafo causal.
Límite inferior para la detección comprimida con modelos generativos que coincide con los límites superiores conocidos
Este artículo presenta un análisis empírico sobre el papel de los diferentes tipos de representaciones de imágenes y sondea las propiedades de estas representaciones para la tarea de subtitulación de imágenes.
Diseñamos analizadores incrementales de secuencia a acción para tareas de texto a SQL y logramos resultados SOTA. Mejoramos aún más utilizando oráculos no deterministas para permitir múltiples secuencias de acción correctas. 
Un enfoque que acelera la búsqueda de arquitecturas neuronales en 10 veces, a la vez que utiliza 100 veces menos recursos informáticos.
Proponemos una nueva arquitectura de DNN para el aprendizaje profundo sobre datos tabulares
Un marco que lleva a cabo el refinamiento en línea de las pseudoetiquetas con una nueva pérdida softmax-triple para la adaptación de dominio no supervisada en la reidentificación de personas.
Presentamos el primer enfoque para certificar la robustez de las redes neuronales frente a las perturbaciones basadas en el ruido en el dominio del audio.
Este trabajo presenta un método para generar y utilizar conjuntos de manera eficaz para identificar ejemplos ruidosos en presencia de ruido de anotación. 
Un algoritmo de aprendizaje basado en datos y en la optimización de minimización alternante para la recuperación de grafos dispersos.
Proponemos un marco neural doble para resolver un juego de información imperfecta a gran escala. 
Presentamos la primera verificación de que una red neuronal para tareas de percepción produce una salida correcta dentro de una tolerancia especificada para cada entrada de interés. 
Estudiamos las aproximaciones de la distorsión de la tasa para evaluar los modelos generativos profundos, y mostramos que las curvas de distorsión de la tasa proporcionan más información sobre el modelo que la log-verosimilitud por sí sola, a la vez que requieren aproximadamente el mismo coste computacional.
Un algoritmo meta-RL basado en modelos que permite a un robot real adaptarse en línea en entornos dinámicos
El artículo analiza el espacio latente aprendido por los enfoques sin modelo en un juego de información incompleta en miniatura, entrena un modelo de avance en el espacio latente y lo aplica a la búsqueda de árboles de Monte-Carlo, obteniendo un rendimiento positivo.
Analizamos la capacidad expresiva de las conexiones utilizadas en DenseNets mediante descomposiciones tensoriales.
Utilizamos la retroalimentación humana implícita (a través de potenciales de error, EEG) para acelerar y optimizar el entrenamiento de un algoritmo DRL, de una manera práctica.
TCN para el aprendizaje multimodal semisupervisado + estudio de ablación de sus mecanismos + interpretaciones de las representaciones latentes
Adaptación de Adam, Amsgrad, Adagrad a las variedades riemannianas. 
Defensa contra los ataques físicamente realizables a la clasificación de imágenes
Los pesos plásticos hebbianos pueden comportarse como un almacenamiento de memoria episódica comprimida en las redes neuronales y, con la combinación de la consolidación sináptica específica de la tarea, pueden mejorar la capacidad de aliviar el olvido catastrófico en el aprendizaje continuo.
Este trabajo demuestra que las redes neuronales de tipo skin no pueden aproximar ciertas funciones, por muy profundas que sean.
Presentamos la Red Lógica Continua (CLN), una novedosa arquitectura neuronal para el aprendizaje automático de invariantes de bucle y fórmulas generales de SMT.
Nuestro hallazgo arroja luz sobre la prevención de la progresión del cáncer
Ampliamos los flujos autorregresivos y RealNVP a los datos discretos.
Una arquitectura de aprendizaje profundo resistente al ruido.
Aprendemos incrustaciones neuronales de grafos en el espacio hiperbólico en lugar del euclidiano
Ideas para futuros ICKEPS
Generamos artículos de Wikipedia de forma abstracta condicionados por el texto del documento fuente.
Un algoritmo para unificar SGD y Adam y estudio empírico de su rendimiento
Aprendizaje de políticas jerárquicas a partir de demostraciones no segmentadas utilizando información dirigida
Los algoritmos tradicionales de procesamiento de imágenes se combinan con las redes neuronales convolucionales, una nueva red neuronal.
Proponemos un método específico de retropropagación a través de un subgradiente espectral adecuado para integrar el proceso de puntos determinantes en el marco del aprendizaje profundo.
Inventamos un novedoso marco de clústeres para el entrenamiento de NMT, que puede comprender mejor la diversidad de las lenguas de origen y de destino.
Un modelo ILP diferenciable eficiente que aprende reglas lógicas de primer orden que pueden explicar los datos.
Introducimos un nuevo método para sintetizar ejemplos adversarios robustos en el mundo físico y lo utilizamos para fabricar los primeros objetos adversarios en 3D.
Aprenda a permutar un conjunto, luego codifique el conjunto permutado con RNN para obtener una representación del conjunto.
Utilizar el aprendizaje de refuerzo profundo para diseñar los atributos físicos de un robot conjuntamente con una política de control.
Proponemos un enfoque que dota a un único modelo de la capacidad de representar ambos extremos: la formación conjunta y la formación independiente, lo que conduce a un aprendizaje multitarea eficaz.
Proponemos un término de regularización que, cuando se añade al objetivo de aprendizaje por refuerzo, permite que la política maximice la recompensa y simultáneamente aprenda a ser invariable a los cambios irrelevantes dentro de la entrada...
Este trabajo propone una representación visual universal para la traducción automática neural (NMT) utilizando imágenes recuperadas con temas similares a la frase de origen, ampliando la aplicabilidad de las imágenes en la NMT.
Combinando ideas del diseño de algoritmos tradicionales y del aprendizaje por refuerzo, introducimos un marco novedoso para el aprendizaje de algoritmos que resuelven problemas de optimización combinatoria en línea.
Un enfoque funcional revela que la inicialización plana, preservada por el descenso de gradiente, conduce a la capacidad de generalización.
La profundidad de la red aumenta los valores propios atípicos en el hessiano. Las conexiones residuales lo mitigan.
Un trabajo experimental que demuestra la cantidad de pesos redundantes que se pueden congelar sólo a partir de la tercera época, con un descenso muy ligero de la precisión.
Un enfoque novedoso para el aprendizaje del currículo mediante el aprendizaje incremental de las etiquetas y el suavizado adaptativo de las etiquetas para las muestras mal clasificadas, lo que aumenta el rendimiento medio y disminuye la desviación estándar.
Proponemos un método para tratar las palabras raras calculando su incrustación a partir de las definiciones.
Este trabajo propone un clasificador generativo profundo que es eficaz para detectar muestras fuera de la distribución, así como para clasificar muestras dentro de la distribución, mediante la integración del concepto de análisis discriminante gaussiano en redes neuronales profundas.
Mostrar que la edad confunde la detección del deterioro cognitivo + resolver con el aprendizaje de la representación justa + proponer métricas y modelos.
Presentamos NetScore, una nueva métrica diseñada para proporcionar una evaluación cuantitativa del equilibrio entre la precisión, la complejidad computacional y la complejidad de la arquitectura de red de una red neuronal profunda.
ataques adversarios ordenados Top-k
La propagación personalizada de predicciones neuronales (PPNP) mejora las redes neuronales de grafos separándolas en predicción y propagación mediante PageRank personalizado.
La elección de la lengua central (de destino) afecta a la calidad de las incrustaciones multilingües, que no deberían evaluarse únicamente con diccionarios centrados en el inglés.
El entrenamiento típico de GAN no optimiza Jensen-Shannon, sino algo así como una divergencia KL inversa.
Demostramos que extrayendo múltiples muestras (predicciones) por entrada (punto de datos), podemos aprender con menos datos ya que obtenemos libremente una línea de base REINFORCE.
Resolvemos eficazmente los problemas de multitarea con un algoritmo de generación automática de currículos basado en un modelo generativo que sigue el rendimiento del agente de aprendizaje.
Este trabajo identifica clases de problemas para los que los ejemplos adversos son inevitables, y deriva límites fundamentales sobre la susceptibilidad de cualquier clasificador a los ejemplos adversos. 
Bajando la precisión (a 4 bits, 2 bits e incluso binaria) y ampliando los bancos de filtros se obtienen redes tan precisas como las obtenidas con pesos y activaciones FP32.
Incorporamos un CRF en un VAE de tokens y etiquetas NER para el aprendizaje semisupervisado y mostramos mejoras en entornos de bajos recursos.
Un marco de principios para la cuantificación de modelos mediante el método del gradiente proximal.
Una nueva técnica de modelado generativo basada en el entrenamiento adversarial asimétrico, y sus aplicaciones a la detección de ejemplos adversariales y a la clasificación robusta
El meta-aprendizaje de algoritmos de curiosidad mediante la búsqueda en un rico espacio de programas produce mecanismos novedosos que se generalizan a través de dominios de aprendizaje de refuerzo muy diferentes.
Este trabajo propone un procedimiento sencillo para evaluar la estructura compositiva en las representaciones aprendidas, y utiliza el procedimiento para explorar el papel de la composicionalidad en cuatro problemas de aprendizaje.
Un modelo DL para la predicción de la estructura secundaria del ARN, que utiliza un algoritmo desenrollado en la arquitectura para hacer cumplir las restricciones.
Presentamos la propagación de la elegibilidad como una alternativa a la BPTT que es compatible con los datos experimentales sobre la plasticidad sináptica y compite con la BPTT en los puntos de referencia del aprendizaje automático.
Extracción de una máquina de estados finitos de una red neuronal recurrente a través de la cuantización con el fin de la interpretabilidad con experimentos en Atari.
Investigamos las pruebas teóricas y prácticas de la mejora del aprendizaje por refuerzo en las políticas mediante la reutilización de los datos de varias políticas consecutivas.
Utilizamos la Transformación de Fourier no euclidiana de formas definidas por un complejo simplicial para el aprendizaje profundo, logrando resultados significativamente mejores que las técnicas de muestreo basadas en puntos utilizadas en la literatura actual de aprendizaje 3D.
Aplicamos el aprendizaje por refuerzo al descubrimiento causal basado en la puntuación y logramos resultados prometedores tanto en conjuntos de datos sintéticos como reales
Proponemos un método universal que se puede utilizar en la etapa de preprocesamiento de datos para generar el tema más significativo que represente mejor el documento dado
Proponemos un novedoso marco de aprendizaje multitarea que extrae la relación de dependencia multivista de forma automática y la utiliza para guiar la transferencia de conocimientos entre diferentes tareas.
Comprobación de la invariabilidad translacional global en redes convolucionales y de cápsulas
Desarrollamos un método analítico para estudiar la inferencia bayesiana de las redes neuronales de ancho finito y encontramos que la imagen del flujo del grupo de renormalización emerge naturalmente.
comprender teóricamente el efecto de regularización de la destilación. Demostramos que la detención temprana es esencial en este proceso. Desde esta perspectiva, desarrollamos un método de destilación para el aprendizaje con Etiqueta corrupta con garantías teóricas.
un enfoque novedoso para el aprendizaje permanente en línea utilizando núcleos de salida.
Modelamos un escenario de construcción de casas en Minecraft en planificación clásica y HTN y comparamos las ventajas y desventajas de ambos tipos de modelos.
Presentamos un marco para evaluar los ejemplos adversarios en el procesamiento del lenguaje natural y demostramos que los ejemplos adversarios generados a menudo no conservan la semántica, son sintácticamente correctos o no son sospechosos.
¿Podemos confiar en la explicación de una red neuronal para su predicción? Examinamos la solidez de varias nociones populares de interpretabilidad de las redes neuronales, incluidos los mapas de saliencia y las funciones de influencia, y diseñamos ejemplos adversos contra ellas.
El trabajo diseña dos algoritmos para el problema de maximización del AUC estocástico con complejidades de última generación cuando se utiliza una red neuronal profunda como modelo predictivo, que también se verifican mediante estudios empíricos.
Abordamos tareas condicionadas por objetivos combinando los algoritmos de Repetición de la Experiencia Retrospectiva y de Aprendizaje por Imitación, mostrando una convergencia más rápida que el primero y un rendimiento final más alto que el segundo.
Derivamos un nuevo límite PAC-Bayesiano para funciones de pérdida no limitadas (por ejemplo, Log-Likelihood negativo). 
Proponemos una sencilla técnica de aumento de datos autosupervisada que mejora el rendimiento de los escenarios totalmente supervisados, incluyendo el aprendizaje de pocos disparos y la clasificación desequilibrada.
Una arquitectura de red basada en LSTM de dos ramas aprende la representación y la dinámica de mallas 3D de simulaciones numéricas de choques.
Los vectores de características de SoundNet pueden predecir la actividad cerebral de los sujetos que ven una película en las regiones cerebrales relacionadas con la audición y el lenguaje.
Proponemos un autoencoder generativo que puede aprender distribuciones posteriores y de probabilidad condicional expresivas utilizando distribuciones implícitas, y entrenamos el modelo utilizando una nueva formulación de la ELBO.
Los niños utilizan el sesgo de exclusividad mutua (ME) para aprender nuevas palabras, mientras que las redes neuronales estándar muestran el sesgo opuesto, dificultando el aprendizaje en escenarios naturalistas como el aprendizaje permanente.
Las redes neuronales recurrentes que realizan una tarea de memoria de trabajo utilizan largas escalas de tiempo heterogéneas, sorprendentemente similares a las observadas en la corteza prefrontal.
 En este trabajo, abordamos el problema del aprendizaje de la expansión de la red a baja altura
Presentamos un modelo de formulación de preguntas humanas que combina redes neuronales y programas simbólicos, que pueden aprender a generar buenas preguntas con o sin ejemplos supervisados.
Un mecanismo de comprensión visual para un entorno especial
Mejor entrenamiento adversarial aprendiendo a mapear de nuevo el colector de datos con autocodificadores en los estados ocultos.  
Demostramos que la minimización de la pérdida de entropía cruzada mediante un método de gradiente podría conducir a un margen muy pobre si las características del conjunto de datos se encuentran en un subespacio de baja dimensión.
Un nuevo modelo RNN que supera significativamente la frontera actual de los modelos en una variedad de tareas secuenciales.
Sorprendentes resultados negativos en la RL basada en el modelo + el modelo profundo
Inspirado en la teoría de los cuellos de botella de la información, proponemos una nueva arquitectura de GAN para el aprendizaje de una representación desenredada
Explicación de la situación de los sesgos con las GAN MMD; las GAN MMD funcionan con redes críticas más pequeñas que las WGAN-GP; nueva métrica de evaluación de las GAN.
Un marco de clasificación multimodal semisupervisado, TCN, que supera varios puntos de referencia.
Un método neuronal iterativo para extraer señales que sólo se observan mezcladas con otras señales
Incrustación de señales fisiológicas para el rendimiento de la predicción y la transferencia hospitalaria con un método general de interpretabilidad del valor Shapley para modelos apilados.
Presentamos un algoritmo demostrable para recuperar exactamente ambos factores del modelo de aprendizaje del diccionario. 
Extracción de relaciones aumentadas con GPT-2
Un algoritmo de inferencia aproximada para el aprendizaje profundo
Proponemos una novedosa estrategia de regularización de colectores basada en el entrenamiento adversarial, que puede mejorar significativamente el rendimiento del aprendizaje semisupervisado.
Un nuevo método de aprendizaje supervisado mediante la subdivisión del espacio de entrada junto con la aproximación de funciones.
Ataques adversarios a incrustaciones de nodos no supervisados basados en la teoría de la perturbación de valores propios.
Presentamos un novedoso algoritmo para el descubrimiento jerárquico de subtareas que aprovecha el marco del proceso de decisión lineal multitarea de Markov.
Proponemos un modelo de red de memoria para resolver instancias de LP binario en las que la información de la memoria se persigue para su uso a largo plazo. 
Introducimos un método novedoso para entrenar modelos Seq2Seq con modelos lingüísticos que convergen más rápido, generalizan mejor y pueden transferirse casi por completo a un nuevo dominio utilizando menos del 10% de datos etiquetados.
Introducimos el planteamiento de problemas de metaaprendizaje en línea para captar mejor el espíritu y la práctica del aprendizaje permanente.
Los pesos de atención no exponen completamente lo que BERT sabe sobre la sintaxis.
Proponemos un novedoso método de superresolución facial que incorpora explícitamente las preconcepciones faciales 3D que captan las estructuras faciales nítidas.
El autoentrenamiento con diferentes vistas de la entrada da excelentes resultados para el reconocimiento de imágenes semisupervisado, el etiquetado de secuencias y el análisis sintáctico de dependencias.
Una forma no reversible de tomar decisiones de aceptación/rechazo puede ser beneficiosa
Proporcionamos un nuevo marco para MAML en el entorno ES/blackbox, y mostramos que permite políticas deterministas y lineales, una mejor exploración y operadores de adaptación no diferenciables.
Presentamos un marco de software para la transformación de distribuciones y demostramos su flexibilidad en la relajación de los supuestos de campo medio en la inferencia variacional con el uso de flujos de acoplamiento para replicar la estructura del modelo generativo objetivo.
Adaptación del dominio adversario y aprendizaje multidominio: una nueva pérdida para manejar clases multi y monodominio en el escenario semi-supervisado.
Una red de aprendizaje que generaliza el marco MLP para realizar una regresión de distribución a distribución
Se propusieron métodos para la representación de eventos dependientes del tiempo y la regularización para la predicción de secuencias; se evaluaron estos métodos en cinco conjuntos de datos que implican una serie de tareas de predicción de secuencias.
Desarrollamos un método para el aprendizaje de refuerzo estable fuera de línea a partir de datos registrados. La clave es regularizar la política de RL hacia un modelo aprendido "ponderado por la ventaja" de los datos.
Este trabajo presenta un modelo de aprendizaje profundo que combina mapas autoorganizativos y redes neuronales convolucionales para el aprendizaje de representación de datos multiómicos
La sparsificación como ajuste de los modelos lingüísticos
Método para abordar el cambio de covariable en el aprendizaje por imitación utilizando la incertidumbre del conjunto
Utilizamos el ajuste supervisado de los vectores de características para mejorar la transferencia de la simulación al mundo real
Introducimos la capacidad de explotar la información sobre el grado de consecución de un objetivo arbitrario, mientras que otro objetivo estaba destinado a los métodos de gradiente de la política.
Proponemos un nuevo punto de referencia para la comprensión de vídeos, con tareas que por su diseño requieren un razonamiento temporal para ser resueltas, a diferencia de la mayoría de los conjuntos de datos de vídeo existentes.
Proponemos un algoritmo de aprendizaje federado asíncrono eficiente y robusto sobre la existencia de rezagados
La adición de un nuevo conjunto de pesos a la LSTM que gira la memoria de las células mejora el rendimiento en algunas tareas de bAbI.
Nueva metodología para la inferencia marginal variacional de permutaciones basada en el algoritmo de Sinkhorn, aplicada a la identificación probabilística de neuronas
Proponemos la primera métrica de robustez independiente de los ataques, también conocida como CLEVER, que puede aplicarse a cualquier clasificador de redes neuronales.
Este trabajo propone un esquema de aprendizaje de comunicación espontánea y autoorganizada (SSoC) para tareas de RL multiagente.
Sobre el uso de BERT como codificador para la predicción secuencial de etiquetas en la tarea de clasificación de texto multietiqueta
DNN y Encoder enhanced FM con atención bilineal y max-pooling para CTR
La inferencia bayesiana basada en el abandono se amplía para tratar la multimodalidad y se evalúa en tareas de anticipación de escenas.
Introducimos un nuevo tipo de GAN condicional, cuyo objetivo es aprovechar la estructura en el espacio objetivo del generador. Aumentamos el generador con una nueva vía no supervisada para aprender la estructura del objetivo. 
En este trabajo, proponemos un nuevo marco de entrenamiento regularizado adversarial ATLPA, es decir, Adversarial Tolerant Logit Pairing with Attention.
Abordamos el problema de la generalización del aprendizaje por refuerzo a espacios de acción no vistos.
Aprender en procesos puntuales temporales modelando la densidad condicional, no la intensidad condicional.
Un modelo profundo para el modelado de temas
Novedoso marco GAN basado en la normalización de instancias para la CV no paralela many-to-many y zero-shot. 
Este trabajo propone Sparse Transformer para mejorar la concentración de la atención en el contexto global a través de una selección explícita de los segmentos más relevantes para el aprendizaje secuencia a secuencia. 
Las representaciones no supervisadas aprendidas con la codificación predictiva contrastiva permiten una clasificación de imágenes eficiente desde el punto de vista de los datos.
La redistribución y el crecimiento de los pesos en función de la magnitud del impulso permite el entrenamiento de redes dispersas a partir de inicializaciones aleatorias que pueden alcanzar niveles de rendimiento densos con pesos del 5% al 50%, al tiempo que se acelera el entrenamiento hasta 5,6 veces.
La superficie de pérdida de las redes neuronales es una unión disjunta de regiones donde cada mínimo local es un mínimo global de la región correspondiente.
Destilamos representaciones de modelos lingüísticos para la sintaxis mediante el aprendizaje métrico no supervisado
Presentamos una nueva arquitectura de memoria para la navegación en entornos no conocidos, inspirada en la navegación basada en puntos de referencia en animales.
Proponemos una arquitectura novedosa que atraviesa una pirámide de imágenes de forma descendente, mientras visita sólo las regiones más informativas a lo largo del camino.
Utilizamos una hiperred para predecir los pesos óptimos dados los hiperparámetros, y entrenamos conjuntamente todo.
Proponemos una nueva métrica para evaluar los GANs condicionales que captura la calidad de la imagen, la consistencia condicional y la diversidad intra-condicionamiento en una sola medida.
Presentamos TreeQN y ATreeC, nuevas arquitecturas para el aprendizaje profundo por refuerzo en dominios de acción discreta que integran la planificación de árboles diferenciables en línea en la función de valor de la acción o política.
Proponemos redes de codificación-decodificación de paso de mensajes para una forma rápida y precisa de modelar las dependencias de las etiquetas para la clasificación multietiqueta.
Proponemos un método para realizar una regresión de pocos disparos mediante el aprendizaje de un conjunto de funciones base para representar la distribución de la función.
Proponemos una forma agnóstica al modelo para aprovechar BERT para la generación de texto y lograr mejoras sobre Transformer en 2 tareas sobre 4 conjuntos de datos.
CNN-F amplía la CNN con una red generativa de retroalimentación para una visión robusta.
Se demuestra que las CNNs de tipo ResNet son un aproximador universal y su capacidad de expresión no es peor que la de las redes neuronales completamente conectadas (FNNs) con estructura \textit{block-sparse} incluso si el tamaño de cada capa en la CNN es fijo.
Un nuevo método de aprendizaje de pocos disparos para generar pesos de clasificación específicos de la consulta mediante la maximización de la información.
Un método neural para responder a preguntas conversacionales con un mecanismo de atención y un uso novedoso de BERT como incrustación contextual
alternativa a la penalización del gradiente
búsqueda automática de arquitecturas multitarea que reduzcan el uso de funciones por tarea
Proponemos el solapamiento del vecino más cercano, un procedimiento que cuantifica la similitud entre los incrustadores de forma independiente de la tarea, y lo utilizamos para comparar 21 incrustadores de frases.
Proponemos un nuevo objetivo para el entrenamiento de los VAE-GANs híbridos que conduce a una mejora significativa de la cobertura y la calidad del modo.
Un nuevo método utiliza la información de la puntuación de apalancamiento estadístico para medir la importancia de las muestras de datos en cada tarea y adopta un enfoque de direcciones frecuentes para permitir una propiedad de aprendizaje permanente.
Aprendemos mapas de características invariantes a la traslación, y equivariantes a la rotación y la escala.
Un algoritmo específico de meta-aprendizaje basado en el gradiente, MAML, es equivalente a un procedimiento de inferencia en un modelo jerárquico bayesiano. Utilizamos esta conexión para mejorar el MAML mediante métodos de inferencia aproximada y estimación de curvatura.
Automatizar el sistema de aprendizaje automático con un algoritmo de búsqueda eficiente y una estructura innovadora para proporcionar mejores líneas de base del modelo.
Proponemos estrategias de diseño experimental bayesiano por lotes basadas en principios y un método para la cuantificación de la incertidumbre de los resúmenes posteriores en un marco de cálculo bayesiano aproximado basado en procesos gaussianos.
Proporcionamos una tasa de convergencia eficiente para el descenso de gradiente en el objetivo de aprendizaje de diccionario ortogonal completo basado en un análisis geométrico.
Demostramos que las arquitecturas RNN diseñadas y entrenadas de forma creativa pueden descodificar códigos secuenciales bien conocidos y lograr rendimientos cercanos a los óptimos.
Analizamos y resolvemos el problema de no convergencia de Adam.
En este trabajo proponemos un método generativo para la adaptación de dominios multifuentes basado en la descomposición de los factores de contenido, estilo y dominio.
Uso del muestreo de importancia recocido en el problema de la cogeneración. 
Desarrollamos un nuevo método de estimación de parámetros sin verosimilitud que es equivalente a la máxima verosimilitud bajo algunas condiciones
Nuestro método infiere las restricciones en la ejecución de la tarea aprovechando el principio de máxima entropía para cuantificar cómo las demostraciones difieren del comportamiento esperado, sin restricciones.
Sistema para aprender tareas robóticas en el mundo real con aprendizaje por refuerzo sin instrumentación
Utilizamos un autocodificador variacional para separar el estilo y el contenido, y logramos la conversión de la voz modificando la incrustación y decodificación del estilo. Investigamos utilizando un corpus de habla multilingüe e investigamos sus efectos.
El artículo propone un método para forzar a las CNN a aprovechar la atención espacial en el aprendizaje de representaciones más centradas en el objeto que se comportan mejor en varios aspectos.
Redes neuronales recurrentes para casos de uso de ciberseguridad
Estructuración de la entrada a lo largo del caos para la estabilidad
Abordamos el entrenamiento de GANs con datos discretos formulando un gradiente de política que generaliza a través de f-divergencias
Las líneas de base dependientes de la acción pueden estar libres de sesgos y producir una mayor reducción de la varianza que las líneas de base dependientes sólo del estado para los métodos de gradiente de la política.
Proponemos un algoritmo de aprendizaje activo multitarea que logra la transferencia de conocimientos entre tareas.
Aprendemos un códec de imagen con pérdidas eficiente que puede ser optimizado para facilitar la detección fiable de la manipulación de fotos con un coste fraccionario en la carga útil/calidad e incluso a bajas tasas de bits.
Este trabajo propone un modelo de secuencia genérico eficaz que aprovecha los puntos fuertes de las RNN y de la atención multicabezal.
Un enfoque estructurado de variables latentes que añade estados de control discretos dentro de un paradigma neuronal autorregresivo estándar para proporcionar una base arbitraria a las decisiones del modelo interno, sin sacrificar ningún poder de representación de los modelos neuronales.
Estimación de la distribución de los datos de entrenamiento a partir del clasificador entrenado mediante GAN.
Establecemos que las leyes de escala derivadas en (Bora et al., 2017) son óptimas o casi óptimas en ausencia de otros supuestos.
meta-aprender un algoritmo de aprendizaje capaz de razonamiento causal
Se ha desarrollado un algoritmo basado en el corpus para generar un léxico de sentimientos en amárico basado en el corpus
Aumentamos las estimaciones del valor Q con una bonificación basada en el recuento que garantiza el optimismo durante la selección de acciones y el bootstrapping, incluso si las estimaciones del valor Q son pesimistas.
Proponemos el actor-crítico blando, un algoritmo de RL profunda basado en el marco del aprendizaje de refuerzo de máxima entropía.
El emparejamiento de la distribución mediante la minimización de la divergencia proporciona una base común para comparar los métodos de aprendizaje de refuerzo inverso de máxima entropía con la clonación de comportamientos.
Proponemos un marco genérico que permite explotar la estructura de bajo rango tanto en la planificación como en el aprendizaje profundo por refuerzo.
Un punto de referencia para evaluar las incrustaciones neuronales de identificadores en el código fuente.
Reordenando los términos de la discrepancia media máxima se obtiene una función de pérdida mucho mejor para el discriminador de las redes generativas adversariales
Este trabajo encuentra algoritmos que utilizan directamente representaciones comprimidas sin pérdidas de las redes profundas feedforward, para realizar la inferencia sin una descompresión completa.
Hemos incluido las GANs en el marco de la desigualdad variacional y hemos importado técnicas de esta literatura para optimizar mejor las GANs; damos extensiones algorítmicas y probamos empíricamente su rendimiento para el entrenamiento de las GANs.
Abordar el problema de la heterogeneidad de las tareas en el metaaprendizaje introduciendo un grafo de metaconocimiento
 Se desarrolla un algoritmo de refuerzo profundo para aprender un clasificador de conjunto más discriminativo mediante la combinación perfecta de un conjunto de CNN profundas básicas.
Un método automático de conversión de música entre instrumentos y estilos
Proponemos varios ataques nuevos y una metodología para medir la robustez frente a ataques adversos imprevistos.
Deep-Net: Redes neuronales profundas para casos de uso de ciberseguridad
Aprendemos un espacio de primitivas motoras a partir de demostraciones robóticas no anotadas, y demostramos que estas primitivas tienen significado semántico y pueden componerse para nuevas tareas robóticas.
Demostramos la viabilidad de un enfoque de clasificación de series temporales débilmente supervisado para los datos de los sensores portátiles. 
Proponemos un marco de alineación local-global para aprender correspondencias semánticas a partir de pares de datos-texto ruidosos con una supervisión débil
Aprender a alcanzar objetivos desde cero mediante el aprendizaje por imitación con reetiquetado de datos
En este artículo, proponemos un método de conjunto llamado InterBoost para el entrenamiento de redes neuronales para la clasificación de muestras pequeñas. El método tiene un mejor rendimiento de generalización que otros métodos de conjunto, y reduce las varianzas de manera significativa.
Detectamos las interacciones estadísticas captadas por una red neuronal multicapa feedforward interpretando directamente sus pesos aprendidos.
Comparamos el modelo neural lineal con los conjuntos de datos UCI y UCI "gap".
Hemos reproducido AlphaZero en Google Cloud Platform
Establecemos la convergencia global a la optimidad para GANs basadas en IPM donde el generador es una red neuronal sobreparametrizada. 
Desarrollamos procedimientos eficientes de incrustación de redes atribuidas a múltiples escalas con propiedades demostrables.
 Un estudio empírico detallado en la clasificación de pocos disparos que revela los desafíos en la configuración de la evaluación estándar y muestra una nueva dirección.
Presentamos un modelo de inferencia bayesiana para inferir explicaciones contrastivas (como especificaciones LTL) que describen cómo difieren dos conjuntos de trazos de planes.
La geometría tropical puede aprovecharse para representar los límites de decisión de las redes neuronales y sacar a la luz interesantes conocimientos.
Un novedoso método Gram-Gauss-Newton para entrenar redes neuronales, inspirado en el núcleo neuronal tangente y el método Gauss-Newton, con una rápida velocidad de convergencia tanto teórica como experimental.
Investigamos el conocimiento sintáctico implícito de las incrustaciones de oraciones utilizando un nuevo conjunto de análisis de oraciones anotadas gramaticalmente con juicios de aceptabilidad.
Proponemos una extensión del aprendizaje multisalida a un continuo de tareas utilizando núcleos valorados por operadores.
Demostramos que, para funciones de activación que satisfacen algunas condiciones, a medida que una red profunda se ensancha, las longitudes de los vectores de las variables ocultas convergen a un mapa de longitudes.
Proponemos un enfoque de aumento de datos para el metaaprendizaje y demostramos que es válido.
Un marco general para destilar expectativas posteriores bayesianas para redes neuronales profundas.
En este trabajo, introducimos una jerarquía discreta de variables latentes categóricas que entrenamos utilizando la relajación Concrete/Gumbel-Softmax y derivamos un límite superior para la diferencia absoluta entre el objetivo insesgado y el sesgado.
Proponemos una nueva clase de optimizadores para la optimización acelerada no convexa a través de una transformación de gradiente no lineal. 
Resolver tareas que impliquen la locomoción humanoide guiada por visión, reutilizando el comportamiento de locomoción a partir de los datos de captura de movimiento.
Proponemos las redes Gated Linear Unit, un modelo que se comporta de forma similar a las redes ReLU en datos reales y que es mucho más fácil de analizar teóricamente.
Proponemos un método de búsqueda de arquitecturas para identificar una distribución de arquitecturas y utilizarla para construir un conjunto bayesiano para la detección de valores atípicos.
Un nuevo enfoque que detecta los valores atípicos de los datos de las imágenes, preservando la precisión de la clasificación de las mismas
Este artículo presenta CloudLSTM, una nueva rama de modelos neuronales recurrentes adaptados a la previsión sobre flujos de datos generados por fuentes de nubes puntuales geoespaciales.
Proponemos TransINT, un método novedoso e interpretable de incrustación de KG que preserva isomórficamente el orden de implicación entre las relaciones en el espacio de incrustación de una manera explicable, robusta y geométricamente coherente.
Introducimos una nueva estrategia de entrenamiento de objetivos complementarios basada en el gradiente para la detección de objetos adaptable al dominio.
Proponemos un enfoque novedoso para conectar redes de tareas específicas en un entorno de aprendizaje multitarea basado en los recientes avances en redes residuales.
Cómo utilizar la pérdida de entropía cruzada para el aprendizaje de tiro cero con etiquetado suave en clases no vistas: una solución simple y eficaz que logra un rendimiento de vanguardia en cinco conjuntos de datos de referencia ZSL.
El crecimiento progresivo del espacio de acción disponible es un gran plan de estudios para los agentes de aprendizaje
Una solución teórica a los ataques y defensas de los adversarios.
Un método novedoso para crear descriptores densos del tiempo (Time Embeddings) para que modelos sencillos comprendan las estructuras temporales
Proponemos una novedosa arquitectura de red neuronal de grafos basada en la matriz de no retroceso definida sobre las adyacencias de las aristas y demostramos su eficacia en tareas de detección de comunidades en grafos.
Las conexiones residuales realmente realizan una inferencia iterativa
Mejoramos el tiempo y la calidad de la reconstrucción en un generador de imágenes sin lentes basado en una máscara experimental utilizando un enfoque de aprendizaje de extremo a extremo que incorpora el conocimiento del modelo de imágenes.
Introducimos un nuevo modelo de aprendizaje de representación, denominado "Sample-Ensemble Genetic Evolutionary Network" (SEGEN), que puede servir como enfoque alternativo a los modelos de aprendizaje profundo.
Proponemos utilizar el metaaprendizaje para un aprendizaje de idiomas más eficiente, mediante una especie de "aleatorización de dominios". 
MARTHE: un nuevo método para ajustar los programas de tasa de aprendizaje de tareas específicas desde la perspectiva de la optimización de hiperparámetros
Generación interactiva de imágenes a partir de grafos de escena que crecen de forma incremental en múltiples pasos utilizando GANs mientras se preserva el contenido de la imagen generada en los pasos anteriores
Estudiamos escenarios de clasificación de baja y muy baja señal-ruido, en los que los objetos que se correlacionan con la etiqueta de clase ocupan una proporción minúscula de toda la imagen (por ejemplo, imágenes médicas o hiperespectrales).
Una capa de autoatención puede realizar la convolución y a menudo aprende a hacerlo en la práctica.
Los algoritmos basados en el aprendizaje pueden mejorar el rendimiento de los algoritmos clásicos para el problema de aproximación de bajo rango, manteniendo la garantía del peor caso.
Arquitectura propuesta para resolver la tarea de concordancia morfológica
Este trabajo propone el uso de métodos de elementos espectrales para el entrenamiento rápido y preciso de ecuaciones diferenciales ordinarias neuronales para la identificación de sistemas.
Una nueva señal de recompensa intrínseca basada en los rasgos del sucesor y una forma novedosa de combinar la recompensa extrínseca e intrínseca.
Proponemos utilizar una política de exploración independiente para recoger las trayectorias de preadaptación en MAML. También demostramos que el uso de un objetivo autosupervisado en el bucle interno conduce a un entrenamiento más estable y a un rendimiento mucho mejor.
Generalización de la propagación hacia atrás, utilizando métodos formales de la supersimetría.
Regularizar la trayectoria de optimización con la información de Fisher de las tareas antiguas reduce en gran medida el olvido catastrófico
Damos un método para generar programas seguros de tipo en un lenguaje tipo Java, dada una pequeña cantidad de información sintáctica sobre el código deseado.
Mostramos cómo los flujos autorregresivos pueden utilizarse para mejorar los modelos de variables latentes secuenciales.
Los ejemplos adversos pueden engañar al sistema de detección de derechos de autor de YouTube
Proponemos una versión continua de la Propagación del Equilibrio, en la que la dinámica de las neuronas y las sinapsis se produce simultáneamente a lo largo de la segunda fase, con garantías teóricas y simulaciones numéricas.
Proponemos una nueva Meta Red de Módulos para resolver algunas de las restricciones de la anterior Red de Módulos Neuronales para lograr un fuerte rendimiento en el conjunto de datos de razonamiento visual realista.
Proponemos un nuevo ataque para tomar el control total de las políticas neuronales en entornos realistas.
Puede generar códigos hash eficaces para una recomendación eficiente en frío y, al mismo tiempo, proporcionar una estrategia de marketing factible.
Proponemos un marco neuronal que puede aprender a resolver el problema de Satisfacción de Circuitos a partir de instancias de circuitos (no etiquetados).
Una perspectiva unificada de varios algoritmos de aprendizaje para la generación de secuencias, como MLE, RL, RAML, ruido de datos, etc.
Introducimos un esquema de "Recurso por Construcción Colaborativa" para crear KB, Wikipedia estructurada 
Un modelo de vanguardia basado en el razonamiento global para la superresolución de imágenes
Proponer un marco de evaluación para analizar y aprender el filtro convolucional gráfico
Una nueva capa de agrupación para GNNs que aprende cómo agrupar los nodos, según sus características, la conectividad del grafo y el objetivo de la tarea descendente.
 Proponemos TuckER, un modelo lineal relativamente sencillo pero potente para la predicción de enlaces en grafos de conocimiento, basado en la descomposición de Tucker de la representación tensorial binaria de los triples de los grafos de conocimiento. 
Un algoritmo para reducir la cantidad de memoria necesaria para el entrenamiento de redes profundas, basado en una estrategia de aproximación.
Los algoritmos de flujo de datos pueden mejorarse utilizando el aprendizaje profundo, manteniendo las garantías de rendimiento.
Proponemos el Predictor Neural de Hipervínculos (NHP). NHP adapta redes convolucionales de grafos para la predicción de enlaces en hipergrafos
Un método que aprende representaciones separadas para el significado y la forma de una frase
Exploramos los diseños de visualización que pueden ayudar a los pacientes crónicos a presentar y revisar sus datos de salud con los proveedores de atención médica durante las visitas clínicas.
Proponemos un predictor estocástico diferenciable de la dinámica hacia delante que es capaz de muestrear múltiples trayectorias físicamente plausibles bajo el mismo estado inicial de entrada y mostramos que puede utilizarse para entrenar políticas sin modelo de forma más eficiente.
Análisis del poder de representación de las redes ReLU y los núcleos polinómicos, en particular en presencia de una estructura latente dispersa.
Un modelo para controlar la generación de imágenes con GAN y beta-VAE con respecto a la escala y la posición de los objetos
Proponemos una familia diferenciable de "matrices caleidoscópicas", demostramos que todas las matrices estructuradas pueden representarse de esta forma y las utilizamos para sustituir los mapas lineales elaborados a mano en los modelos de aprendizaje profundo.
Aprendizaje de la representación de etiquetas para redes profundas
Proponemos el Choco-SGD--descentralizado con comunicación comprimida--para objetivos no convexos y mostramos su fuerte rendimiento en varias aplicaciones de aprendizaje profundo (aprendizaje en el dispositivo, caso de centro de datos).
Mostramos que la Entropía-SGD optimiza la previa de un límite PAC-Bayes, violando el requisito de que la previa sea independiente de los datos; utilizamos la privacidad diferencial para resolver esto y mejorar la generalización.
Demostramos experimentalmente que el aprendizaje por transferencia hace que las características de la red sean escasas y, por tanto, produce una red más comprimible. 
Ampliamos los métodos clásicos de propación de etiquetas para modelar conjuntamente la información de grafos y características desde una perspectiva de filtrado de grafos, y mostramos las conexiones con las redes convulsivas de grafos.
Proporcionamos un paquete de software que simplifica, automatiza y mejora drásticamente la evaluación de los optimizadores de aprendizaje profundo.
extraer incrustaciones contextuales a partir de un modelo supervisado. Ayuda a los modelos de PNL en entornos con pocos recursos
Algoritmos adaptativos prácticos para el meta-aprendizaje basado en el gradiente con garantías demostrables.
Nuestro objetivo es explotar la diversidad de estructuras lingüísticas para construir representaciones de frases.
El análisis no supervisado de los datos registrados en el sistema nervioso periférico denota y categoriza las señales.
Mejoramos las defensas existentes basadas en la transformación utilizando un clasificador de distribución sobre la distribución de softmax obtenida de las imágenes transformadas.
Proponemos un enfoque para aprender políticas descentralizadas en entornos multiagente utilizando críticas basadas en la atención y demostramos resultados prometedores en entornos con interacciones complejas.
Aplicamos la RNN para resolver el problema biológico de la predicción de los patrones de plegado de la cromatina a partir de las marcas epigenéticas y demostramos por primera vez que la utilización de la memoria de los estados secuenciales en la molécula de ADN es significativa para el mejor rendimiento.
Proponemos un método eficiente, demostrable e independiente de los datos para la compresión de redes mediante la poda neuronal utilizando conjuntos de neuronas, una construcción novedosa propuesta en este trabajo.
Red aumentada de memoria para planificar en entornos parcialmente observables. 
Un procedimiento para destilar los modelos contextuales en incrustaciones estáticas; aplicamos nuestro método a 9 modelos populares y demostramos claras ganancias en la calidad de la representación wrt Word2Vec/GloVe y un potencial de análisis mejorado al estudiar a fondo el sesgo social.
El aprendizaje de reglas de actualización no supervisadas para redes neuronales mejora el rendimiento y demuestra potencialmente cómo las neuronas del cerebro aprenden sin acceso a las etiquetas globales.
Demostramos que la eliminación de los términos constantes de las arquitecturas de las CNN permite interpretar el método de eliminación de ruido a través de técnicas de álgebra lineal y también aumenta el rendimiento de la generalización a través de los niveles de ruido.
Proporcionamos por primera vez una prueba rigurosa de que la inicialización ortogonal acelera la convergencia en relación con la inicialización gaussiana, para redes lineales profundas.
Una primera estimación diferencialmente privada de la función de supervivencia
CAML es una instancia de MAML con dependencias de clases condicionales.
Estudiamos el problema de la predicción de conjuntos múltiples y proponemos una nueva función de pérdida de conjuntos múltiples, proporcionando análisis y pruebas empíricas que demuestran su eficacia.
Este trabajo presenta un marco teórico que modela explícitamente la distribución de datos para redes ReLU profundas y localmente conectadas
Introducimos un algoritmo evolutivo modular de inspiración biológica en el que los agentes de RL profunda aprenden a cooperar en un difícil juego social multiagente, que podría ayudar a explicar la evolución del altruismo.
Introducimos un tipo de red neuronal que es estructuralmente resistente a los ataques de los adversarios, incluso cuando se entrena con conjuntos de entrenamiento no segmentados.  La resistencia se debe a la estabilidad de las unidades de la red frente a las perturbaciones de entrada.
Demostramos que la robustez adversarial puede tener un coste en el rendimiento de la clasificación estándar, pero también produce beneficios inesperados.
El entrenamiento en combinaciones convexas entre ejemplos aleatorios de entrenamiento y sus etiquetas mejora la generalización en redes neuronales profundas
Presentamos un enfoque novedoso para la clasificación de picos utilizando el Proceso Neural de Agrupación (NCP), una arquitectura neural recientemente introducida que realiza una inferencia bayesiana aproximada amortizada escalable para una agrupación probabilística eficiente.
Método propuesto para encontrar la solución más generalizable que sea estable frente a las perturbaciones de los datos de entrenamiento.
Implementación y evaluación de la memoria episódica para RL.
Presentamos un método de adaptación de hiperparámetros de modelos probabilísticos mediante transporte óptimo con aplicaciones en robótica
Se aplica un algoritmo para aprender una representación de estado predictiva con funciones de valor generales y aprendizaje fuera de política al problema de la dirección basada en la visión en la conducción autónoma.
Abordamos el aprendizaje integral de representaciones basadas en la energía para conjuntos de datos de observación de señales e imágenes con patrones de muestreo irregulares.
Un algoritmo de aprendizaje por meta-refuerzo novedoso y teóricamente fundamentado
El ajuste lateral adapta una red preentrenada entrenando una red "lateral" ligera que se fusiona con la red preentrenada (sin cambios) mediante un sencillo proceso aditivo.
Entrenar GANs con privacidad diferencial para generar conjuntos de datos artificiales que preserven la privacidad.
Este artículo presenta métodos para desentrañar e interpretar los efectos contextuales que se codifican en una red neuronal profunda.
Proponiendo un método novedoso basado en la atención guiada para reforzar la esparza en redes neuronales profundas.
Recuperamos de forma demostrable la capa más baja de una red neuronal profunda asumiendo que la capa más baja utiliza una activación de "umbral alto" y que la red anterior es un polinomio "bien comportado".
Presentamos FedProx, un marco para abordar la heterogeneidad estadística en entornos federados con garantías de convergencia y una robustez y estabilidad mejoradas.
Posibilitamos tanto la evolución cultural del lenguaje como la evolución genética de los agentes en un juego referencial, utilizando un nuevo motor de transmisión del lenguaje.
Introducimos un método novedoso, sencillo y eficiente de aumento de datos que aumenta el rendimiento de los GAN existentes cuando los datos de entrenamiento son limitados y diversos.  
Desarrollamos un simulador de cuerpo y conectoma completo para C. elegans y demostramos la inferencia conjunta de espacio de estados y parámetros en el simulador.
Inspirado en CapsNet, proponemos una arquitectura novedosa para la incrustación de grafos sobre la base de las características de los nodos extraídas de GNN.
Gen-RKM: un nuevo marco para modelos generativos que utilizan máquinas de núcleo restringido con generación de múltiples vistas y aprendizaje de características no correlacionadas.
Comparamos muchas tareas y combinaciones de tareas para el preentrenamiento de BiLSTMs a nivel de frase para tareas de PNL. El modelado del lenguaje es la mejor tarea de preentrenamiento, pero las líneas de base simples también dan buenos resultados.
Una visión de la razón de la vulnerabilidad adversaria, un método de defensa eficaz contra los ataques adversarios.
Aplicar la búsqueda de árboles Monte Carlo a la generación de episodios en Alpha Zero
Para las redes neuronales de grafos, la agregación en un grafo puede beneficiarse de un espacio continuo subyacente al grafo.
Utilizamos un algoritmo de búsqueda simple que implica una RNN y una cola de prioridad para encontrar soluciones a las tareas de codificación.
Presentamos la red neuronal de ondícula de grafos (GWNN), una nueva red neuronal convolucional de grafos (CNN), que aprovecha la transformada de ondícula de grafos para resolver las deficiencias de los métodos anteriores de CNN de grafos espectrales que dependen de la transformada de Fourier de grafos.
Proporcionamos otra explicación novedosa del decaimiento de la tasa de aprendizaje: una tasa de aprendizaje inicialmente grande impide que la red memorice datos ruidosos, mientras que el decaimiento de la tasa de aprendizaje mejora el aprendizaje de patrones complejos.
La adaptación de la exploración UCB al aprendizaje Q ensemble mejora los métodos anteriores como Double DQN, A3C+ en el benchmark Atari
Las primitivas motoras probabilísticas neuronales comprimen las políticas de seguimiento de la captura de movimiento en un modelo flexible capaz de imitar una sola vez y reutilizarlo como controlador de bajo nivel.
Presentamos un aumento de datos adaptativo y automatizado que funciona para múltiples tareas diferentes. 
Proponemos una nueva técnica de regularización basada en la destilación del conocimiento.
Las estrategias de regularización y optimización efectivas para los modelos lingüísticos basados en LSTM logran SOTA en PTB y WT2. 
Buscando detectores de objetos utilizando muchas medidas de selectividad diferentes; las CNN son ligeramente selectivas, pero no lo suficiente como para ser denominadas detectores de objetos.
Un método para transformar secuencias de ADN en imágenes 2D utilizando Curvas de Hilbert de relleno de espacio para mejorar las fortalezas de las CNNs
Un objetivo de agrupación aprendible para facilitar el aprendizaje de transferencia entre dominios y tareas
Método conjunto para el aprendizaje de incrustaciones multilingües con rendimiento de vanguardia para tareas multilingües y calidad monolingüe
Modelo generativo de datos temporales, que construye el estado de creencia en línea, opera en el espacio latente, hace predicciones saltantes y despliegues de estados.
Presenta un objetivo de entrenamiento teórico de la información para el co-entrenamiento y demuestra su poder en el aprendizaje no supervisado de la fonética.
Nuestros modelos generan voces cantadas sin letra ni partitura. Toman el acompañamiento como entrada y producen voces cantadas.
Aumentamos la eficacia de los analizadores de dependencias de redes neuronales con la destilación maestro-alumno.
Los autocodificadores regularizados adversamente aprenden representaciones suaves de estructuras discretas que permiten obtener resultados interesantes en la generación de textos, como la transferencia de estilos no alineados, el aprendizaje semisupervisado y la interpolación y aritmética del espacio latente.
Presentamos un método para estimar colecciones de modelos de regresión en el que cada modelo se personaliza para una sola muestra.
Una célula de red neuronal recurrente con memoria a corto plazo ampliada y un modelo RNN multitarea para problemas de secuencia en secuencia
Entrenamos en subespacios aleatorios del espacio de parámetros para medir cuántas dimensiones son realmente necesarias para encontrar una solución.
Un modelo de red neuronal de grafos duales primarios para el aprendizaje semisupervisado
Describimos dos analizadores de codificación automática de extremo a extremo para el análisis sintáctico de dependencias basado en grafos semisupervisados.
Una red Fast Weight mejorada que muestra mejores resultados en una tarea general de juguete.
Introducción de un nuevo método de optimización y su aplicación al aprendizaje profundo.
Introducción de una nueva clase de redes neuronales cuánticas para el aprendizaje de representaciones basadas en grafos en ordenadores cuánticos.
"En este trabajo, probamos la influencia de las estrategias de comunicación en los modelos mentales de los usuarios sobre una violación de datos".
Un enfoque de reconocimiento de objetivos basado en la heurística de recuento de operadores utilizada para tener en cuenta el ruido en el conjunto de datos.
la destilación de modelos de una sola tarea en un modelo multitarea mejora el rendimiento de la comprensión del lenguaje natural
Evaluación de los métodos de detección de fuera de distribución a nivel de píxel en dos nuevos conjuntos de datos del mundo real utilizando PSPNet y DeeplabV3+.
Presentamos un nuevo método adversarial para la adaptación de representaciones neuronales basado en un crítico que detecta características no discriminatorias.
Proponemos un marco estadístico y un procedimiento teóricamente consistente para la estimación de la saliencia.
Exploramos cómo un novedoso método de incrustación de conjuntos compositivos puede percibir y representar no sólo una clase, sino todo un conjunto de clases asociadas a los datos de entrada.
Presentamos un conjunto de datos, modelos y protocolos de entrenamiento + evaluación para una tarea de dibujo colaborativo que permite estudiar la generación y comprensión del lenguaje orientada a objetivos y basada en la percepción + la acción. 
Proponemos un método basado en la estrategia de entrenamiento adversarial para aprender rasgos discriminativos insesgados e invariantes a los factores de confusión, incorporando una función de pérdida que fomenta una correlación desaparecida entre el sesgo y los rasgos aprendidos.
Un enfoque modular consistente en un módulo selector de frases seguido del modelo de GC puede ser más robusto a los ataques adversarios en comparación con un modelo de GC entrenado en el contexto completo.
Incrustación de grafos multirrelacionales con variedades riemannianas y función de pérdida tipo TransE. 
Proponemos un algoritmo de metaaprendizaje para el aprendizaje continuo que puede prevenir eficazmente el problema del olvido catastrófico y apoyar el aprendizaje de transferencia hacia atrás.
Análisis de las redes convolucionales profundas en función de la disposición asociada de los hiperplanos
Proponemos un método de metamuestreo bayesiano para adaptar la incertidumbre del modelo en el metaaprendizaje
Modelo de entropía adaptable al contexto para su uso en la compresión de imágenes optimizada de extremo a extremo, que mejora significativamente el rendimiento de la compresión
Un método para el aprendizaje de mejores representaciones, que actúa como un regularizador y que, a pesar de no tener un coste computacional adicional significativo, consigue mejoras sobre las líneas de base fuertes en tareas de aprendizaje supervisado y semi-supervisado.
Empaquetamiento de la región de interés (ROI), como las regiones cancerosas identificadas en los datos de volumen 3D, empaquetamiento de las esferas dentro de la ROI, rotación de la ROI, medidas de la diferencia en el empaquetamiento de las esferas antes y después de la rotación.
La dispersión a nivel de filtro surge implícitamente en las CNNs entrenadas con enfoques de descenso de gradiente adaptativo debido a varios fenómenos, y el grado de dispersión puede verse afectado inadvertidamente por diferentes hiperparámetros aparentemente no relacionados.
Estableciendo un paralelismo con el aprendizaje humano, proponemos un marco unificado para exhibir muchas capacidades de aprendizaje permanente en las redes neuronales utilizando un pequeño número de parámetros de consolidación de pesos.
Demostramos que los priores GAN robustos funcionan mejor que los priores GAN para la reconstrucción de TC de ángulo limitado, que es un problema inverso altamente infradeterminado.
Una nueva forma de atención que funciona bien para el entorno de supervisión a distancia, y un enfoque de aprendizaje multitarea para añadir anotaciones a nivel de frase. 
Análisis del mecanismo de atención en diversas tareas de PNL.
Representar los programas como gráficos, incluyendo la semántica, ayuda a la hora de generar programas
Un nuevo método para inferir un modelo de, estimar la tasa de entropía de, y predecir procesos de tiempo continuo y eventos discretos.
Un modelo unificado para mejorar la solidez del modelo frente a múltiples tareas
Propusimos un método de aprendizaje progresivo para mejorar el aprendizaje y desentrañar las representaciones latentes en diferentes niveles de abstracción.
Aplicamos la transformación de la cópula al Cuello de Botella de Información Profundo, lo que conduce a la restauración de las propiedades de invariancia y a un espacio latente desentrañado con capacidades predictivas superiores.
Punto de referencia y método para medir la generalización composicional maximizando la divergencia de la frecuencia de los compuestos con una pequeña divergencia de la frecuencia de los átomos.
Las redes no supervisadas aprenden de abajo a arriba; las máquinas y los niños adquieren las clases visuales en órdenes diferentes
Para los problemas de clasificación con k clases, mostramos que el gradiente tiende a vivir en un subespacio diminuto, de evolución lenta, abarcado por los vectores propios correspondientes a los k mayores valores propios del hessiano.
El recuperador recurrente basado en grafos que aprende a recuperar rutas de razonamiento sobre el grafo de Wikipedia supera el estado del arte más reciente en HotpotQA en más de 14 puntos.
Introducimos una red de extracción de fetuas poco profundas con un gran campo receptivo para tareas de concordancia estéreo, que utiliza una estructura simple para obtener un mejor rendimiento.
El artículo propone una nueva capa de salida para las redes profundas que permite el uso de la retroalimentación contextual registrada para el entrenamiento. 
Clasificación de familias de proteínas mediante aprendizaje profundo
Este artículo pretende dar una respuesta empírica a la pregunta de si un modelo de respuesta de diálogo bien entrenado puede producir respuestas maliciosas.
diagnosticado todo el problema de las VAE de STOA de forma teórica y cualitativa
Proponemos un nuevo mecanismo de atención dispersa y estructurada, TVmax, que promueve la dispersión y fomenta que el peso de las ubicaciones adyacentes relacionadas sea el mismo.
Las incrustaciones de fonemas aprendidas de la red neuronal de síntesis del habla multilingüe podrían representar las relaciones de pronunciación de los fonemas entre las lenguas.
Se examinan en detalle las representaciones GAN y se encuentran conjuntos de unidades de representación que controlan la generación de conceptos semánticos en la salida.
Las redes móviles dispersas son más rápidas que las densas con los núcleos adecuados.
 Proponemos un novedoso marco de aprendizaje de inferencia de grafos mediante la construcción de relaciones de estructura para inferir etiquetas de nodos desconocidos a partir de esos nodos etiquetados de forma integral.
Dado que la seguridad se está convirtiendo en una noción crítica en el aprendizaje automático, creemos que este trabajo puede servir de base para una serie de direcciones de investigación, como los algoritmos de aprendizaje conscientes de la seguridad.
Introducimos dos enfoques para una inferencia eficiente y escalable en simuladores estocásticos para los que la densidad no puede ser evaluada directamente debido, por ejemplo, a bucles de muestreo de rechazo.
Incluso si no hay compensación en el límite de datos infinitos, el entrenamiento adversarial puede tener una peor precisión estándar incluso en un problema convexo.
Demostramos que las conexiones de acceso directo deben colocarse en patrones que minimicen las distancias entre capas durante la retropropagación, y diseñamos redes que alcanzan distancias log L utilizando L conexiones log(L).
Red Q profunda basada en gráficos para la navegación web 
Construimos un marco teórico para el desenredo débilmente supervisado y realizamos muchos experimentos para respaldar la teoría.
Proponemos por primera vez un enfoque basado en la expansión para el aprendizaje continuo sin tareas. Nuestro modelo consiste en un conjunto de expertos de redes neuronales y expande el número de expertos bajo el principio bayesiano no paramétrico.
Amortizar el impulso de Nesterov para un entrenamiento de aprendizaje profundo más robusto, ligero y rápido.
Proponemos un nuevo modelo que puede desentrañar múltiples factores dinámicos en datos secuenciales
Verificamos las propiedades deterministas y probabilísticas de las redes neuronales utilizando relajaciones no convexas sobre transformaciones visibles especificadas por modelos generativos
Un esquema eficiente de resumen de vídeo multivista avanzado para el reconocimiento de actividades en entornos de IoT.
La rectificación en las redes neuronales profundas las lleva naturalmente a favorecer una representación invariante.
La arquitectura Wave-U-Net, introducida recientemente por Stoller et al para la separación de fuentes musicales, es muy eficaz para la mejora del habla, superando el estado del arte.
Introducimos un marco novedoso para el aprendizaje a partir de la demostración que utiliza la retroalimentación humana continua; evaluamos este marco en el control continuo para vehículos autónomos.
escalar y mejorar el VQ-VAE con potentes prejuicios para generar imágenes casi realistas.
Un enfoque de búsqueda en árbol de Monte Carlo asistido por redes neuronales gráficas para el problema del viajante de comercio
El paso de mensajes direccional incorpora información direccional espacial para mejorar las redes neuronales gráficas.
Diseñamos un método simple y eficiente para el aprendizaje por refuerzo basado en imágenes, que iguala a los métodos basados en modelos del estado de la técnica en cuanto a la eficiencia de la muestra
Presentamos un novedoso y sencillo operador, el chopout, con el que se entrenan las redes neuronales, incluso en un único proceso de entrenamiento, para que las subredes truncadas rindan al máximo.
La distribución guasiana multimodal del espacio latente en los modelos GAN mejora el rendimiento y permite compensar la calidad con la diversidad.
SlowMo mejora el rendimiento de optimización y generalización de los algoritmos descentralizados de comunicación eficiente sin sacrificar la velocidad.
Planificar la estructura sintáctica de la traducción mediante códigos
 Identificamos la memorización como el sesgo inductivo de la interpolación en los autocodificadores totalmente conectados y convolucionales sobreparametrizados. 
Recuperamos de forma demostrable el span de una red neuronal profunda multicapa con estructura latente y aplicamos empíricamente algoritmos eficientes de recuperación del span para atacar las redes ofuscando las entradas.
Estudiamos el sesgo implícito del descenso de gradiente y demostramos bajo un conjunto mínimo de supuestos que la dirección de los parámetros de los modelos homogéneos converge a los puntos KKT de un problema natural de maximización de márgenes.
proponemos el LSTM convolucional tensor-train, que aprende eficientemente el LSTM convolucional de orden superior utilizando la descomposición convolucional tensor-train. 
El método propuesto es un SVM neural de extremo a extremo, que está optimizado para el aprendizaje de pocos disparos.
Una nueva estructura de CNN 4D para el aprendizaje de representaciones a nivel de vídeo, que supera a las recientes CNN 3D.
Estudiamos el problema del aprendizaje y la optimización mediante simulaciones físicas a través de la programación diferenciable, utilizando nuestra propuesta de lenguaje de programación y compilador DiffSim.
Presentamos un método para interpretar los modelos de caja negra mediante el uso de la selección retrospectiva a nivel de instancia para identificar subconjuntos mínimos de características que por sí solos bastan para justificar una decisión particular tomada por el modelo.
Proponemos un método que extrae las incertidumbres de las características en cada capa de las DNNs y las combina para detectar muestras OOD al resolver tareas de clasificación.
Aprovechamos los autocodificadores deterministas como modelos generativos proponiendo funciones de mezcla que combinan estados ocultos de pares de imágenes. Estas mezclas tienen un aspecto realista gracias a un marco adversarial.
Introducimos un espacio de características robusto y aumentado para la transmisión de datos wifi que es capaz de hacer frente a la deriva del concepto para la localización en interiores
presentamos un enfoque basado en principios para el problema de la adaptación de dominios federados, cuyo objetivo es alinear las representaciones aprendidas entre los diferentes nodos con la distribución de datos del nodo objetivo.
Las redes de cápsulas con matrices de pose aprendidas y enrutamiento EM mejoran la clasificación del estado del arte en smallNORB, mejoran la generalizabilidad a nuevos puntos de vista y la robustez de la caja blanca adversarial.  
Proponemos un marco de meta-aprendizaje que aprende una política transferible a partir de una supervisión débil para resolver tareas de síntesis con diferentes especificaciones lógicas y gramáticas.
Haz que el transformador sea fluido con atención monótona.
Aprendizaje de mapeo óptimo con deepNN entre distribuciones junto con garantías teóricas.
Un enfoque novedoso para la construcción de incrustaciones de documentos (frases) no supervisadas a partir de incrustaciones de palabras preentrenadas
Introducimos un enfoque estadístico para evaluar la robustez de las redes neuronales que proporciona una noción informativa sobre el grado de robustez de una red, en lugar de limitarse a la afirmación binaria convencional de si se viola o no una propiedad.
Mejora de la solidez de los modelos de transformadores preentrenados frente al sesgo de solapamiento léxico mediante la ampliación de las frases de entrada de los datos de entrenamiento con sus correspondientes estructuras de predicado-argumento 
La regresión de redes neuronales debe utilizar la distribución de salida Dirichlet cuando los objetivos son probabilidades para cuantificar la incertidumbre de las predicciones.
Aprendizaje de búsqueda eficiente de redes densas con poda por capas
Entrenamos modelos predictivos con información propioceptiva y demostramos que representan propiedades de objetos externos.
Un método basado en GAN para aprender características topológicas importantes de un gráfico de entrada arbitrario.
Predicción del precio de subasta de las matrículas de vehículos en Hong Kong con una red neuronal recurrente profunda, basada en los caracteres de las matrículas.
Presentamos un nuevo modelo latente profundo de imágenes naturales que puede ser entrenado a partir de conjuntos de datos no etiquetados y puede ser utilizado para resolver varias tareas de restauración de imágenes.
Puntúe automáticamente los ensayos sobre datos dispersos comparando los nuevos ensayos con muestras conocidas con la red de árbitros. 
Combinamos el marco de la red de concordancia para el aprendizaje de unos pocos disparos en un modelo multietiqueta a gran escala para la clasificación de secuencias genómicas.
La aplicación de la función softmax en el entrenamiento conduce a una supervisión indirecta e inesperada de las características. Proponemos un nuevo objetivo de entrenamiento para inducir explícitamente regiones de características densas para muestras localmente suficientes para beneficiar la robustez adversarial.
Se examinan en detalle las representaciones GAN y se encuentran conjuntos de unidades de representación que controlan la generación de conceptos semánticos en la salida.
Vecinos más cercanos a nivel de píxel utilizados para generar imágenes múltiples a partir de antecedentes incompletos, como imágenes de baja resolución, normales de superficie, bordes, etc.
Proporcionamos un procedimiento de entrenamiento adversarial rápido y basado en principios con garantías de rendimiento computacional y estadístico.
Descomponemos la brecha entre la log-verosimilitud marginal y el límite inferior de la evidencia y estudiamos el efecto de la posterior aproximada sobre la verdadera distribución posterior en VAE.
Uso de conjuntos y pseudoetiquetas para la agrupación no supervisada 
Aprendizaje eficiente de diccionarios mediante la minimización de L1 a través de un novedoso análisis de la geometría no convexa y no lisa.
Proporcionamos el primer análisis teórico de la recuperación garantizada de las redes neuronales de una capa oculta bajo pérdida de entropía cruzada para problemas de clasificación.
Nuestro códec de redes neuronales (que se basa en la codificación por transformación y la agrupación) permite una compresión transparente de baja complejidad y alta eficiencia de las redes neuronales.
Aceleramos la inferencia segura de la DNN en entornos de ejecución de confianza (por un factor 4x-20x) externalizando selectivamente el cálculo de las capas lineales a un coprocesador más rápido pero no fiable.
Este trabajo propone un método eficaz para comprimir redes neuronales basado en resultados recientes de la teoría de la información.
Un marco general para crear redes neuronales de grafos covariantes
En este trabajo, proponemos un método de poda basado en la regularización tridimensional para acelerar la 3D-CNN.
Una propuesta práctica para una tecnología de PNL más ética y receptiva, operacionalizando la transparencia de los datos de prueba y entrenamiento
Descubrir la estructura de los modelos causales funcionales con redes neuronales generativas
En la poda de redes, el ajuste fino de un modelo podado sólo da un rendimiento comparable o peor que el entrenamiento desde cero. Esto aboga por un replanteamiento de los algoritmos de poda existentes.
Este artículo introduce la teoría del valor extremo en k-means para medir la similitud y propone un nuevo algoritmo llamado Extreme Value k-means para la agrupación.
Proponemos la Tendencia RL para resolver eficientemente tareas orientadas a objetivos con un gran espacio de estados utilizando el aprendizaje curricular automatizado y la recompensa de conformación discriminativa, que tiene el potencial de abordar tareas de manipulación de robots con percepción.
Presentamos los programas de escena, una representación estructurada de la escena que captura tanto la apariencia de los objetos de bajo nivel como la regularidad de alto nivel en la escena.
Compresión de redes neuronales que mejora las técnicas de aproximación de bajo rango del estado de la técnica y es complementaria a la mayoría de otras técnicas de compresión. 
Presentamos una técnica de atribución que aprovecha las normas que inducen la dispersión para lograr la interpretabilidad.
Utilizamos la dispersión para mejorar la complejidad computacional de los métodos de reducción de la varianza.
Proponemos un novedoso marco basado en la VAE que aprende de los datos parcialmente observados para la imputación y la generación. 
Perspectivas sobre el desafío de la adaptación del dominio, al predecir la intención del usuario en el correo electrónico empresarial.
Proponemos HiPPO, un algoritmo estable de Aprendizaje Jerárquico por Refuerzo que puede entrenar varios niveles de la jerarquía simultáneamente, dando un buen rendimiento tanto en el descubrimiento de habilidades como en la adaptación.
Damos un paso hacia la medición de la dificultad de la tarea de aprendizaje y demostramos que, en la práctica, el rendimiento depende en gran medida de la correspondencia entre la representación de la información y el modelo que la interpreta.
Combinamos procesos gaussianos multisalida con redes Q recurrentes profundas para aprender los tratamientos óptimos para la sepsis y mostramos un rendimiento mejorado con respecto a los métodos estándar de aprendizaje de refuerzo profundo,
Desarrollamos un nuevo modelo generativo profundo para el aprendizaje semi-supervisado y proponemos una nueva entropía cruzada Max-Min para el entrenamiento de CNNs.
Proponemos una sencilla técnica de aleatorización para mejorar la generalización en el aprendizaje profundo por refuerzo en tareas con varios patrones visuales no vistos.
Describe un estudio que investiga la interferencia, la transferencia y la retención de múltiples mapeos con el mismo conjunto de botones acordes
Verificación formal de una especificación sobre la hipersensibilidad de la predicción de un modelo mediante la propagación de límites por intervalos
Proponemos un nuevo formato de 8 bits que elimina la necesidad de escalar las pérdidas, el redondeo estocástico y otras técnicas de baja precisión
Nuevo algoritmo para el aprendizaje incremental de la VAE con arquitectura fija
MAML es genial, pero tiene muchos problemas, nosotros resolvemos muchos de esos problemas y como resultado aprendemos la mayoría de los hiperparámetros de extremo a extremo, aceleramos el entrenamiento y la inferencia y establecemos un nuevo SOTA en un aprendizaje de pocos disparos
Detección de comunidades solapadas en grafos mediante redes neuronales de grafos
Desmentimos empíricamente una hipótesis fundamental de la estrategia de reparto de pesos ampliamente adoptada en la búsqueda de arquitecturas neuronales y explicamos por qué los algoritmos NAS de última generación tienen un rendimiento similar al de la búsqueda aleatoria.
En este trabajo utilizamos la distancia de Wasserstein rebanada para dar forma a la distribución latente de un autocodificador en cualquier distribución previa muestreable. 
Introducimos una clase de modelos generativos que aprenden de forma fiable la dinámica hamiltoniana a partir de observaciones de alta dimensión. El hamiltoniano aprendido puede aplicarse al modelado de secuencias o como flujo normalizador.
En este breve artículo, presentamos brevemente las ventajas de utilizar la planificación de la IA en la migración a la nube, un prototipo preliminar, así como los desafíos que requiere la atención de la sociedad de planificación y programación.
Un límite superior general del riesgo del dominio objetivo que refleja el papel de la complejidad de la incrustación.
Para pronosticar series temporales estacionarias multivariadas, aprendemos incrustaciones que contienen características contextuales dentro de una RNN; aplicamos el marco en datos de transporte público
Investigamos un marco para el descubrimiento: curar una gran colección de predicciones, que se utilizan para construir la representación del agente en dominios parcialmente observables.
Una estrategia de inferencia de geolocalización global con una estrategia de malla novedosa y que demuestra la incorporación de información adicional puede utilizarse para mejorar el rendimiento general de un modelo de inferencia de geolocalización.
Técnica de aprendizaje de modelos generativos profundos con variables latentes compartidas, aplicada a Omniglot con un decodificador PixelCNN.
En este trabajo presentamos una arquitectura de lectura agnóstica para la integración dinámica del conocimiento de fondo explícito en modelos NLU neuronales. 
Técnica de precisión dinámica para entrenar redes neuronales profundas
Introducimos la función de activación ISRLU que es continuamente diferenciable y más rápida que la ELU. La ISRU relacionada sustituye a tanh y sigmoide.
Exploramos el problema de la generalización composicional y proponemos un medio para dotar a las arquitecturas de redes neuronales de la capacidad de componerse para resolver estos problemas.
Ampliamos el método del cuello de botella de la información al entorno multivista no supervisado y mostramos los resultados más avanzados en conjuntos de datos estándar
Describimos un algoritmo de aprendizaje biológicamente plausible para redes recurrentes de punto fijo sin pesos ligados
Entrenamos un modelo generativo 3D de formas a partir de imágenes naturales de forma totalmente no supervisada.
Demostramos que un esquema de ataque adversarial de caja negra relativamente sencillo que utiliza la optimización bayesiana y el muestreo de dimensiones es preferible a los métodos existentes cuando el número de consultas disponibles es muy bajo.
Revisamos la sencilla idea de podar las conexiones de las DNNs a través de la regularización $\ell_1$ logrando resultados de vanguardia en múltiples conjuntos de datos con garantías teóricas.
Un método no paramétrico para medir los momentos de error de los regresores sin verdad de fondo puede utilizarse con regresores sesgados
Caracterización de redes neuronales cnvolucionales para la detección y comprensión del clasificador de fondo.
Podemos aprender restricciones de alta dimensión a partir de demostraciones muestreando trayectorias inseguras y aprovechando una parametrización de restricciones conocida.
Aprendizaje paramétrico de pliegues con redes neuronales en un marco geométrico 
Proponemos una generalización de los contadores de visitas que evalúan el valor exploratorio propagado sobre las trayectorias, lo que permite una exploración eficiente para el RL sin modelo
Proponemos una nueva combinación de estrategia de evolución y aprendizaje profundo por refuerzo que toma lo mejor de ambos mundos
Una comparación empírica de las redes profundas bayesianas para el muestreo de Thompson
Entender cómo las etiquetas de clase ayudan al entrenamiento de GAN. Proponer una nueva métrica de evaluación para los modelos generativos. 
Algoritmo iterativo rápido para equilibrar la energía de una red manteniéndose en la misma clase de equivalencia funcional
Encontramos entornos en los que los agentes SOTA entrenados en tareas de navegación muestran fallos extremos que sugieren fallos en la generalización.
Estimación bayesiana robusta mediante la máxima discrepancia media
Creamos un estimador insesgado para la probabilidad logarítmica de los modelos de variables latentes, extendiendo dichos modelos a un mayor ámbito de aplicaciones.
Los lotes más pequeños pueden superar a los lotes muy grandes en el conjunto de pruebas bajo presupuestos de pasos constantes y con programas de tasa de aprendizaje debidamente ajustados.
Mejor algoritmo de aprendizaje profundo por refuerzo para aproximarse a la minimización del arrepentimiento contrafactual
Genera datos nunca vistos durante el entrenamiento a partir de una condición deseada 
Analizamos el descenso de gradiente para redes neuronales lineales profundas, proporcionando una garantía de convergencia al óptimo global a un ritmo lineal.
Una capa que modela conectomas locales aleatorios en la corteza dentro de redes profundas capaces de aprender invariancias generales no paramétricas a partir de los propios datos.
Introducimos un marco eficaz y general para incorporar información condicionante a los modelos generativos basados en la inferencia.
En este artículo se describen tres técnicas que permiten a un planificador sin seguimiento y con limitaciones computacionales considerar un pequeño número de actividades alternativas basadas en la disponibilidad de recursos.
Utilizamos modificaciones sencillas y biológicamente motivadas de las técnicas de aprendizaje estándar para lograr un rendimiento de vanguardia en los puntos de referencia de olvido catastrófico.
Uso de técnicas de aprendizaje profundo en tareas relacionadas con la voz cantada.
Generación de idiomas mediante modelos seq2seq que producen incrustaciones de palabras en lugar de una distribución basada en softmax sobre el vocabulario en cada paso, lo que permite un entrenamiento mucho más rápido manteniendo la calidad de la generación
Resultados de forma cerrada para el aprendizaje profundo en el límite de desacoplamiento de capas aplicable a las redes residuales
 En este trabajo, se proporciona un nuevo método que llamamos Ataque Inicial Centrado (CIA). Asegura por construcción que la perturbación máxima sea menor que un umbral fijado de antemano, sin el proceso de recorte.
Respuesta a una amplia clase de consultas lógicas sobre grafos de conocimiento con incrustaciones de cajas en el espacio vectorial
Abordamos la optimización de hiperparámetros totalmente paralela con procesos puntuales determinantes. 
Un enfoque espectral multinivel para mejorar la calidad y la escalabilidad de la incrustación de gráficos sin supervisión.
Un nuevo modelo generativo para datos estructurados discretos. El atributo perezoso estocástico propuesto convierte la comprobación semántica fuera de línea en una guía en línea para la decodificación estocástica, que aborda eficazmente las restricciones en la sintaxis y la semántica, y también logra un rendimiento superior
los modelos propuestos con conocimiento externo mejoran aún más el estado del arte en el conjunto de datos SNLI.
Enfoque para mejorar la precisión de la predicción mediante el aprendizaje de características profundas sobre imágenes de escenas vecinas en el análisis de imágenes de escenas satelitales.
Proponemos redes de grafos diferenciales con conciencia física diseñadas para aprender eficazmente las diferencias espaciales para modelar dinámicas escasamente observadas.
Aprendizaje de jerarquías funcionalmente descompuestas para tareas de navegación continua
El artículo describe un nuevo algoritmo mediante el cual se pueden inferir patrones de correspondencia de sonidos para múltiples idiomas.
Una regla de aprendizaje biológicamente plausible para el entrenamiento de redes neuronales recurrentes
Un nuevo método de aprendizaje no supervisado de representaciones en grafos, basado en la maximización de la información mutua entre las representaciones locales y globales de un grafo. Resultados de última generación, competitivos con el aprendizaje supervisado.
Un modelo hacia atrás de (estado, acción) anterior dado el siguiente estado, es decir, P(s_t, a_t | s_{t+1}), puede utilizarse para simular trayectorias adicionales que terminen en estados de interés. Mejora la eficacia del aprendizaje de la RL.
Este trabajo trata sobre el método basado en tensores para el entrenamiento de la representación de preposiciones.
Utilizamos la dinámica de tiempo continuo para definir un modelo generativo con verosimilitudes exactas y un muestreo eficiente que está parametrizado por redes neuronales no restringidas.
Un nuevo enfoque basado en el emparejamiento de características no adversariales para entrenar modelos generativos que logra resultados de vanguardia.
Una arquitectura novedosa para la clasificación de pocos disparos capaz de hacer frente a la incertidumbre.
Demostramos que las CNNs y las ResNets con las primas apropiadas sobre los parámetros son procesos gaussianos en el límite de infinitos filtros convolucionales.
Presentamos una metodología de diseño de extremo a extremo para el despliegue eficiente del aprendizaje profundo. 
Acelerar la optimización distribuida explotando los rezagos.
Gracias a un novedoso renderizador diferenciable, proponemos una nueva métrica que tiene implicaciones en el mundo real para evaluar los algoritmos de aprendizaje automático adversario, resolviendo la falta de realismo de la métrica existente basada en las normas de los píxeles.
Demostramos que la arquitectura Transformer y la GPU Neural son Turing completas.
Utilizamos el VAE para capturar la característica de forma para la evaluación automática de la segmentación
Investigamos los valores propios de las capas lineales en las redes profundas y mostramos que las distribuciones desarrollan un comportamiento de cola pesada durante el entrenamiento.
Proponemos un nuevo tipo de módulo de atención entrenable de extremo a extremo, que aplica equilibrios de peso globales entre capas utilizando RNN copropagadas con CNN.
Las características autogeneradas por el modelo bio-mimético MothNet mejoran significativamente la precisión de las pruebas de los métodos ML estándar en MNIST vectorizado. Las características generadas por MothNet también superan a los generadores de características estándar.
Al centrarse más en las predicciones finales en los predictores de cualquier tiempo (como los muy recientes Multi-Scale-DenseNets), hacemos que los modelos pequeños de cualquier tiempo superen a los grandes que no tienen ese enfoque. 
Proponemos un procedimiento de aprendizaje eficiente en cuanto a memoria que explota la reversibilidad de las capas de la red para permitir el diseño basado en datos para la obtención de imágenes computacionales a gran escala.
Neuron as an Agent (NaaA) nos permite entrenar la comunicación entre varios agentes sin necesidad de un tercero de confianza.
Un nuevo método de preentrenamiento que establece nuevos resultados del estado del arte en las pruebas de referencia GLUE, RACE y SQuAD y que tiene menos parámetros en comparación con BERT-large. 
Aprendizaje profundo sobre datos tabulares estructurados utilizando la incrustación bidimensional de palabras con un modelo CNN preentrenado de ImageNet ajustado.
conexiones entre la codificación predictiva y las VAE + nuevas fronteras
Nuevas variantes de métodos de optimización que combinan las ventajas de los métodos adaptativos y no adaptativos.
En este trabajo, propusimos un nuevo algoritmo, GenDICE, para la estimación de la corrección de la distribución estacionaria general, que puede manejar tanto la evaluación descontada como el promedio de la política en múltiples muestras de comportamiento.
Una exploración empírica y visual intuitiva de las propiedades de generalización de las redes neuronales profundas.
Utilizamos la convolución para que las redes neuronales se comporten más como sistemas simbólicos.
Formulación analítica de los fenómenos de ondas estacionarias ecuatoriales: Aplicación a QBO y ENSO
Proponemos entrenar una red neuronal invertible para cada clase para realizar un aprendizaje continuo clase a clase.
Un novedoso conjunto basado en la recuperación y la generación para sistemas de conversación de dominio abierto.
Comprender la transferibilidad desde la perspectiva de la mejora de la generalización, la optimización y la viabilidad de la transferibilidad.
Demostramos que existen redes ReLU cuyos parámetros están determinados casi exclusivamente por la función que implementan.
Proponemos una red de modulación descendente para aplicaciones de aprendizaje multitarea con varias ventajas sobre los esquemas actuales.    
Nuevo algoritmo de agrupación de datos de series temporales basado en las características de los sistemas dinámicos.
Un método para fomentar las atribuciones de características axiomáticas de un modelo profundo para que coincida con la intuición humana.
Proponemos LSTMs de alto rendimiento con pesos binarios/internos, que pueden reducir en gran medida la complejidad de la implementación
Abordamos el problema del reconocimiento no supervisado de objetos de pocos disparos, en el que todas las imágenes de entrenamiento están sin etiquetar y no comparten clases con las imágenes de prueba.
Ataques de caja negra basados en consultas a redes neuronales profundas con tasas de éxito adversarias que coinciden con los ataques de caja blanca
Convertimos los subgráficos en imágenes estructuradas y los clasificamos utilizando 1. aprendizaje profundo y 2. aprendizaje de transferencia (Caffe) y logramos resultados sorprendentes.
Algoritmo basado en el autoensamblaje para la adaptación del dominio visual, resultados del estado del arte, ganó el desafío de adaptación del dominio de clasificación de imágenes VisDA-2017.
Una VAE-variante que puede crear diversas imágenes correspondientes a nuevos "conceptos" concretos o abstractos descritos mediante vectores de atributos.
Proponemos un método basado en un modelo llamado "Búsqueda con estimaciones de valor amortizado" (SAVE) que aprovecha tanto la experiencia real como la planificada combinando el aprendizaje Q con la búsqueda en árbol de Monte-Carlo, logrando un fuerte rendimiento con presupuestos de búsqueda muy pequeños.
Una breve prueba de la equivalencia del aprendizaje Q suave y los gradientes de política.
Proponemos un algoritmo de transferencia de políticas que puede superar grandes y desafiantes discrepancias en la dinámica del sistema, como la latencia, el error de modelado del actuador, etc.
Aprenda a cuantificar la señal de voz y a aplicar algoritmos que requieren entradas discretas a los datos de audio, como el BERT.
Desarrollamos el Agente Jerárquico con Autojuego (HASP), un enfoque de aprendizaje para obtener políticas estructuradas jerárquicamente que pueden alcanzar un alto rendimiento que el autojuego convencional en juegos estratégicos competitivos en tiempo real.
Incrustaciones de palabras de entrada de capacidad variable y SOTA en WikiText-103, referencias de mil millones de palabras.
un modelo profundo de mezcla multivariante de gaussianos para la regresión de cajas delimitadoras bajo oclusión
Sustituimos la restricción de la bola Lp por las celdas de Voronoi de los datos de entrenamiento para producir modelos más robustos. 
Proponemos aprender una política más generalizada para las tareas de navegación basadas en el lenguaje natural mediante el aprendizaje multitarea agnóstico del entorno.
proponemos utilizar los baricentros de Wasserstein para el ensamblaje de modelos semánticos
Clasificación de audio eficiente mediante aprendizaje multitarea y autosupervisión
Proponer los primeros métodos para optimizar exactamente la distribución softmax utilizando el gradiente estocástico con un tiempo de ejecución independiente del número de clases o puntos de datos.
Utilizar la búsqueda de árboles de Monte Carlo y los homoglifos para generar muestras adversas indistinguibles en datos de texto
Aprender a convertir un boceto dibujado a mano en un programa de alto nivel
Este trabajo utiliza principios del campo de la calibración en el aprendizaje automático sobre los logits de una red neuronal para defenderse de los ataques adversarios
Entrenamos conjuntamente un modelo multilingüe de saltos de línea y un modelo de similitud de oraciones multilingües para aprender incrustaciones de texto multilingüe de alta calidad que se comportan bien en el escenario de bajos recursos.
Hemos propuesto un modelo generativo flexible que aprende de forma estable minimizando directamente la distancia empírica exacta de Wasserstein.
Un estudio de cómo los diferentes componentes del proceso NAS contribuyen a la precisión final. Además, una evaluación comparativa de 8 métodos en 5 conjuntos de datos.
Encontrar correspondencias entre dominios mediante la realización de iteraciones de concordancia/mapeo
un modelo temático neural mejorado por la dispersión basado en la VAE
Keras para redes neuronales infinitas.
Presentamos NLProlog, un sistema que realiza razonamientos basados en reglas sobre el lenguaje natural aprovechando incrustaciones de oraciones preentrenadas y afinando con estrategias de evolución, y lo aplicamos a dos tareas de respuesta a preguntas de varios saltos.
Proponemos el Aprendizaje Ponderado por Fidelidad, un enfoque semi-supervisado de profesor-estudiante para el entrenamiento de redes neuronales utilizando datos débilmente etiquetados.
Demostramos que el descenso de gradiente es robusto a la corrupción de etiquetas a pesar de la sobreparametrización bajo un modelo de conjunto de datos rico.
Presentamos un nuevo esquema de codificación de pesos que permite una alta relación de compresión y una rápida conversión de matriz dispersa a densa.
Se ha mejorado una red de inpainting de píxeles basada en GAN para la recuperación de imágenes sísmicas comprimidas y se ha propuesto una recomendación de muestreo no uniforme, que puede aplicarse fácilmente a dominios médicos y de otro tipo para la técnica de detección compresiva.
Desarrollamos el Decodificador de Acciones Simplificado, un algoritmo MARL simple que supera el SOTA anterior en Hanabi por un gran margen en juegos de 2 a 5 jugadores.
Reconocimiento óptico de caracteres entrenable de extremo a extremo en documentos impresos; logramos resultados de vanguardia, superando a Tesseract4 en conjuntos de datos de referencia tanto en términos de precisión como de tiempo de ejecución, utilizando un enfoque puramente basado en la visión por ordenador.
NovoGrad - un método SGD adaptativo con normalización de gradiente por capas y decaimiento de peso desacoplado. 
Mejora de la síntesis de audio combinando el DSP interpretable con el aprendizaje de extremo a extremo.
Un enfoque novedoso para la clasificación de grafos basado en redes convolucionales de grafos espectrales y su extensión a multigrafos con relaciones aprendibles y estructura jerárquica. Mostramos resultados del estado del arte en conjuntos de datos químicos, sociales y de imágenes.
Mostramos cómo realizar con éxito ataques de puerta trasera sin cambiar las etiquetas de entrenamiento.
Encontramos que las redes profundas que generalizan mal son más dependientes de las direcciones únicas que las que generalizan bien, y evaluamos el impacto del abandono y la normalización del lote, así como la selectividad de la clase en la dependencia de la dirección única.
En lugar de aprender los parámetros de un modelo gráfico a partir de los datos, aprende una red de inferencia que pueda responder a las mismas consultas probabilísticas.
Demostramos cómo los bloques residuales pueden verse como pasos de Gauss-Newton; proponemos un nuevo bloque residual que explota la información de segundo orden.
Introducimos un modelo de aprendizaje automático que utiliza características independientes del dominio para estimar la criticidad del estado actual para causar un estado indeseable conocido.
Desarrollamos un marco para encontrar representaciones internas modulares en modelos generativos y manipularlas para generar ejemplos contrafactuales.
Los pesos plásticos hebbianos pueden comportarse como un almacenamiento de memoria episódica comprimida en las redes neuronales; mejorando su capacidad para aliviar el olvido catastrófico en el aprendizaje continuo.
Desarrollamos un enfoque para parcelar una capa oculta en DNN en grupos funcionalmente relacionados, aplicando coclustering espectral en las puntuaciones de atribución de las neuronas ocultas.
Despliegue de aplicaciones de clasificación de textos y análisis de sentimientos para inglés y chino en un chip acelerador de CNN de 300 mW para escenarios de aplicación en el dispositivo.
Desarrollamos VAE donde el codificador toma un vector de parámetros del modelo como entrada, por lo que podemos hacer inferencia rápida para muchos modelos
Secret es un método de transferencia para RL basado en la asignación de créditos.
Trabajando hacia modelos de grafos de conocimiento generativos para estimar mejor la incertidumbre predictiva en la inferencia de conocimiento. 
Un sistema dinámico basado en el flujo de gradientes para el modelado generativo invertible
Introducimos una capa de memoria eficiente que puede aprender la representación y el grosor de los gráficos de entrada simultáneamente sin depender del paso de mensajes.
Un novedoso esquema de codificación que utiliza {-1, +1} para descomponer las QNNs en redes binarias de múltiples ramas, en el que utilizamos operaciones a nivel de bits (xnor y bitcount) para lograr la compresión del modelo, la aceleración computacional y el ahorro de recursos. 
Proponemos una forma novedosa de incorporar la información condicional de la imagen en el discriminador de los GANs utilizando la fusión de características que puede ser utilizada para tareas de predicción estructurada.
Proponemos un algoritmo para el aprendizaje de habilidades útiles sin una función de recompensa, y mostramos cómo estas habilidades pueden utilizarse para resolver tareas posteriores.
El artículo resuelve un problema de ambigüedad léxica causado por la homonimia en la traducción neural mediante BERT.
Este trabajo se centra en la generación sintética de datos de movilidad humana en zonas urbanas utilizando GANs. 
Este trabajo propone un esquema de codificación eficaz para redes neuronales que codifica un conjunto aleatorio de pesos de una distribución variacional.
Mediante el análisis de un algoritmo que minimiza una pérdida no convexa, mostramos que se puede eliminar todo el ruido de una imagen, excepto una pequeña fracción, utilizando una red neuronal profunda basada en un previo generativo.
La arquitectura multitarea a gran escala resuelve ImageNet y la traducción conjuntamente y muestra el aprendizaje de transferencia.
Enfoque inspirado en la filosofía continental para aprender con pocos datos.
Aprender a sintetizar audio en bruto con GANs
Un nuevo método de adaptación de dominios para alinear los manifiestos de los dominios de origen y destino utilizando la propagación de etiquetas para mejorar la precisión.
Este trabajo propone un nuevo método para el aprendizaje de redes neuronales en entornos de bandidos en línea mediante la marginación sobre la última capa
Demostramos en la teoría y en la práctica que la combinación de múltiples métodos de explicación para la DNN beneficia a la explicación.
Aprendizaje con datos de entrenamiento limitados mediante la explotación de instancias "útiles" de una rica fuente de datos.  
Aumentamos la cantidad de supervisión de trazos que es posible utilizar al entrenar arquitecturas de máquinas neuronales totalmente diferenciables.
Proponemos redes cuantizadas bayesianas, para las que aprendemos una distribución posterior sobre sus parámetros cuantizados.
El entrenamiento adversarial en cascada + el aprendizaje de similitud de bajo nivel mejoran la robustez frente a los ataques de caja blanca y de caja negra.
Demostramos que, en contra de la sabiduría popular, el problema de la explosión de gradientes no ha sido resuelto y que limita la profundidad a la que se pueden entrenar eficazmente los MLP. Mostramos por qué los gradientes explotan y cómo los maneja ResNet.
Hemos comprobado que el entrenamiento adversarial no sólo acelera el entrenamiento del GAN, sino que también aumenta la calidad de la imagen
Un método para binarizar tanto los pesos como las activaciones de una red neuronal profunda que es eficiente en el cálculo y el uso de la memoria y tiene un rendimiento mejor que el estado de la técnica.
Presentamos Good-Ennough Model Spaces (GEMS), un marco para el aprendizaje de un modelo agregado sobre nodos distribuidos dentro de un pequeño número de rondas de comunicación.
Proponemos un nuevo autocodificador basado en la distancia Wasserstein, que mejora las propiedades de muestreo de la VAE.
Preservación de la privacidad diferencial en el aprendizaje adversarial con robustez demostrable a los ejemplos adversarios
Construimos y exploramos automáticamente un pequeño Proceso de Decisión de Markov abstracto, lo que nos permite alcanzar resultados de vanguardia en Montezuma's Revenge, Pitfall! y Private Eye por un margen significativo.
Demostramos que el control KL de un previo preentrenado puede permitir que los modelos RL aprendan a partir de un lote estático de datos recogidos, sin la capacidad de explorar en línea en el entorno.
Transferencia de políticas de un solo episodio en una familia de entornos con dinámicas relacionadas, a través de un sondeo optimizado para la inferencia rápida de variables latentes y la ejecución inmediata de una política universal.
Proponemos un modelo de codificador-decodificador basado en redes convolucionales gráficas con atención secuencial para sistemas de diálogo orientados a objetivos.
Mecanismo de incrustación de secuencias de nodos que captura tanto las propiedades del gráfico como las del texto.
Este trabajo pretende aprovechar las buenas propiedades de las características visuales robustas como SIFT para renovar las arquitecturas de las CNN hacia una mayor precisión y robustez.
La teoría predice la transición de fase entre los valores no aprendibles y aprendibles de beta para el objetivo Cuello de Botella de Información
Generar imágenes de entrenamiento corruptas que sean imperceptibles pero que cambien el comportamiento de la CNN en un objetivo durante cualquier nuevo entrenamiento.
Damos un algoritmo para el aprendizaje de una red neuronal de dos capas con distribución de entrada simétrica. 
Demostramos que el entrenamiento de una red de estudiantes y profesores de forma iterativa, en lugar de conjunta, puede producir estrategias de enseñanza emergentes e interpretables.
Análisis no asintótico de SGD y SVRG, mostrando la fuerza de cada algoritmo en la velocidad de convergencia y el coste computacional, tanto en entornos sub-parametrizados como sobre-parametrizados.
Examinamos sistemáticamente por qué la destilación de conocimientos es crucial para el entrenamiento de los modelos de traducción no autorregresiva (NAT), y proponemos métodos para mejorar aún más los datos destilados para que se ajusten mejor a la capacidad de un modelo NAT.
Conseguimos estabilizar los transformadores para el entrenamiento en el entorno RL y demostramos una gran mejora respecto a los LSTM en DMLab-30, ajustándose a una arquitectura de memoria externa.
Inspirados en la variabilidad de ensayo a ensayo en el cerebro que puede resultar de múltiples fuentes de ruido, introducimos la variabilidad a través del ruido en el marco de la destilación del conocimiento y estudiamos su efecto en la generalización y la robustez.
Introducimos un novedoso enfoque de extremo a extremo para aprender a agrupar en ausencia de ejemplos etiquetados. Definimos una función de pérdida diferenciable equivalente a los cortes normalizados esperados.
Presentamos varios conjuntos de datos para el reconocimiento óptico de caracteres cirílicos y un método para su reconocimiento
Proponemos una forma no supervisada de aprender múltiples incrustaciones para oraciones y frases 
Muestra de algoritmos eficientes para adaptar un modelo de texto a voz a un nuevo estilo de voz con el rendimiento más avanzado.
Este artículo presenta un marco probabilístico para la clasificación de imágenes k-shot que logra resultados de última generación
Investigación sobre la combinación de redes neuronales recurrentes y la repetición de la experiencia que conduce a un agente de última generación tanto en Atari-57 como en DMLab-30 utilizando un único conjunto de hiperparámetros.
Nuestra combinación de aprendizaje multitarea y autoatención, entrenando al modelo para que atienda a los padres en un árbol sintáctico de análisis sintáctico, logra resultados SRL de vanguardia en CoNLL-2005 y CoNLL-2012 para modelos que utilizan predicciones.
Proponemos un nuevo módulo que mejora cualquier arquitectura tipo ResNet al imponer un comportamiento "selectivo de canales" a las capas convolucionales
Una teoría y un marco algorítmico para la predicción bajo el cambio de distribución, incluyendo la estimación del efecto causal y la adaptación del dominio
Estudiamos los conjuntos profundos a través de la lente del paisaje de pérdidas y el espacio de predicciones, demostrando que el poder de descorrelación de las inicializaciones aleatorias no es igualado por el muestreo del subespacio que sólo explora un único modo.
¿Podemos confiar en nuestros modelos de aprendizaje profundo? Un marco para medir y mejorar la confianza de un modelo de aprendizaje profundo durante el entrenamiento.
Un enfoque de RL basado en modelos que utiliza una penalización de incertidumbre diferenciable para aprender políticas de conducción a partir de datos puramente observacionales.
Adaptación de las predicciones de los modelos de secuencia (como los LDS y los RNN) mediante un código latente explícito.
Proponemos un novedoso método de entrenamiento adversarial con adaptación de dominio que mejora significativamente la capacidad de generalización sobre ejemplos adversariales de diferentes ataques.
Este artículo propone un novedoso transformador ligero para el modelado del lenguaje a nivel de caracteres, utilizando operaciones de grupo.
Un enfoque estable de entrenamiento adversarial de dominio para una adaptación de dominio robusta y completa
Utilizamos el aprendizaje automático para generar sinónimos para grandes taxonomías de compras.
MOHART utiliza un mecanismo de autoatención para realizar un razonamiento relacional en el seguimiento de múltiples objetos.
Investigamos y proponemos soluciones para dos retos en el aprendizaje por refuerzo: (a) el aprendizaje actor-crítico eficiente con la repetición de la experiencia (b) la estabilidad del aprendizaje de las políticas muy fuera de lugar.
Proponemos un algoritmo de selección del estimador de gradiente con el objetivo de mejorar la eficiencia de la optimización.
Estudiamos el problema de aliviar el problema de la inestabilidad en el procedimiento de entrenamiento del GAN mediante un nuevo diseño de arquitectura, con garantías teóricas.
Este trabajo demuestra la no aceleración de la SGD de Nesterov con cualquier hiperparámetro, y propone un nuevo algoritmo que acelera de forma demostrable la SGD en el entorno sobreparametrizado.
Una capa feedforward para incorporar la suavidad estructurada en un modelo de aprendizaje profundo
No deforme sus circunvoluciones, deforme sus núcleos.
Presentamos un método para aprender modelos de incrustación de secuencias de proteínas utilizando información estructural en forma de similitud estructural global entre proteínas y dentro de los contactos residuo-residuo de la proteína.
Considerando el proceso de optimización de redes neuronales como un problema de selección de modelos, introducimos un método de normalización biológicamente plausible que extrae la regularidad estadística bajo el principio MDL para abordar el problema de los datos desequilibrados y limitados.
"Modelado generativo sin necesidad de entrenamiento adversarial"
Proponemos un método de aprendizaje por imitación para aprender a partir de demostraciones de diversa calidad recogidas por demostradores con diferente nivel de experiencia.
Describir una heurística semántica que se basa en una descripción de servicio OWL-S y utiliza medidas de distancia de palabras y frases para evaluar la utilidad de los servicios para un objetivo determinado. 
Red convolucional gráfica basada en la topología (GCN)
Las redes neuronales artificiales desarrollaron las mismas estructuras presentes en los sistemas olfativos de moscas y ratones tras ser entrenadas para clasificar olores
La regularización suave sobre el gráfico de la muestra para la traducción de imagen a imagen no emparejada da como resultado una consistencia significativamente mejorada
Una red neuronal de convolución para la correspondencia estereoscópica multivista cuyo diseño se inspira en las mejores prácticas de los enfoques tradicionales basados en la geometría
Aumentamos el aprendizaje de políticas sin modelo con una función de recompensa sustitutiva a nivel de secuencia y una bonificación de visitas basada en el recuento, y demostramos su eficacia en el régimen de grandes lotes y bajas rondas que se observa en el diseño de secuencias de ADN y proteínas.
Utilizamos el aprendizaje por refuerzo para entrenar a un agente para que resuelva un conjunto de tareas de aritmética visual utilizando módulos perceptivos preentrenados y transformaciones de las representaciones internas creadas por esos módulos.
Se propone un nuevo algoritmo de RL llamado Diferenciación de Políticas Interiores para aprender una colección de políticas diversas para una tarea primal dada.
Una evaluación empírica de las redes generativas adversariales
Predicción de valores de atributos numéricos asociados a entidades en bases de conocimiento.
Proponemos procedimientos para evaluar y reforzar la alineación de la incrustación contextual y demostramos que tanto mejoran la transferencia XNLI de BERT multilingüe como aportan información útil sobre el modelo.
Usamos redes neuronales entrenadas para la eliminación de ruido de las imágenes como priores "plug-and-play" en algoritmos de minimización de energía para problemas de reconstrucción de imágenes con convergencia demostrable.
Proponemos un método novedoso para calibrar los modelos de incrustación de grafos de conocimiento sin necesidad de ejemplos negativos.
Una nueva pérdida de Aprendizaje Curricular Adaptativo para el reconocimiento facial profundo
El entrenamiento adversarial con métodos de un solo paso se ajusta en exceso, y sigue siendo vulnerable a los ataques simples de caja negra y caja blanca. Demostramos que incluir ejemplos adversarios de múltiples fuentes ayuda a defenderse de los ataques de caja negra.
Este trabajo propone un nuevo enfoque para incorporar la invariancia deseada al aprendizaje de representaciones, basándose en la observación de que el actual estado del arte del AFL tiene problemas prácticos.
La superficie de pérdida es *muy* degenerada, y no hay barreras entre las soluciones de lotes grandes y pequeños.
Proponemos CR-NAS para reasignar los recursos de computación comprometidos en diferentes resoluciones y posiciones espaciales.
Un método de entrenamiento que puede hacer que los algoritmos de aprendizaje profundo funcionen mejor en chips de computación neuromórfica con incertidumbre
Una arquitectura CNN que puede rechazar eficazmente las incógnitas en los objetos de prueba
Llevamos a cabo una inferencia variacional amortizada en un modelo de proceso gaussiano latente para lograr un rendimiento superior en la imputación de series temporales multivariantes con datos perdidos.
Realizamos estudios experimentales masivos caracterizando las relaciones entre las normas jacobianas, las regiones lineales y la generalización.
El ruido en el espacio de los parámetros permite a los algoritmos de aprendizaje por refuerzo explorar perturbando los parámetros en lugar de las acciones, lo que a menudo conduce a una mejora significativa del rendimiento de la exploración.
Presentamos nuevas técnicas de destilación que permiten entrenar modelos de estudiantes con diferentes vocabularios y comprimir el BERT en 60 veces con una menor caída de rendimiento.
Aprendizaje de extremo a extremo de representaciones invariantes con variables a través de ejemplos, como por ejemplo, si alguien fue a algún lugar, entonces está allí.
Resolvemos problemas inversos mal planteados con escasos ejemplos de verdad sobre el terreno estimando un conjunto de proyecciones aleatorias del modelo en lugar del propio modelo.
Una técnica para acelerar la selección de la arquitectura neuronal mediante la aproximación de los pesos de cada arquitectura candidata en lugar de entrenarlos individualmente.
Proponemos cuatro nuevas formas de recoger datos de NLI. Algunas ayudan ligeramente como datos de preentrenamiento, todas ayudan a reducir los artefactos de anotación.
Predicción estocástica variacional de vídeo en entornos reales.
Modelización de interacciones complejas entre agentes en un marco de aprendizaje por imitación con modelización explícita de políticas correlacionadas mediante la aproximación de las políticas de los oponentes. 
Un sistema de detección de plagio multilingüe (inglés-ruso)
Proponemos una implementación para acelerar el entrenamiento paralelo de datos de la DNN reduciendo el requisito de ancho de banda de comunicación.
Las perturbaciones pueden utilizarse para aprender los pesos de retroalimentación en grandes redes totalmente conectadas y convolucionales.
Sugerimos el número suficiente de bits para representar los pesos de las DNNs y los bits óptimos son conservadores a la hora de resolver problemas reales.
Perfeccionamiento de las propuestas de segmentación mediante la inferencia iterativa con autocodificadores de eliminación de ruido condicional.
Proponemos una arquitectura GAN basada en la autoatención para la generación de texto incondicional y mejoramos los resultados anteriores basados en códigos adversariales.
Proponemos unas novedosas redes neuronales codificadoras-decodificadoras de marcas de agua. Realizan un juego cooperativo para definir su propio esquema de marca de agua. Ya no es necesario diseñar métodos de marca de agua.
Derivamos un estimador de gradiente insesgado y de baja varianza para las expectativas sobre variables aleatorias discretas basado en el muestreo sin reemplazo
Proponemos un método que permite el plegado de la CNN para crear conexiones recurrentes
El recorte de gradiente no confiere robustez al ruido de las etiquetas, pero una simple variante basada en las pérdidas sí lo hace.
muestran evidencias experimentales sobre la débil correlación entre las probabilidades de los flujos y la semántica de las imágenes.
Aplicamos una estrategia de defensa agnóstica del modelo contra ejemplos adversos y logramos una precisión de caja blanca del 60% y una precisión de caja negra del 90% contra los principales algoritmos de ataque.
Demostramos la primera prueba de convergencia de un algoritmo acelerado asíncrono que logra un aumento de velocidad.
Incorporamos los muestreadores SG-MCMC dentro de una aproximación variacional
Argumentamos teóricamente que suponiendo simplemente que los pesos de una red ReLU se distribuyen de forma gaussiana (sin ni siquiera un formalismo bayesiano) se podría solucionar este problema; para una incertidumbre más calibrada, un simple método bayesiano podría ser ya suficiente.
Utilizamos representaciones entrenadas sin datos paralelos para crear alineaciones de palabras.
Un nuevo enfoque para el aprendizaje con recompensas ruidosas en el aprendizaje por refuerzo
Este artículo se centra en un mecanismo tradicionalmente ignorado: una arquitectura con unidades ocultas privadas y compartidas explícitamente diseñadas para mitigar la influencia perjudicial de la pérdida auxiliar no supervisada sobre la tarea principal supervisada.
Un estudio teórico del aprendizaje multitarea con implicaciones prácticas para mejorar el entrenamiento multitarea y el aprendizaje por transferencia
Nuevo método para evaluar la calidad de los evaluadores de similitud y mostrar el potencial de los modelos lingüísticos basados en Transformer para sustituir a BLEU y ROUGE.
Los métodos de metaaprendizaje utilizados para la visión, aplicados directamente a la PNL, funcionan peor que los vecinos más cercanos en las clases nuevas; podemos hacerlo mejor con las firmas distributivas.
Un análisis teórico de una nueva clase de RNNs, entrenadas en tareas de neurociencia, nos permite identificar el papel de la dimensionalidad dinámica y las clases de células en los cálculos neuronales.
Proponemos el discriminador de fusión, una arquitectura novedosa para incorporar información condicional en el discriminador de GANs para tareas de predicción estructurada.
Definimos, exploramos y empezamos a abordar el problema del desajuste de objetivos en el aprendizaje por refuerzo basado en modelos.
Damos una explicación detallada de las trayectorias en el plano de información e investigamos su uso para el diseño de redes neuronales (poda)
Emplear medidas de entrelazamiento cuántico para cuantificar las correlaciones en el aprendizaje profundo, y utilizar la conexión para ajustar la arquitectura de la red profunda a las correlaciones en los datos.
Utilizamos un aprendizaje por refuerzo sobre los grafos moleculares para generar razonamientos para la predicción de propiedades moleculares interpretables.
Unificamos las redes convolucionales gráficas como co-entrenamiento y factorización matricial unificada.
Un modelo autorregresivo basado en el flujo para la generación de gráficos moleculares. Alcanzando resultados de vanguardia en la generación de moléculas y la optimización de propiedades.
Proponemos un nuevo marco para el aprendizaje de precondicionadores, derivamos nuevas formas de precondicionadores y métodos de aprendizaje, y revelamos la relación con métodos como RMSProp, Adam, Adagrad, ESGD, KFAC, normalización por lotes, etc.
Unas sencillas técnicas de aumento de texto pueden mejorar significativamente el rendimiento en las tareas de clasificación de textos, especialmente en conjuntos de datos pequeños.
Proponemos un modelo que es capaz de realizar la estimación de parámetros físicos de sistemas a partir de vídeo, donde se conocen las ecuaciones diferenciales que gobiernan la dinámica de la escena, pero no se dispone de estados u objetos etiquetados.
ASAL es un método de aprendizaje activo basado en un pool que genera muestras de alta entropía y recupera las muestras coincidentes del pool en un tiempo sublineal.
Señalamos importantes problemas con la práctica común de utilizar el mejor rendimiento de un solo modelo para comparar arquitecturas de aprendizaje profundo, y proponemos un método que corrige estos defectos.
Estudiamos el efecto de la complejidad de la incrustación en el aprendizaje de representaciones invariantes del dominio y desarrollamos una estrategia que mitiga la sensibilidad a la misma.
Proponemos una nueva arquitectura denominada Red de Transferencia Dual Adversarial (DATNet) para abordar el Reconocimiento de Entidades Nombradas (NER) de bajos recursos y lograr nuevos rendimientos del estado del arte en CoNLL y Twitter NER.
Los GANs de Coulomb pueden aprender de forma óptima una distribución planteando el problema de aprendizaje de la distribución como la optimización de un campo potencial
Proponemos una red convolucional de grafos basada en la confianza para el aprendizaje semi-supervisado.
Proponemos ImageNet-C para medir la robustez de la corrupción del clasificador e ImageNet-P para medir la robustez de la perturbación
Ofuscar el código usando redes seq2seq, y ejecutar usando el código ofuscado y el par de claves
Método basado en GAN para la síntesis conjunta de imágenes y anotaciones por píxel
Introducimos una nueva tarea y un conjunto de datos sobre la navegación multilingüe de visión y lenguaje, y proponemos un marco general de VLN multilingüe para la tarea.
Clasificación no supervisada mediante modelado generativo profundo con aprendizaje de características controlable evaluado en una difícil tarea del mundo real
Modelos de Aprendizaje de Representación sobre grafos dinámicos como proceso oculto latente que une dos procesos observados de Evolución Topológica de e Interacciones sobre grafos dinámicos.
Introducimos una clase de juegos de n jugadores que se adaptan a los métodos basados en el gradiente.
Estudiamos la clase de lenguajes formales aceptables por los autómatas contadores en tiempo real, un modelo de computación relacionado con algunos tipos de redes neuronales recurrentes.
Un modelo de resumen que combina un nuevo método de aprendizaje intra-atención y de refuerzo para aumentar las puntuaciones de resumen ROUGE y la calidad de las secuencias largas.
Estudiamos si el aumento adaptativo de datos y la destilación de conocimientos pueden aprovecharse simultáneamente de forma sinérgica para mejorar el entrenamiento de las redes de estudiantes y cómo hacerlo.
Introducimos un procedimiento sencillo para readaptar los modelos lingüísticos basados en transformadores preentrenados para realizar bien el resumen abstracto.
Presentamos una arquitectura basada en la memoria neuronal para la adaptación incremental de dominios, y proporcionamos resultados teóricos y empíricos.
Formulando la recuperación de la señal dispersa como un problema de decisión secuencial, desarrollamos un método basado en RL y MCTS que aprende una política para descubrir el soporte de la señal dispersa. 
Aprendizaje de la incrustación para el control con observaciones de alta dimensión
Primeros hallazgos en la intersección de la neurociencia de redes y el aprendizaje profundo. C. Elegans y una corteza visual de ratón aprenden a reconocer dígitos escritos a mano.
Un método de aprendizaje de estructuras no supervisado para redes profundas de avance parsimonioso.
Uso de GANs como priores para la inferencia bayesiana eficiente de campos complejos.
Omniglot y miniImageNet son demasiado sencillos para el aprendizaje de pocos disparos porque podemos resolverlos sin usar etiquetas durante la metaevaluación, como se demuestra con un método llamado redes centroides
Identificar los estados de decisión (en los que el agente puede realizar acciones importantes) sin la supervisión de la recompensa, utilizarla para la transferencia.
Un enfoque para combinar la inferencia variacional y la optimización bayesiana para resolver problemas inversos complicados
Demostramos que, bajo algunos supuestos sobre la dinámica del vehículo y la incertidumbre del entorno, es posible sintetizar automáticamente primitivas de movimiento que no acumulen errores con el tiempo.
Las redes convolucionales profundas existentes en tareas de clasificación de imágenes son sensibles a los patrones de ruido de Gabor, es decir, pequeños cambios estructurados en la entrada provocan grandes cambios en la salida.
El estudio de la robustez y la redundancia en las redes neuronales profundas revela características que limitan la capacidad y ayudan a explicar la falta de ajuste.
Un algoritmo escalable para establecer derivadas robustas de redes profundas con respecto a las entradas.
En este trabajo, exploramos una estructura de red interna densa pero externa dispersa de las redes neuronales profundas y analizamos sus propiedades clave.
En este trabajo, pretendemos mejorar el MCMC y el VI mediante un novedoso método híbrido basado en la idea de reducir el sesgo de simulación de las cadenas MCMC de longitud finita utilizando la optimización basada en el gradiente.
La información sobre si la salida de una red neuronal será correcta o incorrecta está de alguna manera presente en las salidas de las capas intermedias de la red.
Algoritmo de autoimitación no supervisado capaz de inferir a partir de una única demostración experta.
Desarrollamos un marco de trabajo para generar explicaciones comprensibles para el ser humano de por qué la inviabilidad está ocurriendo en instancias sobre-restringidas de una clase de problemas de programación con recursos limitados.
Demostramos que los gradientes no son capaces de capturar los cambios en la saliencia debidos a las perturbaciones de los adversarios y presentamos una defensa alternativa contra los adversarios utilizando modelos de saliencia aprendidos que es eficaz contra los ataques de caja negra y de caja blanca.
Inadecuación de las métricas de desentrañamiento
Proponemos el Aprendizaje por Refuerzo de la Gestión Multiagente (M^3RL) consciente de la mente para entrenar a un gerente a motivar a los trabajadores interesados para lograr una colaboración óptima asignándoles contratos adecuados.
Un método de estados latentes persistentes en ResBlocks demostrado para la superresolución de secuencias de imágenes alizadas.
Proponemos Diversely Stale Parameters para romper los bloqueos del algoritmo de backpropoagation y entrenar una CNN en paralelo.
Una tarea auxiliar de predicción puede acelerar el aprendizaje en configuraciones de emergencia lingüística.
Módulo TEB para IPC
Algoritmo de aprendizaje métrico totalmente paralelizable y resistente al ruido adversarial con garantías teóricas.
Desarrollamos atractivos modelos de subtitulación de imágenes condicionados por la personalidad que también son punteros en tareas de subtitulación habituales.
Proponemos un descenso de gradiente estocástico con suavizado de Laplaciano diferencialmente privado para entrenar modelos de aprendizaje automático con mejor utilidad y mantener las garantías de privacidad diferencial.
Proporcionamos un análisis estadístico y computacional del problema de detección comprimida de un bit con un previo generativo. 
Un enfoque basado en principios para el aprendizaje de estructuras de redes neuronales profundas con una nueva interpretación de la profundidad y la conectividad entre capas. 
Investigamos cómo y por qué falla la regularización fuerte L1/L2 y proponemos un método que puede lograr una regularización fuerte.
Este trabajo pretende dar respuestas cuantitativas a la importancia relativa de los conceptos de interés mediante vectores de activación de conceptos (CAV). En particular, este marco permite a los expertos en aprendizaje no mecánico expresar conceptos de interés y probar hipótesis utilizando ejemplos (por ejemplo, un conjunto de imágenes que ilustran el concepto). Demostramos que el CAV puede aprenderse con un conjunto relativamente pequeño de ejemplos. Las pruebas de hipótesis con CAV pueden responder si un concepto concreto (por ejemplo, el género) es más importante para predecir una clase determinada (por ejemplo, médico) que otros conjuntos de conceptos. La interpretación de redes con CAV no requiere ningún reentrenamiento o modificación de la red. 
El cuello de botella de la entropía condicional es una función objetivo teórica de la información para el aprendizaje de representaciones óptimas.
Proponemos un enfoque para aprender representaciones dispersas de alta dimensión que son rápidas de buscar, incorporando un sustituto del número de operaciones directamente en la función de pérdida.
Combinar la formación auxiliar y la adversaria para interrogar y ayudar a la comprensión física.
Modelos basados en el flujo, pero no invertibles, para aprender también variables discretas
Demostramos constructivamente que incluso las funciones de activación no lineales más leves introducen mínimos locales espurios, para conjuntos de datos y funciones de activación generales.
Planificación compositiva basada en atributos que se generaliza a tareas de prueba largas, a pesar de haber sido entrenada en tareas cortas y simples.
Identificamos y formalizamos el problema de la memorización en el meta-aprendizaje y resolvemos este problema con un novedoso método de meta-regularización, que amplía enormemente el dominio en el que el meta-aprendizaje puede ser aplicable y eficaz.
Proponemos un marco novedoso para el meta-aprendizaje de una regla de actualización basada en el gradiente que se extiende más allá del aprendizaje de unos pocos disparos y es aplicable a cualquier forma de aprendizaje, incluyendo el aprendizaje continuo.
Defense-GAN utiliza una Red Adversarial Generativa para defenderse de los ataques de caja blanca y caja negra en los modelos de clasificación.
Desarrollamos métodos eficientes para entrenar modelos neuronales de incrustación con una estructura de producto punto, reformulando la función objetivo en términos de matrices de Gram generalizadas, y manteniendo las estimaciones de dichas matrices.
Presentamos una plataforma de análisis y referencia multitarea para evaluar la generalización en los sistemas de comprensión del lenguaje natural.
Un método modular para el aprendizaje de refuerzo multiobjetivo totalmente cooperativo, basado en el aprendizaje curricular para la exploración eficiente y la asignación de créditos para las interacciones acción-objetivo.
Abordamos la ineficiencia de la muestra y el sesgo de la recompensa en los algoritmos de aprendizaje de imitación adversarial como GAIL y AIRL.
Una variante de las redes de cápsulas que puede utilizarse para tareas de aprendizaje por pares. Los resultados muestran que las redes de cápsulas siamesas funcionan bien en la configuración de aprendizaje de pocos disparos.
Este artículo introduce la neuromodulación en las redes neuronales artificiales.
Proponemos un método de convolución dinámica para acelerar significativamente el tiempo de inferencia de las CNNs manteniendo la precisión.
En este trabajo introducimos un método de entrenamiento, llamado cuantificación de tabla de consulta (LUT-Q), que aprende un diccionario y asigna cada peso a uno de los valores del diccionario
Consideramos la transferencia negativa desde el punto de vista de la adaptación del dominio para derivar un algoritmo de aprendizaje adversarial.
Entrenamos máquinas cuánticas de Boltzmann utilizando un método de apilamiento de réplicas y un recocido cuántico para realizar una tarea de aprendizaje por refuerzo.
Propusimos un Método de Gradiente Rápido Iterativo de Nesterov (NI-FGSM) y un Método de Ataque de Escala (SIM) que pueden impulsar la transferibilidad de los ejemplos adversarios para la clasificación de imágenes.
Introducimos un método de entrenamiento estocástico para entrenar redes neuronales binarias con pesos y activaciones binarias.
Analizamos el impacto del espacio latente de los generadores totalmente entrenados mediante una pseudoinversión.
Proponemos un proceso de construcción de modelos de principio a fin que es universalmente aplicable a una amplia variedad de corpus de verificación de la autoría y que supera el estado de la técnica con poca o ninguna modificación o ajuste.
Consideramos abordar un problema de RL de un solo agente distribuyéndolo entre $n$ aprendices.
Un modelo híbrido que utiliza información de audio en bruto y de espectrograma para tareas de mejora del habla.
Este documento compara las pruebas estadísticas para las comparaciones de la VR (falsos positivos, poder estadístico), comprueba la solidez de los supuestos utilizando distribuciones simuladas y distribuciones empíricas (SAC, TD3), proporciona directrices para los estudiantes e investigadores de la VR.
Ofrecemos un análisis teórico del objetivo del cuello de botella de la información para comprender y predecir las transiciones de fase observadas en el equilibrio entre predicción y compresión.
Propuesta de funciones de activación localmente adaptativas en redes neuronales profundas e informadas por la física para una convergencia más rápida
Análisis de la inferencia bayesiana de hiperparámetros en la regresión de procesos gaussianos 
Entrenamos modelos variacionales con redes cuantificadas para el determinismo computacional. Esto permite utilizarlos para la compresión de datos entre plataformas.
Una simulación neuronal de la Máquina de Turing Universal
Disminuir la tasa de aprendizaje y aumentar el tamaño del lote durante el entrenamiento son equivalentes.
Introducimos la DCN+ con coattention residual profunda y RL de objetivo mixto, que logra un rendimiento de vanguardia en el conjunto de datos de respuesta a preguntas de Stanford.
Un benchmark NAS aplicable a casi todos los algoritmos NAS.
Proponemos una penalización de gradiente centrada en cero para mejorar la generalización y la estabilidad de los GANs
Una visión sobria del estado actual de las GAN desde una perspectiva práctica
Proponemos un enfoque agnóstico del modelo para explicar el comportamiento de los agentes RL profundos de caja negra, entrenados para jugar a juegos de Atari y de mesa, destacando las características relevantes de un estado de entrada.
Investigamos la representación profunda de arquitecturas CNN-DCN no entrenadas y de peso aleatorio, y mostramos su calidad de reconstrucción de imágenes y sus posibles aplicaciones.
Este trabajo introduce un nuevo enfoque de representación dinámica de características para proporcionar una forma más eficiente de hacer inferencia en redes neuronales profundas.
Cuando se inicializan correctamente, las redes neuronales pueden aprender la clase simple de funciones simétricas; cuando se inicializan al azar, fracasan.  
Proponemos un método para la búsqueda eficiente de arquitecturas neuronales multiobjetivo basado en la herencia lamarckiana y los algoritmos evolutivos.
Modelo neuronal unificado de modelado de temas y lenguaje para introducir la estructura del lenguaje en los modelos de temas para vectores temáticos contextualizados 
Proponemos una nueva forma de comprimir las redes neuronales utilizando estructuras de datos probabilísticas.
Estudiamos el impacto del uso de diferentes tipos de unidades de subpalabras en la calidad de las representaciones resultantes cuando se utilizan para modelar la sintaxis, la semántica y la morfología.
Un estudio empírico que ofrece una perspectiva novedosa sobre el aprendizaje de pocos disparos, en el que un método de ajuste fino muestra una precisión comparable a la de los métodos más complejos del estado de la técnica en varias tareas de clasificación.
Proponemos un enfoque para generar datos bursátiles realistas y de alta fidelidad basados en redes generativas adversariales.
Presentamos un enfoque de estimación del gradiente basado en el signo, en lugar de en la magnitud, que cambia la estimación del gradiente de la optimización de caja negra continua a la binaria.
Analizamos la propagación del gradiente en las RNN profundas y, a partir de nuestro análisis, proponemos una nueva RNN profunda multicapa.
Analizamos matemáticamente el efecto de la normalización por lotes en un modelo sencillo y obtenemos nuevas ideas clave que se aplican al aprendizaje supervisado general.
Para las restricciones complejas en las que no es fácil estimar el gradiente, utilizamos la penalización descontada como señal de guía. Demostramos que, bajo ciertos supuestos, converge a una solución factible.
El artículo investiga la adquisición de objetivos para paneles virtuales de mano en la RV y muestra que la anchura del objetivo, la distancia, la dirección de aproximación con respecto a la gravedad y el ángulo de aproximación influyen en el rendimiento del usuario.
iSparse elimina las aristas irrelevantes o insignificantes de la red con un impacto mínimo en el rendimiento de la misma, determinando la importancia de las aristas con respecto a la salida final de la red. 
Aprendemos representaciones de entidades que pueden reconstruir las categorías de Wikipedia con sólo unos pocos ejemplares.
Usando el logaritmo deformado por q, derivamos límites más ajustados que IWAE, para entrenar autocodificadores variacionales.
Se muestra el dilema de Bregman en el aprendizaje profundo que la mejora de los márgenes de los modelos sobreparametrizados puede dar lugar a un sobreajuste, y se proponen dinámicas de distribuciones de márgenes normalizados para predecir el error de generalización e identificar dicho dilema. 
Propusimos un sistema de diálogo de extremo a extremo con un novedoso rastreador de estado de diálogo multinivel y logramos un rendimiento consistente en MultiWOZ2.1 en cuanto a seguimiento de estado, finalización de tareas y rendimiento de generación de respuestas.
Presentamos una aproximación escalable a una amplia gama de objetivos de EBM, y aplicaciones en VAE y WAE implícitas
Este artículo desarrolla un método basado en principios para el aprendizaje continuo en modelos profundos.
Un algoritmo RL profundo para resolver POMDPs mediante la autocodificación de los estados subyacentes utilizando un modelo recurrente variacional
Este artículo formaliza el problema de la selección de algoritmos en línea en el contexto del aprendizaje por refuerzo.
Proponemos un nuevo modelo de variable latente para aprender incrustaciones latentes para algunos datos de alta dimensión. 
Proponemos estrategias de defensa adversarial basadas en la función de activación dependiente de los datos, la minimización de la variación total y el aumento de los datos de entrenamiento
Este trabajo presenta una solución escalable para el reconocimiento visual continuo del habla.
Proponemos un modelo de autocodificadores variacionales para el modelado de textos sin debilitar el decodificador, que mejora la calidad de la generación de textos y la interpretabilidad de las representaciones adquiridas.
Demostramos que los modelos grandes pero podados (large-sparse) superan a sus homólogos más pequeños pero densos (small-dense) con idéntica huella de memoria.
Controlamos el tema y el sentimiento de la generación de texto (casi) sin ningún tipo de entrenamiento. 
Relajar la restricción de las jerarquías compartidas permite un aprendizaje multitarea profundo más eficaz.
Proponemos un marco para aprender redes calibradas por confianza mediante el diseño de una nueva función de pérdida que incorpora la incertidumbre predictiva estimada a través de inferencias estocásticas.
Aprendizaje de la dinámica de partículas con gráficos de interacción dinámicos para simular y controlar cuerpos rígidos, objetos deformables y fluidos. 
Introducimos una teoría para explicar el fallo de los GAN en conjuntos de datos complejos y proponemos una solución para solucionarlo.
El aumento de datos y el entrenamiento adversarial son muy eficaces para desentrañar la correlación entre el hablante y el ruido, lo que permite un control independiente de cada atributo para la síntesis de texto a voz.
Las LSTM aprenden compositivamente las dependencias de largo alcance construyéndolas a partir de componentes más cortos en el transcurso del entrenamiento.
Entrenamos las redes neuronales linealizándolas localmente y utilizando un solucionador SVM lineal (Frank-Wolfe) en cada iteración.
Presentamos una versión mejorada del método DRL basado en características universales de sucesión que puede mejorar el aprendizaje de transferencia de los agentes.
Un método para el aprendizaje de representaciones de imágenes que son buenas tanto para desentrañar los factores de variación como para obtener reconstrucciones fieles.
Utilizamos el rango no negativo de las matrices de activación ReLU como medida de complejidad y demostramos que se correlaciona (negativamente) con una buena generalización.
El objetivo de este trabajo es conseguir el efecto de las redes de profesores múltiples explotando los bloques estocásticos y las conexiones de salto.
Construimos un teclado para Android con capacidades de sugerencia de emoji tanto léxicas (basadas en palabras) como semánticas (basadas en el significado) y comparamos sus efectos en dos estudios de chat diferentes. 
Proponemos un paradigma de aprendizaje autoadversarial (SAL) que mejora el generador de forma autodidacta para mejorar el rendimiento de los GAN en la generación de textos.
En este estudio, introducimos un método novedoso que se basa en la SVD para descubrir el número de dimensiones latentes.
Un novedoso enfoque de detección adversarial, que utiliza métodos de explicabilidad para identificar imágenes cuyas explicaciones son inconsistentes con la clase predicha.  
Un método de compresión de modelos entrenable de principio a fin que optimiza la precisión conjuntamente con el tamaño esperado del modelo.
Proponemos una técnica inteligente de selección de lotes llamada Ada-Boundary.
Presentamos arquitecturas de redes neuronales basadas en ontologías para la clasificación de eventos sonoros.
Nuestro trabajo demuestra que la información posicional se ha codificado implícitamente en una red. Esta información es importante para detectar características dependientes de la posición, por ejemplo, la semántica y la saliencia.
Red neuronal general-detallada (GDNN) con aprendizaje multitarea mediante la incorporación de un esquema de dominio cruzado (CDS) para el análisis sintáctico semántico
Demostramos que la capacidad de aprendizaje de diferentes arquitecturas neuronales puede caracterizarse directamente mediante medidas computables de complejidad de los datos.
Abordar el diseño inverso mediante algoritmos genéticos aumentados con redes neuronales profundas. 
Investigamos las activaciones de estados ocultos de los modelos de transformación en las tareas de respuesta a preguntas.
combinar el aprendizaje por refuerzo y el aprendizaje por imitación para resolver tareas complejas de manipulación de robots a partir de píxeles
Introducimos BatchEnsemble, un método eficiente de ensamblaje y aprendizaje permanente que puede utilizarse para mejorar la precisión y la incertidumbre de cualquier red neuronal como los típicos métodos de ensamblaje.
Estimación de recompensas a partir de vídeos de juegos
Proponemos la medición de la importancia de las frases y algoritmos para la explicación jerárquica de las predicciones del modelo de secuencia neural
Un parámetro de momento más alto $\beta$ ayuda a escapar más rápido de los puntos de silla
Describimos cómo mejorar un modelo generativo de imágenes en función de un objetivo lento o difícil de evaluar, como la retroalimentación humana, que podría tener muchas aplicaciones, como hacer imágenes más estéticas.
Nuestro algoritmo propuesto no utiliza todos los datos no etiquetados para el entrenamiento, sino que los utiliza selectivamente.
Un nuevo enfoque de la generación condicional mediante la restricción del espacio latente de un modelo generativo incondicional.
Cuantificamos el coste energético en términos de dinero (créditos en la nube) y huella de carbono del entrenamiento de modelos de redes neuronales de reciente éxito para la PNL. Los costes son elevados.
Se propone la poda VAE para buscar variables desenredadas con dimensión intrínseca.
Los modelos lingüísticos recurrentes a nivel de bytes aprenden representaciones del texto de alta calidad y específicas del dominio.
Análisis empírico y explicación de los estimadores de gradiente basados en partículas para la inferencia aproximada con modelos generativos profundos.
Aprendizaje profundo multietiqueta escalable y preciso con millones de etiquetas.
Se demuestra que los GANs nos proporcionan una nueva estimación media robusta y eficaz contra las contaminaciones agnósticas, con optimalidad estadística y trazabilidad práctica.
Presentamos modelos LSTM de espacio de estado, una combinación de modelos de espacio de estado y LSTMs, y proponemos un algoritmo de inferencia basado en Monte Carlo secuencial. 
Ampliamos el algoritmo de vigilia-sueño y lo utilizamos para aprender modelos estructurados a partir de pocos ejemplos, 
Proteínas, secuencias de aminoácidos, aprendizaje automático, aprendizaje profundo, red neuronal recurrente (RNN), memoria a largo plazo (LSTM), unidad recurrente cerrada (GRU), redes neuronales profundas
Detección de términos hablados, utilizando predicción estructurada y redes profundas, implementando una nueva función de pérdida que maximiza el AUC y clasifica según un umbral predefinido.
Proponemos un novedoso objetivo de optimización que fomenta la equidad en redes federadas heterogéneas, y desarrollamos un método escalable para resolverlo.
Proponemos un nuevo modelo de autocodificación con pérdida de reconstrucción adversarial aumentada. Introducimos una nueva métrica para la evaluación del contenido de las reconstrucciones. 
un algoritmo robusto de aprendizaje profundo bayesiano para inferir posteriors complejos con variables latentes
Ampliamos la descomposición tensorial espacio-temporal de un solo ensayo basada en la factorización de matrices no negativas para descontar de forma eficiente la actividad de la línea de base previa al estímulo, lo que mejora el rendimiento de la decodificación en datos con líneas de base no despreciables.
Método de compresión extrema de imágenes basado en GAN que utiliza menos de la mitad de bits que el códec de ingeniería SOTA, conservando la calidad visual
Aprender a clasificar utilizando la arquitectura Transformer.
El artículo describe un algoritmo de aprendizaje estratégico intrínseco que aborda el aprendizaje de políticas motoras complejas.
Usamos el MCTS para optimizar aún más una política bootstrapped para espacios de acción continuos bajo una configuración de iteración de políticas.
por qué las VAE anteriores sobre texto no pueden aprender una representación latente controlable como en las imágenes, así como una solución para permitir el primer éxito hacia la generación de texto controlado sin supervisión
Un nuevo modelo cortical jerárquico para la codificación de la memoria espaciotemporal y la predicción de vídeo
Proponer una nueva metodología basada en contrafactuales para evaluar las hipótesis generadas a partir de los mapas de saliencia sobre el comportamiento del agente de RL profunda. 
La mayoría de las redes neuronales se aproximan a la misma función de clasificación, incluso entre arquitecturas, a través de todas las etapas de aprendizaje.
Representar cada entidad en base a su histograma de contextos y entonces Wasserstein es todo lo que necesitas.
Metodologías para sistemas de recomendación con información lateral basadas en la regularización de la norma de rastreo
Este trabajo presenta un agente basado en la exploración y el aprendizaje por imitación capaz de obtener un rendimiento de vanguardia en la ejecución de juegos de ordenador basados en texto. 
En la poda de redes neuronales, es importante poner a cero los pesos podados, el signo de la inicialización es clave y el enmascaramiento puede considerarse como un entrenamiento.
Proponemos SesameBERT, un método generalizado de ajuste fino que permite la extracción de información global entre todas las capas a través de Squeeze y Excitation y enriquece la información local capturando los contextos vecinos a través del desenfoque gaussiano.
La conformación de los oponentes es un enfoque poderoso para el aprendizaje de los agentes múltiples, pero puede impedir la convergencia; nuestro algoritmo SOS lo soluciona con fuertes garantías en todos los juegos diferenciables.
Demostramos que la concordancia pregunta-respuesta es una tarea de preentrenamiento particularmente buena para la similitud de preguntas y publicamos un conjunto de datos para la similitud de preguntas médicas
Un estudio sobre el beneficio de compartir la representación en el aprendizaje por refuerzo multitarea.
Arquitecturas profundas para nubes de puntos 3D que son equivariantes a rotaciones SO(3), así como a traslaciones y permutaciones. 
Comparación y análisis detallado de varios modelos de incrustación de frases a través de la tarea de resumen automático en el mundo real.
Proponemos Value Propagation, un novedoso planificador de extremo a extremo que puede aprender a resolver tareas de navegación en 2D mediante el aprendizaje por refuerzo, y que se generaliza a entornos más grandes y dinámicos.
Se propone un método para extraer y aprovechar las interpretaciones de las interacciones de los rasgos
Demostramos que es posible recuperar los parámetros de un modelo generativo ReLU de 1 capa a partir de las muestras generadas por él
Aprender representaciones vectoriales densas de tipos arbitrarios de características en conjuntos de datos etiquetados y no etiquetados
Los autómatas finitos pueden decodificarse linealmente a partir de RNNs que reconocen el lenguaje utilizando funciones de abstracción de baja tosquedad y decodificadores de alta precisión. 
Proponemos HURRICANE para abordar el reto de la diversidad de hardware en la búsqueda de arquitecturas neuronales de un solo disparo
Traducción automática basada en frases neuronales con tiempo de descodificación lineal
Proponemos un GAN basado en AE que alivia el colapso de los modos en los GAN.
Aprendizaje por refuerzo y muestreo adaptativo para la compilación optimizada de redes neuronales profundas.
Diseñamos una gramática que se aprende en un entorno adversarial y la aplicamos a la predicción del futuro en vídeo.
Proponemos Janossy pooling, un método de aprendizaje de funciones profundas invariantes de la permutación diseñado para explotar las relaciones dentro de la secuencia de entrada y las estrategias de inferencia trazables como un procedimiento de optimización estocástica que llamamos piSGD
Un nuevo modelo de meta-aprendizaje que equilibra de forma adaptativa el efecto del meta-aprendizaje y el aprendizaje específico de la tarea, así como el aprendizaje específico de la clase dentro de cada tarea.
Revisamos la idea de la arquitectura maestro-esclavo en el aprendizaje de refuerzo profundo multiagente y superamos el estado de la técnica.
Estudiamos el sesgo implícito de los métodos de gradiente en la resolución de un problema de clasificación binaria con modelos ReLU no lineales.
Un método de poda de modelos CNN que utiliza ISTA y un truco de reescalado para reforzar la escasez de parámetros de escalado en la normalización de lotes.
¿Qué podemos aprender sobre el entrenamiento de redes neuronales si tratamos cada capa como un problema de refuerzo de gradiente?
La anticipación mejora la convergencia del aprendizaje profundo por refuerzo.
Encontramos que el movimiento en el espacio de la función no es proporcional al movimiento en el espacio de los parámetros durante la optimización. Proponemos un nuevo optimizador de estilo de gradiente natural para solucionar este problema.
Introducimos una familia general de Lagrangianos que permiten explorar la curva IB en todos los escenarios. Cuando se utilizan, y se conoce la curva IB, se puede optimizar directamente un nivel de rendimiento/compresión directamente.
Proponemos la Máquina Lógica Neural (NLM), una arquitectura neural-simbólica para el aprendizaje inductivo y el razonamiento lógico.
Proponemos un modelo de resumen neural consciente de la semántica y un novedoso esquema de evaluación de resumen automático que mide lo bien que un modelo identifica la información fuera de tema a partir de muestras adversas.
Imprime la frase de entrada y la frase de respuesta actual en una imagen y utiliza el modelo ImageNet CNN ajustado para predecir la siguiente palabra de respuesta.
Permitimos que las CNN ordinarias aprendan en pocas ocasiones explotando los conceptos visuales que son pistas visuales interpretables aprendidas dentro de las CNN.
Aplicar el modelo de ecuaciones diferenciales ordinarias a los datos estructurados en forma de gráfico
Propuesta de nueva tarea, conjuntos de datos y líneas de base; 3D Conv CycleGAN preserva las propiedades de los objetos a través de los fotogramas; la estructura del lote en los métodos a nivel de fotogramas es importante.
Un nuevo modelo escalable y equivariante de grupo para redes de cápsulas que preserva la composicionalidad bajo transformaciones, y es empíricamente más resistente a las transformaciones que los modelos de redes de cápsulas más antiguos.
El artículo propone una línea de base sencilla pero eficaz para el aprendizaje con etiquetas ruidosas.
Los calificadores prefieren la adecuación en la traducción humana sobre la automática cuando evalúan documentos completos, pero no cuando evalúan frases sueltas.
Este trabajo extiende el aprendizaje de imitación generativa adversarial multiagente a los juegos de Markov de forma extensiva.
Volvemos a examinar el autoentrenamiento como un método de aprendizaje semi-supervisado para el problema de generación de secuencias neuronales, y mostramos que el autoentrenamiento puede tener bastante éxito con ruido inyectado.
Un modelo de memoria generativa que combina redes neuronales de aprendizaje lento y un modelo lineal gaussiano de adaptación rápida como memoria.
Presentamos un nuevo enfoque, SNIP, que es sencillo, versátil e interpretable; depura las conexiones irrelevantes para una tarea determinada en un solo disparo antes del entrenamiento y es aplicable a una variedad de modelos de redes neuronales sin modificaciones.
Una técnica para etiquetar automáticamente grandes conjuntos de datos no etiquetados de manera que puedan entrenar modelos de origen para el aprendizaje de transferencia y su evaluación experimental. 
Nuestro trabajo propone un módulo de atención que capta las relaciones entre canales y ofrece grandes ganancias de rendimiento.
La aplicabilidad del aprendizaje por refuerzo inverso se ve a menudo obstaculizada por el gasto que supone la recopilación de demostraciones de expertos; este trabajo trata de ampliar su aplicabilidad incorporando información de tareas anteriores mediante el metaaprendizaje.
Una nueva arquitectura neuronal en la que las capas densas superiores de las arquitecturas convolucionales estándar se sustituyen por una aproximación de una función de núcleo basándose en la aproximación de Nyström.
Hay imágenes no consentidas y pornográficas en el conjunto de datos de ImageNet
Este trabajo propone un nuevo marco para el aprendizaje de similitudes de grafos en un escenario inductivo y no supervisado.
Mostramos cómo los modelos de codificación neuronal pueden ser entrenados para capturar tanto la señal como la variabilidad de los datos de la población neuronal utilizando GANs.
Un marco de clustering basado en el aprendizaje débilmente supervisado tiene un rendimiento comparable al de los modelos de aprendizaje totalmente supervisados al explotar el recuento único de clases.
RL profundo basado en modelos que funciona bien.
Analizamos y determinamos los requisitos de precisión para el entrenamiento de redes neuronales cuando todos los tensores, incluidas las señales retropropagadas y los acumuladores de pesos, se cuantifican en formato de punto fijo.
Podemos identificar ejemplos prototípicos y atípicos en el aprendizaje automático que son cuantitativamente muy diferentes, y hacer uso de ellos para mejorar muchos aspectos de las redes neuronales.
Proponemos mejorar la red de dispersión profunda con el fin de mejorar el control y la estabilidad de cualquier tubería de aprendizaje de máquinas, proponiendo un esquema de umbralización de ondícula continua
Agrupación neuronal sin necesidad de un número de clusters
El modelo de conciliación es un marco establecido para las explicaciones del plan, pero puede ser fácilmente secuestrado para producir mentiras.
Consideramos nuevas variantes de algoritmos de optimización para el entrenamiento de redes profundas.
Aceleramos la inferencia de la RNN reduciendo dinámicamente el acceso a la memoria redundante mediante una mezcla de módulos precisos y aproximados.
Iniciamos un impulso hacia la construcción de sistemas de ER para reconocer miles de tipos proporcionando un método para construir automáticamente conjuntos de datos adecuados basados en la jerarquía de tipos. 
Este trabajo propone una teoría para clasificar las Invocaciones de Métodos por diferentes niveles de abstracción y llevar a cabo un enfoque estadístico para la finalización del código desde el nombre del método hasta la invocación del mismo.
Nos centramos en la creación de adversarios universales para engañar a los detectores de objetos y ocultar los objetos de los detectores. 
Autoencoder de Wasserstein con espacio latente hiperbólico
Método de compresión del mapa de características que convierte las activaciones cuantificadas en vectores binarios, seguido de capas de reducción no lineal de la dimensionalidad incrustadas en una DNN
Conseguir una robustez adversarial fuerte comparable a la formación adversarial sin entrenar con ejemplos adversariales
Aprendemos un algoritmo de aprendizaje no supervisado que produce representaciones útiles a partir de un conjunto de tareas supervisadas. En el momento de la prueba, aplicamos este algoritmo a nuevas tareas sin ninguna supervisión y mostramos un rendimiento comparable al de una VAE.
La sobreparametrización en anchura parece ayudar en el aprendizaje profundo por refuerzo, al igual que en el aprendizaje supervisado.
Modelo generativo jerárquico (híbrido de VAE y GAN) que aprende una representación desenredada de los datos sin comprometer la calidad generativa.
Introducimos una arquitectura ligera para el reconocimiento de entidades con nombre y llevamos a cabo un aprendizaje activo incremental, que es capaz de igualar el rendimiento del estado del arte con sólo el 25% de los datos de entrenamiento originales.
Entrenamos redes precisas totalmente cuantificadas utilizando una función de pérdida que maximiza la precisión del modelo de precisión total y minimiza la diferencia entre las redes de precisión total y las cuantificadas.
En este trabajo introducimos un algoritmo para aprender la conectividad de las redes profundas de múltiples ramas. El enfoque se evalúa en la categorización de imágenes, donde se obtienen ganancias de precisión consistentes en comparación con los modelos del estado de la técnica que utilizan una conectividad fija.
Demostramos que las unidades individuales de las representaciones de la CNN aprendidas en tareas de PNL responden selectivamente a los conceptos del lenguaje natural.
Proponemos un marco novedoso de HRL, en el que formulamos el problema de abstracción temporal como el aprendizaje de una representación latente de la secuencia de acciones.
Introducimos las RNN MIST, que a) muestran propiedades superiores de gradiente de fuga en comparación con las LSTM; b) mejoran sustancialmente el rendimiento sobre las LSTM y las RNN Clockwork en tareas que requieren dependencias a muy largo plazo; y c) son mucho más eficientes que las RNN NARX propuestas anteriormente, con incluso menos parámetros y operaciones que las LSTM.
(Versión preparada para la cámara) Un módulo de entrelazamiento de características para aprovechar las características de un conjunto preciso para ayudar al aprendizaje de otro conjunto menos fiable.
Un marco de aprendizaje continuo que aprende a adaptar automáticamente su arquitectura basándose en un algoritmo de inferencia variacional propuesto. 
Proponemos Noisy-DR-L0-SSC (Noisy Dimension Reduction L0-Sparse Subspace Clustering) para dividir eficazmente los datos ruidosos de acuerdo con su estructura subespacial subyacente.
Un nuevo enfoque que utiliza la conectividad de los modos en los paisajes de pérdidas para mitigar los efectos de los adversarios, reparar los modelos manipulados y evaluar la solidez de los adversarios
Un marco GAN multigenerador con una red adicional para aprender una previa sobre el ruido de entrada.
Los BigGANs no capturan las distribuciones de datos de ImageNet y sólo tienen un éxito modesto para el aumento de datos.
Presentamos Leaf, un marco de referencia modular para el aprendizaje en datos federados, con aplicaciones a paradigmas de aprendizaje como el aprendizaje federado, el metaaprendizaje y el aprendizaje multitarea.
Introducimos una nueva pérdida de incrustación espacio-temporal en vídeos que genera una segmentación de instancias de vídeo temporalmente consistente, incluso con oclusiones y detecciones perdidas, utilizando la apariencia, la geometría y el contexto temporal.
Este trabajo propone un método avanzado de optimización de políticas con experiencia retrospectiva para el aprendizaje por refuerzo de recompensas dispersas.
Exploramos cómo el uso del conocimiento de fondo con la reformulación de la consulta puede ayudar a recuperar mejores pruebas de apoyo al responder a las preguntas de ciencia de opción múltiple.
Comprimimos las CNN profundas reutilizando una sola capa convolucional de forma iterativa, reduciendo así su número de parámetros en un factor proporcional a su profundidad, sin que sus precisiones se vean afectadas en gran medida
Análisis espectral para comprender cómo las diferentes representaciones pueden mejorar la optimización y la generalización.
Proporcionamos apoyo teórico a las estimaciones de incertidumbre para el aprendizaje profundo obtenidas ajustando priores aleatorios.
Proponemos un marco de imputación de datos arbitrariamente condicionados construido sobre autocodificadores variacionales y flujos de normalización
Desarrollamos un ataque a la privacidad que puede recuperar los datos de entrada sensibles de una red profunda a partir de su salida
Presentamos un método novedoso para la generación de textos bilingües que produce frases paralelas concurrentes en dos idiomas.
Introducimos la explicación en línea para considerar el requisito cognitivo del ser humano para entender la explicación generada por el agente.
Proponemos un algoritmo de intercambio de variables y recálculo basado en el aprendizaje por refuerzo para reducir el coste de memoria.
La diferenciación temporal iterativa con la alineación de retroalimentación aleatoria fija apoya la plasticidad dependiente del tiempo del pico en la retropropagación de vainilla para el aprendizaje profundo.
Este trabajo propone el uso de un modelo acústico generativo profundo para el reconocimiento automático del habla, combinándolo de forma natural con otros módulos profundos de secuencia a secuencia utilizando la regla de Bayes.
Proponemos un nuevo enfoque para generar ejemplos adversarios basados en la transformación espacial, que produce ejemplos perceptualmente realistas en comparación con los ataques existentes. 
Se propone un algoritmo híbrido DQN y DDPG para tratar el espacio de acción híbrido discreto-continuo.
Un nuevo método de modelización de grafos de conocimiento basado en incrustaciones de distancia y redes neuronales
Mejora de la estabilidad del entrenamiento de las redes adversariales generativas semisupervisadas con entrenamiento colaborativo
Mostramos cómo hacer predicciones utilizando redes profundas, sin entrenar redes profundas.
Graphon es un buen espacio de búsqueda para la búsqueda de arquitecturas neuronales y produce empíricamente buenas redes.
Entrenamiento adversarial adaptable a las instancias para mejorar la relación robustez-precisión
Proponemos un enfoque de protección de la distinción defensiva y demostramos la fuerte capacidad de distinción de los ejemplos adversos.
Introducimos la NLC, una métrica que es barata de calcular en el estado inicializado aleatorio de las redes y que es altamente predictiva de la generalización, al menos en las redes totalmente conectadas.
salvar las distancias en soft computing
Este artículo presenta MarginAttack, un ataque adversario más fuerte y rápido de confianza cero.
La optimización no supervisada durante la inferencia proporciona una retroalimentación descendente para ajustar iterativamente la predicción de la variación de la escala para un reconocimiento más equitativo.
Investigamos las propiedades de la recientemente introducida Deep Image Prior (Ulyanov et al, 2017)
Proponemos una metodología de aumento de los datos disponibles públicamente para los estudios de rumores basada en la relación samántica entre los datos limitados etiquetados y no etiquetados.
Las convoluciones dinámicas ligeras son competitivas para la autoatención en tareas lingüísticas.
Mostramos cómo la inclusión de un paso extra-gradiente en los métodos de entrenamiento GAN de primer orden puede mejorar la estabilidad y conducir a mejores resultados de convergencia.
La normalización por lotes reduce la robustez en el momento de la prueba frente a corrupciones comunes y ejemplos adversos.
Aprendemos un algoritmo de optimización que se generaliza a tareas no vistas
Predecimos el error de generalización y especificamos el modelo que lo alcanza a través de las escalas modelo/datos.
Método de aprendizaje por refuerzo no supervisado para el aprendizaje de una política que permita alcanzar de forma robusta los objetivos especificados por la percepción.
Modelo de secuencia que ajusta dinámicamente la cantidad de cálculo para cada entrada.
Caracterizamos los óptimos globales problemáticos del objetivo VAE y presentamos un novedoso método de inferencia para evitar dichos óptimos.
Proponemos una nueva incrustación de palabras no supervisada que preserva la propiedad de inclusión en la distribución del contexto y logra resultados de vanguardia en la detección de hipernimia no supervisada
Un enfoque basado en la regularización para el aprendizaje continuo mediante redes neuronales bayesianas para predecir la importancia de los parámetros
Este artículo explora el uso de la tecnología de aumento sensorial vestible para facilitar la toma de perspectiva de primera mano de lo que es tener bigotes de gato.
Damos algunos límites de error de generalización de los métodos de gradiente ruidoso como el SGLD, la dinámica de Langevin, el momento ruidoso, etc.
Para el aprendizaje por refuerzo de recompensa dispersa, se utiliza el conjunto de modelos de dinámica múltiple para generar una recompensa intrínseca diseñada como el mínimo de la sorpresa.
Estudiamos las representaciones de la fonología en los modelos de redes neuronales del lenguaje hablado con diversas variantes de técnicas analíticas.
Resolvemos el problema específico del SR de las imágenes JPG de baja calidad mediante submodelos funcionales.
Proponemos un modelo interpretable para detectar las palabras de vigilia elegidas por el usuario que aprende de los ejemplos del usuario.
Proponemos un modelo que aprende a descubrir fotogramas informativos en una secuencia de vídeo futura y a representar el vídeo mediante sus fotogramas clave.
Aprendemos la representación profunda maximizando la información mutua, aprovechando la estructura en el objetivo, y somos capaces de calcular con clasificadores totalmente supervisados con arquitecturas comparables
En primer lugar, proponemos un estimador de importancia atómica totalmente automatizado y dirigido a un objetivo, basado en las redes neuronales de grafos y en un nuevo concepto de autoatención inversa.
Agrupación espectral no supervisada mediante redes neuronales profundas
Descubrimos que los modelos profundos son cruciales para que MAML funcione y proponemos un método que permite un metaaprendizaje eficaz en modelos más pequeños.
La agrupación se logra utilizando wavelets en lugar de los enfoques tradicionales de vecindad (máximo, promedio, etc.).
Proponemos un novedoso marco dinámico para la formación de viajes que optimiza tanto el valor operativo para el proveedor de servicios como el valor para el usuario mediante la incorporación de las preferencias sociales de los usuarios en el proceso de toma de decisiones.
Caracterizamos las propiedades dimensionales de los subespacios adversos en la vecindad de los ejemplos adversos mediante el uso de la Dimensionalidad Intrínseca Local (LID).
Diseñamos y analizamos un nuevo algoritmo de optimización estocástica de orden cero, ZO-signSGD, y demostramos su conexión y aplicación a los ataques adversariales de caja negra en el aprendizaje profundo robusto
Este artículo propone una arquitectura de red neuronal recursiva unificada para la previsión solar a corto plazo con horizonte temporal múltiple y valida las ganancias de rendimiento de la previsión respecto a los métodos anteriormente descritos
La conexión de salto en ResNet y la normalización por lotes mejoran la capacidad de separación de datos y ayudan a entrenar una red neuronal profunda.
Proponemos un modelo generativo que no sólo produce datos con las características deseadas a partir del espacio latente predefinido, sino que también entiende completamente las características de los datos para crear características que no están en el conjunto de datos.
Un marco para estudiar la comunicación emergente en una configuración de aprendizaje de refuerzo multiagente en red.
Ampliamos los conjuntos profundos a las incrustaciones funcionales y a los procesos neuronales para incluir miembros equivariantes de la traducción
Un modelo CNN de rotación-equivariante de V1 que supera los modelos anteriores y sugiere agrupaciones funcionales de las neuronas de V1.
Redirigir una amplia clase de procedimientos de inferencia a partir de un objetivo de cuello de botella de información global.
El entrenamiento de agentes con computación adaptativa basada en el cuello de botella de la información puede promover la generalización. 
Se utilizó un estudio dentro de los sujetos para evaluar cuatro visuales de respiración acelerada comunes en las aplicaciones móviles para entender cuál es el más eficaz para proporcionar orientación sobre el ejercicio de la respiración.
Una forma de generar corpus de entrenamiento para la síntesis de códigos neuronales utilizando un discriminador entrenado en datos no etiquetados
Demostramos la vulnerabilidad a los ataques de hipersensibilidad en los modelos neurales de comprensión lectora SQuAD2.0 y NewsQA, en los que el modelo predice la misma respuesta con mayor confianza a preguntas elegidas de forma adversa, y comparamos las estrategias de defensa.
El uso de técnicas de compresión para la codificación de palabras es una posibilidad para un entrenamiento más rápido de la CNN y la reducción de la dimensionalidad de la representación
Un formalismo de optimización de políticas regularizado por la entropía subsume un conjunto de algoritmos de aprendizaje de predicción de secuencias. Un nuevo algoritmo de interpolación con resultados mejorados en la generación de textos y el aprendizaje de imitación de juegos.
Proponemos un modelo CNN puramente convolucional con mecanismo de atención para predecir los flujos espacio-temporales de origen-destino. 
Proponemos un nuevo enfoque de entrenamiento adversarial llamado Características Locales Robustas para el Entrenamiento Adversarial (RLFAT) que mejora significativamente tanto la generalización adversarialmente robusta como la generalización estándar.
Por qué y cómo restringir la verificación del modelo del dominio de planificación con objetivos de planificación para evitar contraejemplos inalcanzables (resultados de verificación falsos positivos).
StrokeNet es una arquitectura novedosa en la que el agente se entrena para dibujar mediante trazos en una simulación diferenciable del entorno, lo que podría explotar eficazmente la potencia de la retropropagación.
Demostramos cómo el aprendizaje automático es capaz de modelar experimentos en física cuántica.
 un marco de aprendizaje métrico no lineal no supervisado para mejorar el rendimiento de los algoritmos de agrupación.
Frente a modelos complejos y de caja negra, cifrar los datos no es tan útil como aproximar el modelo y utilizarlo para fijar el precio de una posible transacción.
Sistema de escritura interactivo basado en un lápiz óptico que incorpora sonido
Presentamos un marco codificador-decodificador para la transferencia de estilos lingüísticos, que permite el uso de datos no paralelos y datos de origen con varios estilos lingüísticos desconocidos.
Una nueva función de pérdida para el ACP con autocodificadores lineales que produce de forma demostrable eigenvectores exactos ordenados 
Este artículo desarrolla un marco para integrar las opiniones de los usuarios bajo la incertidumbre de la identidad en las bases de conocimiento. 
En este trabajo proponemos un novedoso modelo generativo para elaborar ataques de envenenamiento sistemático con restricciones de detectabilidad contra clasificadores de aprendizaje automático, incluyendo redes profundas. 
Es el algoritmo cuántico para la maximización de expectativas. Es rápido: el tiempo de ejecución sólo depende polilogarítmicamente del número de elementos del conjunto de datos. 
Un algoritmo de optimización dispersa para modelos CNN profundos.
Una alternativa simple y efectiva al aprendizaje de imitación adversarial: inicializar el buffer de repetición de experiencias con demostraciones, establecer su recompensa a +1, establecer la recompensa para todos los demás datos a 0, ejecutar Q-learning o soft actor-critic para entrenar.
Presentamos una nueva arquitectura profunda, VarPSOM, y su extensión a los datos de series temporales, VarTPSOM, que consiguen un rendimiento de clustering superior al de los actuales métodos de clustering profundo en datos estáticos y temporales.
Analizamos qué tareas se aprenden mejor juntas en una red, y cuáles es mejor aprender por separado. 
Un marco semántico profundo para la recuperación de documentos en motores de búsqueda textual
Proponemos un nuevo algoritmo basado en el transporte óptimo para entrenar una CNN de forma SSL.
La normalización por lotes reduce la robustez del adversario, así como la robustez general en muchos casos, en particular a las corrupciones por ruido.
Aprendizaje de HGNs, dominios ND
un meta-aprendizaje sencillo basado en RNN que alcanza un rendimiento SOTA en los puntos de referencia más populares
Presentado en EMNLP
Introducimos un nuevo entorno de fútbol MuJoCo para la investigación del aprendizaje por refuerzo continuo multiagente, y mostramos que el entrenamiento basado en la población de aprendices de refuerzo independientes puede aprender comportamientos cooperativos
Uso de la gramática DSL y del aprendizaje por refuerzo para mejorar la síntesis de programas con flujo de control complejo.
Proponemos un novedoso modelo de series temporales de espacio de estado con la capacidad de capturar la estructura de los puntos de cambio y los puntos de anomalía, de modo que tiene un mejor rendimiento de previsión cuando existen puntos de cambio y anomalías en las series temporales.
Un transformador multimodal para el aprendizaje secuencial multimodal, con sólidos resultados empíricos en métricas lingüísticas multimodales como el análisis de sentimientos multimodales, el reconocimiento de emociones y el reconocimiento de rasgos de personalidad. 
Utilizamos un coeficiente adaptativo sobre el impulso regular inspirado en la optimización geodésica que acelera significativamente el entrenamiento tanto en funciones convexas como no convexas.
Utilizamos un codificador transformador para hacer la traducción entrenándolo al estilo de un modelo de traducción enmascarado.
Presentamos conjuntos locales, un método para detectar la extrapolación en modelos entrenados, que aproxima la varianza de un conjunto utilizando información local de segundo orden.
La privacidad puede considerarse del mismo modo que otros recursos en la planificación
aprendizaje de la representación desenredada
Proponemos un enfoque de entrenamiento adversarial para el problema de la generación de preguntas de aclaración que utiliza la respuesta a la pregunta para modelar la recompensa. 
El uso de la partición de costes saturados para seleccionar patrones es preferible a todos los algoritmos de selección de patrones existentes.
El uso de la atención ramificada con pesos de combinación aprendidos supera al transformador de línea base para las tareas de traducción automática.
Aprendizaje híbrido por imitación basado en la visión y aprendizaje por refuerzo basado en modelos para la planificación, la previsión y el control
Destacamos los problemas con las métricas comunes de la incertidumbre en el dominio y realizamos un amplio estudio de las técnicas modernas de ensamblaje.
Desarrollar un marco general para establecer la solidez certificada de los modelos de ML frente a varias clases de perturbaciones adversas
Proponemos un modelo generativo de variables latentes para la descomposición no supervisada de escenas que proporciona una representación factorizada de los objetos en primer plano, a la vez que descompone segmentos de fondo de morfología compleja.
Proponemos una extensión del autoencoder variacional condicional que permite condicionar en un subconjunto arbitrario de las características y muestrear las restantes.
En este trabajo proponemos una representación jerárquica de la arquitectura en la que haciendo una búsqueda aleatoria o evolutiva de la arquitectura se obtienen resultados altamente competitivos utilizando menos recursos computacionales que el arte previo.
Proponemos la Memoria Topológica Alucinante (HTM), un algoritmo de planificación visual que puede realizar una planificación de largo horizonte en entornos nuevos. 
Proponemos acelerar la normalización por lotes (BN) mediante el muestreo de datos menos correlacionados para las operaciones de reducción con un patrón de ejecución regular, lo que consigue una aceleración de hasta el doble y el 20% para la propia BN y el entrenamiento general, respectivamente.
Aprendizaje federado eficiente en cuanto a la comunicación con la adaptación de capas
Aprendizaje con datos de entrenamiento limitados mediante la explotación de instancias "útiles" de una rica fuente de datos.  
un nuevo algoritmo de optimización sin derivadas derivado de los métodos de gradiente acelerado de Nesterov y de la dinámica hamiltoniana
Back-Propagation binarizado todo lo que necesitas para un entrenamiento completamente binarizado es inflar el tamaño de la red
Cómo elegir eficazmente la función de inicialización y activación para las redes neuronales profundas
Introducimos las descomposiciones contextuales, un algoritmo de interpretación para LSTMs capaz de extraer la puntuación de importancia a nivel de palabra, frase e interacción
Este trabajo propone un nuevo método de enmascaramiento complejo para la mejora del habla junto con una función de pérdida para la estimación eficiente de la fase.
Aprendizaje del comportamiento emergente minimizando la sorpresa bayesiana con RL en entornos naturales con entropía.
Las representaciones profundas combinadas con el descenso de gradiente pueden aproximarse a cualquier algoritmo de aprendizaje.
Presentamos una interfaz cerebro-máquina de bucle abierto cuyo rendimiento no está limitado por el enfoque tradicional de bolsa de palabras.
Presentamos una incrustación de red completa de CNN que supera a las incrustaciones de una sola capa para las tareas de aprendizaje por transferencia.
Presentamos un nuevo método de poda de redes que puede encontrar la estructura dispersa óptima durante el proceso de entrenamiento con un umbral de poda entrenable
Evaluamos la plausibilidad biológica de los nuevos algoritmos de aprendizaje ML en abstracto basándonos en las operaciones matemáticas necesarias
Introducimos un método para entrenar modelos con una robustez demostrable contra todas las formas $l_p$ para $p\geq 1$ simultáneamente.
Proponemos un método novedoso para manejar las degradaciones de la imagen de diferentes niveles mediante el aprendizaje de un tiempo terminal de difusión. Nuestro modelo puede generalizarse a niveles de degradación no vistos y a diferentes estadísticas de ruido.
Demostramos que es posible aproximar rápidamente el cálculo de las distancias de Wasserstein encontrando una incrustación adecuada en la que la distancia euclidiana emula la distancia de Wasserstein
Presentamos un novedoso esquema de entrenamiento para obtener eficientemente representaciones de oraciones conscientes del orden.
La parametrización recursiva de los modelos recurrentes mejora el rendimiento 
Un estudio comparativo de modelos generativos en escenarios de aprendizaje continuo.
primero planteando y resolviendo el problema de optimización de la eficiencia de la muestra en el espacio de la política no parametrizada, y luego resolviendo un problema de regresión supervisada para encontrar una política parametrizada que esté cerca de la política óptima no parametrizada.
Un enfoque orientado a objetivos para modelar cuatro áreas visuales de ratón (V1, LM, AL, RL) basado en redes neuronales profundas entrenadas en el reconocimiento de objetos estáticos no desvela una organización funcional de la corteza visual a diferencia de los primates
un modelo de gradiente basado en la transformación generalizada para la inferencia variacional
Introducimos un novedoso modelo de lenguaje de contexto más amplio para capturar simultáneamente la sintaxis y la semántica, por lo que es capaz de generar frases y párrafos altamente interpretables
Entrenamos un agente de pintura de medios naturales utilizando un modelo de entorno. Basándonos en nuestro agente de pintura, presentamos un enfoque novedoso para entrenar a un agente de pintura restringido que sigue la orden codificada en la observación.
Desarrollamos un marco de búsqueda y una penalización de consistencia para mitigar el sesgo delirante.
El sistema propuesto puede evitar que suplantadores con disfraces faciales completen una transacción fraudulenta utilizando una DCNN preentrenada.
análisis teórico del autocodificador ancho no lineal
Presentamos el primer enfoque de RL jerárquico que aprende con éxito jerarquías de 3 niveles en paralelo en tareas con espacios de estado y acción continuos.
Este trabajo estudió el problema de clasificación PUbN, en el que incorporamos datos negativos sesgados (bN), es decir, datos negativos que no son totalmente representativos de la verdadera distribución negativa subyacente, en el aprendizaje positivo sin etiquetar (PU).
Las prácticas de refuerzo para mejorar el rendimiento de la traducción automática podrían no provenir de mejores predicciones.
Entrenamos una CNN pequeña y eficiente con el mismo rendimiento que el OpenAI Transformer en tareas de clasificación de texto
Método de conjunto para el aprendizaje por refuerzo que pondera las funciones Q en función de los errores de TD acumulados.
Bsuite es una colección de experimentos cuidadosamente diseñados que investigan las capacidades básicas de los agentes de RL.
mejorar el preentrenamiento y analizar el resultado del codificador y la atención
Una formulación para un método de aprendizaje de refuerzo de caja negra para encontrar el fallo más probable de un sistema que actúa en escenarios complejos.
Utilizar algoritmos sin modelo, como DQN/TRPO, para resolver problemas de horizonte corto (sin modelo) de forma iterativa en forma de Iteración de Políticas/Valores.
Demostramos que incluso los métodos de entrenamiento adversarial más potentes no pueden defenderse de los ejemplos adversariales elaborados con imágenes de prueba ligeramente escaladas y desplazadas.
Mejorar las activaciones de saturación (sigmoide, tanh, htanh, etc.) y la red neuronal binarizada con inicialización de sesgo
utilizando redes neuronales profundas y algoritmos inteligentes para captar los conceptos visuales mentales humanos
Presentamos un novedoso ataque dirigido de caja negra que es capaz de engañar al estado de la técnica de transcripción de voz a texto.
Sintetización de movimientos humanos en tareas interactivas mediante datos mocap y RL jerárquica.
Análisis de la convergencia y del colapso del modo estudiando el proceso de entrenamiento de GAN como minimización del arrepentimiento
Proponemos un marco novedoso para evaluar la interpretabilidad de las redes neuronales.
Un agente RL profundo que aprende valores Q hiperbólicos (y otros no exponenciales) y una nueva tarea auxiliar multihorizonte.
Este artículo presenta la detección de emociones de una persona hacia un estímulo de imagen basada en el EEG y su aplicabilidad en el neuromarketing.
Aproximaciones variacionales rápidas para aproximar un estado de usuario y aprender incrustaciones de productos
Presentamos una función de evaluación demostrable y fácilmente calculable que estima el rendimiento de las representaciones transferidas de una tarea de aprendizaje a otra en el aprendizaje por transferencia de tareas.
Proponemos un esquema de aprendizaje adversarial condicional fiable junto con un marco simple, genérico pero eficaz para las tareas de UDA.
De la distancia al núcleo y la incrustación mediante características aleatorias para entradas estructuradas
Un núcleo de inspiración cuántica para la red de convolución, que exhibe fenómenos de interferencia, puede ser muy útil (y lo comparamos con su homólogo de valor real).
Una plataforma de juego de investigación inspirada en los MMO para estudiar los comportamientos emergentes de grandes poblaciones en un entorno complejo
Este artículo mejora la evaluación existente basada en muestras para GANs y contiene algunos experimentos perspicaces.
Las redes neuronales binarias residuales mejoran significativamente la tasa de convergencia y la precisión de inferencia de las redes neuronales binarias.
Método no supervisado para detectar muestras adversas en el espacio de activaciones y errores de reconstrucción del autoencoder
Proponemos aprender representaciones de entidades y relaciones con conocimiento a partir de Bert para incrustaciones de grafos de conocimiento.
Un módulo neuronal diferenciable y escalable que implementa el razonamiento sobre KBs simbólicas.
DCEM aprende los dominios latentes para los problemas de optimización y ayuda a cerrar la brecha entre la RL basada en modelos y la libre de modelos --- creamos un controlador diferenciable y afinamos partes del mismo con PPO
Utilizamos recompensas dinámicas para entrenar a los extractores de eventos.
Las GAN se benefician de la ampliación.
El error conjunto es importante para la adaptación de dominio no supervisada, especialmente cuando el cambio de dominio es enorme
El "flujo de conocimiento" entrena una red profunda (alumno) inyectando información de múltiples redes (profesores). El alumno es independiente tras el entrenamiento y rinde muy bien en las tareas aprendidas, independientemente del entorno (aprendizaje reforzado o supervisado).
Una estimación eficiente del primer momento gaussiano de las DNNs como regularizador para el entrenamiento de redes robustas.
Proponemos cascadas neuronales, un enfoque simple y trivialmente paralelizable para la comprensión de la lectura, que consiste sólo en redes feed-forward y la atención que logra el rendimiento del estado de la técnica en el conjunto de datos TriviaQA.
Avanzamos en el estado del arte de la compresión de modelos proponiendo las Redes de Compresión Atómica (ACN), una novedosa arquitectura que se construye mediante la repetición recursiva de un pequeño conjunto de neuronas.
Demostramos que los modelos generativos basados en el flujo ofrecen un enfoque viable y competitivo para el modelado generativo del vídeo.
Proporcionamos un análisis teórico y empírico sobre el papel del ruido anisotrópico introducido por el gradiente estocástico en el escape de los mínimos.
Gradiente de la política a través de la retropropagación en el tiempo utilizando modelos aprendidos y funciones Q. Resultados de SOTA en entornos de referencia de aprendizaje por refuerzo.
Metaaprendizaje sobre distribuciones de tareas autopropuestas para acelerar el aprendizaje por refuerzo sin distribuciones de tareas especificadas por el ser humano 
Un método novedoso y eficaz en la práctica para adaptar redes neuronales preentrenadas a nuevas tareas mediante el reentrenamiento de un número mínimo (por ejemplo, menos del 2%) de parámetros
Una nueva explicación teórica de la existencia de ejemplos adversos
Elastic-InfoGAN es una modificación de InfoGAN que aprende, sin ningún tipo de supervisión, representaciones desenredadas en datos de clase desequilibrada
un marco distribuido de intercambio de conocimientos basado en el espacio latente para el aprendizaje profundo multitarea
Game Changer es un sistema que proporciona tanto descripciones sonoras como complementos táctiles para hacer accesible el estado del juego de mesa a los jugadores ciegos y con discapacidad visual.
La supervisión combinada de reglas y ejemplos y la pérdida de implicación ayudan a aprender conjuntamente a eliminar las reglas y a implicar las etiquetas.
Nuestro método introduce el aprendizaje de refuerzo inverso de máxima entropía regularizado para aprender recompensas y políticas casi óptimas a partir de demostraciones de expertos.
Las RNN implementan implícitamente representaciones de producto tensorial, un método interpretable y basado en principios para representar estructuras simbólicas en el espacio continuo.
El aumento de los datos aprendidos infunde sesgos inductivos favorables al algoritmo que permiten a las RNN aprender algoritmos de procesamiento de listas a partir de menos ejemplos.
Proponemos un problema especial de aprendizaje multietiqueta débilmente supervisado junto con un algoritmo recién adaptado que aprende el clasificador subyacente aprendiendo a asignar pseudoetiquetas.
Un asistente de búsqueda conversacional basado en el aprendizaje por refuerzo que proporciona asistencia contextual en la búsqueda subjetiva (como los activos digitales).
¡Las redes neuronales convolucionales se comportan como Vecinos más Próximos Compositivos!
Factorizar los estados de LSTM y las matrices de pesos de LSTM de acuerdo con los sesgos estructurales del mundo real expresados por los programas Datalog.
Proponemos un enfoque novedoso para resolver problemas de optimización basados en modelos de datos tanto en entornos pasivos como activos que pueden escalar a espacios de entrada de alta dimensión.
En este trabajo, proponemos un nuevo modelo de codificador-decodificador basado en representaciones de productos tensoriales para la generación de lenguaje natural a formal, denominado TP-N2F.
Este trabajo presenta un defogger, un modelo que aprende a predecir la información oculta futura a partir de observaciones parciales, aplicado a un conjunto de datos de StarCraft.
Estudiamos la generalización de las redes neuronales en el meta-aprendizaje basado en el gradiente, analizando varias propiedades del paisaje objetivo.
Presentamos un modelo generativo que demuestra el estado del arte en imágenes en escala de grises y naturales.
Proponemos una red novedosa llamada Red Recurrente de Identidad (RIN) que permite a una red recurrente simple superar el problema del gradiente de fuga mientras entrena modelos muy profundos sin el uso de puertas.
El documento aborda la tolerancia a los fallos bajo paradas aleatorias y adversas.
Presentamos una novedosa arquitectura unificada que restaura fotogramas de vídeo a partir de una única imagen borrosa por movimiento de forma integral.
Proponemos una nueva técnica de poda ciega estructurada para producir redes neuronales altamente comprimidas.
Utilizamos las aproximaciones de la suma de Kronecker para el entrenamiento de bajo rango con el fin de abordar los desafíos en el entrenamiento de redes neuronales en dispositivos de borde que utilizan tecnologías de memoria emergentes.
Examina sistemáticamente hasta qué punto podemos explicar las características ocultas de una red profunda en términos de reglas lógicas.
Mejora de las estimaciones de verosimilitud en los autocodificadores variacionales mediante el aprendizaje autosupervisado de características
Este trabajo muestra que los métodos de gradiente de política sin modelo pueden converger a la solución óptima global para problemas de control linealizados no convexos.
Usamos la teoría de la detección comprimida para demostrar que los LSTMs pueden funcionar al menos tan bien en la clasificación de texto lineal como los Bag-of-n-Grams.
Introducimos nuevas capas de convolución puntuales equipadas con transformadas convencionales extremadamente rápidas en la red neuronal profunda.
Proponemos utilizar celosías para representar objetos y demostramos un resultado fundamental sobre cómo entrenar redes que las utilizan.
Intentamos diseñar y entrenar un clasificador cuya robustez adversarial se asemeje más a la robustez del ser humano.
Proponemos un modelo Discrete Wasserstein GAN (DWGAN) que se basa en una formulación dual de la distancia de Wasserstein entre dos distribuciones discretas.
Se trata de una nueva arquitectura AGI para el rendimiento trans-sapiente.Esta es una visión general de alto nivel de la arquitectura Omega AGI que es la base de un sistema de automatización de la ciencia de datos. Presentado en un taller. 
Proponemos el mecanismo Flow y una arquitectura de extremo a extremo, FlowQA, que logra SotA en dos conjuntos de datos de QA conversacional y una tarea de comprensión de instrucciones secuenciales.
Presentamos un novedoso algoritmo para resolver problemas de aprendizaje por refuerzo y de predicción estructurada de bandidos con una retroalimentación de pérdidas muy dispersa.
Presentamos una sencilla modificación del método SGD alternante, denominada paso de predicción, que mejora la estabilidad de las redes adversarias.
Este trabajo introduce compilaciones independientes del dominio de las preguntas de los usuarios en restricciones para las explicaciones contrastivas.
 Incrustamos los nodos en un gráfico como distribuciones gaussianas que nos permiten capturar la incertidumbre sobre su representación.
Los métodos de regularización Logit ayudan a explicar y mejorar las defensas adversariales más avanzadas
Describimos un lenguaje modular y componible para describir espacios de búsqueda expresivos sobre arquitecturas y algoritmos simples de búsqueda de modelos aplicados a estos espacios de búsqueda. 
Demostramos que las técnicas de transferencia de conocimiento pueden mejorar la precisión de las redes de baja precisión y establecer un nuevo estado de la técnica para la precisión ternaria y de 4 bits. 
El artículo presenta un mecanismo de entrenamiento mejorado para obtener redes binarias con una menor caída de la precisión que ayuda a cerrar la brecha con su contraparte de precisión total
Marco unificador para realizar clustering mediante redes neuronales profundas
HYPE es una métrica de evaluación humana fiable para puntuar modelos generativos, empezando por la generación de rostros humanos a través de 4 GAN.
Proponemos un nuevo modelo de traducción automática no supervisada que puede aprender sin utilizar corpus paralelos; los resultados experimentales muestran un rendimiento impresionante en múltiples corpus y pares de idiomas.
Premiamos a los agentes por tener una influencia causal en las acciones de otros agentes, y mostramos que esto da lugar a una mejor cooperación y a protocolos de comunicación emergentes más significativos. 
Desarrollamos un agente que llamamos algoritmo de Gradiente de Política Profunda Determinista Distribucional, que logra un rendimiento de vanguardia en una serie de problemas de control continuo desafiantes.
Proponemos una nueva función de valor Q que permite un mejor aprendizaje de las políticas gaussianas.
Presentamos KG-A2C, un agente de aprendizaje por refuerzo que construye un grafo de conocimiento dinámico mientras explora y genera lenguaje natural utilizando un espacio de acción basado en plantillas, superando a todos los agentes actuales en un amplio conjunto de juegos basados en texto.
Demostramos que las redes neuronales profundas son exponencialmente más eficientes que las superficiales en la aproximación de polinomios multivariantes dispersos.
Proponemos la clasificación de las neuronas de la CNN con dos métodos diferentes y mostramos su consistencia en la producción del resultado que permite interpretar lo que la red considera importante y comprimir la red manteniendo los nodos más relevantes.
Un enfoque modular y jerárquico para aprender políticas de exploración de entornos 3D.
Un método no supervisado de adaptación del dominio sim a real para la segmentación semántica utilizando información privilegiada de un simulador con traducción de imágenes basada en GAN.
Primer diagnóstico de rigor del entrenamiento adversarial a gran escala en ImageNet
Atribuir los términos de sesgo de las redes neuronales profundas a las características de entrada mediante un algoritmo de tipo retropropagación; Generar explicaciones complementarias y altamente interpretables de las DNNs además de las atribuciones basadas en el gradiente.
Este trabajo presenta un método para encontrar de forma autónoma múltiples periodicidades en una señal, utilizando la FFT y la ACF y añadiendo tres nuevos pasos (clustering/filtrado/detrending)
Un esquema de aprendizaje por imitación sencillo pero eficaz que incentiva la exploración de un entorno sin ninguna recompensa extrínseca ni demostración humana.
 un nuevo marco que utiliza el espacio dual para generar imágenes correspondientes a etiquetas multiclase cuando el número de clases es grande
Presentamos una nueva ConvNet de grafos de avance basada en la generalización de la transformada de dispersión wavelet de Mallat, y demostramos su utilidad en tareas de clasificación de grafos y exploración de datos.
Presentamos un conjunto de datos de recepción a gran escala para tareas de análisis sintáctico posterior a la ROC.
Aceleración de la formación de la CNN en una cadena de aceleradores con pesos fijos
Demostramos que las redes profundas no sólo son demasiado sensibles a los cambios irrelevantes de su entrada, sino también demasiado invariables a una amplia gama de cambios relevantes para la tarea, lo que hace que vastas regiones del espacio de entrada sean vulnerables a los ataques de los adversarios.
Mejora del entrenamiento de los actuales modelos generativos basados en el flujo (Glow y RealNVP) en los puntos de referencia de estimación de la densidad
Las redes neuronales profundas entrenadas con aumento de datos no requieren ninguna otra regularización explícita (como el decaimiento de pesos y el abandono) y muestran una mayor adaptabilidad a los cambios en la arquitectura y la cantidad de datos de entrenamiento.
Este trabajo mejora la calidad del enfoque de inclinación de rasgos adversariales (AFL) recientemente propuesto para incorporar restricciones explícitas a las representaciones, introduciendo el concepto de la {vulnerabilidad} del adversario. 
Extendemos un exitoso autoencoder variacional para sistemas dinámicos para modelar un caso de jerarquía de sistemas dinámicos en neurociencia utilizando el método de la escalera.
Introducimos un proceso de cuantificación eficiente que permite acelerar el rendimiento en aceleradores de redes neuronales especializados en enteros.
Este trabajo propone un nuevo modelo de CNN que combina el coste de la energía con una estrategia de enrutamiento dinámico para permitir la inferencia adaptativa de eficiencia energética.
presentamos LSH Softmax, una capa de aproximación softmax para el aprendizaje y la inferencia sublineal con fuertes garantías teóricas; mostramos tanto su aplicabilidad como su eficiencia evaluando en una tarea del mundo real: el modelado del lenguaje.
La RL puede resolver problemas (estocásticos) de programación/robots múltiples de forma escalable y transferible utilizando la incrustación de grafos
Presentamos un nuevo algoritmo de aprendizaje por currículo basado en la noción de tasa de dominio que supera a los algoritmos anteriores.
Inspiración en los procesos dendríticos locales del aprendizaje neocortical para hacer grande de nuevo el aprendizaje no supervisado.
Redes de memoria con inferencia más rápida
Inspirándonos en la lingüística, concretamente en la hipótesis de la gramática universal, aprendemos representaciones universales agnósticas de la lengua que podemos utilizar para hacer un aprendizaje de cero a través de las lenguas.
Este trabajo muestra que el objetivo de la distancia de Wasserstein permite el entrenamiento de modelos de variables latentes con latentes discretas en un caso en el que el objetivo del Autoencoder Variacional no lo consigue.
Una red neuronal de grafos capaz de aprender y aprovechar automáticamente una estructura gráfica dinámica e interactiva
Un nuevo algoritmo para entrenar redes neuronales que se compara favorablemente con los métodos adaptativos populares.
Señala problemas en la función de pérdida utilizada en IRGAN, un marco GAN recientemente propuesto para la recuperación de información. Además, se propone un modelo motivado por el co-entrenamiento, que logra un mejor rendimiento.
Proponemos el Aprendizaje de Representación del Usuario Federado (FURL), una forma sencilla, escalable, que preserva la privacidad y que hace un uso eficiente del ancho de banda para utilizar las técnicas de personalización neuronal existentes en el entorno del Aprendizaje Federado (FL).
Autocodificadores para texto con un nuevo método de utilización del espacio latente discreto.
Espacio latente de estructura múltiple para modelos generativos
LoopGAN amplía la longitud del ciclo en CycleGAN para permitir la transformación secuencial no alineada para más de dos pasos de tiempo.
Proponemos SWAP, un algoritmo distribuido para el entrenamiento de grandes lotes de redes neuronales.
Un nuevo algoritmo de entrenamiento de lotes grandes basado en el escalado de velocidad adaptable por capas (LARS); utilizando LARS, escalamos AlexNet y ResNet-50 a un lote de 16K.
Aprendizaje de operadores Koopman composicionales para la identificación eficiente de sistemas y el control basado en modelos.
Presentamos un procedimiento de cálculo de gradiente de memoria constante a través de soluciones de ecuaciones diferenciales estocásticas (SDE) y aplicamos el método para el aprendizaje de modelos SDE latentes.
Aprendizaje de transformaciones que preservan la privacidad de los datos. Un enfoque colaborativo
Proponemos varias funciones de recompensa intrínseca para fomentar la exploración coordinada en problemas multiagente, e introducimos un enfoque para seleccionar dinámicamente el mejor método de exploración para una tarea determinada, en línea.
Proponemos aprender sintetizando clasificadores de pocos disparos y clasificadores de muchos disparos utilizando una única función objetivo para GFSL.
Combinamos la búsqueda A* con el aprendizaje por refuerzo para acelerar el código de aprendizaje automático
El aprendizaje por refuerzo profundo y eficiente de los datos puede utilizarse para aprender políticas de apilamiento precisas.
parametrizaciones de políticas y estimadores insesgados de entropía de políticas para MDP con un gran espacio de acción discreto multidimensional
Descomponer los pesos para utilizar menos FLOPs con SVD
Convergencia asintótica para el método subgradien estocástico con momentum bajo computación asíncrona paralela general para optimización general no convexa no lisa
Presentamos un estimador de bajo sesgo para modelos de variables estocásticas booleanas con muchas capas estocásticas.
Proponemos un método novedoso para manipular imágenes dadas utilizando descripciones en lenguaje natural.
Utilizar el método basado en GAN para resolver de forma escalable el transporte óptimo
Aprovechando el control como inferencia y los métodos de Monte Carlo secuencial, propusimos un algoritmo de planificación probabilística.
Una sencilla modificación del GAN que mejora el rendimiento en muchas pérdidas, arquitecturas, esquemas de regularización y conjuntos de datos. 
Cómo estimar el vector de probabilidad original para millones de clases a partir de las mediciones de los bocetos de count-min - una configuración teórica y práctica.
Se puede fijar el clasificador en las redes neuronales sin perder precisión
Aprender a detectar objetos sin etiquetas de imagen a partir de 3 minutos de vídeo
Introducimos ReClor, un conjunto de datos de comprensión lectora que requiere razonamiento lógico, y descubrimos que los modelos actuales del estado del arte tienen problemas con el razonamiento lógico real con un rendimiento pobre cercano al de las conjeturas al azar.
Sólo ruido de entrada, espigar las salidas de softmax, robar los pesos
Proponemos una nueva forma de modelo de autocodificación que incorpora las mejores propiedades de los autocodificadores variacionales (VAE) y las redes generativas adversariales (GAN)
Utilizamos la conexión entre el meta-aprendizaje basado en el gradiente y el Bayes jerárquico para aprender una mezcla de meta-aprendices que sea apropiada para una distribución de tareas heterogénea y en evolución.
Presentamos un nuevo método de enrutamiento para redes Capsule, y su rendimiento es igual al de ResNet-18 en CIFAR-10/ CIFAR-100.
Presentamos Doc2Dial, un marco de trabajo integral para generar datos conversacionales basados en documentos empresariales a través del crowdsourcing para entrenar agentes de diálogo automatizados
Introducimos un modelo generativo autorregresivo para espectrogramas y demostramos aplicaciones a la generación de voz y música
Las CNN profundas modernas no son invariantes a las traslaciones, escalamientos y otras transformaciones realistas de la imagen, y esta falta de invariabilidad está relacionada con la operación de submuestreo y los sesgos contenidos en los conjuntos de datos de imágenes.
Sintetizar movimientos humanos complejos y extensos mediante una red LSTM autocondicionada
Hemos ideado un mecanismo llamado competencia entre píxeles que permite que los métodos de saliencia (aproximadamente) completos pasen las comprobaciones de cordura.
Clasificación de imágenes mediante la consulta iterativa de la imagen de referencia de una clase candidata con una RNN y el uso de la CNN para comparar con la imagen de entrada
definimos por primera vez el problema de poda a nivel de filtro para redes neuronales binarias y proponemos un método para resolverlo.
Reducción de la complejidad computacional y de memoria de los modelos RNN hasta 100 veces mediante módulos de compresión de bajo rango dispersos, entrenados mediante destilación de conocimientos.
Comparamos las RNN de grafos y las ConvNets de grafos, y consideramos la clase más genérica de ConvNets de grafos con residualidad.
Comparación del perceptrón multicapa de valores complejos y reales con respecto al número de parámetros de valores reales.
Una red neuronal convolucional de grafos espectrales con propiedades de zoom espectral.
Presentamos un modelo de segmentación en tiempo real descubierto automáticamente por un marco NAS multiescala, logrando un 30% más de velocidad que los modelos del estado del arte.
Presentamos R2D3, un agente que hace un uso eficiente de las demostraciones para resolver problemas de exploración difíciles en entornos parcialmente observables con condiciones iniciales muy variables.
Investigamos cómo una red neuronal recurrente aprende con éxito una tarea que combina la memoria a largo plazo y el recuerdo secuencial.
Proponemos la idea de utilizar la norma de la representación del sucesor un bono de exploración en el aprendizaje por refuerzo. En los juegos Atari de exploración dura, nuestro algoritmo de RL profunda iguala el rendimiento de los métodos recientes basados en el pseudoconteo.
Factorización de las dimensiones en función de los datos en una arquitectura multiescala basada en la contribución a la log-verosimilitud total
Los cuatro métodos de atribución basados en la retropropagación existentes son fundamentalmente similares. ¿Cómo se evalúa?
SGD y Adam bajo el modelo de un solo pico para el PCA tensorial
Este trabajo presenta un método para explicar cuantitativa y semánticamente el conocimiento codificado en una red neuronal convolucional (CNN).
El documento presenta una metodología de evaluación dinámica para el modelado adaptativo de secuencias
Proponemos una forma novedosa, basada en la proyección, de incorporar la información condicional en el discriminador de los GANs que respeta el papel de la información condicional en el modelo probabilístico subyacente.
La distancia de Frechet entre la distribución del tren y la de la prueba se correlaciona con el cambio de rendimiento para las funciones que no son invariables al desplazamiento.
Se introduce un nuevo sistema dinámico muy sencillo que genera bonitos patrones; se demuestran las propiedades y se exploran las posibilidades
GMM-UNIT es un modelo de traducción de imagen a imagen que mapea una imagen a múltiples dominios de forma estocástica.
Presentamos una arquitectura novedosa, basada en la memoria dinámica, la atención y la composición para la tarea de razonamiento de la máquina.
Para comprender la información almacenada en el espacio latente, entrenamos un decodificador de tipo GAN restringido a producir imágenes que el codificador VAE asignará a la misma región del espacio latente.
Se construyen dos nuevos GAN para generar imágenes cerebrales fMRI 3D de alta calidad y las imágenes cerebrales sintéticas ayudan en gran medida a mejorar las tareas de clasificación posteriores.
Transferencia multilingüe cero mediante el uso de la traducción automática neural multilingüe 
Proponemos un algoritmo de búsqueda de arquitectura diferenciable tanto para redes convolucionales como recurrentes, logrando un rendimiento competitivo con el estado del arte utilizando órdenes de magnitud menos recursos de computación.
Los sistemas actuales de generación de lenguaje, o bien buscan una alta probabilidad y caen en la repetición genérica, o bien calibran mal su estocasticidad; nosotros aportamos pruebas de ambas cosas y proponemos una solución: El muestreo de núcleos.
El primer método de defensa de texto adverso a nivel de palabra, y el método de ataque mejorado basado en genéricos contra los ataques basados en la sustitución de sinónimos.
Hacia una asignación eficiente de créditos en redes recurrentes sin retropropagación a través del tiempo
Proponemos un novedoso marco de aprendizaje adversarial para la predicción estructurada, en el que los modelos discriminativos pueden utilizarse para refinar los modelos de predicción estructurada en la fase de inferencia. 
Una nueva metodología para la detección de novedades utilizando los valores de activación del espacio oculto obtenidos de un autoencoder profundo.
Aprendizaje de las preferencias sobre las trazas del plan utilizando el aprendizaje activo.
Fundamentamos las órdenes lingüísticas en un entorno visual de alta dimensión mediante el aprendizaje de recompensas condicionadas por el lenguaje utilizando el aprendizaje de refuerzo inverso.
Abogamos por las características aleatorias como teoría de las redes neuronales biológicas, centrándonos en las redes escasamente conectadas
Proponemos el método Prob2Vec para la incrustación de problemas utilizado en una herramienta de aprendizaje electrónico personalizado, además de un método de clasificación a nivel de datos, denominado preentrenamiento negativo, para los casos en que el conjunto de datos de entrenamiento está desequilibrado.
Presentamos CrescendoNet, una arquitectura de CNN profunda mediante el apilamiento de bloques de construcción simples sin conexiones residuales.
Combinamos splines con redes neuronales para obtener una novedosa distribución sobre funciones y la utilizamos para modelar funciones de intensidad de procesos puntuales.
Desarrollamos un BERT comprimido de forma agnóstica, que es 4,3 veces más pequeño y 4,0 veces más rápido que el BERT-BASE, a la vez que consigue un rendimiento competitivo en GLUE y SQuAD.
Demostramos que la mayoría de las variantes de los autocodificadores de importancia ponderada pueden derivarse de una manera más principista como casos especiales de enfoques de muestreo de importancia adaptativa como el algoritmo de sueño reponderado.
NUQSGD cierra la brecha entre las garantías teóricas de QSGD y el rendimiento empírico de QSGDinf.
Las redes neuronales pueden entrenarse para modificar su propia conectividad, mejorando su rendimiento de aprendizaje en línea en tareas difíciles.
Se propone un método geométrico basado en simplex para hacer frente a los problemas de aprendizaje de pocos disparos.
Demostramos que una entrada de memoria de trabajo a una red de depósito hace que una regla Hebbiana local modulada por la recompensa funcione tan bien como los mínimos cuadrados recursivos (también conocidos como FORCE)
Combinamos las ventajas computacionales de las arquitecturas convolucionales temporales con la expresividad de las variables latentes estocásticas.
Se propone un método sin gradiente para un problema de optimización no convexo 
Proponemos un método novedoso que aprovecha los gradientes de los simuladores diferenciables para mejorar el rendimiento de la RL para el control de la robótica
Proponemos hiperredes bayesianas: un marco para la inferencia bayesiana aproximada en redes neuronales.
Deep Innovation Protection permite evolucionar modelos de mundo complejos de principio a fin para tareas 3D.
Proponemos MACER: un algoritmo de defensa demostrable que entrena modelos robustos maximizando el radio certificado. No utiliza el entrenamiento adversarial, pero se comporta mejor que todas las defensas l2 demostrables existentes.
Este trabajo propone un novedoso método actor-crítico que utiliza los hessianos de un crítico para actualizar un actor.
escalar clasificadores generativos en conjuntos de datos complejos, y evaluar su eficacia para rechazar entradas ilegales, incluyendo muestras fuera de distribución y ejemplos adversos.
Una teoría para la inicialización y el escalado de las capas de la red neuronal ReLU
Los resultados de las modernas APIs de PNL en textos sin sentido proporcionan fuertes señales sobre los internos del modelo, lo que permite a los adversarios robar las APIs.
Introducimos SeaRNN, un novedoso algoritmo para el entrenamiento de RNN, inspirado en el enfoque de aprendizaje de búsqueda para la predicción estructurada, con el fin de evitar las limitaciones del entrenamiento MLE.
Un método de aprendizaje continuo que utiliza la destilación para combinar las políticas de los expertos y el aprendizaje por transferencia para acelerar el aprendizaje de nuevas habilidades.
Modelo de aprendizaje por refuerzo explicable mediante una novedosa combinación de mezcla de expertos con árboles de decisión no diferenciables.
Desarrollamos y analizamos un nuevo algoritmo de optimización sin derivadas con muestreo de momento e importancia con aplicaciones al control continuo.
Proponemos un nuevo método para entrenar el hashing profundo para la recuperación de imágenes utilizando únicamente una métrica de distancia relacional entre muestras
Proponemos un enfoque novedoso para mejorar un determinado mapeo de superficies cruzadas a través del refinamiento local con un nuevo método iterativo para deformar la malla con el fin de cumplir con las restricciones del usuario.
Introducir un punto de vista teórico de la información sobre el comportamiento de los procesos de optimización de las redes profundas y su capacidad de generalización
La representación de la arquitectura de la red como un conjunto de árboles sintácticos y la optimización de su estructura conducen a modelos de regresión precisos y concisos. 
Estudio empírico y teórico de los efectos del estancamiento en la ejecución no sincrónica en algoritmos de aprendizaje automático.
Este trabajo presenta un algoritmo escalable para la identificación de sistemas no lineales fuera de línea a partir de observaciones parciales.
Análisis general de los métodos basados en signos (por ejemplo, signSGD) para la optimización no convexa, construido sobre límites intuitivos en las probabilidades de éxito.
Para el aprendizaje fuera de política con retroalimentación de bandidos, proponemos un nuevo algoritmo de aprendizaje contrafactual regularizado por la varianza, que tiene tanto fundamentos teóricos como un rendimiento empírico superior.
Combinamos restricciones duras elaboradas a mano con una restricción débil a priori para realizar imágenes sísmicas y obtener información sobre la distribución "posterior" aprovechando la multiplicidad de los datos.
Estado del arte en el análisis sintáctico complejo de texto a SQL mediante la combinación de razonamiento relacional duro y blando en la codificación de esquemas/preguntas.
Introducimos una configuración de aprendizaje continuo basada en el modelado del lenguaje en la que no se da ninguna señal explícita de segmentación de la tarea y proponemos un modelo de red neuronal con memoria a largo plazo creciente para abordarla.
Propuesta de algoritmo basado en RNN para estimar la distribución de la predicción en los problemas de predicción de series temporales en uno y varios pasos
Las LSTM pueden modelar con mayor eficacia la memoria de trabajo si se aprenden utilizando el aprendizaje por refuerzo, de forma similar al sistema de dopamina que modula la memoria en la corteza prefrontal    
Reformular las no linealidades de las redes profundas desde un ámbito de cuantificación vectorial y unir la mayoría de las no linealidades conocidas.
Aprendemos a generar condicionalmente secuencias de proteínas dadas estructuras con un modelo que captura dependencias dispersas y de largo alcance.
Un marco que vincula las capas profundas de la red con los algoritmos de optimización estocástica; puede utilizarse para mejorar la precisión del modelo e informar sobre el diseño de la red.
Un método de aprendizaje de la configuración de cuantificación para redes de baja precisión que consigue un rendimiento de vanguardia para las redes cuantificadas.
Proponemos varias estrategias generales de debiasing para abordar los sesgos comunes que se observan en diferentes conjuntos de datos y obtener una mejora sustancial del rendimiento fuera del dominio en todos los escenarios.
Presentamos un algoritmo de reconstrucción basado en la inferencia de la CNN para abordar la TC de muy pocas vistas. 
Construimos agentes conversacionales conocedores mediante el condicionamiento de Wikipedia + una nueva tarea supervisada.
Síntesis de los algoritmos GCN y LINUCB para el aprendizaje en línea con retroalimentación perdida
Un buen etiquetador da etiquetas similares a un artículo determinado y a los artículos que cita
Proponemos un método basado en la cuantificación que regulariza las representaciones aprendidas de una CNN para que se alineen automáticamente con la matriz de conceptos entrenable, filtrando así eficazmente las perturbaciones adversas.
El documento proporciona una caracterización completa de las capas lineales invariantes de la permutación y equivariantes para los datos de los gráficos.
Los modelos parciales causalmente correctos no tienen que generar toda la observación para seguir siendo causalmente correctos en entornos estocásticos.
Un algoritmo eficiente de aprendizaje permanente que proporciona un mejor equilibrio entre la precisión y la complejidad de tiempo/memoria en comparación con otros algoritmos. 
Demostramos los resultados de entrenamiento más avanzados utilizando una representación de punto flotante de 8 bits, a través de Resnet, GNMT, Transformer.
Proponemos la entropía cruzada de instancia (ICE), que mide la diferencia entre una distribución de coincidencia estimada a nivel de instancia y su verdad de base. 
La incorporación, en el modelo, de variables latentes que codifican el contenido futuro mejora la precisión de la predicción a largo plazo, lo que es fundamental para una mejor planificación en la RL basada en modelos.
Marco de detección de anomalías basado en un tensor integrador (ITAD) para un sistema de satélites.
La limitación de la información de estado para la política por defecto puede mejorar el rendimiento, en un marco de RL regularizado por KL en el que tanto el agente como la política por defecto se optimizan conjuntamente
Calculamos la saliencia utilizando un modelo generativo fuerte para marginar eficazmente sobre entradas alternativas plausibles, revelando áreas de píxeles concentradas que conservan la información de la etiqueta.
La Red de Variación es un modelo generativo capaz de aprender atributos de alto nivel sin supervisión que luego pueden utilizarse para la manipulación controlada de entradas.
Los humanos en el bucle revisan los documentos para que concuerden con las etiquetas contrafactuales, lo que ayuda a reducir la dependencia de las asociaciones espurias.
Proponemos una nueva medida objetiva para evaluar las explicaciones basada en la noción de robustez adversarial. Los criterios de evaluación nos permiten además derivar nuevas explicaciones que capturan las características pertinentes cualitativa y cuantitativamente.
Este trabajo presenta un marco basado en GAN para el aprendizaje de la distribución a partir de datos incompletos de alta dimensión.
Proponemos un nuevo método de compresión, Inter-Layer Weight Prediction (ILWP) y un método de cuantificación que cuantifica los residuos predichos entre los pesos en las capas de convolución.
Ampliamos una técnica del estado del arte para incorporar directamente los FLOPs como parte del objetivo de optimización, y demostramos que, dado un requisito de FLOPs deseado, se entrenan con éxito diferentes redes neuronales.
Método de traducción multidominio y multimodal de imagen a imagen con control de granularidad
Análisis de la expresividad y generalidad de las redes neuronales recurrentes con no linealidades ReLu utilizando la descomposición Tensor-Train.
Proponemos un nuevo y eficiente algoritmo para construir ejemplos adversos mediante deformaciones, en lugar de perturbaciones aditivas.
Regularización del aprendizaje adversarial con un cuello de botella de información, aplicado al aprendizaje por imitación, al aprendizaje de refuerzo inverso y a las redes adversariales generativas.
El sencillo método de aumento supera la relación robustez/precisión observada en la literatura y abre preguntas sobre el efecto de la distribución de entrenamiento en la generalización fuera de la distribución.
Utilizamos redes de densidad de mezcla para hacer una estimación de densidad condicional completa para la regresión de desplazamiento espacial y la aplicamos a la tarea de estimación de la pose humana.
Visualización de las diferencias entre la atención regular y la relativa para Music Transformer.
Tres factores (tamaño del lote, tasa de aprendizaje, ruido de gradiente) cambian de forma predecible las propiedades (por ejemplo, la nitidez) de los mínimos encontrados por el SGD.
Enfoque generativo sencillo para resolver el problema de la analogía de palabras que permite comprender las relaciones entre las palabras y los problemas para estimarlas
Este artículo reexamina varias prácticas habituales de fijación de hiperparámetros para el ajuste fino.
mejora del aprendizaje profundo de transferencia con regularización mediante mapas de características basados en la atención
Modelo neuronal que predice sentimientos multiaspecto y genera simultáneamente una máscara probabilística multidimensional. El modelo supera las líneas de base fuertes y genera máscaras que son: fuertes predictores de características, significativas e interpretables.
Proponer una nueva función objetivo para la generación de secuencias neuronales que integre las funciones objetivo basadas en ML y RL.
Una red capsular aprendida por pares que rinde bien en tareas de verificación de rostros con datos etiquetados limitados 
Reactor combina múltiples contribuciones algorítmicas y arquitectónicas para producir un agente con mayor eficiencia de muestreo que el DQN de duelo priorizado, a la vez que ofrece un mejor rendimiento en tiempo de ejecución que A3C.
El artículo describe métodos para verificar y reconocer los planes de HTN mediante el análisis sintáctico de las gramáticas de atributos.
Exploramos la búsqueda de arquitecturas neuronales para tareas lingüísticas. La búsqueda de células recurrentes es un reto para la NMT, pero la búsqueda de mecanismos de atención funciona. El resultado de la búsqueda de atención en la traducción es transferible a la comprensión lectora.
Proponemos un regularizador que mejora la interpolación y los autocodificadores y mostramos que también mejora la representación aprendida para las tareas posteriores.
Este artículo presenta un método para generar estocásticamente fotogramas de vídeo intermedios a partir de fotogramas clave dados, utilizando convoluciones 3D directas.
Este trabajo estudia la alineación de grafos de conocimiento débilmente supervisada con marcos de entrenamiento adversariales.
El aprendizaje multivista mejora el aprendizaje no supervisado de la representación de frases
Proponemos un enfoque de meta-aprendizaje para guiar las tareas de segmentación visual a partir de cantidades variables de supervisión.
La optimización latente mejora la dinámica de entrenamiento adversarial. Presentamos tanto el análisis teórico como el estado de la técnica de generación de imágenes con ImageNet 128x128.
Este artículo trata de las propiedades teóricas del punto óptimo de primer orden de la red neuronal de dos capas en el caso de sobreparametrización
Una arquitectura permite que las CNN entrenadas en las secuencias de vídeo converjan rápidamente 
Presentamos un nuevo método que combina el ataque adversario basado en la transferencia y el ataque adversario de caja negra puntuado, mejorando la tasa de éxito y la eficiencia de la consulta del ataque adversario de caja negra en diferentes arquitecturas de red.
Describir una técnica de interfaz neuro-AI para evaluar las redes generativas adversariales
Utilizando métodos de muestreo adaptativo para acelerar la evaluación de la probabilidad de eventos raros, estimamos la probabilidad de un accidente bajo una distribución base que rige el comportamiento estándar del tráfico. 
Un enfoque de métodos dinámicos de bagging para evitar la transferencia negativa en el aprendizaje de transferencia de redes neuronales de pocos disparos
Un nuevo algoritmo basado en la finalización de la matriz para modelar la progresión de la enfermedad con eventos
Unas simples restricciones de similitud sobre la NMT multilingüe permiten por primera vez una traducción de alta calidad entre pares de idiomas no vistos.
El núcleo neural tangente en una red ReLU inicializada aleatoriamente tiene fluctuaciones no triviales siempre que la profundidad y la anchura sean comparables. 
Proponemos nuevas descomposiciones tensoriales y regularizadores asociados para obtener rendimientos de vanguardia en la finalización de bases de conocimiento temporales.
Utilizamos una estructura de modelo de tipo CVAE para aprender a generar directamente pizarras/páginas enteras para los sistemas de recomendación.
Combinando las redes neuronales de grafos y el modelo generativo de grafos RNN, proponemos una arquitectura novedosa que es capaz de aprender de una secuencia de grafos en evolución y predecir la evolución de la topología del grafo para los futuros pasos de tiempo
Proponemos un agente de aprendizaje de descomposición que ayuda a los contestadores de preguntas simples a responder preguntas compuestas sobre el grafo de conocimiento.
Modelo basado en la energía aprendida con la coincidencia de la puntuación
Proponer un modelo RBM general basado en un tensor que puede comprimir el modelo en gran medida y al mismo tiempo mantener una fuerte capacidad de expresión del modelo
Un enfoque de aprendizaje de refuerzo actor-crítico con retornos de varios pasos aplicado a la conducción autónoma con el simulador Carla.
Proponemos nuevos métodos para evaluar y cuantificar la calidad de las distribuciones GAN sintéticas desde la perspectiva de las tareas de clasificación
El objetivo de la agrupación de la supervivencia es asignar a los sujetos en grupos. Sin señales de fin de vida, esta es una tarea difícil. Para abordar esta tarea, proponemos una nueva función de pérdida modificando la estadística de Kuiper.
Mostramos cómo el uso de estimaciones previas semiparamétricas puede acelerar la HPO de forma significativa en todos los conjuntos de datos y métricas.
Los procedimientos de enrutamiento no son necesarios para CapsNets
Ajustando la anchura o la varianza de inicialización de cada capa de forma diferente, podemos realmente someter los problemas de explosión de gradiente en las redes residuales (con capas totalmente conectadas y sin batchnorm). Se ha desarrollado una teoría matemática que no sólo dice cómo hacerlo, sino que sorprendentemente también es capaz de predecir, después de aplicar tales trucos, la rapidez con la que se entrena la red para alcanzar un determinado rendimiento del conjunto de pruebas. Esto es algo de magia negra, y se llama "Teoría del Campo Medio Profundo".
Comunicación dirigida en el aprendizaje cooperativo por refuerzo de múltiples agentes
Hemos desarrollado un sistema de apoyo al grabado de arte latte que proyecta el procedimiento de elaboración directamente sobre un capuchino para ayudar a los principiantes a hacer un arte latte de grabado bien equilibrado.
Proponemos auto-supervisiones temporales para el aprendizaje de funciones temporales estables con GANs.
Clasificación translingüística semi-supervisada de documentos
¿Son los HMM un caso especial de las RNN? Investigamos una serie de transformaciones arquitectónicas entre los HMM y las RNN, tanto a través de derivaciones teóricas como de la hibridación empírica, y proporcionamos nuevas perspectivas.
Proporcionamos un análisis teórico de la información y experimental de los autocodificadores variacionales más avanzados.
Desarrollamos los fundamentos teóricos de la potencia expresiva de las GNN y diseñamos una GNN probadamente más potente.
Un nuevo algoritmo para el aprendizaje multitarea en línea que aprende sin reiniciar en los límites de la tarea
Capacidad multilingüe del BERT multilingüe: un estudio empírico
Un marco teórico para la red ReLU profunda que puede explicar múltiples fenómenos desconcertantes como la sobreparametrización, la regularización implícita, los billetes de lotería, etc. 
Alineación de lenguas sin la piedra Rosetta: sin datos paralelos, construimos diccionarios bilingües utilizando un entrenamiento adversarial, un escalado local entre dominios y un criterio proxy preciso para la validación cruzada.
Realizamos el recuento para responder a las preguntas visuales; nuestro modelo produce salidas interpretables contando directamente a partir de los objetos detectados.
Estudiamos el problema de la generación de grafos y proponemos un potente modelo generativo profundo capaz de generar grafos arbitrarios.
Representar oraciones componiéndolas con Tree-LSTMs según árboles de análisis inducidos automáticamente.
Tres nuevos algoritmos con estudios de ablación para podar la red neuronal con el fin de optimizar la longitud del cableado, frente al número de pesos restantes.
Recuperación de momentos de vídeo basada en un texto débilmente supervisado
Cómo utilizar la generalización apilada para mejorar el rendimiento de los algoritmos de aprendizaje de transferencia existentes cuando se dispone de datos etiquetados limitados.
Este trabajo introduce una física previa para el Deep Learning y aplica la topología de red resultante para el control basado en modelos.
Mejoramos los modelos generativos proponiendo un meta-algoritmo que filtra los nuevos datos de entrenamiento de las salidas del modelo.
Utilizamos un simulador desenrollado como modelo diferenciable de extremo a extremo de la estructura de la proteína y mostramos que puede (a veces) generalizar jerárquicamente a topologías de pliegues no vistas.
Entrenamiento automatizado de ratones para la neurociencia con inferencia iterativa de estrategias latentes en línea para la predicción del comportamiento
Analizamos las redes recurrentes entrenadas en la clasificación de sentimientos y descubrimos que todas exhiben una dinámica de atractor lineal aproximada cuando resuelven esta tarea.
Construimos una simulación física de un roedor, lo entrenamos para que resolviera un conjunto de tareas y analizamos las redes resultantes.
Una extensión de los GANs que combina el transporte óptimo en forma primaria con una distancia de energía definida en un espacio de características aprendido de forma adversa.
Entrenamiento de un agente en un mundo virtual 2D para la adquisición y generalización del lenguaje en tierra.
Un algoritmo de RL que aprende a ser robusto ante los cambios de dinámica
Este trabajo proporciona un esquema de abstracción basado en el juego para calcular políticas probables para POMDPs.
Un conjunto de datos de juguete basado en la percolación crítica en un grafo planar proporciona una ventana analítica a la dinámica de entrenamiento de las redes neuronales profundas  
Reformulamos el problema de generación como uno de edición de puntos existentes, y como resultado extrapolamos mejor que los GAN tradicionales.
Un nuevo enfoque que aprende una representación para describir modelos de transición en dominios inciertos complejos utilizando reglas relacionales. 
Proponemos una red de planificación diferenciable de extremo a extremo para grafos. Esto puede ser aplicable a muchos problemas de planificación del movimiento
Aprendemos a desentrañar de alta calidad utilizando sólo instancias únicas de imágenes corruptas como datos de entrenamiento.
Resolvemos el problema de las recompensas dispersas en las tareas de la interfaz de usuario web utilizando la exploración guiada por demostraciones
Arquitectura embebida para el aprendizaje profundo en dispositivos optimizados para la detección de rostros y el reconocimiento de emociones 
Utilizar la misma incrustación en todas las covariables no tiene sentido, mostramos que un algoritmo de descomposición tensorial aprende incrustaciones dispersas específicas de las covariables y temas naturalmente separables de forma conjunta y con eficiencia de datos.
Utilizando la programación lineal, demostramos que la complejidad computacional del entrenamiento aproximado de las redes neuronales profundas depende polinomialmente del tamaño de los datos para varias arquitecturas
Unificamos el filtro de Kalman ampliado (EKF) y el enfoque del espacio de estados para la propagación de la expectativa de potencia (PEP) resolviendo las integrales de coincidencia de momentos intratables en PEP mediante la linealización. Esto conduce a una extensión globalmente iterada del EKF.
Exploración de la capacidad de aprendizaje de las redes neuronales
Proponemos una metodología de evaluación generalizada para interpretar los sesgos del modelo, los sesgos del conjunto de datos y su correlación.
Los agentes sociales aprenden a hablar entre sí en lenguaje natural para alcanzar un objetivo
Demostramos que el colapso posterior en las VAE lineales está causado enteramente por la log-verosimilitud marginal (no por la ELBO). Los experimentos con VAE profundas sugieren que se produce un fenómeno similar.
Este trabajo propone un nuevo modelo que combina información de múltiples escalas para el aprendizaje secuencia a secuencia.
Proponemos un nuevo método de entrenamiento adversarial certificado, CROWN-IBP, que logra una robustez de última generación para perturbaciones adversariales de norma L_inf.
En la poda de redes estructuradas, el ajuste fino de un modelo podado sólo ofrece un rendimiento comparable al del entrenamiento desde cero.
Técnica interactiva para mejorar el cepillado en conjuntos de datos de trayectorias densas teniendo en cuenta la forma del cepillado.
Desarrollamos un enfoque novedoso para modelar la composicionalidad de los objetos en las imágenes en un marco GAN.
Discriminación auditiva adversarial mediante la dependencia temporal
 Proponemos un novedoso método de entrenamiento de GAN considerando ciertas muestras falsas como reales para aliviar el colapso del modo y estabilizar el proceso de entrenamiento.
Presentamos una herramienta visual para explorar interactivamente el espacio latente de un autocodificador de secuencias peptídicas y sus atributos.
Se presentan experimentos que proporcionan pruebas sólidas de que una neurona se comporta como un clasificador binario durante el entrenamiento y la prueba
Un método para enriquecer y combinar características para mejorar la precisión de la clasificación
Ampliar la arquitectura GAN para obtener el control de las ubicaciones e identidades de múltiples objetos dentro de las imágenes generadas.
Proponemos un novedoso modelo de extremo a extremo (SPNet) para incorporar andamiajes semánticos que mejoren el resumen abstracto de los diálogos.
Presentamos un agente RL MINERVA que aprende a caminar sobre un grafo de conocimiento y a responder consultas
Una aproximación de la corriente ventral de los primates como una red convolucional tiene un bajo rendimiento en el reconocimiento de objetos, y múltiples características arquitectónicas contribuyen a ello. 
Consideramos el problema del aprendizaje de políticas óptimas en dominios de tiempo limitado y de tiempo ilimitado utilizando interacciones de tiempo limitado.
Una de las cuestiones teóricas del aprendizaje profundo
Analizamos y desarrollamos una implementación computacionalmente eficiente de la regularización jacobiana que aumenta los márgenes de clasificación de las redes neuronales.
Somos los primeros en el campo en mostrar cómo elaborar un diseño de núcleo disperso eficaz desde tres aspectos: composición, rendimiento y eficiencia.
Una nueva red atencional media marginada para la localización temporal de la acción débilmente supervisada 
Proponemos un nuevo autocodificador incorporado con una transformada de retardo de inserción multidireccional para interpretar imágenes profundas a priori.
Garantizar que los modelos aprendidos de forma federada no revelen la participación de un cliente.
Mostramos cómo el preentrenamiento de una red neuronal no entrenada con tan sólo 5-25 ejemplos puede mejorar los resultados de reconstrucción en problemas de detección comprimida y recuperación semántica como la coloración.
Proponemos el Entrenamiento Cooperativo, un novedoso algoritmo de entrenamiento para el modelado generativo de datos discretos.
Introducimos un método para calcular una recompensa intrínseca por la curiosidad utilizando métricas derivadas del muestreo de un modelo de variable latente utilizado para estimar la dinámica.
Presentamos un modelo generativo para incrustaciones de palabras compositivas que captura las relaciones sintácticas, y proporcionamos una verificación y evaluación empíricas.
Proponemos un enfoque híbrido basado en modelos y sin modelos que utiliza información semántica para mejorar la generalización del DRL en entornos artificiales.
Utilizamos técnicas de aprendizaje profundo para resolver el problema de representación y recuperación de señales dispersas.
Presentamos Dreamer, un agente que aprende comportamientos de largo horizonte puramente por imaginación latente utilizando gradientes de valor analíticos.
Proponemos MULTIPOLAR, un método de RL de transferencia que aprovecha un conjunto de políticas de origen recogidas bajo diversas dinámicas ambientales desconocidas para aprender eficientemente una política objetivo en otra dinámica.
Un agente entrenado sólo con curiosidad, y sin recompensa extrínseca, se desenvuelve sorprendentemente bien en 54 entornos populares, incluyendo el conjunto de juegos de Atari, Mario, etc.
para las transformaciones espaciales, el minimizador robusto también minimiza la precisión estándar; la regularización que induce la invarianza conduce a una mayor robustez que las arquitecturas especializadas
Se propone la noción de aprendizaje de orden y se aplica a los problemas de regresión en visión por ordenador
Demostramos que las redes neuronales funcionan cambiando la topología de un conjunto de datos y exploramos cómo las elecciones arquitectónicas afectan a este cambio.
Utilizamos herramientas empíricas de conectividad de modo y SVCCA para investigar la heurística de entrenamiento de redes neuronales de reinicio de la tasa de aprendizaje, calentamiento y destilación de conocimientos.
Inferencia variacional para inferir una distribución discreta de la que se deriva una red neuronal de baja precisión
Proponemos un novedoso método basado en tensores para redes convolucionales en grafos dinámicos
"Generación de nuevos materiales químicos mediante novedosos GANs de dominio cruzado".
Proporcionamos un estimador y un algoritmo de estimación para una clase de problema de regresión multitarea y proporcionamos un análisis estadístico y computacional..
Utilización del aprendizaje profundo por refuerzo para enseñar a los agentes la coordinación del estilo de la flota de transporte compartido.
Estabilidad de las representaciones de la transformada de dispersión de los datos de los gráficos a las deformaciones del soporte del gráfico subyacente.
Proponemos una novedosa arquitectura de red profunda que puede decidir dinámicamente su capacidad de red mientras se entrena en un escenario de aprendizaje permanente.
En este trabajo se analizan diferentes métodos para emparejar la OV con el aprendizaje profundo y se propone una predicción simultánea de las correcciones y la incertidumbre.
Hemos introducido Deep Density Network, un modelo DNN unificado para estimar la incertidumbre para la exploración/explotación en los sistemas de recomendación.
Entrenamos RNNs en usuarios famosos de Twitter para determinar si la población general de Twitter es más propensa a creer en el cambio climático después de un desastre natural.
Utilizando una novedosa representación de sistemas dinámicos lineales simétricos con un estado latente, formulamos el control óptimo como un programa convexo, dando el primer algoritmo en tiempo polinómico que resuelve el control óptimo con una complejidad muestral sólo polilogarítmica en el horizonte temporal.
Modelamos el generador de datos (en GAN) mediante un polinomio de alto orden representado por tensores de alto orden.
Demostramos que las redes neuronales profundas son capaces de aprender a partir de datos que han sido diluidos por una cantidad arbitraria de ruido.
proponemos un enfoque de meta-aprendizaje para la traducción automática neural de bajos recursos que puede aprender rápidamente a traducir en un nuevo idioma
Un método para la detección activa de anomalías. Presentamos una nueva capa que se puede adjuntar a cualquier modelo de aprendizaje profundo diseñado para la detección de anomalías sin supervisión para transformarlo en un método activo.
Generamos ejemplos para explicar una desición del clasificador mediante interpolaciones en el espacio latente. El coste del autocodificador variacional se amplía con un funcional del clasificador sobre la ruta del ejemplo generado en el espacio de datos.
Introducir un enfoque que permita a los agentes aprender modelos de acción PPDDL de forma incremental sobre múltiples problemas de planificación en el marco del aprendizaje por refuerzo.
Proponemos un nuevo algoritmo de DRL off-policy que consigue el rendimiento más avanzado. 
Proponemos un método que puede hacer uso de la información de múltiples pasajes para la garantía de calidad de dominio abierto.
Algoritmo de reducción de la dimensionalidad para visualizar textos con información de red, por ejemplo un corpus de correos electrónicos o coautorías.
Presentamos un marco que aprovecha las simulaciones informáticas de alta fidelidad para interrogar y diagnosticar los sesgos dentro de los clasificadores ML. 
Presentamos y evaluamos decodificadores de nubes de puntos basados en el muestreo que superan el enfoque MLP de referencia al ajustarse mejor a la semántica de las nubes de puntos.
Usamos la RL profunda para aprender una política que dirija la búsqueda de un algoritmo genético para optimizar mejor el coste de ejecución de los grafos de computación, y mostramos resultados mejorados en grafos TensorFlow del mundo real.
Demostramos que con la pérdida y la arquitectura adecuadas, el aprendizaje predictivo de la vista mejora la detección de objetos en 3D
una red generativa adversarial para modelar el estilo en un sistema de conversión de texto en voz
Demostramos en una tarea de aprendizaje simplificada que la sobreparametrización mejora la generalización de una convnet que se entrena con descenso de gradiente.
Metaaprendizaje bayesiano mediante el marco PAC-Bayes y distribuciones implícitas a priori
Documento de posición que propone explicaciones rebeldes y engañosas para los agentes.
Investigamos una variante de los autocodificadores variacionales en la que hay una superestructura de variables latentes discretas sobre las características latentes.
Demostramos que la clave para conseguir un buen rendimiento con los IDMs reside en el aprendizaje de representaciones latentes para codificar la información compartida entre experiencias equivalentes, de forma que puedan generalizarse a escenarios no vistos.
Identificamos el sesgo angular que causa el problema del gradiente evanescente en las redes profundas y proponemos un método eficiente para reducir el sesgo.
Empleamos redes neuronales de grafos en el marco de la EM variacional para la inferencia y el aprendizaje eficientes de las redes lógicas de Markov.
Un enfoque de aprendizaje de meta-reforzamiento incorporando un controlador de red neuronal aplicado a la conducción autónoma con el simulador Carla.
Deducir un marco de cuello de botella de información en el aprendizaje por refuerzo y algunas teorías y herramientas simples relevantes.
Proponemos un enfoque de módulos neuronales para el aprendizaje continuo utilizando un entorno visual unificado con un gran espacio de acción.
Proponemos un método de uso de GANs para generar razonamientos visuales de alta calidad que ayuden a explicar las predicciones del modelo. 
Proponemos un nuevo algoritmo que aprovecha la expresividad de las redes neuronales generativas para mejorar los algoritmos de las estrategias evolutivas.
Comprimimos y aceleramos los modelos de reconocimiento de voz en dispositivos integrados mediante una técnica de regularización de normas de trazado y núcleos optimizados.
Hacemos una justificación teórica del concepto de estimador directo.
Con un conjunto de modificaciones, de menos de 10 LOC, a A2C se obtiene un actor-crítico sin política que supera a A2C y tiene un rendimiento similar a ACER. Las modificaciones son tamaños de lote grandes, sujeción agresiva y "forzamiento" de la política con ruido gumbel.
Generación de texto utilizando incrustaciones de frases a partir de vectores de salto de pensamiento con la ayuda de redes adversariales generativas.
nuevo decodificador fuera de orden para la traducción automática neural
En este trabajo, estudiamos un nuevo problema de aprendizaje de grafos: aprender a contar isomorfismos de subgrafos.
Presentamos un agente que utiliza una beta-vae para extraer características visuales y un mecanismo de atención para ignorar características irrelevantes de las observaciones visuales para permitir una transferencia robusta entre dominios visuales.
Proponemos el primer algoritmo para verificar la robustez de los Transformers.
En contra de lo que se creía hasta ahora, el rendimiento de entrenamiento de las redes profundas, cuando se mide adecuadamente, es predictivo del rendimiento en las pruebas, de acuerdo con la teoría clásica del aprendizaje automático.
Proponemos un marco que incorpora la planificación para la exploración y el aprendizaje eficientes en entornos complejos.
Nuestro artículo analiza el enorme poder de representación de las redes, especialmente con "conexiones de salto", que pueden utilizarse como método para una mejor generalización.
Este trabajo propone una nueva función objetivo para sustituir el término KL por uno que emula el objetivo de máxima discrepancia media (MMD). 
Planteamos que las probabilidades de los modelos generativos están excesivamente influenciadas por la complejidad de la entrada, y proponemos una forma de compensarla al detectar entradas fuera de distribución
Investigamos la convergencia de algoritmos de optimización populares como Adam , RMSProp y proponemos nuevas variantes de estos métodos que convergen de forma demostrable a la solución óptima en entornos convexos. 
Presentamos defensas eficaces contra los ataques de envenenamiento de etiqueta limpia. 
MXGNet es una arquitectura multicapa basada en grafos multiplexados que consigue un buen rendimiento en varias tareas de razonamiento diagramático.
Proponemos un novedoso marco multitarea que aprende la detección de tablas, el reconocimiento de componentes semánticos y la clasificación de tipos de celdas para tablas de hojas de cálculo con resultados prometedores.
Proponemos métricas automáticas para evaluar de forma holística la generación de diálogos abiertos y éstas se correlacionan fuertemente con la evaluación humana.
Hemos ideado una nueva Convolución Gráfica Separable en Profundidad (DSGC) para los datos de dominio espacial genérico, que es altamente compatible con la convolución separable en profundidad.
Entrenamos un conjunto de modelos capaces de transcribir, componer y sintetizar formas de onda de audio con una estructura musical coherente, gracias al nuevo conjunto de datos MAESTRO.
Un estudio empírico de la inferencia variacional basada en la minimización de la divergencia chi-cuadrado, mostrando que minimizar el CUBO es más difícil que maximizar el ELBO
Aprovechamos la linealidad global de los modelos entrenados para la mezcla en la inferencia para romper la localidad de las perturbaciones adversarias.
La puesta a punto de BERT en corpus jurídicos proporciona mejoras marginales, pero valiosas, en las tareas de PNL en el ámbito jurídico.
Formulamos un modelo probabilístico de secuencia latente para abordar la transferencia de estilo de texto sin supervisión, y mostramos su eficacia en un conjunto de tareas de transferencia de estilo de texto sin supervisión. 
Propone un modelo y un procedimiento de inferencia analíticamente trazables (regresión dispersa mal parametrizada, inferida utilizando la penalización L_1 y estudiada en el límite de interpolación de datos) para estudiar los fenómenos relacionados con las redes profundas en el contexto de los problemas inversos. 
Proponemos un nuevo enfoque de filtrado colaborativo basado en el hashing variacional, optimizado para una nueva variante de la distancia Hamming, que supera al estado del arte hasta en un 12% en NDCG.
Un algoritmo de optimización que explora varios tamaños de lote basados en la probabilidad y explota automáticamente el tamaño de lote exitoso que minimiza la pérdida de validación.
Proponemos un marco unificado de Redes Generativas Adversariales (GAN) para aprender a incrustar grafos de conocimiento conscientes del ruido.
Una EBM residual para texto cuya formulación es equivalente a discriminar entre texto humano y generado por máquina. Estudiamos su comportamiento de generalización.
El seudoetiquetado ha demostrado ser una alternativa débil para el aprendizaje semisupervisado. Nosotros, por el contrario, demostramos que el tratamiento del sesgo de confirmación con varias regularizaciones hace que el pseudoetiquetado sea un enfoque adecuado.
Demostramos que una función de valor de condición de objetivo especial entrenada con métodos libres de modelo puede utilizarse dentro del control basado en modelos, lo que da como resultado una eficiencia y un rendimiento de la muestra sustancialmente mejores.
Una nueva arquitectura neuronal para la inferencia amortizada eficiente sobre permutaciones latentes 
Proponemos una novedosa arquitectura de modelo de fondo compartido de dos torres para transferir el conocimiento de las ricas retroalimentaciones implícitas para predecir la relevancia para los sistemas de recuperación a gran escala.
Abordamos la tarea de exploración y navegación autónoma utilizando mapas de asequibilidad espacial que pueden ser aprendidos de manera auto-supervisada, estos superan las líneas de base geométricas clásicas mientras que son más eficientes en cuanto a muestras que los algoritmos contemporáneos de RL
