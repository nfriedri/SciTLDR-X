Forniamo forme analitiche necessarie e sufficienti per i punti critici delle funzioni di perdita quadrata per varie reti neurali, e sfruttiamo le forme analitiche per caratterizzare le proprietà del paesaggio per le funzioni di perdita di queste reti neurali.
Gli algoritmi di apprendimento biologicamente plausibili, in particolare la simmetria dei segni, funzionano bene su ImageNet
Introduciamo il 2-simplicial Transformer e mostriamo che questa architettura è un utile bias induttivo per il ragionamento logico nel contesto del deep reinforcement learning.
Previsione accurata su orizzonti temporali molto lunghi usando RNN tensor-train
Proponiamo un algoritmo di message-passing variazionale per modelli che contengono sia il modello profondo che il modello grafico probabilistico.
Una semplice modifica alla fattorizzazione low-rank che migliora le prestazioni (sia in compiti di immagine che di lingua) pur essendo compatta.
Proponiamo un formato di dati semplice, generale ed efficiente dal punto di vista dello spazio per accelerare l'addestramento dell'apprendimento profondo, permettendo che la fedeltà del campione sia selezionata dinamicamente al momento dell'addestramento
APPRENDIMENTO ROBUSTO DELLA RAPPRESENTAZIONE DISCRIMINATIVA ATTRAVERSO IL RESCALING DEL GRADIENTE: UNA PROSPETTIVA DI REGOLARIZZAZIONE DELL'ENFASI
Le GAN hanno successo grazie all'addestramento avversario o all'uso di ConvNet? Mostriamo che un generatore ConvNet addestrato con una semplice perdita di ricostruzione e vettori di rumore apprendibili porta molte delle proprietà desiderabili di una GAN.
Equipaggiare le MMD GAN con un nuovo kernel a foresta casuale.
Un metodo per stime critiche più accurate nell'apprendimento per rinforzo.
Introduciamo un quadro sistematico per quantificare la robustezza dei classificatori alle perturbazioni naturali delle immagini presenti nei video.
Apprendimento profondo per l'apprendimento automatico di dati tabulari strutturati usando un modello CNN pre-addestrato da ImageNet.
La decodifica dei pixel può ancora funzionare per l'apprendimento della rappresentazione sulle immagini
AdaGrad/Adam a matrice intera, veloce e veramente scalabile, con la teoria per l'ottimizzazione adattativa stocastica non convessa
In questo articolo, proponiamo di imparare un sistema di dialogo che parametrizza indipendentemente diverse abilità di dialogo, e impara a selezionare e combinare ciascuna di esse attraverso l'Attenzione sui Parametri (AoP). 
Proponiamo di distillare un grande set di dati in un piccolo set di dati sintetici che possono addestrare reti vicine alle prestazioni originali. 
Proponiamo un metodo primal-dual subgradient per l'addestramento di GANs e questo metodo allevia efficacemente il collasso della modalità.
Troviamo che l'irrazionalità di un dimostratore esperto può aiutare un allievo a dedurre le sue preferenze. 
Confrontiamo la robustezza dei modelli di 4 popolari compiti NLP: Q&A, NLI, NER e Sentiment Analysis testando le loro prestazioni su input perturbati.
Un nuovo algoritmo basato su cluster di apprendimento del curriculum è proposto per risolvere la formazione robusta di modelli generativi.
Abbiamo proposto un nuovo attacco backdoor distribuito sull'apprendimento federato e dimostriamo che non solo è più efficace rispetto agli attacchi centralizzati standard, ma anche più difficile da difendere con i metodi FL robusti esistenti
Rete neurale per l'apprendimento semi-supervisionato basato sui grafi; rivisita i classici e propaga le *etichette* piuttosto che le rappresentazioni delle caratteristiche
Architettura neurale Ricerca di una serie di compiti di comprensione del linguaggio naturale. Progettare lo spazio di ricerca per i compiti di NLU. E applicare la ricerca dell'architettura differenziabile per scoprire nuovi modelli
In questo articolo introduciamo EvalNE, un toolbox Python per automatizzare la valutazione dei metodi di embedding di rete sulla previsione dei link e garantire la riproducibilità dei risultati.
Garanzia di recupero della discesa del gradiente stocastico con inizializzazione casuale per l'apprendimento di una rete neurale a due strati con due nodi nascosti, pesi a norma unitaria, funzioni di attivazione ReLU e ingressi gaussiani.
Jumpout applica tre semplici ma efficaci modifiche al dropout, basate su nuove conoscenze sulle prestazioni di generalizzazione della DNN con ReLU nelle regioni locali.
Studiamo l'emergere naturale della sparsità nelle attivazioni e nei gradienti per alcuni strati di un modello linguistico LSTM denso, nel corso della formazione.
Le reti di memoria convenzionali generano molti vettori latenti ridondanti con conseguente overfitting e la necessità di memorie più grandi. Introduciamo il dropout della memoria come una tecnica automatica che incoraggia la diversità nello spazio latente.
Il metodo di Nesterov si presenta come una discretizzazione diretta di un'ODE diversa da quella di Su-Boyd-Candes e dimostriamo l'accelerazione del caso stocastico
Proponiamo di imparare a trasferire l'apprendimento (L2TL) per migliorare l'apprendimento di trasferimento su un set di dati di destinazione attraverso l'estrazione giudiziosa di informazioni da un set di dati di origine.
In Deep RL, le funzioni invarianti all'ordine possono essere utilizzate insieme ai moduli di memoria standard per migliorare il decadimento del gradiente e la resilienza al rumore.
Questo articolo introduce un algoritmo per gestire un problema di ottimizzazione con vincoli multipli sotto la visione di manifold.
Un metodo per fare Q-learning su spazi d'azione continui prevedendo una sequenza di azioni 1-D discretizzate.
Il nostro metodo incorpora WGAN per ottenere la corrispondenza delle misure di occupazione per l'apprendimento delle transizioni.
La normalizzazione gaussiana esegue un adattamento ai minimi quadrati durante la back-propagation, che azzera e decorrela le derivate parziali dalle attivazioni normalizzate.
Diamo un'analisi teorica della capacità della normalizzazione dei lotti di sintonizzare automaticamente i tassi di apprendimento, nel contesto della ricerca di punti stazionari per un obiettivo di apprendimento profondo.
Proponiamo DVD-GAN, un modello generativo di video di grandi dimensioni che è allo stato dell'arte su diversi compiti e produce video altamente complessi quando addestrato su grandi set di dati del mondo reale.
Proponiamo una nuova architettura di memoria ricorrente che può tracciare i cambiamenti di stato delle entità di senso comune simulando gli effetti causali delle azioni.
Studiamo l'efficienza spaziale delle reti neurali con memoria aumentata quando imparano l'appartenenza al set.
Costruiamo un'approssimazione di Kronecker factored Laplace per le reti neurali che porta ad un'efficiente distribuzione normale della matrice sui pesi.
La regolarizzazione dei grafici costringe l'incorporazione spettrale a concentrarsi sui cluster più grandi, rendendo la rappresentazione meno sensibile al rumore. 
Mostriamo che il bias di esposizione potrebbe essere molto meno grave di quello che si presume attualmente per la formazione MLE LM.
Uno studio controllato del ruolo degli ambienti rispetto alle proprietà nei protocolli di comunicazione emergenti.
Rappresentazione del documento basata sulla griglia con vettori di incorporazione contestualizzati per documenti con layout 2D
Le politiche di RL profonde possono essere attaccate da altri agenti che compiono azioni in modo da creare osservazioni naturali che sono avversarie.
Presentiamo un nuovo algoritmo iterativo basato su modelli generalizzati di basso rango per il calcolo e l'interpretazione dei modelli di incorporazione delle parole.
Impariamo un flusso autoregressivo condizionato per proporre perturbazioni che non inducono il fallimento del simulatore, migliorando le prestazioni di inferenza.
Miglioriamo la risposta alle domande che richiedono un ragionamento multi-hop estraendo una catena intermedia di frasi.
Sviluppiamo un nuovo metodo per la stima della costante di normalizzazione (evidenza bayesiana) usando un Optimal Bridge Sampling e un nuovo Normalizing Flow, che dimostra di superare i metodi esistenti in termini di precisione e tempo di calcolo.
Controlliamo i modelli DNN per la dimenticanza catastrofica usando un nuovo schema di valutazione che riflette le tipiche condizioni di applicazione, con risultati sorprendenti.
Federated Averaging è già un algoritmo di Meta Learning, mentre i metodi addestrati nel datacenter sono significativamente più difficili da personalizzare.
Identifichiamo il downsampling come un mechansim per la memorizzazione negli autocodificatori convoluzionali.
Proponiamo un algoritmo di apprendimento di rinforzo inverso in grado di apprendere funzioni di ricompensa che possono essere trasferite a nuovi ambienti non visti.
La generalizzazione è fortemente correlata all'evidenza bayesiana, e il rumore del gradiente spinge SGD verso i minimi la cui evidenza è grande.
reti avversarie, meccanismo di attenzione, immagini di positroni, scarsità di dati
 Ispirato dalla ricerca sulle neuroscienze, risolve tre debolezze chiave del modello di attenzione ricorrente ampiamente citato aggiungendo semplicemente due termini sulla funzione obiettivo.
Questo articolo introduce un algoritmo di apprendimento attivo basato sul clustering sui grafi.
Proponiamo l'InfoCNF, un efficiente CNF condizionale che impiega reti di gating per imparare le tolleranze di errore dei solutori ODE  
Un metodo di apprendimento non supervisionato che utilizza il meta-apprendimento per consentire l'apprendimento efficiente dei compiti di classificazione delle immagini a valle, superando i metodi all'avanguardia.
VAE condizionale su spazi latenti di modelli generativi pre-addestrati che permette il trasferimento tra domini drasticamente diversi preservando la localizzazione e l'allineamento semantico.
Un nuovo metodo di apprendimento induttivo di trasferimento che impiega l'apprendimento avversario e l'apprendimento multi-task per affrontare la discrepanza nello spazio di input e output
Una nuova architettura ad alte prestazioni per il riconoscimento end-to-end di entità nominate e l'estrazione di relazioni che è veloce da addestrare.
 Schema di Bayes variazionale per reti neurali ricorrenti
caso di studio sul modello ottimale di deep learning per gli UAV
Mostriamo il primo uso di successo di Transformer nella generazione di musica che mostra una struttura a lungo termine. 
Proponiamo un nuovo algoritmo Monte Carlo Tree Search / rollout che si basa sulla ricerca basata sulla larghezza per costruire un lookahead.
Proponiamo un nuovo strato di rete neurale profonda per normalizzare la covarianza all'interno della classe di una rappresentazione interna in una rete neurale che risulta in un miglioramento significativo della generalizzazione delle rappresentazioni apprese.
L'aggiunta di un criterio di diversità ispirato a DPP nell'obiettivo GAN evita il collasso della modalità e porta a generazioni migliori. 
Suggeriamo un limite di generalizzazione che potrebbe spiegare in parte il miglioramento della generalizzazione con la sovra-parametrizzazione.
Introduciamo tre blocchi generici di elaborazione delle nuvole di punti che migliorano sia la precisione che il consumo di memoria di più reti all'avanguardia, permettendo così di progettare reti più profonde e accurate.
Metodi per apprendere le incorporazioni di parole acustiche contestuali da un modello di riconoscimento vocale end-to-end, che si comportano in modo competitivo con le incorporazioni di parole basate sul testo.
Questo articolo propone un metodo di maschera che risolve i precedenti risultati sfocati della stima della profondità monoculare non supervisionata causata dall'occlusione
Introduciamo un nuovo modo di rappresentare i grafi come strutture multicanale simile alle immagini che permette loro di essere gestiti da CNN 2D vanilla.
Proponiamo una misura della memoria a lungo termine e dimostriamo che le reti ricorrenti profonde sono molto più adatte a modellare le dipendenze temporali a lungo termine rispetto a quelle superficiali.
Confrontiamo le rappresentazioni percettive, neurali e modellate della comunicazione animale utilizzando l'apprendimento automatico, il comportamento e la fisiologia. 
Il principio dell'Information Bottleneck applicato alle ResNets, usando i modelli PixelCNN++ per decodificare l'informazione reciproca e generare condizionatamente immagini per l'illustrazione delle informazioni
L'adattamento di un agente RL in un ambiente di destinazione con dinamiche sconosciute è veloce e sicuro quando trasferiamo l'esperienza precedente in una varietà di ambienti e poi selezioniamo azioni avverse al rischio durante l'adattamento.
Proponiamo il Neuro-Symbolic Concept Learner (NS-CL), un modello che impara concetti visivi, parole e parsing semantico di frasi senza supervisione esplicita su nessuno di essi.
Introduciamo un Gaussian Process Prior sui pesi in una rete neurale ed esploriamo la sua capacità di modellare i pesi dipendenti dall'input con benefici per vari compiti, inclusa la stima dell'incertezza e la generalizzazione nell'impostazione a basso campione.
Eseguiamo un'indagine approfondita sull'idoneità dei modelli di auto-attenzione per la traduzione automatica neurale a livello di carattere.
presentiamo i risultati allo stato dell'arte dell'uso delle reti neurali per diagnosticare le radiografie del torace
Dimostriamo l'utilità di una recente tecnica di spiegabilità AI visualizzando le caratteristiche apprese da una CNN addestrata sulla classificazione binaria dei movimenti di zebrafish.
I vincoli di coerenza interna migliorano la capacità degli agenti di sviluppare protocolli emergenti che si generalizzano attraverso i ruoli comunicativi.
Introduciamo una nuova tecnica di analisi che scopre la struttura compositiva interpretabile nelle reti neurali ricorrenti notoriamente difficili da interpretare.
Abbiamo riprodotto le rappresentazioni neurali trovate nei sistemi visivi biologici simulando i loro vincoli di risorse neurali in un modello convoluzionario profondo.
una teoria che collega l'Hessiano della soluzione e il potere di generalizzazione del modello
Abbiamo introdotto la massimizzazione dell'entropia nelle GAN, portando a una reinterpretazione del critico come una funzione energetica.
Presentiamo un algoritmo di trasferimento di stile audio musicale su lunga scala temporale che sintetizza l'audio nel dominio del tempo, ma utilizza rappresentazioni tempo-frequenza dell'audio.
Proponiamo un compito di riferimento ripetuto e un approccio di apprendimento continuo regolarizzato per la comunicazione adattiva con gli esseri umani in domini non familiari
Ordinamento nel codificatore e annullamento dell'ordinamento nel decodificatore per evitare il problema della responsabilità negli autocodificatori impostati
Presentiamo un quadro di apprendimento gerarchico per la navigazione in un ambiente di apprendimento incarnato
L'attribuzione a volte può essere fuorviante
Trasformatore efficiente con hashing sensibile alla località e strati reversibili
Mostriamo che la comprensione del linguaggio attraverso la lettura è un modo promettente per imparare politiche che si generalizzano a nuovi ambienti.
Proponiamo un'ipotesi sul perché la discesa del gradiente generalizza basandosi su come i gradienti per-esempio interagiscono tra loro.
Nuova architettura per la sintesi della vista stereoscopica a spostamenti arbitrari della telecamera utilizzando kernel adattivi a forma di T con dilatazioni adattive.
Questo articolo propone la teoria fondamentale e gli algoritmi ottimali per l'addestramento DNN, che riducono fino all'80% della memoria di addestramento per le DNN popolari.
Questo articolo dimostra l'approssimabilità universale delle reti neurali quantizzate ReLU e presenta il limite di complessità dato un errore arbitrario.
Un quadro generale di apprendimento di rinforzo basato sul valore per il controllo continuo
L'addestramento generativo delle reti adversariali è un problema di apprendimento continuo.
Un quadro unificato per l'apprendimento a pochi colpi e l'apprendimento a zero colpi basato sulla riparametrizzazione della rete
GraphQA è un metodo basato sui grafici per la valutazione della qualità delle proteine che migliora lo stato dell'arte sia per gli approcci di apprendimento manuale che di rappresentazione
Affrontiamo l'apprendimento attivo nell'impostazione batch con oracoli rumorosi e usiamo l'incertezza del modello per codificare la qualità della decisione dell'algoritmo di apprendimento attivo durante l'acquisizione.
Trasferimento in stile stocastico con caratteristiche regolabili. 
Proponiamo AGILE, un framework per l'addestramento degli agenti ad eseguire istruzioni a partire da esempi di rispettivi goal-states.
In Hierarchical RL, introduciamo la nozione di opzione 'soft', cioè adattabile, e mostriamo che questo aiuta l'apprendimento in ambienti multitask.
Apprendimento di un modello generativo controllabile mediante l'apprendimento della rappresentazione latente disentanglement.
Migliorare il modello linguistico per il compito di apprendimento supervisionato 
generare dinamicamente filtri condizionati sull'immagine di ingresso per le CNN in ogni passaggio in avanti 
Proponiamo una nuova rete neurale in qualsiasi momento che permette una valutazione parziale tramite sottoreti con diverse larghezze e profondità.
Proponiamo un nuovo modello per fare previsioni di reazioni retrosintetiche generalizzabili e diverse.
Disentanglement-PyTorch è una libreria per l'apprendimento della rappresentazione variazionale
Estendiamo le recenti intuizioni relative alla coerenza di softmax per ottenere risultati all'avanguardia nel controllo continuo.
Adattiamo una famiglia di giochi combinatori con difficoltà regolabile e una politica ottimale esprimibile come rete lineare, sviluppandola come un ricco ambiente per l'apprendimento di rinforzo, mostrando contrasti nelle prestazioni con l'apprendimento supervisionato, e analizzando l'apprendimento e la generalizzazione multiagente. 
Un metodo aggiuntivo per l'apprendimento profondo per rilevare gli outlier durante la predizione
Un'architettura completamente connessa è usata per produrre embeddings di parole da rappresentazioni di caratteri, supera le embeddings tradizionali e fornisce informazioni sulla sparsità e sul dropout.
Conduciamo attacchi avversari contro le reti neurali binarizzate e mostriamo che riduciamo l'impatto degli attacchi più forti, mantenendo una precisione comparabile in un'impostazione black-box
Un'indagine empirica dell'allineamento basato su GAN di spazi vettoriali di parole, concentrandosi sui casi in cui le trasformazioni lineari esistono provatamente, ma l'addestramento è instabile.
Il nostro obiettivo in questo articolo è quello di proporre un nuovo approccio per affrontare il problema del transfer learning da progetti software etichettati a progetti software non etichettati nel contesto di SVD al fine di risolvere il problema del collasso delle modalità affrontato negli approcci precedenti.
Un metodo più veloce per generare le embeddings dei nodi che impiega una serie di permutazioni sul vicinato immediato di un nodo come contesto per generare la sua rappresentazione.
Mostriamo come inizializzare le architetture ricorrenti con la soluzione in forma chiusa di un autocodificatore lineare per sequenze. Mostriamo i vantaggi di questo approccio rispetto alle RNN ortogonali.
Forniamo una comprensione approfondita della NER con etichettatura di sequenza e proponiamo di usare due tipi di strutture incrociate, entrambe le quali portano miglioramenti teorici ed empirici.
Presentiamo un modello generativo teoricamente provato di embedding dei grafi di conoscenza. 
Studiamo empiricamente quanto sia difficile recuperare le parti mancanti dei modelli addestrati
Questo articolo propone l'adattamento variazionale del dominio, una struttura univoca, scalabile e semplice per l'apprendimento di distribuzioni multiple attraverso l'inferenza variazionale
Proponiamo una nuova combinazione di addestramento avversario e difese dimostrabili che produce un modello con accuratezza allo stato dell'arte e robustezza certificata su CIFAR-10. 
I programmi hanno una struttura che può essere rappresentata come grafici, e le reti neurali a grafo possono imparare a trovare i bug su tali grafici
Introduciamo e analizziamo diversi criteri per rilevare l'overfitting.
Sviluppiamo un solutore di iterazione del valore basato sul punto per POMDP con compiti di percezione e pianificazione attiva.
Introduciamo una rete neurale profonda semplice, non rivoluzionaria e sottoparametrizzata che può, senza addestramento, rappresentare efficacemente le immagini naturali e risolvere compiti di elaborazione delle immagini come la compressione e il denoising in modo competitivo.
Questo articolo 1) caratterizza le funzioni rappresentabili da ReLU DNNs, 2) studia formalmente il beneficio della profondità in tali architetture, 3) fornisce un algoritmo per implementare la minimizzazione del rischio empirico all'ottimalità globale per reti ReLU a due strati.
Benchmark per algoritmi di apprendimento biologicamente plausibili su dataset e architetture complesse
Abbiamo proposto di utilizzare il recente regolatore GrOWL per la simultanea sparsità dei parametri e la legatura nell'apprendimento DNN. 
Un'analisi delle strutture di apprendimento e di ottimizzazione della ricerca dell'architettura nelle reti neurali e oltre.
Facciamo la compressione senza perdite di grandi insiemi di dati di immagini usando un VAE, battendo gli algoritmi di compressione esistenti.
Ottimizzazione bayesiana basata sull'ottimizzazione online degli iperparametri.
In questo articolo, proponiamo la Latent Question Reformulation Network (LQR-net), una rete attenta, multi-hop e parallela, progettata per compiti di risposta alle domande che richiedono capacità di ragionamento.
Spiegare i modelli multivariati di serie temporali trovando osservazioni importanti nel tempo usando i controfattuali
Usiamo l'auto-supervisione su entrambi i domini per allinearli per un adattamento di dominio non supervisionato.
Il minimo di un insieme di hash distribuiti esponenzialmente ha una probabilità di collisione molto utile che generalizza l'indice Jaccard alle distribuzioni di probabilità.
Un modello di rete neurale a grafo con parametri generati da linguaggi naturali, che può eseguire ragionamenti a più vie. 
Presentiamo Meta-Critic, un modulo critico ausiliario per i metodi off-policy actor-critic che può essere meta-appreso online durante l'apprendimento di un singolo compito.
Otteniamo limiti di generalizzazione non virtuosi sulle reti neurali profonde su scala ImageNet combinando un limite PAC-Bayes originale e un metodo di compressione delle reti neurali fuori commercio.
Proponiamo una misura alternativa per determinare l'efficacia degli attacchi avversari nei modelli NLP secondo un metodo basato su una misura di distanza come L2-gain incrementale nella teoria del controllo.
Proponiamo la Warped Residual Network utilizzando un operatore di curvatura parallelizzabile per la propagazione in avanti e all'indietro verso strati lontani che si allena più velocemente della rete neurale residua originale. 
Proponiamo una suite di metriche che catturano le proprietà desiderate degli algoritmi di spiegabilità e la utilizziamo per confrontare e valutare oggettivamente tali metodi
Un recente metodo di rilevamento di out-of-distribution aiuta a misurare la fiducia delle previsioni RNN per alcuni compiti NLP
separazione profondità-2-vs-3 per reti neurali sigmoidali su distribuzioni generali
Proponiamo un metodo scalabile per approssimare gli autovettori del Laplaciano nel contesto del reinforcement learning e mostriamo che le rappresentazioni apprese possono migliorare le prestazioni di un agente RL.
Traduzione da simulazione a immagini reali e generazione di video
Proponiamo PocketFlow, un framework automatizzato per la compressione e l'accelerazione dei modelli, per facilitare l'implementazione dei modelli di deep learning sui dispositivi mobili.
Come imparare le GAN da osservazioni rumorose, distorte e parziali
Vedere l'abstract.  (Per la revisione, il documento è identico, tranne che per un materiale supplementare di 59 pagine, che può servire come una versione di relazione tecnica stand-along del documento).
Introduciamo un meccanismo di attenzione per migliorare l'estrazione delle caratteristiche per l'apprendimento attivo profondo (AL) nell'impostazione semi-supervisionata.
Applichiamo forme canoniche di complessi di gradiente (codici a barre) per esplorare le superfici di perdita delle reti neurali.
Utilizzo di aggiornamenti asincroni del gradiente per accelerare l'addestramento dinamico delle reti neurali
Studiamo il problema della progettazione delle ricompense nelle MARL cooperative basate su ambienti di routing dei pacchetti. I risultati sperimentali ci ricordano di essere attenti a progettare le ricompense, poiché sono davvero importanti per guidare il comportamento dell'agente.
Le reti di Neumann sono un approccio di apprendimento end-to-end, efficiente in termini di campioni, per risolvere problemi inversi lineari nell'imaging che sono compatibili con l'approccio ottimale MSE e ammettono un'estensione all'apprendimento basato su patch.
GLMP: un codificatore di memoria globale (RNN di contesto, puntatore globale) e un decodificatore di memoria locale (RNN di schizzo, puntatore locale) che condividono la conoscenza esterna (MemNN) sono proposti per rafforzare la generazione di risposte nel dialogo orientato al compito.
Proponiamo un nuovo modulo aritificial checkerboard enhancer (ACE) che guida gli attacchi in uno spazio di pixel prestabilito e lo difende con successo con una semplice operazione di padding.
Analizziamo sistematicamente il comportamento di convergenza di popolari algoritmi a gradiente per la risoluzione di giochi bilineari, con aggiornamenti sia simultanei che alternati.
Usiamo i VAE per imparare un'incorporazione condivisa dello spazio latente tra le caratteristiche e gli attributi dell'immagine e quindi raggiungere risultati all'avanguardia nell'apprendimento generalizzato a zero colpi.
Le informazioni spaziali negli ultimi strati non sono necessarie per una buona precisione di classificazione.
Usiamo le reti siamesi per guidare e districare il processo di generazione nelle GAN senza dati etichettati.
Presentiamo Predicted Variables, un approccio per rendere il machine learning un cittadino di prima classe nei linguaggi di programmazione.
Mostriamo come addestrare un modello di predizione video gerarchico senza bisogno di etichette di posa.
In questo lavoro, studiamo il problema dell'apprendimento di rappresentazioni per identificare nuovi oggetti esplorando gli oggetti utilizzando il rilevamento tattile. Il punto chiave qui è che la query è fornita nel dominio delle immagini.
Impieghiamo schemi di compressione lineare omomorfica per rappresentare le statistiche sufficienti di un modello di campo casuale condizionato di coreferenza e questo ci permette di scalare l'inferenza e migliorare la velocità di un ordine di grandezza.
Diamo un'analisi teorica della misura e dell'ottimizzazione dell'informazione reciproca.
Rompendo la gerarchia degli strati, proponiamo un approccio in 3 fasi per la costruzione di reti a gerarchia di neuroni che superano NAS, SMASH e la rappresentazione gerarchica con meno parametri e un tempo di ricerca più breve.
Proponiamo un algoritmo che regola automaticamente i parametri di un motore di simulazione per generare dati di addestramento per una rete neurale in modo da massimizzare l'accuratezza della convalida.
Uno schema di regolarizzazione model-agnostic per la stima della densità condizionale basata sulla rete neurale.
Una formulazione del collo di bottiglia basata su patch in un quadro VAE che impara rappresentazioni non supervisionate più adatte al riconoscimento visivo.
Per risolvere i problemi di scomparsa/esplosione del gradiente, proponiamo una parametrizzazione efficiente della matrice di transizione di RNN che non perde potenza espressiva, converge più velocemente e ha una buona generalizzazione.
Un articolo che suggerisce un metodo per trasformare lo stile delle immagini utilizzando reti neurali profonde.
Miglioriamo i sistemi di dialogo esistenti per rispondere alle persone che condividono storie personali, incorporando rappresentazioni di previsione delle emozioni e rilasciamo anche un nuovo benchmark e un dataset di dialoghi empatici.
Una nuova architettura di rete neurale ricorrente per rilevare la causalità di Granger a coppie tra serie temporali non linearmente interagenti. 
Un algoritmo di addestramento stocastico basato sulla variabile di controllo per reti convoluzionali a grafo che il campo recettivo può essere solo due vicini per nodo.
Metodi Monte Carlo per quantizzare i modelli pre-addestrati senza alcun addestramento aggiuntivo.
Approccio teorico dell'informazione per l'apprendimento non supervisionato di un ibrido di rappresentazioni discrete e continue, 
È importante considerare l'ottimizzazione nello spazio delle funzioni, non solo nello spazio dei parametri. Introduciamo una regola di apprendimento che riduce la distanza percorsa nello spazio delle funzioni, proprio come SGD limita la distanza percorsa nello spazio dei parametri.
Teoria della convergenza per stimatori di gradiente distorti (ma coerenti) nell'ottimizzazione stocastica e applicazione alle reti convoluzionali a grafo
Usiamo le istantanee del processo di formazione per migliorare qualsiasi metodo di stima dell'incertezza di un classificatore DNN.
Un nuovo set di dati di immagini facciali per l'equilibrio di razza, sesso ed età che può essere utilizzato per la misurazione e l'attenuazione dei pregiudizi
Tentiamo di modellare il processo di disegno dei font costruendo modelli generativi sequenziali di grafica vettoriale (SVGs), una rappresentazione altamente strutturata dei caratteri dei font.
Sviluppiamo "l'inferenza relazionale neurale dinamica", un modello di autoencoder variazionale che può rappresentare in modo esplicito e interpretabile le relazioni dinamiche nascoste tra i neuroni.
Per quanto ne sappiamo, DeePa è il primo framework di deep learning che controlla e ottimizza il parallelismo delle CNN in tutte le dimensioni parallelizzabili alla granularità di ogni strato.
Combiniamo il metodo del kernel con i modelli connessionisti e dimostriamo che le architetture profonde risultanti possono essere addestrate a strati e hanno dinamiche di apprendimento più trasparenti. 
Proponiamo un metodo per ottimizzare stocasticamente le penalità di secondo ordine e mostriamo come questo possa applicarsi all'addestramento di classificatori consapevoli dell'equità.
Mostriamo che le derivate delle reti di apprendimento profondo hanno una struttura a basso rango, e questa struttura ci permette di utilizzare le informazioni sulle derivate del secondo ordine per calcolare i tassi di apprendimento in modo adattivo e in un modo computazionalmente fattibile.
Un quadro unificato di ottimizzazione min-max per l'attacco e la difesa avversaria
riduzione della dimensionalità per i casi in cui gli esempi possono essere rappresentati come distribuzioni morbide di probabilità
Proponiamo una nuova architettura di Intrinsically Motivated Goal Exploration con apprendimento non supervisionato delle rappresentazioni dello spazio degli obiettivi, e valutiamo come le varie implementazioni permettono la scoperta di una diversità di politiche.
Proponiamo un ulteriore passo di formazione, chiamato post-formazione, che calcola i pesi ottimali per l'ultimo strato della rete.
Comprimendo le embeddings di parole oltre il 94% senza danneggiare le prestazioni.
OE insegna ai rilevatori di anomalie ad apprendere l'euristica per rilevare anomalie non viste; gli esperimenti riguardano la classificazione, la stima della densità e la calibrazione in impostazioni NLP e di visione; non ci accordiamo su campioni di distribuzione di test, a differenza del lavoro precedente
Un metodo per imparare una trasformazione tra una coppia di set di dati sorgente/target e applicarla a un set di dati sorgente separato per il quale non esiste un set di dati target
Combinare l'apprendimento per imitazione e l'apprendimento per rinforzo per imparare a superare l'esperto
Un approccio di apprendimento non supervisionato per separare due segnali strutturati dalla loro sovrapposizione
Esploriamo la relazione tra i flussi di normalizzazione e gli autocodificatori di variazione e denoising, e proponiamo un nuovo modello che li generalizza.
Usiamo l'apprendimento di rinforzo per la riformulazione delle query su due compiti e sorprendentemente troviamo che quando si addestrano più agenti la diversità delle riformulazioni è più importante della specializzazione.
Un quadro generale per incorporare vincoli di sicurezza a lungo termine nell'apprendimento di rinforzo basato sulla politica
Valutazione delle reti generative attraverso la loro capacità di aumento dei dati su modelli discrimativi.
Novità: applicazione della modellazione seq2seq all'automazione del giornalismo scientifico; set di dati altamente astraenti; trucchi per il transfer learning; misura di valutazione automatica.
Presentiamo un approccio per riprogettare l'ambiente in modo che i comportamenti non interpretabili degli agenti siano ridotti al minimo o eliminati.
Proponiamo una nuova classe di modelli di inferenza che codificano iterativamente i gradienti per stimare le distribuzioni posteriori approssimate.
Presentiamo una regola di apprendimento per i pesi di feedback in una rete neurale a spirale che affronta il problema del trasporto dei pesi.
Combiniamo l'inferenza variazionale e l'apprendimento del manifold (in particolare VAEs e mappe di diffusione) per costruire un modello generativo basato su un cammino casuale di diffusione su un manifold di dati; generiamo campioni attingendo dalla distribuzione stazionaria del cammino.
Sviluppiamo un approccio semplice e generale per evitare l'interferenza tra i gradienti di diversi compiti, che migliora le prestazioni dell'apprendimento multi-task in entrambi i domini di apprendimento supervisionato e di rinforzo.
Imparare a campionare tramite il limite inferiore del tasso di accettazione dell'algoritmo Metropolis-Hastings
BERT generalizzato per input continui e cross-modali; rappresentazioni video auto-supervisionate allo stato dell'arte.
Un'architettura dinamica generica che impiega un meccanismo di biforcazione differenziabile specifico del problema per codificare ipotesi di strutture di dati difficili. Applicato a CLEVR VQA e alla valutazione delle espressioni.
Unifichiamo la stima del supporto con la famiglia di algoritmi Adversarial Imitation Learning in Support-guided Adversarial Imitation Learning, una struttura di apprendimento per imitazione più robusta e stabile.
Applichiamo il meta-apprendimento basato sul gradiente al dominio dei grafici e introduciamo una nuova funzione di trasferimento specifica per i grafici per avviare ulteriormente il processo.
Proponiamo un nuovo metodo per addestrare incrementalmente un modello generativo a miscela per approssimare la proiezione delle informazioni della distribuzione dei dati reali.
Recuperare i video da misure compressive imparando una rappresentazione a bassa dimensione (low-rank) direttamente dalle misure mentre si allena un generatore profondo. 
Studiamo una generalizzazione multistrato della potatura basata sulla magnitudine.
Introduciamo la massimizzazione dell'ipervolume per l'addestramento di GAN con discriminatori multipli, mostrando miglioramenti delle prestazioni in termini di qualità e diversità del campione. 
Un nuovo stato dell'arte su Imagenet per l'impostazione mobile
Un quadro di simulazione robotica ad alte prestazioni e sviluppo di algoritmi.
Un nuovo paradigma di adattamento di dominio non supervisionato - che esegue l'adattamento senza accedere ai dati di origine ('source-free') e senza alcuna assunzione circa il gap di categoria tra fonte e obiettivo ('universale').
Lasciare che un meta-apprendista decida il compito su cui addestrare un agente in un ambiente multi-task migliora sostanzialmente la capacità multi-tasking
Proponiamo Answer-containing Sentence Generation (ASGen), un nuovo metodo di pre-addestramento per generare dati sintetici per la comprensione automatica della lettura.
Approccio di quantizzazione morbida per imparare rappresentazioni pure a punto fisso di reti neurali profonde
Presentiamo una nuova architettura di rete per l'apprendimento di reti neurali profonde compatte ed efficienti
Studiamo per la prima volta gli attacchi adversarial machine learning contro i meccanismi di Multiple Object Tracking. 
Accoppiare l'apprendimento semi-supervisionato con l'apprendimento auto-supervisionato e modellare esplicitamente il compito auto-supervisionato condizionato da quello semi-supervisionato
Un'architettura di rete di puntatori per il re-ranking degli articoli, appresa dai log dei click-through.
Il metodo del gradiente stocastico con quantità di moto generalizza.
Imparare a imitare un esperto in assenza di azioni ottimali imparando un modello dinamico durante l'esplorazione dell'ambiente.
Mostriamo la possibilità del pruning per trovare una piccola sottorete con un tasso di convergenza significativamente più alto del modello completo.
Proponiamo un approccio basato sull'inferenza variazionale per favorire l'inferenza di latenti disentangolati. Proponiamo anche una nuova metrica per quantificare il disentanglement. 
La nostra proposta ASN caratterizza l'influenza di diverse azioni su altri agenti usando reti neurali basate sulla semantica delle azioni tra di loro.
 Dimostriamo una rete neurale spiking asincrona ricorrente gated che corrisponde a un'unità LSTM.
Classificazione video efficiente utilizzando un modulo di gating condizionale basato sui fotogrammi per selezionare i fotogrammi più dominanti, seguito dalla modellazione temporale e dal classificatore.
Programmazione dinamica differenziabile su pesi di ingresso perturbati con applicazione al VAE semi-supervisionato
Senza apprendimento, è impossibile spiegare le decisioni di un modello di apprendimento automatico.
Rete neurale a grafo semplice ed efficace con una miscela di passi casuali e attenzione
Presentiamo una ricostruzione non supervisionata di deep learning per problemi inversi di imaging che combina reti neurali con vincoli basati su modelli.
Introduciamo un compito diagnostico che è una variazione dell'apprendimento a pochi colpi e introduciamo un set di dati per esso.
Presentiamo l'uso di un codificatore-decodificatore secondario come funzione di perdita per aiutare ad addestrare un sintetizzatore.
Un quadro di traduzione video-video non supervisionato, coerente dal punto di vista temporale e flessibile dal punto di vista della modalità, addestrato in modo auto-supervisionato.
I quadri di argomentazione sono usati per rappresentare la causalità dei piani/modelli da utilizzare per le spiegazioni.
Proponiamo un approccio di rete neurale generativa per nuvole di punti temporalmente coerenti.
Presentiamo una visione unificante sugli attacchi avversari black-box come un problema di stima del gradiente, e poi presentiamo una struttura (basata sull'ottimizzazione dei banditi) per integrare i priori nella stima del gradiente, portando a prestazioni significativamente aumentate.
Migliorare l'efficienza delle etichette attraverso l'apprendimento multi-task su dati uditivi
L'articolo presenta due tecniche per incorporare una struttura di alto livello nella generazione di testo procedurale da una sequenza di immagini.
Abbiamo introdotto un nuovo stimatore di gradiente utilizzando il metodo di Stein, e confrontato con altri metodi sull'apprendimento di modelli impliciti per l'inferenza approssimativa e la generazione di immagini.
Metodologia ideale per iniettare rumore ai dati di input durante l'addestramento CNN
Proponiamo di modellare esplicitamente le distribuzioni di caratteristiche profonde dei dati di origine e di destinazione come distribuzioni di miscele gaussiane per l'Unsupervised Domain Adaptation (UDA) e di ottenere risultati superiori in più compiti UDA rispetto ai metodi all'avanguardia.
Impariamo un'astrazione del grafo del mondo dell'ambiente indipendente dal compito e mostriamo come usarlo per l'esplorazione strutturata può accelerare significativamente la RL specifica del compito a valle.
Rappresentiamo un programma per computer usando un insieme di programmi più semplici e usiamo questa rappresentazione per migliorare le tecniche di sintesi dei programmi.
Come possiamo costruire agenti artificiali che risolvano i dilemmi sociali (situazioni in cui gli individui affrontano la tentazione di aumentare i loro payoff a un costo per il benessere totale)?
Proponiamo un nuovo modello di gradiente generalizzato basato sulla trasformazione e proponiamo uno stimatore di gradiente polinomiale basato sul modello.
apprendimento semi-supervisionato e di trasferimento sulla classificazione del flusso di pacchetti, tramite un sistema di blocchi neurali cooperativi o avversari
Il nostro lavoro presenta una fattorizzazione di Kronecker delle matrici di peso ricorrenti per reti neurali ricorrenti efficienti e ben condizionate.
Proponiamo un metodo per calcolare rappresentazioni adversamente robuste in un modo completamente non supervisionato.
Proponiamo un nuovo approccio basato sul punteggio per l'apprendimento strutturale/causale sfruttando le reti neurali e una recente formulazione continua vincolata a questo problema
Il documento analizza il problema della progettazione di attacchi avversari contro classificatori multipli, introducendo algoritmi che sono ottimali per classificatori lineari e che forniscono risultati allo stato dell'arte per l'apprendimento profondo.
Presentiamo un'analisi generale del ciclo chiuso per i giochi potenziali di Markov e mostriamo che l'apprendimento profondo di rinforzo può essere usato per imparare l'equilibrio di Nash approssimato a ciclo chiuso.
Scaliamo la compressione senza perdita con variabili latenti, battendo gli approcci esistenti su immagini ImageNet a grandezza naturale.
Noi ipotizziamo che la vulnerabilità dei modelli di immagine a piccole perturbazioni avversarie sia un risultato naturale della geometria ad alta dimensione del collettore di dati. Esploriamo e dimostriamo teoricamente questa ipotesi per un semplice set di dati sintetici.
Introduciamo Variational Intrinsic Successor FeatuRes (VISR), un nuovo algoritmo che impara caratteristiche controllabili che possono essere sfruttate per fornire un'inferenza veloce dei compiti attraverso il quadro delle caratteristiche del successore.
Un metodo di adattamento al dominio per l'output strutturato tramite l'apprendimento di rappresentazioni di caratteristiche discriminanti a livello di patch
Un nuovo attacco avversario che può attaccare direttamente i modelli di apprendimento automatico black-box del mondo reale senza trasferimento.
La privacy differenziale a livello di utente per i modelli linguistici delle reti neurali ricorrenti è possibile con un set di dati sufficientemente grande.
Addestrare i convnet con immagini di dimensioni miste può migliorare i risultati su più dimensioni alla valutazione
L'articolo introduce un metodo di addestramento delle reti ricorrenti generative che aiuta a pianificare in anticipo. Eseguiamo una seconda RNN in una direzione inversa e facciamo un vincolo morbido tra gli stati cotemporali in avanti e indietro.
Proponiamo di strutturare il generatore di una GAN per considerare esplicitamente gli oggetti e le loro relazioni, e generare immagini per mezzo della composizione
Riusciamo a far emergere la comunicazione con agenti egoisti, contrariamente alla visione corrente in ML
proponiamo un nuovo quadro per la regolarizzazione DNN dipendente dai dati che può impedire alle DNN di adattarsi troppo ai dati casuali o alle etichette casuali.
L'apprendimento multi-task migliora il riconoscimento vocale a livello di parole e caratteri interpolando i bias di preferenza dei suoi componenti: la frequenza e la lunghezza delle parole.
Impariamo una rete neurale che uniforma la distribuzione dell'input, il che porta a prestazioni di indicizzazione competitive nello spazio ad alta densità
Questo articolo fornisce uno studio rigoroso dell'apprendimento TD a varianza ridotta e caratterizza il suo vantaggio rispetto all'apprendimento TD alla vaniglia
Una rete multiflow è un'architettura dinamica per l'adattamento al dominio che apprende grafi computazionali potenzialmente diversi per ogni dominio, in modo da mapparli in una rappresentazione comune in cui l'inferenza può essere eseguita in modo domain-agnostic.
IMPACT aiuta gli agenti RL ad addestrarsi più velocemente, diminuendo il tempo del wall-clock di addestramento e aumentando contemporaneamente l'efficienza del campione.
Questo articolo introduce uno schema di colorazione per la disambiguazione dei nodi nelle reti neurali a grafo basato sulla separabilità, che si dimostra essere un'estensione MPNN universale.
Rappresentando le melodie come immagini con unità semantiche allineate possiamo generarle usando una DCGAN senza componenti ricorrenti.
Introduciamo e analizziamo il fenomeno delle "allucinazioni" nella NMT, o traduzioni spurie non correlate al testo di origine, e proponiamo metodi per ridurre la sua frequenza.
Un quadro di valutazione basato su una rete neurale del mondo reale per metodi esplicativi post-hoc
Presentiamo un metodo ispirato alle neuroscienze basato su reti neurali per la ricerca nello spazio latente
Introducendo la nozione di uno spazio di rappresentazione ottimale, forniamo un argomento teorico e una convalida sperimentale che un modello non supervisionato per le frasi può funzionare bene sia in compiti di similarità supervisionata che di trasferimento non supervisionato.
Un dataset di test cloze progettato dagli insegnanti per valutare le competenze linguistiche
Le reti neurali artificiali addestrate con la discesa del gradiente sono in grado di ricapitolare sia l'attività neurale realistica che l'organizzazione anatomica di un circuito biologico.
Prune e ReLU nel dominio di Winograd per una rete neurale convoluzionale efficiente
Un nuovo algoritmo per addestrare reti neurali profonde. Testato su funzioni di ottimizzazione e MNIST.
Introduciamo il flipout, un metodo efficiente per decorrelare i gradienti calcolati dai pesi delle reti neurali stocastiche all'interno di un mini-batch, campionando implicitamente perturbazioni di peso pseudo-indipendenti per ogni esempio.
Un nuovo modello Latently Invertible Autoencoder è proposto per risolvere il problema dell'inferenza variazionale in VAE utilizzando la rete invertibile e l'addestramento avversario a due stadi.
Introduciamo il modello PHP per la rappresentazione gerarchica dei programmi neurali, e un algoritmo per l'apprendimento di PHP da una miscela di supervisione forte e debole.
Proponiamo un metodo per trasferire la conoscenza tra compiti RL correlati usando mappature visive, e dimostriamo la sua efficacia su varianti visive del gioco Atari Breakout e diversi livelli di Road Fighter, un gioco di guida automobilistica Nintendo.
I metodi a gradiente adattivo, se fatti bene, non incorrono in una penalità di generalizzazione. 
Introduciamo un modello che generalizza rapidamente da poche osservazioni memorizzando informazioni sorprendenti e frequentando i dati più rilevanti ad ogni punto temporale.
Sviluppiamo un approccio addestrabile end-to-end per la scrematura, la rilettura e l'arresto anticipato applicabile ai compiti di classificazione. 
Vediamo l'esplorazione in RL come un problema di corrispondenza di una distribuzione marginale sugli stati.
Introduciamo G-HexaConv, una rete neurale convoluzionale equivariante di gruppo su tralicci esagonali.
Proporre un nuovo approccio di localizzazione degli oggetti basato sull'interpretazione della CNN profonda utilizzando la rappresentazione interna e i pensieri della rete
Le reti Trellis sono una nuova architettura di modellazione di sequenze che collega i modelli ricorrenti e convoluzionali e stabilisce un nuovo stato dell'arte nella modellazione del linguaggio a livello di parole e caratteri.
Si può ottenere un'alta accuratezza di rilevamento degli oggetti addestrando modelli compatti specifici del dominio e l'addestramento può essere molto breve.
Confrontiamo algoritmi di RL profondi basati su modelli e senza modelli studiando l'approssimabilità delle funzioni $Q$, delle politiche e delle dinamiche da parte delle reti neurali. 
Introduciamo un nuovo approccio al ragionamento fisico di senso comune che impara a scoprire gli oggetti e a modellare le loro interazioni fisiche da immagini visive grezze in modo puramente non supervisionato
In molte mappe input-ouput semplici si osserva una distorsione molto forte verso gli outpout semplici. La mappa parametro-funzione delle reti profonde risulta essere distorta nello stesso modo.
In questo articolo, proponiamo modelli imitativi per combinare i vantaggi dell'IL e della pianificazione orientata agli obiettivi: modelli predittivi probabilistici di comportamenti desiderabili in grado di pianificare traiettorie interpretabili da esperti per raggiungere obiettivi specifici.
Nuova architettura del meccanismo di attenzione basato sulla memoria per la comunicazione multi-agente.
Questo lavoro applica la dinamica hamiltoniana con il controllo per imparare i modelli di sistema dai dati incorporati di posizione e velocità, e sfrutta questa dinamica fisicamente coerente per sintetizzare il controllo basato sul modello tramite la modellazione dell'energia.
Indaghiamo le ragioni interne delle nostre osservazioni, gli effetti decrescenti dei ben noti metodi di ottimizzazione degli iperparametri sull'apprendimento federato dai dati non IID decentralizzati.
Un nuovo attacco di imitazione avversaria per ingannare i modelli di apprendimento automatico.
Addestramento di grandi lotti utilizzando l'addestramento adversariale e le informazioni del secondo ordine
prima rete neurale profonda per la modellazione della memoria spaziale egocentrica ispirata dalle scoperte neurofisiologiche delle cellule di navigazione nel cervello dei mammiferi
Dimostriamo la generalizzazione dei DNN aggiungendo un termine di regolarizzazione Lipschitz alla perdita di formazione. Risolviamo una questione posta in Zhang et al. (2016).
Addestriamo ampie reti residue che possono essere immediatamente distribuite usando solo un singolo bit per ogni peso convoluzionale, con una precisione significativamente migliore rispetto ai metodi passati.
Visualizzazione immersiva degli spazi non euclidei classici usando il Ray Tracing in tempo reale.
Proponiamo il set autoencoder, un modello per l'apprendimento non supervisionato della rappresentazione di insiemi di elementi.
Proponiamo un metodo autonomo per un apprendimento di rinforzo sicuro ed efficiente che impara simultaneamente una politica in avanti e una all'indietro, con la politica all'indietro che resetta l'ambiente per un tentativo successivo.
Presentiamo la prova che le LM catturano il senso comune con risultati all'avanguardia sia su Winograd Schema Challenge che su Commonsense Knowledge Mining.
Un algoritmo online per l'acquisizione e la previsione di caratteristiche consapevoli dei costi
Noi sosteniamo che le reti convoluzionali dovrebbero essere considerate il punto di partenza predefinito per i compiti di modellazione delle sequenze.
Addestrare le DNN per interfacciare le funzioni della scatola nera con le etichette intermedie utilizzando una sottorete di stima che può essere sostituita con la scatola nera dopo l'addestramento
Proponiamo l'algoritmo Dual Actor-Critic, che è derivato in modo principesco dalla forma duale lagrangiana dell'equazione di ottimalità di Bellman. L'algoritmo raggiunge lo stato dell'arte delle prestazioni su diversi benchmark.
Un robusto adattamento al dominio impiegando una perdita specifica per il compito nell'apprendimento ciclicamente contraddittorio
Ottimizzazione della politica utilizzando i buoni rollout passati dell'agente; apprendimento di ricompense modellate tramite minimizzazione della divergenza; SVPG con JS-kernel per l'esplorazione basata sulla popolazione.
Studiamo il funzionamento degli autocodificatori in un ambiente semplice e consigliamo nuove strategie per la loro regolarizzazione al fine di ottenere una migliore generalizzazione con interpolazione latente in vista della sintesi di immagini. 
Presentiamo un'idea semplice che permette di registrare un oratore in una data lingua e sintetizzare la sua voce in altre lingue che potrebbe anche non conoscere.
In questo articolo, abbiamo proposto un algoritmo IL senza modello e senza politica per il controllo continuo. I risultati sperimentali hanno mostrato che il nostro algoritmo raggiunge risultati competitivi con GAIL, riducendo significativamente le interazioni con l'ambiente.
Un sistema di riscrittura del testo condizionato da più attributi controllabili
Sviluppiamo un nuovo approccio di ottimizzazione per la RNN basata sulla vaniglia ReLU che permette la memoria a breve termine e l'identificazione di sistemi dinamici non lineari arbitrari con scale temporali molto diverse.
Proporre un quadro migliorato per le WGAN e dimostrare le sue migliori prestazioni nella teoria e nella pratica.
Le operazioni nello spazio latente GAN possono indurre un mismatch di distribuzione rispetto alla distribuzione di addestramento, e noi affrontiamo questo problema usando un trasporto ottimale per far corrispondere le distribuzioni. 
Un nuovo modo di imparare l'incorporazione semantica dei programmi
Proponiamo un'estensione della normalizzazione batch, mostriamo una prima analisi di convergenza per questa estensione e dimostriamo in esperimenti numerici che ha prestazioni migliori della normalizzazione batch originale.
Proponiamo un quadro per modificare le operazioni dello spazio latente in modo tale che il mismatch della distribuzione tra gli output risultanti e la distribuzione a priori su cui è stato addestrato il modello generativo sia completamente eliminato.
Questo articolo fornisce un approccio multi -stream end to end per apprendere embeddings unificati per coppie di domande-risposte nei sistemi di dialogo, sfruttando insieme informazioni contestuali, sintattiche, semantiche ed esterne.
Tecniche per combinare politiche generalizzate con algoritmi di ricerca per sfruttare i punti di forza e superare le debolezze di ciascuno quando si risolvono problemi di pianificazione probabilistica
Otteniamo lo stato dell'arte sulla robustezza agli spostamenti dei dati, e manteniamo la calibrazione sotto lo spostamento dei dati anche se anche quando la precisione scende
Estraiamo automaticamente le informazioni sulla diteggiatura dai video delle esecuzioni di pianoforte, per essere utilizzati in modelli di predizione automatica della diteggiatura.
SOTA sull'adattamento non supervisionato del dominio sfruttando l'ipotesi del cluster.
Modelli generativi grafici basati sulla generalizzazione del passaggio dei messaggi al tempo continuo usando equazioni differenziali ordinarie 
Mostriamo che diverse affermazioni della teoria del collo di bottiglia informativo dell'apprendimento profondo non sono vere nel caso generale.
Le reti neurali hanno grandi gradienti per progettazione; questo le rende vulnerabili agli avversari.
Introduciamo l'amortized proximal optimization (APO), un metodo per adattare una varietà di iperparametri di ottimizzazione online durante la formazione, compresi i tassi di apprendimento, i coefficienti di smorzamento e gli esponenti di varianza del gradiente.
Senza richiedere alcun vincolo o post-elaborazione, dimostriamo che le dimensioni salienti dei vettori di parole possono essere interpretate come caratteristiche semantiche. 
strategia per riparare le reti neurali danneggiate
Generazione automatica di domande da paragrafi utilizzando modelli gerarchici
L'interrogazione di una rete neurale black-box rivela molte informazioni su di essa; proponiamo nuovi "metamodelli" per estrarre efficacemente informazioni da una scatola nera.
Utilizzo di una struttura supervisionata di modellazione della variabile latente per determinare la ricompensa in un compito di apprendimento del rinforzo inverso
Questo articolo combina la ricerca ad albero di Monte Carlo con la ricerca locale a 2-opt in una modalità di vicinato variabile per risolvere efficacemente il TSP.
Applicare la sintesi del programma ai compiti di completamento e generazione di immagini all'interno di un framework di deep learning
Questo articolo presenta un modello computazionale per un efficiente adattamento del controllo posturale umano basato su funzioni di acquisizione gerarchiche con caratteristiche ben note. 
Studiamo il problema degli agenti di controllo continuo nella RL profonda con attacchi avversari e abbiamo proposto un algoritmo in due fasi basato sulla dinamica del modello appreso. 
Studiamo il bias che induce la sparsità dei modelli profondi, causato dalle loro dinamiche di apprendimento.
Le divergenze parametriche avversarie definiscono implicitamente perdite di compito più significative per la modellazione generativa, facciamo dei paralleli con la predizione strutturata per studiare le proprietà di queste divergenze e la loro capacità di codificare il compito di interesse.
Forniamo un confronto rigoroso di diverse reti grafiche neurali per la classificazione dei grafi.
Apprendimento automatico dell'aumento dei dati utilizzando un'architettura basata su GAN per migliorare un classificatore di immagini
Nuova classe di autocodificatori con architettura pseudo invertibile
Sfruttiamo uno schema di inversione per reti neurali profonde arbitrarie per sviluppare un nuovo quadro di apprendimento semi-supervisionato applicabile a molte topologie.
Confronto tra reti neurali siamesi, GAN e IVA per l'apprendimento di pochi colpi. 
Proponiamo un miglioramento leggero per l'attenzione e un'architettura neurale, FusionNet, per ottenere SotA su SQuAD e SQuAD avversario.
Modello generativo gerarchico addestrato in modo avverso con rappresentazione latente robusta e appresa semanticamente.
Osserviamo che i risolutori numerici di PDE possono essere considerati come processi di Markov Desicion, e proponiamo di usare il Reinforcement Learning per risolvere leggi di conservazione scalari 1D
Introduciamo un'architettura di rendering neurale che aiuta i VAE ad apprendere rappresentazioni latenti dissociate.
I deficit sensoriali nelle prime fasi dell'addestramento possono portare a una perdita irreversibile delle prestazioni sia nelle reti artificiali che in quelle neuronali, suggerendo fenomeni informativi come causa comune, e indicano l'importanza del transitorio iniziale e dell'oblio.
Proponiamo un metodo per imparare in modo incrementale uno spazio di incorporazione sul dominio delle architetture di rete, per permettere la selezione accurata delle architetture da valutare durante la ricerca di architetture compresse.
Migliorare le prestazioni di un agente RL nel dominio continuo delle azioni e dello spazio di stato utilizzando la riproduzione prioritaria dell'esperienza e il rumore dei parametri.
mostrare il peso di attenzione multicanale contiene la caratteristica semantica per risolvere il compito di inferenza del linguaggio naturale.
Approssimiamo i processi puntuali determinanti con le reti neurali; giustifichiamo il nostro modello teoricamente ed empiricamente.
Questo articolo introduce un'architettura di rete per risolvere il problema della struttura dal movimento (SfM) attraverso l'aggiustamento del fascio di caratteristiche (BA)
Mostriamo che l'aggiunta di un vincolo agli aggiornamenti TD stabilizza l'apprendimento e permette l'apprendimento Q profondo senza una rete di destinazione
Proponiamo DuoRC, un nuovo set di dati per la comprensione della lettura (RC) che contiene 186.089 coppie di AQ generate dall'uomo create da una collezione di 7680 coppie di trame cinematografiche parallele e introduciamo un compito RC che consiste nel leggere una versione della trama e rispondere a domande create dall'altra versione; quindi, per progettazione, richiede un ragionamento complesso e una comprensione linguistica più profonda per superare la scarsa sovrapposizione lessicale tra la trama e la domanda.
Un componente di pianificazione basato sul modello migliora l'analisi semantica basata su RL su WikiTableQuestions.
Un nuovo modo di quantizzare l'attivazione delle reti neurali profonde tramite il ritaglio parametrizzato che ottimizza la scala di quantizzazione tramite la discesa del gradiente stocastico.
Dimostriamo che i metodi di potatura che introducono una maggiore instabilità nella perdita conferiscono anche una migliore generalizzazione, ed esploriamo i meccanismi alla base di questo effetto.
Reti neurali profonde meno biologicamente implausibili addestrate senza trasporto di peso possono essere più difficili da ingannare.
Un modello generativo per la predizione delle reazioni che impara i passi meccanici elettronici di una reazione direttamente dai dati di reazione grezzi.
Incorporare la capacità di dire I-don't-know può migliorare la correttezza di un classificatore senza sacrificare troppo la precisione, e questo miglioramento aumenta quando il classificatore ha una visione del processo decisionale a valle.
Un approccio per eseguire la pianificazione HTN utilizzando procedure esterne per valutare i predicati in fase di esecuzione (allegati semantici).
I vettori di parole max-pooled con similarità fuzzy Jaccard set sono una linea di base estremamente competitiva per la similarità semantica; noi proponiamo una semplice variante dinamica che funziona ancora meglio.
L'obiettivo generale di questo lavoro è di permettere un'imitazione efficiente a campione da dimostrazioni di esperti, sia con che senza la fornitura di etichette di azioni di esperti, attraverso l'uso di f-divergenze.
Con un'interfaccia cognitiva cervello-macchina, mostriamo un legame diretto tra gli effetti attenzionali sulla precisione percettiva e il guadagno neurale nella potenza EEG-SSVEP, nel cervello umano.
Un quadro generale e facile da usare che migliora la robustezza avversaria dei modelli di classificazione profonda attraverso la regolarizzazione dell'incorporazione.
Proponiamo un algoritmo di clustering basato sul completamento della matrice per l'apprendimento profondo multi-task e few-shot nelle impostazioni con un gran numero di compiti diversi.
Questo approccio supera i problemi di scalabilità e implica nuove connessioni matematiche tra la fisica quantistica a molti corpi, la teoria dell'informazione quantistica e l'apprendimento automatico.
Addestriamo una combinazione di reti neurali per prevedere traiettorie ottimali per sistemi fisici complessi.
Forniamo una garanzia di generalizzazione basata su PAC-Bayes per reti profonde non compresse e deterministiche generalizzando la resistenza al rumore della rete sui dati di allenamento ai dati di test.
Dimostriamo che per una grande classe di funzioni f esiste una rete robusta certificata da un intervallo che approssima f fino a una precisione arbitraria.
Questo è un lavoro che mira a potenziare tutti i metodi di potatura e di imitazione esistenti.
Introduciamo un ulteriore obiettivo prioritario gaussiano dipendente dai dati per aumentare l'attuale addestramento MLE, che è progettato per catturare la conoscenza precedente nei dati ground-truth.
Proponiamo un approccio interattivo per classificare le interrogazioni in linguaggio naturale chiedendo agli utenti informazioni aggiuntive utilizzando il guadagno di informazioni e un controller di politica di apprendimento di rinforzo.
Autocodificatori convoluzionali generalizzati a superfici mesh per la codifica e la ricostruzione di espressioni facciali 3D estreme.
Jiffy è un approccio convoluzionale all'apprendimento di una metrica di distanza per le serie temporali multivariate che supera i metodi esistenti in termini di accuratezza della classificazione nearest-neighbor.
L'architettura modulare estendibile è proposta per lo sviluppo di una varietà di comportamenti di agenti in DQN.
Isoliamo un fattore di generalizzazione RL analizzando il caso in cui l'agente si adatta solo alle osservazioni. Mostriamo che le regolarizzazioni implicite architettoniche si verificano in questo regime.
In questo articolo, proponiamo un nuovo modello neurale del linguaggio, chiamato Parsing-Reading-Predict Networks (PRPN), che può indurre simultaneamente la struttura sintattica da frasi non annotate e sfruttare la struttura dedotta per imparare un modello linguistico migliore.
Abbiamo proposto un approccio completo per l'apprendimento non supervisionato di embedding sulla base dell'algoritmo AND.
Proponiamo un metodo di apprendimento debolmente supervisionato per la classificazione e la localizzazione dei tumori in immagini istopatologiche di vetrini interi ad altissima risoluzione usando solo etichette a livello di immagine.
 Proponiamo un nuovo metodo per utilizzare le informazioni dell'ontologia per migliorare le prestazioni su problemi di predizione/classificazione massicciamente multi-label.
Applichiamo un'assegnazione greedy sui campioni proiettati invece dell'ordinamento per approssimare la distanza di Wasserstein
Questo articolo studia le interazioni tra i modelli di apprendimento veloce e di previsione lenta e dimostra come tali interazioni possano migliorare la capacità della macchina di risolvere i problemi di apprendimento congiunto per tutta la vita e per pochi colpi.
Il primo metodo di inizializzazione dei pesi basato su principi per le iperreti
Un nuovo quadro di apprendimento profondo bayesiano che cattura e mette in relazione concetti semantici e visivi gerarchici, con buone prestazioni su una varietà di compiti di generazione e modellazione di immagini e testi.
Questo articolo introduce il grounding parziale per affrontare il problema che si presenta quando il processo di grounding completo, cioè la traduzione di un compito di input PDDL in una rappresentazione ground come STRIPS, non è fattibile a causa di limiti di memoria o di tempo.
Introduzione del metodo di caratterizzazione della risposta per interpretare la dinamica delle cellule nelle reti apprese di memoria a breve termine (LSTM). 
A nostra conoscenza, questo è il primo studio che mostra come le rappresentazioni neurali dello spazio, comprese le cellule a griglia e le cellule di confine come osservate nel cervello, potrebbero emergere dall'addestramento di una rete neurale ricorrente per eseguire compiti di navigazione.
Confrontiamo le prestazioni del modello basato sullo spettrogramma con un modello addestrato end-to-end nel dominio della forma d'onda
Forniamo una soluzione scalabile per la valutazione multi-agente con una complessità lineare sia nel tempo che nella memoria in termini di numero di agenti
Proponiamo un nuovo approccio di apprendimento semi-supervisionato con prestazioni SOTA per combattere l'apprendimento con etichette rumorose.
Progettiamo un metodo di addestramento avversario per le reti neurali bayesiane, mostrando una difesa molto più forte agli attacchi avversari white-box
Efficaci attacchi di model poisoning all'apprendimento federato in grado di causare un'errata classificazione mirata ad alta confidenza degli input desiderati
 In questo articolo, ipotizziamo che i punti di dati superficialmente perturbati non dovrebbero semplicemente mappare alla stessa classe - dovrebbero mappare alla stessa rappresentazione.
modello acustico armonico
Affrontare il trade-off causato dalla dipendenza delle classi dai domini migliorando le reti avversarie di dominio
Proponiamo FVD: una nuova metrica per modelli generativi di video basati su FID. Uno studio umano su larga scala conferma che FVD si correla bene con il giudizio umano qualitativo dei video generati.
Un'architettura di memoria doppia ispirata al cervello umano per imparare in modo sequenziale i compiti in arrivo, evitando la dimenticanza catastrofica.
Modellazione linguistica per l'apprendimento permanente delle lingue.
Usiamo idee dall'informatica quantistica per proporre embeddings di parole che utilizzano molti meno parametri addestrabili.
Addestriamo agenti di rete neurale per sviluppare un linguaggio con proprietà compositive da input di pixel grezzi.
Impariamo una funzione di campionamento della diversità con le DPP per ottenere un insieme diversificato di campioni da un modello generativo.
Le rappresentazioni dei modelli linguistici hanno costantemente prestazioni migliori dei codificatori di traduzione nei compiti di predizione sintattica ausiliaria.
Proponiamo il campionamento di Langevin vincolato basato su surrogati con applicazione nella progettazione della configurazione di materiali nano-porosi.
Migliorare i modelli di embedding gerarchico usando lo smoothing del kernel
Approccio di bootstrapping aumentato che combina informazioni da un set di riferimento con raffinamenti iterativi di etichette morbide per migliorare il riconoscimento di entità di nomi dalla letteratura biomedica.
Estendiamo i quantum SVM all'impostazione semi-supervisionata, per affrontare il probabile problema di molte etichette di classe mancanti in enormi set di dati.
Questo articolo collega le architetture delle reti profonde con le equazioni differenziali numeriche (stocastiche). Questa nuova prospettiva permette nuovi progetti di reti neurali profonde più efficaci.
CNN e LSTM per generare codice simile al markup che descrive le immagini dell'interfaccia grafica.
Mostriamo che le embeddings iperboliche sono utili per compiti di visione di alto livello, specialmente per la classificazione di pochi scatti.
Presentiamo un metodo per imparare rappresentazioni interpretabili su serie temporali usando idee da autoencoder variazionali, mappe auto-organizzanti e modelli probabilistici.
Architettura convoluzionale per l'apprendimento di pesi dipendenti dai dati per la previsione autoregressiva di serie temporali.
Presentiamo una nuova interpretazione di MixUp come appartenente a una classe altamente analoga all'addestramento avversario, e su questa base introduciamo una semplice generalizzazione che supera MixUp
Gestire l'incertezza nella percezione visiva per il riconoscimento dei piani
Accesso multi-hop differenziabile a una base di conoscenza testuale di rappresentazioni contestuali indicizzate
Algoritmo di fattorizzazione generale scalabile - aiuta anche ad aggirare il problema dell'avvio a freddo.
Presentiamo un sistema di authoring di tutorial di montaggio a media misti che ottimizza la creazione di video, immagini, testo e istruzioni dinamiche in situ.
Dimostriamo che l'uso delle note cliniche in congiunzione con i dati degli strumenti dell'ICU migliora la performance nei compiti di benchmark della gestione dell'ICU
Proponiamo un gradiente di politica basato sugli eventi per addestrare il leader e un gradiente di politica di astrazione dell'azione per addestrare i seguaci nel gioco di Markov leader-follower.
Usiamo la trasmissione culturale per incoraggiare la compositività nei linguaggi che emergono dalle interazioni tra agenti neurali.
Proponiamo un metodo basato su SVD per esplorare la dimensione locale del manifold di attivazione nelle reti neurali profonde.
L'inferenza in grandi trasformatori è costosa a causa dell'auto-attenzione in più strati. Mostriamo che una semplice tecnica di decomposizione può produrre un modello più veloce, a bassa impronta di memoria che è altrettanto accurato dei modelli originali.
Un adattamento dell'apprendimento profondo dell'iterazione del valore dei minimi quadrati randomizzata
I parametri di una rete neurale addestrata possono essere permutati per produrre un modello completamente separato per un compito diverso, permettendo l'incorporazione di reti a cavallo di Troia dentro un'altra rete.
Introduciamo un design GAN alternativo basato su percorsi casuali nel generatore, che può servire come strumento per l'interpretabilità dei modelli generativi.
Presentiamo un quadro teorico e sperimentale per definire, comprendere e raggiungere la generalizzazione, e di conseguenza la robustezza, nell'apprendimento profondo attingendo alla teoria dell'informazione algoritmica e alla teoria della codifica.
Abbiamo lanciato la scoperta della struttura causale come una selezione di modelli bayesiani in un modo che ci permette di discriminare tra i grafi equivalenti di Markov per identificare il grafo causale unico.
Limite inferiore per il rilevamento compresso con modelli generativi che corrisponde ai limiti superiori conosciuti
Questo articolo presenta un'analisi empirica sul ruolo di diversi tipi di rappresentazioni di immagini e sonda le proprietà di queste rappresentazioni per il compito di didascalia delle immagini.
Progettiamo parser incrementali sequence-to-action per compiti text-to-SQL e otteniamo risultati SOTA. Miglioriamo ulteriormente utilizzando oracoli non deterministici per consentire più sequenze di azioni corrette. 
Un approccio che accelera la ricerca dell'architettura neurale di 10 volte, mentre usa 100 volte meno risorse di calcolo.
Proponiamo una nuova architettura DNN per l'apprendimento profondo su dati tabulari
Una struttura che conduce il perfezionamento online delle pseudo etichette con una nuova perdita softmax-triplet per l'adattamento di dominio non supervisionato sulla re-identificazione della persona.
Presentiamo il primo approccio per certificare la robustezza delle reti neurali contro le perturbazioni basate sul rumore nel dominio audio.
Questo lavoro presenta un metodo per generare e utilizzare efficacemente gli ensemble per identificare gli esempi rumorosi in presenza di rumore di annotazione. 
Un algoritmo di apprendimento guidato dai dati basato sullo srotolamento dell'ottimizzazione Alternating Minimization per il recupero di grafi sparsi.
Abbiamo proposto un doppio quadro neurale per risolvere il gioco di informazioni imperfette su larga scala. 
Presentiamo la prima verifica che una rete neurale per compiti di percezione produce un output corretto entro una tolleranza specificata per ogni input di interesse. 
Studiamo approssimazioni di distorsione del tasso per la valutazione di modelli generativi profondi, e mostriamo che le curve di distorsione del tasso forniscono più intuizioni sul modello rispetto alla sola log-likelihood mentre richiedono più o meno lo stesso costo computazionale.
Un algoritmo meta-RL basato sul modello che permette a un robot reale di adattarsi online in ambienti dinamici
L'articolo analizza lo spazio latente appreso da approcci senza modello in un gioco di informazioni incomplete in miniatura, allena un modello in avanti nello spazio latente e lo applica alla ricerca ad albero Monte-Carlo, ottenendo prestazioni positive.
Analizziamo la potenza espressiva delle connessioni usate nelle DenseNets attraverso decomposizioni tensoriali.
Usiamo un feedback umano implicito (tramite i potenziali di errore, EEG) per accelerare e ottimizzare l'addestramento di un algoritmo DRL, in modo pratico.
TCN per l'apprendimento multimodale semi-supervisionato + studio di ablazione dei suoi meccanismi + interpretazioni delle rappresentazioni latenti
Adattare Adam, Amsgrad, Adagrad ai manifesti Riemanniani. 
Difendersi dagli attacchi fisicamente realizzabili alla classificazione delle immagini
I pesi plastici di Hebbian possono comportarsi come un immagazzinamento di memoria episodica compressa nelle reti neurali e con la combinazione di consolidamento sinaptico compito-specifico può migliorare la capacità di alleviare l'oblio catastrofico nell'apprendimento continuo.
Questo articolo dimostra che le reti neurali magre non possono approssimare certe funzioni, non importa quanto siano profonde.
Introduciamo la Continuous Logic Network (CLN), una nuova architettura neurale per l'apprendimento automatico di invarianti di loop e formule SMT generali.
La nostra scoperta fa luce sulla prevenzione della progressione del cancro
Estendiamo i flussi autoregressivi e RealNVP ai dati discreti.
Un'architettura di apprendimento profondo robusta e rumorosa.
Impariamo embeddings neurali di grafi in spazio iperbolico invece che euclideo
Idee per futuri ICKEPS
Generiamo articoli di Wikipedia astrattamente condizionati dal testo del documento di origine.
Un algoritmo per unificare SGD e Adam e uno studio empirico delle sue prestazioni
Apprendere politiche gerarchiche da dimostrazioni non segmentate usando informazioni dirette
I tradizionali algoritmi di elaborazione delle immagini sono combinati con le reti neurali convoluzionali, una nuova rete neurale.
Abbiamo proposto un metodo specifico di back-propagation attraverso un appropriato sub-gradiente spettrale per integrare il processo determinantico del punto nel quadro dell'apprendimento profondo.
Inventiamo un nuovo quadro cluster-to-cluster per l'addestramento NMT, che può comprendere meglio la diversità della lingua di origine e di destinazione.
Un efficiente modello ILP differenziabile che impara regole logiche del primo ordine che possono spiegare i dati.
Introduciamo un nuovo metodo per sintetizzare esempi di avversione robusti nel mondo fisico e lo usiamo per fabbricare i primi oggetti 3D di avversione.
Impara come permutare un insieme, poi codifica l'insieme permutato con RNN per ottenere una rappresentazione dell'insieme.
Utilizzare il deep reinforcement learning per progettare gli attributi fisici di un robot insieme a una politica di controllo.
Proponiamo un approccio che conferisce a un singolo modello la capacità di rappresentare entrambi gli estremi: formazione congiunta e formazione indipendente, il che porta a un efficace apprendimento multi-task.
Proponiamo un termine di regolarizzazione che, quando aggiunto all'obiettivo di apprendimento per rinforzo, permette alla politica di massimizzare la ricompensa e contemporaneamente imparare ad essere invariante ai cambiamenti irrilevanti all'interno dell'input.
Questo lavoro ha proposto una rappresentazione visiva universale per la traduzione automatica neurale (NMT) utilizzando immagini recuperate con argomenti simili alla frase di origine, estendendo l'applicabilità delle immagini nella NMT.
Combinando idee dalla progettazione di algoritmi tradizionali e dal reinforcement learning, introduciamo una nuova struttura per l'apprendimento di algoritmi che risolvono problemi di ottimizzazione combinatoria online.
Un approccio funzionale rivela che l'inizializzazione piatta, preservata dalla discesa del gradiente, porta alla capacità di generalizzazione.
La profondità della rete aumenta gli autovalori outlier nell'Hessiano. Le connessioni residue mitigano questo fenomeno.
Un documento sperimentale che dimostra la quantità di pesi ridondanti che possono essere congelati solo a partire dalla terza epoca, con solo un leggerissimo calo di precisione.
Un nuovo approccio all'apprendimento del curriculum attraverso l'apprendimento incrementale delle etichette e lo smussamento adattivo delle etichette per i campioni mal classificati che aumenta la performance media e diminuisce la deviazione standard.
Proponiamo un metodo per trattare le parole rare calcolando la loro incorporazione dalle definizioni.
Questo articolo propone un classificatore generativo profondo che è efficace per rilevare i campioni fuori distribuzione così come classificare i campioni in distribuzione, integrando il concetto di analisi discriminante gaussiana nelle reti neurali profonde.
Mostrare che l'età confonde l'individuazione del deterioramento cognitivo + risolvere con l'apprendimento della rappresentazione equa + proporre metriche e modelli.
Introduciamo NetScore, una nuova metrica progettata per fornire una valutazione quantitativa dell'equilibrio tra precisione, complessità computazionale e complessità dell'architettura di una rete neurale profonda.
Attacchi top-k adversarial ordinati
La propagazione personalizzata delle previsioni neurali (PPNP) migliora le reti neurali a grafo separandole in previsione e propagazione tramite PageRank personalizzato.
La scelta della lingua principale (di destinazione) influisce sulla qualità delle incorporazioni multilingue, che non dovrebbero essere valutate solo su dizionari anglo-centrici.
Il tipico addestramento GAN non ottimizza Jensen-Shannon, ma qualcosa come una divergenza KL inversa.
Mostriamo che disegnando più campioni (predizioni) per ogni input (datapoint), possiamo imparare con meno dati poiché otteniamo liberamente una linea di base REINFORCE.
Risolviamo in modo efficiente i problemi multi-task con un algoritmo di generazione automatica del curriculum basato su un modello generativo che tiene traccia delle prestazioni dell'agente di apprendimento.
Questo articolo identifica classi di problemi per i quali gli esempi contraddittori sono inevitabili, e deriva limiti fondamentali sulla suscettibilità di qualsiasi classificatore agli esempi contraddittori. 
Abbassando la precisione (a 4-bit, 2-bit e persino binario) e allargando i banchi di filtri si ottiene una rete accurata come quelle ottenute con pesi e attivazioni FP32.
Incorporiamo una CRF in una VAE di token e tag NER per l'apprendimento semi-supervisionato e mostriamo miglioramenti in impostazioni a bassa risorsa.
Un quadro di principio per la quantizzazione del modello usando il metodo del gradiente prossimale.
Una nuova tecnica di modellazione generativa basata sull'addestramento asimmetrico dell'avversario, e le sue applicazioni al rilevamento di esempi avversari e alla classificazione robusta
Il meta-apprendimento di algoritmi di curiosità attraverso la ricerca in un ricco spazio di programmi produce nuovi meccanismi che si generalizzano attraverso domini di rinforzo-apprendimento molto diversi.
Questo articolo propone una semplice procedura per valutare la struttura compositiva nelle rappresentazioni apprese, e usa la procedura per esplorare il ruolo della compositività in quattro problemi di apprendimento.
Un modello DL per la predizione della struttura secondaria dell'RNA, che usa un algoritmo srotolato nell'architettura per far rispettare i vincoli.
Presentiamo la propagazione di ammissibilità un'alternativa al BPTT che è compatibile con i dati sperimentali sulla plasticità sinaptica e compete con il BPTT sui benchmark di apprendimento automatico.
Estrazione di una macchina a stati finiti da una rete neurale ricorrente tramite quantizzazione ai fini dell'interpretabilità con esperimenti su Atari.
Studiamo l'evidenza teorica e pratica del miglioramento dell'apprendimento di rinforzo on-policy riutilizzando i dati di diverse politiche consecutive.
Usiamo la trasformazione non euclidea di Fourier delle forme definite da un complesso simpliciale per l'apprendimento profondo, ottenendo risultati significativamente migliori rispetto alle tecniche di campionamento basate sui punti utilizzate nell'attuale letteratura sull'apprendimento 3D.
Applichiamo il reinforcement learning alla scoperta causale basata sul punteggio e otteniamo risultati promettenti su set di dati sia sintetici che reali
Abbiamo proposto un metodo universale che può essere utilizzato nella fase di pre-elaborazione dei dati per generare l'argomento più significativo che rappresenta meglio il documento dato
Proponiamo un nuovo quadro di apprendimento multi-task che estrae automaticamente la relazione di dipendenza multi-vista e la usa per guidare il trasferimento della conoscenza tra diversi compiti.
Verifica dell'invarianza traslazionale globale nelle reti convoluzionali e a capsule
Sviluppiamo un metodo analitico per studiare l'inferenza bayesiana delle reti neurali a larghezza finita e troviamo che l'immagine del flusso del gruppo di rinormalizzazione emerge naturalmente.
capire teoricamente l'effetto di regolarizzazione della distillazione. Mostriamo che l'arresto precoce è essenziale in questo processo. Da questa prospettiva, abbiamo sviluppato un metodo di distillazione per l'apprendimento con Label corrotto con garanzie teoriche.
un nuovo approccio per l'apprendimento permanente online utilizzando kernel di output.
Modelliamo uno scenario di costruzione di una casa in Minecraft in pianificazione classica e HTN e confrontiamo i vantaggi e gli svantaggi di entrambi i tipi di modelli.
Presentiamo una struttura per valutare gli esempi avversari nell'elaborazione del linguaggio naturale e dimostriamo che gli esempi avversari generati spesso non sono semanticamente conservanti, sintatticamente corretti o non sospetti.
Possiamo fidarci della spiegazione di una rete neurale per la sua previsione? Esaminiamo la robustezza di diverse nozioni popolari di interpretabilità delle reti neurali, comprese le mappe di salienza e le funzioni di influenza, e progettiamo esempi avversari contro di esse.
L'articolo progetta due algoritmi per il problema di massimizzazione dell'AUC stocastico con complessità all'avanguardia quando si usa una rete neurale profonda come modello predittivo, che sono anche verificati da studi empirici.
Affrontiamo compiti condizionati da obiettivi combinando gli algoritmi Hindsight Experience Replay e Imitation Learning, mostrando una convergenza più veloce del primo e prestazioni finali più elevate del secondo.
Deriviamo un nuovo PAC-Bayesian Bound per funzioni di perdita senza limiti (per esempio Negative Log-Likelihood). 
Proponiamo una semplice tecnica di aumento dei dati auto-supervisionata che migliora le prestazioni degli scenari completamente supervisionati, tra cui l'apprendimento a pochi colpi e la classificazione squilibrata.
Un'architettura di rete basata su LSTM a due rami impara la rappresentazione e la dinamica delle mesh 3D delle simulazioni numeriche di crash.
I vettori di caratteristiche di SoundNet possono prevedere l'attività cerebrale dei soggetti che guardano un film nelle regioni cerebrali legate all'udito e al linguaggio.
Proponiamo un autocodificatore generativo che può apprendere distribuzioni posteriori e di verosimiglianza condizionale espressive usando distribuzioni implicite, e addestrare il modello usando una nuova formulazione dell'ELBO.
I bambini usano il bias di mutua esclusività (ME) per imparare nuove parole, mentre le reti neurali standard mostrano il bias opposto, ostacolando l'apprendimento in scenari naturalistici come l'apprendimento permanente.
Le reti neurali ricorrenti spike che eseguono un compito di memoria di lavoro utilizzano lunghe scale temporali eterogenee, sorprendentemente simili a quelle osservate nella corteccia prefrontale.
 In questo articolo, affrontiamo il problema dell'apprendimento dell'espansione della rete a basso costo
Introduciamo un modello di domanda umana che combina reti neurali e programmi simbolici, che può imparare a generare buone domande con o senza esempi supervisionati.
Un meccanismo di comprensione visiva per ambienti speciali
Migliore formazione avversaria imparando a mappare il manifold dei dati con autoencoders negli stati nascosti.  
Mostriamo che la minimizzazione della perdita di cross-entropia utilizzando un metodo a gradiente potrebbe portare a un margine molto povero se le caratteristiche del set di dati si trovano su un sottospazio a bassa densità.
Un nuovo modello RNN che supera significativamente l'attuale frontiera dei modelli in una varietà di compiti sequenziali.
Sorprendenti risultati negativi su Model Based + Model deep RL
Ispirati dalla teoria dell'Information Bottleneck, proponiamo una nuova architettura di GAN per l'apprendimento di una rappresentazione dissociata
Spiegare la situazione di bias con le GAN MMD; le GAN MMD funzionano con reti critiche più piccole delle WGAN-GP; nuova metrica di valutazione delle GAN.
Un quadro di classificazione multimodale semi-supervisionato, TCN, che supera vari benchmark.
Un metodo neurale iterativo per l'estrazione di segnali che vengono osservati solo mescolati ad altri segnali
Embeddings del segnale fisiologico per le prestazioni di previsione e il trasferimento dell'ospedale con un metodo generale di interpretabilità del valore di Shapley per i modelli impilati.
Presentiamo un algoritmo dimostrabile per recuperare esattamente entrambi i fattori del modello di apprendimento del dizionario. 
Estrazione di relazioni aumentata dai dati con GPT-2
Un algoritmo di inferenza approssimato per l'apprendimento profondo
Proponiamo una nuova strategia di regolarizzazione del manifold basata sulla formazione avversaria, che può migliorare significativamente le prestazioni dell'apprendimento semi-supervisionato.
Un nuovo metodo per l'apprendimento supervisionato attraverso la suddivisione dello spazio di input insieme all'approssimazione della funzione.
Attacchi avversari su embeddings di nodi non supervisionati basati sulla teoria della perturbazione degli autovalori.
Presentiamo un nuovo algoritmo per la scoperta gerarchica di subtask che sfrutta la struttura del processo decisionale lineare di Markov multitask.
Proponiamo un modello di rete di memoria per risolvere istanze LP binarie in cui l'informazione della memoria è conservata per l'uso a lungo termine. 
Introduciamo un nuovo metodo per addestrare modelli Seq2Seq con modelli linguistici che convergono più velocemente, generalizzano meglio e possono trasferirsi quasi completamente a un nuovo dominio usando meno del 10% di dati etichettati.
Introduciamo l'impostazione del problema del meta apprendimento online per catturare meglio lo spirito e la pratica dell'apprendimento permanente continuo.
I pesi di attenzione non espongono completamente ciò che il BERT conosce della sintassi.
Proponiamo un nuovo metodo di super risoluzione del viso che incorpora esplicitamente priori facciali 3D che afferrano le strutture facciali nitide.
L'auto-addestramento con diversi punti di vista dell'input dà risultati eccellenti per il riconoscimento semi-supervisionato delle immagini, il tagging delle sequenze e il parsing delle dipendenze.
Un modo non reversibile di prendere decisioni di accettazione/rifiuto può essere vantaggioso
Forniamo una nuova struttura per MAML nell'impostazione ES/blackbox, e mostriamo che permette politiche deterministiche e lineari, una migliore esplorazione e operatori di adattamento non differenziabili.
Presentiamo una struttura software per la trasformazione delle distribuzioni e dimostriamo la sua flessibilità nel rilassare le ipotesi di campo medio nell'inferenza variazionale con l'uso di flussi di accoppiamento per replicare la struttura dal modello generativo di destinazione.
Adattamento al dominio avversario e apprendimento multidominio: una nuova perdita per gestire classi multi e monodominio nell'impostazione semi-supervisionata.
Una rete di apprendimento che generalizza la struttura MLP per eseguire la regressione da distribuzione a distribuzione
Ha proposto metodi per la rappresentazione di eventi dipendenti dal tempo e la regolarizzazione per la predizione di sequenze; ha valutato questi metodi su cinque set di dati che coinvolgono una serie di compiti di predizione di sequenze.
Sviluppiamo un metodo per un apprendimento di rinforzo offline stabile dai dati registrati. La chiave è regolarizzare la politica RL verso un modello appreso "ponderato per il vantaggio" dei dati.
Questo articolo presenta un modello di apprendimento profondo che combina mappe auto-organizzanti e reti neurali convoluzionali per l'apprendimento della rappresentazione dei dati multiomici
Sparsificazione come messa a punto dei modelli linguistici
Metodo per affrontare lo spostamento delle covariate nell'apprendimento per imitazione usando l'incertezza d'insieme
Usiamo il finetuning supervisionato dei vettori di caratteristiche per migliorare il trasferimento dalla simulazione al mondo reale
Introduciamo la capacità di sfruttare le informazioni sul grado in cui un obiettivo arbitrario è stato raggiunto mentre un altro obiettivo era destinato ai metodi di gradiente della politica.
Proponiamo un nuovo benchmark per la comprensione dei video, con compiti che per progettazione richiedono un ragionamento temporale per essere risolti, a differenza della maggior parte dei dataset video esistenti.
Proponiamo un algoritmo di apprendimento federato asincrono efficiente e robusto sull'esistenza dei ritardatari
L'aggiunta di un nuovo set di pesi alla LSTM che ruota la memoria cellulare migliora le prestazioni su alcuni compiti bAbI.
Nuova metodologia per l'inferenza marginale variazionale delle permutazioni basata sull'algoritmo di Sinkhorn, applicata all'identificazione probabilistica dei neuroni
Proponiamo la prima metrica di robustezza indipendente dagli attacchi, nota come CLEVER, che può essere applicata a qualsiasi classificatore di rete neurale.
Questo articolo propone uno schema di apprendimento spontaneo e auto-organizzante della comunicazione (SSoC) per compiti RL multi-agente.
Sull'uso del BERT come codificatore per la predizione sequenziale delle etichette nel compito di classificazione del testo a più etichette
DNN e Encoder migliorato FM con attenzione bilineare e max-pooling per CTR
L'inferenza bayesiana basata sul dropout è estesa per trattare la multi-modalità ed è valutata su compiti di anticipazione della scena.
Introduciamo un nuovo tipo di GAN condizionale, che mira a sfruttare la struttura nello spazio di destinazione del generatore. Aumentiamo il generatore con un nuovo percorso non supervisionato per imparare la struttura di destinazione. 
In questo articolo, proponiamo un nuovo quadro di allenamento regolarizzato ATLPA, cioè Adversarial Tolerant Logit Pairing with Attention.
Affrontiamo il problema della generalizzazione dell'apprendimento del rinforzo a spazi d'azione non visti.
Imparare in processi puntuali temporali modellando la densità condizionata, non l'intensità condizionata.
Un modello profondo per la modellazione dei temi
Una nuova struttura GAN basata sulla normalizzazione adattiva delle istanze per il VC non parallelo many-to-many e zero-shot. 
Questo lavoro propone Sparse Transformer per migliorare la concentrazione dell'attenzione sul contesto globale attraverso una selezione esplicita dei segmenti più rilevanti per l'apprendimento sequenza per sequenza. 
Le rappresentazioni non supervisionate apprese con Contrastive Predictive Coding permettono una classificazione delle immagini efficiente dal punto di vista dei dati.
La ridistribuzione e la crescita dei pesi in base alla grandezza del momento permette l'addestramento di reti sparse da inizializzazioni casuali che possono raggiungere livelli di prestazioni dense con pesi dal 5% al 50%, accelerando l'addestramento fino a 5,6x.
La superficie di perdita delle reti neurali è un'unione disgiunta di regioni dove ogni minimo locale è un minimo globale della regione corrispondente.
Distilliamo le rappresentazioni dei modelli linguistici per la sintassi attraverso l'apprendimento metrico non supervisionato
Introduciamo una nuova architettura di memoria per la navigazione in ambienti mai visti prima, ispirata alla navigazione basata sui punti di riferimento negli animali.
Proponiamo una nuova architettura che attraversa una piramide di immagini in modo top-down, mentre visita solo le regioni più informative lungo il percorso.
Usiamo un hypernetwork per prevedere i pesi ottimali dati gli iperparametri, e alleniamo tutto insieme.
Proponiamo una nuova metrica per valutare le GAN condizionali che cattura la qualità dell'immagine, la coerenza condizionale e la diversità intra-condizionata in un'unica misura.
Presentiamo TreeQN e ATreeC, nuove architetture per l'apprendimento di rinforzo profondo in domini ad azione discreta che integrano la pianificazione on-line ad albero differenziabile nella funzione o politica di valore dell'azione.
Proponiamo reti Message Passing Encoder-Decode per un modo veloce e accurato di modellare le dipendenze delle etichette per la classificazione multietichetta.
Proponiamo un metodo per fare la regressione a pochi scatti imparando un insieme di funzioni di base per rappresentare la distribuzione della funzione.
Proponiamo un modo modello-agnostico per sfruttare BERT per la generazione di testo e ottenere miglioramenti rispetto a Transformer su 2 compiti su 4 set di dati.
CNN-F estende CNN con una rete generativa di feedback per una visione robusta.
Si dimostra che le CNN di tipo ResNet sono un approssimatore universale e la sua capacità di espressione non è peggiore delle reti neurali completamente connesse (FNN) con una struttura \textit{block-sparse} anche se la dimensione di ogni strato nella CNN è fissa.
Un nuovo metodo di apprendimento a pochi colpi per generare pesi di classificazione specifici per la domanda attraverso la massimizzazione dell'informazione.
Un metodo neurale per la risposta alle domande conversazionali con meccanismo di attenzione e un nuovo uso di BERT come embedder contestuale
alternativa alla penalità di gradiente
ricerca automatica di architetture multi-task che riducono l'uso di funzioni per-task
Proponiamo la nearest neighbor overlap, una procedura che quantifica la somiglianza tra embedders in modo indipendente dal compito, e la usiamo per confrontare 21 embedders di frasi.
Proponiamo un nuovo obiettivo per l'addestramento di VAE-GAN ibride che portano a un miglioramento significativo della copertura e della qualità della modalità.
Un nuovo metodo usa l'informazione statistica del punteggio di leva per misurare l'importanza dei campioni di dati in ogni compito e adotta un approccio di direzioni frequenti per permettere una proprietà di apprendimento permanente.
Impariamo mappe di caratteristiche invarianti alla traslazione, ed equivarianti alla rotazione e alla scala.
Uno specifico algoritmo di meta-apprendimento basato sul gradiente, MAML, è equivalente a una procedura di inferenza in un modello gerarchico bayesiano. Usiamo questa connessione per migliorare MAML attraverso metodi di inferenza approssimativa e stima della curvatura.
Automatizzare il sistema di apprendimento automatico con un algoritmo di ricerca efficiente e una struttura innovativa per fornire migliori modelli di base.
Proponiamo strategie di progettazione sperimentale batch bayesiana basata su principi e un metodo per la quantificazione dell'incertezza dei sommari posteriori in un quadro di calcolo bayesiano approssimato basato su surrogati di processo gaussiano.
Forniamo un tasso di convergenza efficiente per la discesa del gradiente sull'obiettivo di apprendimento del dizionario ortogonale completo basato su un'analisi geometrica.
Mostriamo che architetture RNN progettate e addestrate in modo creativo possono decodificare codici sequenziali ben noti e raggiungere prestazioni quasi ottimali.
Analizziamo e risolviamo il problema della non convergenza di Adam.
In questo articolo proponiamo un metodo generativo per l'adattamento al dominio multisource basato sulla decomposizione dei fattori di contenuto, stile e dominio.
Utilizzo del campionamento di importanza annealed sul problema della co-generazione. 
Sviluppiamo un nuovo metodo di stima dei parametri senza likelihood che è equivalente alla massima verosimiglianza sotto alcune condizioni
Il nostro metodo infonde i vincoli sull'esecuzione dei compiti sfruttando il principio della massima entropia per quantificare come le dimostrazioni differiscono dal comportamento atteso, senza vincoli.
Sistema per imparare compiti robotici nel mondo reale con apprendimento per rinforzo senza strumentazione
Usiamo un Variational Autoencoder per separare lo stile e il contenuto, e otteniamo la conversione della voce modificando l'incorporazione e la decodifica dello stile. Indaghiamo utilizzando un corpus vocale multilingue e analizziamo i suoi effetti.
L'articolo propone un metodo per costringere le CNN a sfruttare l'attenzione spaziale nell'apprendimento di rappresentazioni più centrate sull'oggetto che si comportano meglio sotto vari aspetti.
Reti neurali ricorrenti per i casi d'uso della Cybersecurity
Strutturazione degli ingressi lungo il caos per la stabilità
Ci occupiamo dell'addestramento delle GAN con dati discreti formulando un gradiente di policy che generalizza attraverso le f-divergenze
Le linee di base dipendenti dall'azione possono essere prive di bias e produrre una maggiore riduzione della varianza rispetto alle linee di base dipendenti solo dallo stato per i metodi di gradiente della politica.
Proponiamo un algoritmo attivo di apprendimento multitask che realizza il trasferimento di conoscenza tra i compiti.
Impariamo un efficiente codec di immagini lossy che può essere ottimizzato per facilitare il rilevamento affidabile della manipolazione delle foto a un costo frazionato nel carico utile/qualità e anche a bitrate bassi.
Questo articolo propone un efficace modello generico di sequenza che sfrutta i punti di forza delle RNN e dell'attenzione multi-testa.
Un approccio strutturato a variabili latenti che aggiunge stati di controllo discreti all'interno di un paradigma neurale autoregressivo standard per fornire un fondamento arbitrario delle decisioni interne del modello, senza sacrificare alcun potere di rappresentazione dei modelli neurali.
Stima della distribuzione dei dati di allenamento dal classificatore addestrato usando GAN.
Stabiliamo che le leggi di scala derivate in (Bora et al., 2017) sono ottimali o quasi ottimali in assenza di ulteriori ipotesi.
meta-apprendere un algoritmo di apprendimento capace di ragionamento causale
L'algoritmo basato sul corpus è sviluppato per generare il lessico del sentimento amarico basandosi sul corpus
Noi aumentiamo le stime del valore Q con un bonus basato sul conteggio che assicura l'ottimismo durante la selezione delle azioni e il bootstrapping, anche se le stime del valore Q sono pessimistiche.
Proponiamo soft actor-critic, un algoritmo di RL profondo off-policy actor-critic basato sul framework di apprendimento di rinforzo a massima entropia.
La corrispondenza della distribuzione attraverso la minimizzazione della divergenza fornisce un terreno comune per confrontare i metodi di apprendimento di rinforzo inverso a massima estropia avversaria con la clonazione del comportamento.
Proponiamo un quadro generico che permette di sfruttare la struttura a basso rango sia nella pianificazione che nel deep reinforcement learning.
Un benchmark per valutare le incorporazioni neurali degli identificatori nel codice sorgente.
Riordinando i termini della discrepanza media massima si ottiene una funzione di perdita molto migliore per il discriminatore delle reti generative avversarie
Questo articolo trova algoritmi che usano direttamente rappresentazioni compresse senza perdite di reti feedforward profonde, per eseguire l'inferenza senza decompressione completa.
Abbiamo lanciato le GAN nel quadro della disuguaglianza variazionale e importiamo tecniche da questa letteratura per ottimizzare meglio le GAN; diamo estensioni algoritmiche e testiamo empiricamente le loro prestazioni per l'addestramento delle GAN.
Affrontare il problema dell'eterogeneità dei compiti nel meta-apprendimento introducendo il grafico della meta-conoscenza
 Un algoritmo di boosting profondo è sviluppato per imparare un classificatore d'insieme più discriminante combinando senza soluzione di continuità un insieme di CNN profonde di base.
Un metodo automatico per convertire la musica tra strumenti e stili
Proponiamo diversi nuovi attacchi e una metodologia per misurare la robustezza contro gli attacchi avversari imprevisti.
Deep-Net: Rete neurale profonda per i casi d'uso della sicurezza informatica
Impariamo uno spazio di primitive motorie da dimostrazioni robotiche non annotate, e dimostriamo che queste primitive sono semanticamente significative e possono essere composte per nuovi compiti robotici.
Dimostriamo la fattibilità di un approccio di classificazione delle serie temporali debolmente supervisionato per i dati dei sensori indossabili. 
Proponiamo un quadro di allineamento locale-globale per imparare corrispondenze semantiche da coppie di dati-testo rumorose con una supervisione debole
Imparare a raggiungere gli obiettivi da zero usando l'apprendimento per imitazione con la rietichettatura dei dati
Nell'articolo, abbiamo proposto un metodo di ensemble chiamato InterBoost per l'addestramento di reti neurali per la classificazione di piccoli campioni. Il metodo ha migliori prestazioni di generalizzazione rispetto ad altri metodi d'insieme e riduce significativamente le varianze.
Rileviamo le interazioni statistiche catturate da una rete neurale multistrato feedforward interpretando direttamente i suoi pesi appresi.
Facciamo un benchmark del modello lineare neurale sui set di dati UCI e UCI "gap".
Abbiamo riprodotto AlphaZero su Google Cloud Platform
Stabiliamo la convergenza globale all'ottimalità per le GAN basate su IPM dove il generatore è una rete neurale iperparametrizzata. 
Sviluppiamo efficienti procedure di inclusione di reti approssimate su più scale con proprietà dimostrabili.
 Uno studio empirico dettagliato nella classificazione di pochi colpi che rivela le sfide nell'impostazione di valutazione standard e mostra una nuova direzione.
Presentiamo un modello di inferenza bayesiana per dedurre spiegazioni contrastive (come specifiche LTL) che descrivono come due serie di tracce di piano differiscono.
La geometria tropicale può essere sfruttata per rappresentare i confini decisionali delle reti neurali e portare alla luce intuizioni interessanti.
Un nuovo metodo Gram-Gauss-Newton per addestrare le reti neurali, ispirato dal kernel della tangente neurale e dal metodo Gauss-Newton, con velocità di convergenza veloce sia teoricamente che sperimentalmente.
Indaghiamo la conoscenza sintattica implicita degli embeddings di frasi usando un nuovo set di analisi di frasi annotate grammaticalmente con giudizi di accettabilità.
Proponiamo un'estensione dell'apprendimento multi-output a un continuum di compiti utilizzando kernel valutati dall'operatore.
Dimostriamo che, per funzioni di attivazione che soddisfano alcune condizioni, man mano che una rete profonda si allarga, le lunghezze dei vettori delle variabili nascoste convergono verso una mappa di lunghezza.
Proponiamo un approccio di aumento dei dati per il meta-apprendimento e dimostriamo che è valido.
Un quadro generale per distillare le aspettative posteriori bayesiane per le reti neurali profonde.
In questo articolo, introduciamo una gerarchia discreta di variabili latenti categoriche che addestriamo usando il rilassamento Concrete/Gumbel-Softmax e deriviamo un limite superiore per la differenza assoluta tra l'obiettivo imparziale e quello distorto.
Proponiamo una nuova classe di ottimizzatori per l'ottimizzazione accelerata non convessa tramite una trasformazione non lineare del gradiente. 
Risolvere compiti che coinvolgono la locomozione umanoide guidata dalla visione, riutilizzando il comportamento di locomozione dai dati di motion capture.
Proponiamo le reti Gated Linear Unit - un modello che si comporta in modo simile alle reti ReLU su dati reali, pur essendo molto più facile da analizzare teoricamente.
Proponiamo un metodo di ricerca dell'architettura per identificare una distribuzione di architetture e usarla per costruire un insieme bayesiano per il rilevamento degli outlier.
Un nuovo approccio che rileva i valori anomali dai dati di immagine, preservando l'accuratezza della classificazione delle immagini
Questo articolo introduce CloudLSTM, un nuovo ramo di modelli neurali ricorrenti su misura per la previsione su flussi di dati generati da fonti geospaziali point-cloud.
Proponiamo TransINT, un metodo di incorporazione KG nuovo e interpretabile che conserva isomorficamente l'ordine di implicazione tra le relazioni nello spazio di incorporazione in un modo spiegabile, robusto e geometricamente coerente.
Introduciamo una nuova strategia di addestramento con obiettivo complementare basata sul gradiente per la rilevazione adattiva degli oggetti nel dominio.
Proponiamo un nuovo approccio per collegare le reti specifiche di un compito in un'impostazione di apprendimento multi-task basata su recenti progressi della rete residua.
Come usare la perdita di cross-entropia per l'apprendimento a colpo zero con etichettatura morbida su classi non viste: una soluzione semplice ed efficace che raggiunge prestazioni all'avanguardia su cinque set di dati di riferimento ZSL.
Far crescere progressivamente lo spazio d'azione disponibile è un grande curriculum per gli agenti di apprendimento
Una soluzione game-theoretic agli attacchi e alle difese avversarie.
Un nuovo metodo per creare descrittori densi di tempo (Time Embeddings) per far capire le strutture temporali a modelli semplici
Proponiamo una nuova architettura di rete neurale a grafo basata sulla matrice non-backtracking definita sulle adiacenze dei bordi e dimostriamo la sua efficacia nei compiti di rilevamento della comunità sui grafi.
Le connessioni residue eseguono davvero un'inferenza iterativa
Miglioriamo il tempo e la qualità della ricostruzione su un imager sperimentale senza maschera utilizzando un approccio di apprendimento end-to-end che incorpora la conoscenza del modello di imaging.
Introduciamo un nuovo modello di apprendimento della rappresentazione, cioè "Sample-Ensemble Genetic Evolutionary Network" (SEGEN), che può servire come un approccio alternativo ai modelli di apprendimento profondo.
Proponiamo di utilizzare il meta-apprendimento per un apprendimento linguistico più efficiente, attraverso una sorta di "randomizzazione del dominio". 
MARTHE: un nuovo metodo per adattare i programmi di tasso di apprendimento specifici del compito dal punto di vista dell'ottimizzazione degli iperparametri
Generazione interattiva di immagini da grafici di scena in crescita incrementale in più passi utilizzando GANs mentre si conservano i contenuti dell'immagine generata nei passi precedenti
Studiamo scenari di classificazione a basso e bassissimo segnale-rumore, dove gli oggetti che si correlano con l'etichetta di classe occupano una piccola parte dell'intera immagine (ad esempio, immagini mediche o iperspettrali).
Uno strato di auto-attenzione può eseguire la convoluzione e spesso impara a farlo nella pratica.
Gli algoritmi basati sull'apprendimento possono migliorare le prestazioni degli algoritmi classici per il problema dell'approssimazione low-rank mantenendo la garanzia del caso peggiore.
Architettura proposta per risolvere il compito di accordo morfologico
Questo articolo propone l'uso di metodi di elementi spettrali per l'addestramento veloce e accurato delle Equazioni Differenziali Ordinarie Neurali per l'identificazione del sistema.
Un nuovo segnale di ricompensa intrinseca basato su caratteristiche di successo e un nuovo modo di combinare la ricompensa estrinseca e intrinseca.
Proponiamo di utilizzare una politica di esplorazione separata per raccogliere le traiettorie di pre-adattamento in MAML. Mostriamo anche che l'utilizzo di un obiettivo auto-supervisionato nel ciclo interno porta ad un addestramento più stabile e a prestazioni molto migliori.
Generalizzazione della propagazione all'indietro, usando metodi formali dalla supersimmetria.
Regolarizzare la traiettoria di ottimizzazione con le informazioni di Fisher dei vecchi compiti riduce notevolmente la dimenticanza catastrofica
Diamo un metodo per generare programmi type-safe in un linguaggio simile a Java, data una piccola quantità di informazioni sintattiche sul codice desiderato.
Mostriamo come i flussi autoregressivi possono essere utilizzati per migliorare i modelli di variabili latenti sequenziali.
Gli esempi avversari possono ingannare il sistema di rilevamento del copyright di YouTube
Proponiamo una versione continua della Propagazione dell'Equilibrio, in cui la dinamica dei neuroni e delle sinapsi avviene simultaneamente durante la seconda fase, con garanzie teoriche e simulazioni numeriche.
Proponiamo una nuova Rete Meta Modulo per risolvere alcune delle restrizioni della precedente Rete Neurale Modulo per ottenere forti prestazioni su dataset realistici di ragionamento visivo.
Proponiamo un nuovo attacco per prendere il pieno controllo delle politiche neurali in ambienti realistici.
Può generare codici hash efficaci per un'efficiente raccomandazione a freddo e nel frattempo fornire una strategia di marketing fattibile.
Proponiamo una struttura neurale che può imparare a risolvere il problema di Circuit Satisfiability da istanze di circuito (non etichettate).
Una prospettiva unificata di vari algoritmi di apprendimento per la generazione di sequenze, come MLE, RL, RAML, data noising, ecc.
Introduciamo uno schema "Resource by Collaborative Construction" per creare KB, Wikipedia strutturata 
Un modello all'avanguardia basato sul ragionamento globale per la super-risoluzione delle immagini
Proporre un quadro di valutazione per analizzare e imparare il filtro convoluzionale a grafo
Un nuovo livello di raggruppamento per GNN che impara come raggruppare i nodi, secondo le loro caratteristiche, la connettività del grafico e l'obiettivo del compito a valle.
 Proponiamo TuckER, un modello lineare relativamente semplice ma potente per la previsione dei link nei grafi di conoscenza, basato sulla decomposizione Tucker della rappresentazione tensoriale binaria delle triple dei grafi di conoscenza. 
Un algoritmo per ridurre la quantità di memoria richiesta per l'addestramento delle reti profonde, basato su una strategia di approssimazione.
Gli algoritmi di flusso di dati possono essere migliorati utilizzando l'apprendimento profondo, pur mantenendo garanzie di prestazioni.
Noi proponiamo Neural Hyperlink Predictor (NHP). NHP adatta le reti convoluzionali grafiche per la predizione dei link negli ipergrafi
Un metodo che impara rappresentazioni separate per il significato e la forma di una frase
Abbiamo esplorato i disegni di visualizzazione che possono sostenere i pazienti cronici per presentare e rivedere i loro dati sanitari con i fornitori di assistenza sanitaria durante le visite cliniche.
Proponiamo un predittore stocastico di dinamiche in avanti differenziabili che è in grado di campionare più traiettorie fisicamente plausibili sotto lo stesso stato iniziale di input e mostriamo che può essere utilizzato per addestrare politiche senza modello in modo più efficiente.
Analisi del caso peggiore del potere di rappresentazione delle reti ReLU e dei kernel polinomiali - in particolare in presenza di strutture latenti sparse.
Un modello per controllare la generazione di immagini con GAN e beta-VAE per quanto riguarda la scala e la posizione degli oggetti
Proponiamo una famiglia differenziabile di "matrici caleidoscopio", dimostriamo che tutte le matrici strutturate possono essere rappresentate in questa forma, e le usiamo per sostituire le mappe lineari fatte a mano nei modelli di apprendimento profondo.
Imparare la rappresentazione delle etichette per le reti profonde
Proponiamo Choco-SGD - SGD decentralizzato con comunicazione compressa - per obiettivi non convessi e mostriamo le sue forti prestazioni in varie applicazioni di apprendimento profondo (apprendimento su dispositivo, caso del datacenter).
Mostriamo che Entropy-SGD ottimizza il priore di un PAC-Bayes bound, violando il requisito che il priore sia indipendente dai dati; usiamo la privacy differenziale per risolvere questo e migliorare la generalizzazione.
Mostriamo sperimentalmente che l'apprendimento di trasferimento rende le caratteristiche sparse nella rete e quindi produce una rete più comprimibile. 
Estendiamo i metodi classici di label propation per modellare congiuntamente le informazioni del grafico e delle caratteristiche da una prospettiva di filtraggio del grafico, e mostriamo le connessioni con le reti convlutorie del grafico.
Forniamo un pacchetto software che semplifica drasticamente, automatizza e migliora la valutazione degli ottimizzatori di deep learning.
estrarre embeddings contestuali da un modello supervisionato off-the-shelf. Aiuta i modelli NLP a valle in ambienti con poche risorse
Algoritmi adattivi pratici per il meta-apprendimento basato sul gradiente con garanzie dimostrabili.
Miriamo a sfruttare la diversità delle strutture linguistiche per costruire rappresentazioni di frasi.
L'analisi non supervisionata dei dati registrati dal sistema nervoso periferico denota e categorizza i segnali.
Miglioriamo le difese esistenti basate sulla trasformazione utilizzando un classificatore di distribuzione sulla distribuzione di softmax ottenuta dalle immagini trasformate.
Proponiamo un approccio per apprendere politiche decentralizzate in ambienti multi-agente usando criteri basati sull'attenzione e dimostriamo risultati promettenti in ambienti con interazioni complesse.
Applichiamo RNN per risolvere il problema biologico della previsione dei modelli di ripiegamento della cromatina dai segni epigenetici e dimostriamo per la prima volta che l'utilizzo della memoria degli stati sequenziali sulla molecola di DNA è significativo per la migliore performance.
Proponiamo un metodo efficiente, dimostrabile e indipendente dai dati per la compressione della rete attraverso la potatura neurale usando i coretti di neuroni - una nuova costruzione proposta in questo articolo.
Memory Augmented Network per pianificare in ambienti parzialmente osservabili. 
Una procedura per distillare i modelli contestuali in embeddings statici; applichiamo il nostro metodo a 9 modelli popolari e dimostriamo chiari guadagni nella qualità della rappresentazione rispetto a Word2Vec/GloVe e un potenziale di analisi migliorato studiando a fondo i bias sociali.
Metalearning unsupervised update rules per le reti neurali migliora le prestazioni e dimostra potenzialmente come i neuroni nel cervello imparano senza accesso alle etichette globali.
Mostriamo che la rimozione dei termini costanti dalle architetture CNN fornisce l'interpretabilità del metodo di denoising attraverso tecniche di algebra lineare e aumenta anche le prestazioni di generalizzazione attraverso i livelli di rumore.
Forniamo per la prima volta una prova rigorosa che l'inizializzazione ortogonale accelera la convergenza rispetto all'inizializzazione gaussiana, per reti lineari profonde.
Una prima stima differenziata della funzione di sopravvivenza
CAML è un'istanza di MAML con dipendenze di classe condizionali.
Studiamo il problema della predizione di multiset e proponiamo una nuova funzione di perdita multiset, fornendo analisi e prove empiriche che dimostrano la sua efficacia.
Questo articolo presenta un quadro teorico che modella esplicitamente la distribuzione dei dati per le reti ReLU profonde e connesse localmente
Introduciamo un algoritmo evolutivo modulare biologicamente ispirato in cui gli agenti di RL profonda imparano a cooperare in un difficile gioco sociale multi-agente, che potrebbe aiutare a spiegare l'evoluzione dell'altruismo.
Introduciamo un tipo di rete neurale che è strutturalmente resistente agli attacchi avversari, anche quando viene addestrata su set di allenamento non modificati.  La resistenza è dovuta alla stabilità delle unità della rete rispetto alle perturbazioni di input.
Mostriamo che la robustezza avversaria potrebbe venire al costo delle prestazioni di classificazione standard, ma produce anche benefici inaspettati.
L'addestramento su combinazioni convesse tra esempi di addestramento casuali e le loro etichette migliora la generalizzazione nelle reti neurali profonde
Presentiamo un nuovo approccio allo spike sorting utilizzando il Neural Clustering Process (NCP), un'architettura neurale di recente introduzione che esegue un'inferenza bayesiana approssimativa ammortizzata scalabile per un efficiente clustering probabilistico.
Metodo proposto per trovare la soluzione più generalizzabile che sia stabile con le perturbazioni dei dati del treno.
Implementazione e valutazione della memoria episodica per RL.
Presentiamo un metodo per adattare gli iperparametri dei modelli probabilistici utilizzando il trasporto ottimale con applicazioni nella robotica
Un algoritmo per imparare una rappresentazione di stato predittiva con funzioni di valore generale e apprendimento off-policy è applicato al problema della guida basata sulla visione nella guida autonoma.
Ci occupiamo dell'apprendimento end-to-end di rappresentazioni basate sull'energia per i dataset di osservazione di segnali e immagini con modelli di campionamento irregolari.
Un nuovo algoritmo di apprendimento di meta-rinforzo teoricamente fondato
Il side-tuning adatta una rete pre-addestrata addestrando una rete leggera "laterale" che viene fusa con la rete pre-addestrata (invariata) utilizzando un semplice processo additivo.
Addestrare le GAN con privacy differenziale per generare set di dati artificiali che preservano la privacy.
Questo articolo presenta metodi per distinguere e interpretare gli effetti contestuali che sono codificati in una rete neurale profonda.
Proponendo un nuovo metodo basato sull'attenzione guidata per far rispettare la spartanità nelle reti neurali profonde.
Proviamo a recuperare lo strato più basso in una rete neurale profonda assumendo che lo strato più basso utilizzi un'attivazione ad "alta soglia" e che la rete di cui sopra sia un polinomio "ben educato".
Introduciamo FedProx, una struttura per affrontare l'eterogeneità statistica in ambienti federati con garanzie di convergenza e migliore robustezza e stabilità.
Permettiamo sia l'evoluzione culturale del linguaggio che l'evoluzione genetica degli agenti in un gioco referenziale, utilizzando un nuovo motore di trasmissione del linguaggio.
Abbiamo introdotto un metodo di aumento dei dati nuovo, semplice ed efficiente che aumenta le prestazioni delle GAN esistenti quando i dati di formazione sono limitati e diversi.  
Sviluppiamo un simulatore del corpo e dell'intero connettoma per C. elegans e dimostriamo lo spazio di stato congiunto e l'inferenza dei parametri nel simulatore.
Ispirati da CapsNet, proponiamo una nuova architettura per l'embedding dei grafi sulla base delle caratteristiche dei nodi estratte da GNN.
Gen-RKM: un nuovo quadro per i modelli generativi usando Restricted Kernel Machines con generazione multi-vista e apprendimento di caratteristiche non correlate.
Confrontiamo molti compiti e combinazioni di compiti per il preaddestramento di BiLSTM a livello di frase per compiti NLP. La modellazione del linguaggio è il miglior compito di preaddestramento singolo, ma anche le linee di base semplici si comportano bene.
Una visione della ragione della vulnerabilità avversaria, un metodo di difesa efficace contro gli attacchi avversari.
Applicare la ricerca ad albero Monte Carlo alla generazione di episodi in Alpha Zero
Per le reti neurali a grafo, l'aggregazione su un grafico può beneficiare di uno spazio continuo sottostante il grafico.
Usiamo un semplice algoritmo di ricerca che coinvolge una RNN e una coda di priorità per trovare soluzioni ai compiti di codifica.
Presentiamo la rete neurale wavelet a grafo (GWNN), una nuova rete neurale convoluzionale a grafo (CNN), che sfrutta la trasformazione wavelet a grafo per affrontare la lacuna dei precedenti metodi CNN a grafo spettrale che dipendono dalla trasformazione di Fourier a grafo.
Forniamo un'altra nuova spiegazione del decadimento del tasso di apprendimento: un tasso di apprendimento inizialmente grande sopprime la rete dalla memorizzazione di dati rumorosi, mentre il decadimento del tasso di apprendimento migliora l'apprendimento di modelli complessi.
L'adattamento dell'esplorazione UCB all'ensemble Q-learning migliora rispetto ai metodi precedenti come Double DQN, A3C+ sul benchmark Atari
Le primitive motorie probabilistiche neurali comprimono le politiche di cattura del movimento in un modello flessibile in grado di imitare e riutilizzare un solo colpo come controller di basso livello.
Presentiamo un aumento automatico e adattivo dei dati che funziona per più compiti diversi. 
Proponiamo una nuova tecnica di regolarizzazione basata sulla distillazione della conoscenza.
Strategie efficaci di regolarizzazione e ottimizzazione per modelli linguistici basati su LSTM raggiungono SOTA su PTB e WT2. 
Alla ricerca di rivelatori di oggetti utilizzando diverse misure di selettività; le CNN sono leggermente selettive, ma non abbastanza per essere definite rivelatori di oggetti.
Un metodo per trasformare sequenze di DNA in immagini 2D utilizzando le curve di Hilbert di riempimento dello spazio per migliorare la forza delle CNN
Un obiettivo di clustering apprendibile per facilitare l'apprendimento di trasferimento tra domini e compiti
Metodo congiunto per l'apprendimento di embeddings multilingue con prestazioni allo stato dell'arte per compiti multilingue e qualità monolingue
Modello generativo di dati temporali, che costruisce online lo stato di credenza, opera nello spazio latente, fa previsioni saltuarie e rollout di stati.
Presenta un obiettivo di formazione teorica dell'informazione per il co-training e dimostra la sua potenza nell'apprendimento non supervisionato della fonetica.
I nostri modelli generano voci cantanti senza testi e spartiti. Prendono l'accompagnamento come input e producono voci cantate.
Aumentiamo l'efficienza dei parser di dipendenze a rete neurale con la distillazione insegnante-allievo.
Gli autocodificatori regolati avversarialmente apprendono rappresentazioni lisce di strutture discrete permettendo risultati interessanti nella generazione di testo, come il trasferimento di stile non allineato, l'apprendimento semi-supervisionato e l'interpolazione e l'aritmetica dello spazio latente.
Presentiamo un metodo per stimare collezioni di modelli di regressione in cui ogni modello è personalizzato per un singolo campione.
Una cella di rete neurale ricorrente con memoria a breve termine estesa e un modello RNN multi-task per problemi di sequenza-in-sequenza-out
Ci alleniamo in sottospazi casuali dello spazio dei parametri per misurare quante dimensioni sono realmente necessarie per trovare una soluzione.
Un modello primal dual graph neural network per l'apprendimento semi-supervisionato
Descriviamo due parser di autocodifica end-to-end per l'analisi delle dipendenze basata su grafi semi-supervisionati.
Una rete Fast Weight migliorata che mostra risultati migliori su un compito generale del giocattolo.
Introduzione di un nuovo metodo di ottimizzazione e sua applicazione all'apprendimento profondo.
Introduzione di una nuova classe di reti neurali quantistiche per l'apprendimento di rappresentazioni basate su grafi su computer quantistici.
"In questo articolo, abbiamo testato l'influenza delle strategie di comunicazione sui modelli mentali degli utenti di una violazione dei dati".
Un approccio di riconoscimento degli obiettivi basato sull'euristica del conteggio degli operatori usato per tenere conto del rumore nel dataset.
distillare i modelli a compito singolo in un modello multitasking migliora le prestazioni di comprensione del linguaggio naturale
Valutazione dei metodi di rilevamento di fuori distribuzione a livello di pixel su due nuovi set di dati del mondo reale utilizzando PSPNet e DeeplabV3+.
Presentiamo un nuovo metodo avversario per adattare le rappresentazioni neurali basate su un critico che rileva le caratteristiche non discriminatorie.
Proponiamo un quadro statistico e una procedura teoricamente coerente per la stima della salienza.
Abbiamo esplorato come un nuovo metodo di compositional set embeddings può sia percepire che rappresentare non solo una singola classe ma un intero insieme di classi che è associato ai dati di input.
Introduciamo un set di dati, modelli e protocolli di addestramento + valutazione per un compito di disegno collaborativo che permette di studiare la generazione e la comprensione del linguaggio guidato dall'obiettivo e basato su percezione + azione. 
Proponiamo un metodo basato sulla strategia di addestramento avversaria per imparare caratteristiche discriminative imparziali e invarianti ai confonditori incorporando una funzione di perdita che incoraggia una correlazione svanita tra il bias e le caratteristiche apprese.
Un approccio modulare che consiste in un modulo selettore di frasi seguito dal modello di AQ può essere reso più robusto agli attacchi avversari rispetto a un modello di AQ addestrato sul contesto completo.
Incorporazione di grafi multirelazionali con collettori Riemanniani e funzione di perdita simile a TransE. 
Proponiamo un meta algoritmo di apprendimento per l'apprendimento continuo che può prevenire efficacemente il problema della dimenticanza catastrofica e sostenere l'apprendimento di trasferimento a ritroso.
Analisi delle reti convoluzionali profonde in termini di disposizione associata degli iperpiani
Abbiamo proposto un metodo di meta campionamento bayesiano per adattare l'incertezza del modello nel meta apprendimento
Modello di entropia adattato al contesto da utilizzare nella compressione di immagini ottimizzata end-to-end, che migliora significativamente le prestazioni di compressione
Un metodo per l'apprendimento di rappresentazioni migliori, che agisce come un regolatore e nonostante il suo costo di calcolo aggiuntivo non significativo, raggiunge miglioramenti rispetto a forti basi su compiti di apprendimento supervisionato e semi-supervisionato.
Imballaggio delle regioni di interesse (ROI) come le regioni cancerose identificate nei dati di volume 3D, imballaggio delle sfere all'interno del ROI, rotazione del ROI, misure della differenza di imballaggio delle sfere prima e dopo la rotazione.
La sparsità a livello di filtro emerge implicitamente nelle CNN addestrate con approcci di discesa del gradiente adattivi a causa di vari fenomeni, e l'estensione della sparsità può essere inavvertitamente influenzata da diversi iperparametri apparentemente non correlati.
Facendo un parallelo con l'apprendimento umano, proponiamo un quadro unificato per esibire molte capacità di apprendimento permanente nelle reti neurali utilizzando un piccolo numero di parametri di consolidamento dei pesi.
Mostriamo che i priori GAN robusti funzionano meglio dei priori GAN per la ricostruzione CT ad angolo limitato che è un problema inverso altamente sottodeterminato.
Una nuova forma di attenzione che funziona bene per l'impostazione di supervisione a distanza, e un approccio di apprendimento multitask per aggiungere annotazioni a livello di frase. 
Analisi del meccanismo di attenzione in diversi compiti NLP.
Rappresentare i programmi come grafici, inclusa la semantica, aiuta a generare programmi
Un nuovo metodo per dedurre un modello di, stimare il tasso di entropia di, e prevedere processi a tempo continuo ed eventi discreti.
Un modello unificato per migliorare la robustezza del modello contro compiti multipli
Abbiamo proposto un metodo di apprendimento progressivo per migliorare l'apprendimento e la separazione delle rappresentazioni latenti a diversi livelli di astrazione.
Applichiamo la trasformazione della copula al collo di bottiglia dell'informazione profonda che porta a ripristinare le proprietà di invarianza e uno spazio latente disentangolato con capacità predittive superiori.
Benchmark e metodo per misurare la generalizzazione composizionale massimizzando la divergenza della frequenza dei composti a una piccola divergenza della frequenza degli atomi.
Le reti non supervisionate imparano dal basso verso l'alto; le macchine e i bambini acquisiscono classi visive in ordini diversi
Per i problemi di classificazione con k classi, mostriamo che il gradiente tende a vivere in un piccolo sottospazio a lenta evoluzione spaziato dagli autovettori corrispondenti ai k più grandi autovalori dell'Hessiano.
Il retriever ricorrente basato sul grafico che impara a recuperare i percorsi di ragionamento su Wikipedia Graph supera il più recente stato dell'arte su HotpotQA di oltre 14 punti.
Abbiamo introdotto una rete di estrazione di featrue poco profonda con un grande campo recettivo per compiti di corrispondenza stereo, che utilizza una struttura semplice per ottenere prestazioni migliori.
L'articolo propone un nuovo strato di uscita per le reti profonde che permette l'uso del feedback contestuale di bandito registrato per l'addestramento. 
Classificazione delle famiglie di proteine utilizzando l'apprendimento profondo
Questo articolo mira a fornire una risposta empirica alla domanda se un modello di risposta al dialogo ben addestrato può produrre risposte maliziose.
diagnosticato tutto il problema di STOA VAEs teoricamente e qualitativamente
Proponiamo un nuovo meccanismo di attenzione sparsa e strutturata, TVmax, che promuove la sparsità e incoraggia il peso delle posizioni adiacenti correlate ad essere lo stesso.
Le incorporazioni dei fonemi apprese dalla rete di sintesi vocale neurale multilingue potrebbero rappresentare le relazioni di pronuncia dei fonemi tra le lingue.
Le rappresentazioni GAN sono esaminate in dettaglio, e si trovano insiemi di unità di rappresentazione che controllano la generazione di concetti semantici nell'output.
Le reti mobili sparse sono più veloci di quelle dense con i kernel appropriati.
 Proponiamo un nuovo quadro di apprendimento dell'inferenza dei grafi costruendo relazioni di struttura per dedurre etichette di nodi sconosciuti da quelli etichettati in un modo end-to-end.
Poiché la sicurezza sta diventando una nozione critica nell'apprendimento automatico, crediamo che questo lavoro possa fungere da base per una serie di direzioni di ricerca come gli algoritmi di apprendimento consapevoli della sicurezza.
Introduciamo due approcci per un'inferenza efficiente e scalabile nei simulatori stocastici per i quali la densità non può essere valutata direttamente a causa, per esempio, di cicli di campionamento di rifiuto.
Anche se non c'è compromesso nel limite infinito dei dati, l'addestramento avversario può avere un'accuratezza standard peggiore anche in un problema convesso.
Mostriamo che le connessioni di scorciatoia dovrebbero essere posizionate in modelli che minimizzano le distanze tra gli strati durante la backpropagation, e progettiamo reti che raggiungono distanze log L usando L log(L) connessioni.
Rete Q profonda basata su grafici per la navigazione web 
Abbiamo costruito un quadro teorico per il disentanglement debolmente supervisionato e abbiamo condotto molti esperimenti per sostenere la teoria.
Proponiamo per la prima volta un approccio basato sull'espansione per l'apprendimento continuo senza compiti. Il nostro modello consiste in un insieme di esperti di reti neurali ed espande il numero di esperti secondo il principio Bayesiano nonparametrico.
Ammortizzare lo slancio di Nesterov per un training di deep learning più robusto, leggero e veloce.
Proponiamo un nuovo modello che può distinguere più fattori dinamici in dati sequenziali
Verifichiamo le proprietà deterministiche e probabilistiche delle reti neurali usando rilassamenti non convessi su trasformazioni visibili specificate da modelli generativi
Un efficiente schema di riassunto video multi-vista avanzato per il riconoscimento delle attività in ambienti IoT.
La rettifica nelle reti neurali profonde le porta naturalmente a favorire una rappresentazione invariante.
L'architettura Wave-U-Net, recentemente introdotta da Stoller et al per la separazione delle fonti musicali, è altamente efficace per il miglioramento del parlato, battendo lo stato dell'arte.
Introduciamo un nuovo quadro per l'apprendimento dalla dimostrazione che utilizza il feedback umano continuo; valutiamo questo quadro sul controllo continuo per i veicoli autonomi.
scalare e migliorare VQ-VAE con priori potenti per generare immagini quasi realistiche.
Un approccio di ricerca ad albero Monte Carlo assistito da reti neurali grafiche al Traveling Salesman Problem
Il passaggio direzionale dei messaggi incorpora informazioni direzionali spaziali per migliorare le reti neurali a grafo.
Progettiamo un metodo off-policy semplice ed efficiente senza modello per l'apprendimento di rinforzo basato sulle immagini che eguaglia i metodi basati sul modello allo stato dell'arte nell'efficienza del campione
Presentiamo un nuovo operatore semplice, chopout, con il quale le reti neurali sono addestrate, anche in un unico processo di addestramento, in modo da troncare le sottoreti per ottenere le migliori prestazioni possibili.
La distribuzione guassiana multimodale dello spazio latente nei modelli GAN migliora le prestazioni e permette di scambiare qualità e diversità
SlowMo migliora le prestazioni di ottimizzazione e generalizzazione degli algoritmi decentralizzati efficienti dal punto di vista della comunicazione senza sacrificare la velocità.
Pianificare la struttura sintattica della traduzione usando i codici
 Identifichiamo la memorizzazione come il bias induttivo dell'interpolazione in autocodificatori completamente connessi e convoluzionali iperparametrizzati. 
Proviamo a recuperare lo span di una rete neurale profonda multistrato con struttura latente e applichiamo empiricamente algoritmi efficienti di recupero dello span per attaccare le reti offuscando gli input.
Studiamo la polarizzazione implicita della discesa del gradiente e dimostriamo sotto un insieme minimo di ipotesi che la direzione dei parametri dei modelli omogenei converge ai punti KKT di un problema naturale di massimizzazione del margine.
proponiamo convolutional tensor-train LSTM, che impara LSTM di ordine superiore in modo efficiente usando la decomposizione convolutional tensor-train. 
Il metodo proposto è un SVM neurale end-to-end, che è ottimizzato per l'apprendimento di pochi colpi.
Una nuova struttura CNN 4D per l'apprendimento della rappresentazione a livello video, che supera le recenti CNN 3D.
Studiamo il problema dell'apprendimento e dell'ottimizzazione attraverso simulazioni fisiche tramite la programmazione differenziabile, utilizzando il linguaggio di programmazione e il compilatore DiffSim da noi proposti.
Presentiamo un metodo per interpretare i modelli black-box utilizzando la selezione a ritroso instance-wise per identificare sottoinsiemi minimi di caratteristiche che da soli bastano a giustificare una particolare decisione presa dal modello.
Proponiamo un metodo che estrae le incertezze delle caratteristiche in ogni strato di DNNs e le combina per rilevare i campioni OOD quando si risolvono i compiti di classificazione.
Sfruttiamo gli autocodificatori deterministici come modelli generativi proponendo funzioni di miscelazione che combinano stati nascosti da coppie di immagini. Questi mix sono fatti per sembrare realistici attraverso un quadro avversario.
Introduciamo uno spazio delle caratteristiche robusto aumentato per lo streaming dei dati wifi che è in grado di affrontare la deriva dei concetti per la localizzazione interna
presentiamo un approccio di principio al problema dell'adattamento del dominio federato, che mira ad allineare le rappresentazioni apprese tra i diversi nodi con la distribuzione dei dati del nodo di destinazione.
Le reti di capsule con matrici di posa apprese e l'instradamento EM migliorano lo stato dell'arte della classificazione su smallNORB, migliorano la generalizzabilità a nuovi punti di vista e la robustezza avversaria della scatola bianca.  
Proponiamo un quadro di meta-apprendimento che impara una politica trasferibile dalla sola supervisione debole per risolvere compiti di sintesi con diverse specifiche logiche e grammatiche.
Rendere il trasformatore fluido con attenzione monotona.
Apprendimento della mappatura ottimale con deepNN tra le distribuzioni insieme alle garanzie teoriche.
Un nuovo approccio per costruire un documento non supervisionato (frase) embeddings da pre-trainedword embeddings
Introduciamo un approccio statistico per valutare la robustezza delle reti neurali che fornisce una nozione informativa di quanto sia robusta una rete, piuttosto che la convenzionale affermazione binaria del fatto che una proprietà sia violata o meno.
Migliorare la robustezza dei modelli di trasformatori preaddestrati contro il bias di sovrapposizione lessicale estendendo le frasi di input dei dati di formazione con le loro corrispondenti strutture predicato-argomento 
La regressione delle reti neurali dovrebbe usare la distribuzione di uscita di Dirichlet quando gli obiettivi sono probabilità, al fine di quantificare l'incertezza delle previsioni.
Imparare a cercare una rete densa efficiente con la potatura dei livelli
Addestriamo modelli predittivi sulle informazioni propriocettive e dimostriamo che rappresentano le proprietà degli oggetti esterni.
Un metodo basato su GAN per imparare importanti caratteristiche topologiche di un grafo arbitrario in ingresso.
Previsione del prezzo d'asta delle targhe dei veicoli a Hong Kong con una rete neurale ricorrente profonda, basata sui caratteri delle targhe.
Presentiamo un nuovo modello latente profondo di immagini naturali che può essere addestrato da set di dati non etichettati e può essere utilizzato per risolvere vari compiti di restauro delle immagini.
Assegna automaticamente un punteggio ai saggi su dati sparsi, confrontando i nuovi saggi con campioni noti con Referee Network. 
Combiniamo la struttura della rete di corrispondenza per l'apprendimento di pochi colpi in un modello multietichetta su larga scala per la classificazione delle sequenze genomiche.
L'applicazione della funzione softmax nell'addestramento porta a una supervisione indiretta e inaspettata sulle caratteristiche. Proponiamo un nuovo obiettivo di formazione per indurre esplicitamente regioni di caratteristiche dense per campioni localmente sufficienti a beneficiare della robustezza avversaria.
Le rappresentazioni GAN sono esaminate in dettaglio, e si trovano insiemi di unità di rappresentazione che controllano la generazione di concetti semantici nell'output.
Vicini vicini pixel-wise usati per generare immagini multiple da priori incompleti come immagini a bassa risoluzione, norme di superficie, bordi, ecc.
Forniamo una procedura di addestramento adversariale veloce e basata su principi, con garanzie di prestazioni computazionali e statistiche.
Decomponiamo il divario tra la log-likelihood marginale e il limite inferiore dell'evidenza e studiamo l'effetto del posteriore approssimato sulla vera distribuzione posteriore nelle VAE.
Utilizzo di insiemi e pseudo etichette per il clustering non supervisionato 
Apprendimento efficiente dei dizionari tramite minimizzazione L1 attraverso una nuova analisi della geometria non convessa e non liscia.
Forniamo la prima analisi teorica del recupero garantito di reti neurali a uno strato nascosto sotto perdita di entropia incrociata per problemi di classificazione.
Il nostro codec per le reti neurali (che è basato sulla codifica di trasformazione e sul clustering) permette una compressione trasparente a bassa complessità e ad alta efficienza delle reti neurali.
Acceleriamo l'inferenza sicura DNN in ambienti di esecuzione fidati (di un fattore 4x-20x) esternalizzando selettivamente il calcolo degli strati lineari a un co-processore più veloce ma non fidato.
Questo articolo propone un metodo efficace per comprimere le reti neurali basato sui recenti risultati della teoria dell'informazione.
Un quadro generale per la creazione di reti neurali a grafo covariante
In questo articolo, proponiamo un metodo di pruning basato sulla regolarizzazione tridimensionale per accelerare la 3D-CNN.
Una proposta pratica per una tecnologia NLP più etica e reattiva, operando la trasparenza dei dati di test e di allenamento
Scoprire la struttura dei modelli causali funzionali con reti neurali generative
Nella potatura della rete, la regolazione fine di un modello potato dà solo prestazioni paragonabili o peggiori dell'addestramento da zero. Questo richiede un ripensamento degli algoritmi di pruning esistenti.
Questo articolo introduce la teoria dei valori estremi in k-means per misurare la somiglianza e propone un nuovo algoritmo chiamato Extreme Value k-means per il clustering.
Proponiamo Tendency RL per risolvere in modo efficiente i compiti orientati all'obiettivo con un grande spazio di stato utilizzando l'apprendimento automatico del curriculum e la ricompensa discriminante di modellamento, che ha il potenziale per affrontare i compiti di manipolazione dei robot con la percezione.
Presentiamo i programmi di scena, una rappresentazione strutturata della scena che cattura sia l'aspetto degli oggetti di basso livello che le regolarità di alto livello nella scena.
Compressione delle reti neurali che migliora lo stato dell'arte delle tecniche di approssimazione di basso rango ed è complementare alla maggior parte delle altre tecniche di compressione. 
Presentiamo una tecnica di attribuzione che sfrutta le norme che inducono la sparsità per ottenere l'interpretabilità.
Usiamo la sparsità per migliorare la complessità computazionale dei metodi di riduzione della varianza.
Proponiamo un nuovo quadro basato su VAE che impara dai dati parzialmente osservati per l'imputazione e la generazione. 
Approfondimenti sulla sfida dell'adattamento del dominio, quando si predice l'intento dell'utente nelle e-mail aziendali.
Proponiamo HiPPO, un algoritmo stabile di Hierarchical Reinforcement Learning che può addestrare diversi livelli della gerarchia simultaneamente, dando buone prestazioni sia nella scoperta delle abilità che nell'adattamento.
Facciamo un passo avanti verso la misurazione della difficoltà del compito di apprendimento e dimostriamo che in pratica la performance dipende fortemente dalla corrispondenza tra la rappresentazione dell'informazione e il modello che la interpreta.
Combiniamo processi gaussiani multi-uscita con reti Q ricorrenti profonde per imparare trattamenti ottimali per la sepsi e mostriamo prestazioni migliori rispetto ai metodi standard di apprendimento di rinforzo profondo,
Sviluppiamo un nuovo modello generativo profondo per l'apprendimento semi-supervisionato e proponiamo un nuovo Max-Min cross-entropy per l'addestramento delle CNN.
Proponiamo una semplice tecnica di randomizzazione per migliorare la generalizzazione nell'apprendimento di rinforzo profondo attraverso compiti con vari modelli visivi non visti.
Descrive uno studio che indaga l'interferenza, il trasferimento e la ritenzione di mappature multiple con lo stesso set di pulsanti accordati
Verifica formale di una specifica sulla sottosensibilità della previsione di un modello usando la propagazione dei limiti di intervallo
Proponiamo un nuovo formato a 8 bit che elimina la necessità del loss scaling, dell'arrotondamento stocastico e di altre tecniche a bassa precisione
Nuovo algoritmo per l'apprendimento incrementale di VAE con architettura fissa
MAML è grande, ma ha molti problemi, noi risolviamo molti di questi problemi e come risultato impariamo la maggior parte dei parametri hyper end to end, velocizziamo l'addestramento e l'inferenza e impostiamo un nuovo SOTA in pochi colpi di apprendimento
Rilevamento di comunità sovrapposte nei grafi utilizzando reti neurali a grafo
Smentiamo empiricamente un'ipotesi fondamentale della strategia di condivisione dei pesi ampiamente adottata nella ricerca dell'architettura neurale e spieghiamo perché lo stato dell'arte degli algoritmi NAS si comporta in modo simile alla ricerca casuale.
In questo articolo usiamo la distanza di Wasserstein a fette per modellare la distribuzione latente di un auto-encoder in qualsiasi distribuzione a priori campionabile. 
Introduciamo una classe di modelli generativi che imparano in modo affidabile la dinamica hamiltoniana da osservazioni ad alta densità. L'hamiltoniana appresa può essere applicata alla modellazione di sequenze o come flusso normalizzante.
In questo breve documento, introduciamo brevemente i vantaggi dell'uso della pianificazione AI in Cloud Migration, un prototipo preliminare, così come le sfide che richiedono attenzione da parte della società di pianificazione e programmazione.
Un limite superiore generale sul rischio del dominio di destinazione che riflette il ruolo dell'embedding-complexity.
Per prevedere serie temporali stazionarie multivariate impariamo embeddings contenenti caratteristiche contestuali all'interno di una RNN; applichiamo il quadro su dati di trasporto pubblico
Studiamo un quadro per la scoperta: curare una grande collezione di previsioni, che sono utilizzate per costruire la rappresentazione dell'agente in domini parzialmente osservabili.
Una strategia globale di inferenza di geolocalizzazione con una nuova strategia di meshing e la dimostrazione di incorporare informazioni aggiuntive può essere utilizzata per migliorare le prestazioni complessive di un modello di inferenza di geolocalizzazione.
Tecnica per l'apprendimento di modelli generativi profondi con variabili latenti condivise, applicata a Omniglot con un decoder PixelCNN.
In questo articolo presentiamo un'architettura di lettura task-agnostica per l'integrazione dinamica della conoscenza esplicita del background nei modelli NLU neurali. 
Tecnica di precisione dinamica per addestrare reti neurali profonde
Introduciamo la funzione di attivazione ISRLU che è continuamente differenziabile e più veloce di ELU. La relativa ISRU sostituisce tanh e sigmoide.
Esploriamo il problema della generalizzazione compositiva e proponiamo un mezzo per dotare le architetture delle reti neurali della capacità di comporsi per risolvere questi problemi.
Estendiamo il metodo dell'information bottleneck all'impostazione multiview non supervisionata e mostriamo risultati allo stato dell'arte su set di dati standard
Descriviamo un algoritmo di apprendimento biologicamente plausibile per reti ricorrenti a punto fisso senza pesi legati
Addestriamo un modello generativo 3D di forme da immagini naturali in modo completamente non supervisionato.
Mostriamo che uno schema di attacco adversariale relativamente semplice che utilizza l'ottimizzazione bayesiana e l'upsampling delle dimensioni è preferibile ai metodi esistenti quando il numero di query disponibili è molto basso.
Rivisitiamo la semplice idea di sfrondare le connessioni delle DNN attraverso la regolarizzazione $\ell_1$ ottenendo risultati allo stato dell'arte su più dataset con garanzie teoriche.
Un metodo non parametrico per misurare i momenti di errore dei regressori senza verità di base può essere usato con regressori distorti
Caratterizzazione delle reti neurali cnvoluzionali per il rilevamento e la comprensione del classificatore backdoored.
Possiamo imparare i vincoli ad alta densità dalle dimostrazioni campionando le traiettorie non sicure e sfruttando una parametrizzazione nota dei vincoli.
Apprendimento parametrico di manifold con reti neurali in un quadro geometrico 
Proponiamo una generalizzazione dei contatori di visite che valutano il valore esplorativo che si propaga sulle traiettorie, permettendo un'esplorazione efficiente per RL senza modello
Proponiamo una nuova combinazione di strategia di evoluzione e apprendimento di rinforzo profondo che prende il meglio di entrambi i mondi
Un confronto empirico di reti profonde bayesiane per il campionamento di Thompson
Capire come le etichette di classe aiutano l'addestramento GAN. Proporre una nuova metrica di valutazione per i modelli generativi. 
Algoritmo iterativo veloce per bilanciare l'energia di una rete rimanendo nella stessa classe di equivalenza funzionale
Troviamo impostazioni ambientali in cui gli agenti SOTA addestrati su compiti di navigazione mostrano fallimenti estremi che suggeriscono fallimenti nella generalizzazione.
Stima bayesiana robusta attraverso la massima discrepanza media
Creiamo uno stimatore imparziale per la probabilità di log di modelli di variabili latenti, estendendo tali modelli a un più ampio campo di applicazioni.
I lotti di dimensioni più piccole possono superare i lotti molto grandi sul set di prova sotto budget di passi costanti e con programmi di tasso di apprendimento adeguatamente sintonizzati.
Migliore algoritmo di Deep Reinforcement Learning per approssimare la minimizzazione del rimpianto controfattuale
Genera dati mai visti durante l'addestramento da una condizione desiderata 
Analizziamo la discesa del gradiente per le reti neurali lineari profonde, fornendo una garanzia di convergenza all'optimum globale ad un tasso lineare.
Uno strato che modella connettori casuali locali nella corteccia all'interno di reti profonde in grado di apprendere invarianze generali non parametriche dai dati stessi.
Introduciamo un quadro efficace e generale per incorporare informazioni di condizionamento in modelli generativi basati sull'inferenza.
Questo articolo descrive tre tecniche per permettere a uno scheduler non-backtracking, computazionalmente limitato, di considerare un piccolo numero di attività alternative basate sulla disponibilità delle risorse.
Usiamo modifiche semplici e biologicamente motivate di tecniche di apprendimento standard per ottenere prestazioni allo stato dell'arte su benchmark di dimenticanza catastrofica.
Utilizzo di tecniche di deep learning su compiti relativi alla voce cantata.
Generazione della lingua utilizzando modelli seq2seq che producono embeddings di parole invece di una distribuzione basata su softmax sul vocabolario ad ogni passo, consentendo un addestramento molto più veloce pur mantenendo la qualità della generazione
Risultati in forma chiusa per l'apprendimento profondo nel limite di disaccoppiamento dei livelli applicabili alle reti residue
 In questo articolo, viene fornito un nuovo metodo che chiamiamo Centered Initial Attack (CIA). Esso assicura per costruzione che la perturbazione massima sia più piccola di una soglia fissata in anticipo, senza il processo di clipping.
Rispondere a un'ampia classe di interrogazioni logiche su grafi di conoscenza con box embeddings nello spazio vettoriale
Affrontiamo l'ottimizzazione degli iperparametri completamente parallela con i processi di punti determinanti. 
Un approccio spettrale multilivello per migliorare la qualità e la scalabilità dell'incorporazione non supervisionata dei grafi.
Un nuovo modello generativo per dati strutturati discreti. L'attributo pigro stocastico proposto converte il controllo semantico offline in una guida online per la decodifica stocastica, che affronta efficacemente i vincoli nella sintassi e nella semantica, e raggiunge anche prestazioni superiori
i modelli proposti con la conoscenza esterna migliorano ulteriormente lo stato dell'arte sul dataset SNLI.
Approccio per migliorare l'accuratezza della previsione attraverso l'apprendimento di caratteristiche profonde sulle immagini di scena vicine nell'analisi delle immagini di scena del satellite.
Proponiamo reti di grafi di differenza fisicamente consapevoli, progettate per imparare efficacemente le differenze spaziali per modellare le dinamiche scarsamente osservate.
Apprendimento di gerarchie funzionalmente decomposte per compiti di navigazione continua
L'articolo descrive un nuovo algoritmo che permette di dedurre i modelli di corrispondenza sonora per più lingue.
Una regola di apprendimento biologicamente plausibile per l'addestramento di reti neurali ricorrenti
Un nuovo metodo per l'apprendimento non supervisionato della rappresentazione sui grafi, basato sulla massimizzazione dell'informazione reciproca tra le rappresentazioni locali e globali in un grafico. Risultati allo stato dell'arte, competitivi con l'apprendimento supervisionato.
Un modello a ritroso del precedente (stato, azione) dato lo stato successivo, cioè P(s_t, a_t | s_{t+1}), può essere usato per simulare ulteriori traiettorie che terminano negli stati di interesse! Migliora l'efficienza dell'apprendimento RL.
Questo lavoro riguarda il metodo basato sui tensori per la formazione della rappresentazione delle preposizioni.
Usiamo dinamiche a tempo continuo per definire un modello generativo con verosimiglianze esatte e un campionamento efficiente che è parametrizzato da reti neurali non limitate.
Un nuovo approccio non-adversariale basato sulla corrispondenza delle caratteristiche per addestrare modelli generativi che raggiunge risultati all'avanguardia.
Una nuova architettura per la classificazione a pochi colpi in grado di gestire l'incertezza.
Mostriamo che le CNN e le ResNet con appropriati priori sui parametri sono processi gaussiani nel limite di infiniti filtri convoluzionali.
Presentiamo una metodologia di progettazione end-to-end per l'implementazione efficiente dell'apprendimento profondo. 
Accelerare l'ottimizzazione distribuita sfruttando i ritardatari.
Grazie a un nuovo renderer differenziabile, proponiamo una nuova metrica che ha implicazioni nel mondo reale per valutare gli algoritmi di apprendimento automatico avversari, risolvendo la mancanza di realismo della metrica esistente basata sulle norme dei pixel.
Mostriamo che l'architettura Transformer e la GPU Neural sono Turing complete.
Usiamo VAE per catturare la caratteristica di forma per la valutazione automatica della segmentazione
Indaghiamo gli autovalori degli strati lineari nelle reti profonde e mostriamo che le distribuzioni sviluppano un comportamento a coda pesante durante la formazione.
Proponiamo un nuovo tipo di modulo di attenzione allenabile end-to-end, che applica equilibri di peso globali tra gli strati utilizzando RNN co-propaganti con CNN.
Le caratteristiche auto-generate dal modello bio-mimetico MothNet migliorano significativamente l'accuratezza del test dei metodi ML standard su MNIST vettorizzato. Le caratteristiche generate da MothNet superano anche i generatori di caratteristiche standard.
Concentrandosi maggiormente sulle previsioni finali nei predittori anytime (come le recentissime Multi-Scale-DenseNets), facciamo sì che i piccoli modelli anytime superino quelli grandi che non hanno questa focalizzazione. 
Proponiamo una procedura di apprendimento efficiente in termini di memoria che sfrutta la reversibilità degli strati della rete per consentire la progettazione guidata dai dati per l'imaging computazionale su larga scala.
Neuron as an Agent (NaaA) ci permette di allenare la comunicazione multi-agente senza una terza parte fidata.
Un nuovo metodo di preformazione che stabilisce nuovi risultati allo stato dell'arte sui benchmark GLUE, RACE e SQuAD pur avendo meno parametri rispetto a BERT-large. 
Apprendimento profondo su dati tabellari strutturati utilizzando l'incorporazione di parole bidimensionali con un modello CNN preaddestrato di ImageNet.
connessioni tra codifica predittiva e VAEs + nuove frontiere
Nuove varianti di metodi di ottimizzazione che combinano i vantaggi dei metodi adattivi e non adattivi.
In questo articolo, abbiamo proposto un nuovo algoritmo, GenDICE, per la stima della correzione della distribuzione stazionaria generale, che può gestire sia la valutazione scontata che la valutazione media off-policy su campioni multipli behavior-agnostic.
Un'esplorazione empirica e visiva intuitiva delle proprietà di generalizzazione delle reti neurali profonde.
Usiamo la convoluzione per far sì che le reti neurali si comportino più come sistemi simbolici.
Formulazione analitica dei fenomeni di onde stazionarie equatoriali: Applicazione a QBO e ENSO
Proponiamo di addestrare una rete neurale invertibile per ogni classe per eseguire l'apprendimento continuo classe per classe.
Un nuovo ensemble basato sul recupero e sulla generazione per sistemi di conversazione a dominio aperto.
Capire la trasferibilità dal punto di vista di una migliore generalizzazione, dell'ottimizzazione e della fattibilità della trasferibilità.
Dimostriamo che esistono reti ReLU i cui parametri sono determinati quasi unicamente dalla funzione che implementano.
Proponiamo una rete di modulazione top-down per applicazioni di apprendimento multi-task con diversi vantaggi rispetto agli schemi attuali.    
Nuovo algoritmo di clustering di dati di serie temporali basato sulle caratteristiche del sistema dinamico.
Un metodo per incoraggiare l'attribuzione assiomatica delle caratteristiche di un modello profondo che corrisponda all'intuizione umana.
Proponiamo LSTM ad alte prestazioni con pesi binari/ternari, che possono ridurre notevolmente la complessità di implementazione
Affrontiamo il problema del riconoscimento non supervisionato di oggetti a pochi scatti, dove tutte le immagini di allenamento sono prive di etichetta e non condividono le classi con le immagini di test.
Attacchi black-box basati su query alle reti neurali profonde con tassi di successo avversari che corrispondono agli attacchi white-box
Convertiamo i sottografi in immagini strutturate e li classifichiamo usando 1. deep learning e 2. transfer learning (Caffe) e otteniamo risultati sorprendenti.
Algoritmo basato sull'auto-assemblaggio per l'adattamento al dominio visivo, risultati allo stato dell'arte, ha vinto la sfida di adattamento al dominio di classificazione delle immagini di VisDA-2017.
Una variante VAE che può creare diverse immagini corrispondenti a nuovi "concetti" concreti o astratti descritti usando vettori di attributi.
Proponiamo un metodo basato sul modello chiamato "Search with Amortized Value Estimates" (SAVE) che sfrutta sia l'esperienza reale che quella pianificata combinando Q-learning con Monte-Carlo Tree Search, ottenendo forti prestazioni con budget di ricerca molto piccoli.
Una breve dimostrazione dell'equivalenza del soft Q-learning e dei gradienti politici.
Proponiamo un algoritmo di trasferimento della politica che può superare grandi e impegnative discrepanze nella dinamica del sistema come la latenza, l'errore di modellazione degli attuatori, ecc.
Impara a quantizzare il segnale del discorso e ad applicare algoritmi che richiedono ingressi discreti ai dati audio come il BERT.
Sviluppiamo Hierarchical Agent with Self-play (HASP), un approccio di apprendimento per ottenere politiche strutturate gerarchicamente che possono raggiungere alte prestazioni rispetto al convenzionale self-play su giochi strategici competitivi in tempo reale.
Embeddings di parole a capacità variabile e SOTA su WikiText-103, benchmark Billion Word.
una profonda miscela multivariata di modelli gaussiani per la regressione bounding box sotto occlusione
Sostituiamo il vincolo della sfera Lp con le celle di Voronoi dei dati di formazione per produrre modelli più robusti. 
Proponiamo di imparare una politica più generalizzata per compiti di navigazione basati sul linguaggio naturale attraverso un apprendimento multitask indipendente dall'ambiente.
proponiamo di usare i baricentri di Wasserstein per l'assemblaggio di modelli semantici
Classificazione audio efficiente delle etichette attraverso l'apprendimento multi-task e l'auto-supervisione
Proporre i primi metodi per ottimizzare esattamente la distribuzione softmax usando il gradiente stocastico con un tempo di esecuzione indipendente dal numero di classi o di punti dati.
Utilizzare Monte carlo Tree Search e Homoglyphs per generare campioni avversari indistinguibili su dati di testo
Imparare a convertire uno schizzo disegnato a mano in un programma di alto livello
Questo documento utilizza i principi del campo della calibrazione nell'apprendimento automatico sui logit di una rete neurale per difendersi dagli attacchi avversari
Addestriamo congiuntamente un modello di skip-gram multilingue e un modello di somiglianza di frase cross-lingue per imparare embeddings di testo multilingue di alta qualità che si comportano bene nello scenario di risorse basse.
Abbiamo proposto un modello generativo flessibile che impara in modo stabile minimizzando direttamente la distanza empirica esatta di Wasserstein.
Uno studio di come i diversi componenti della pipeline NAS contribuiscono alla precisione finale. Inoltre, un benchmark di 8 metodi su 5 set di dati.
Trovare le corrispondenze tra i domini eseguendo iterazioni di corrispondenza/mappatura
un modello neurale di argomento con sparsità basato su VAE
Keras per reti neurali infinite.
Introduciamo NLProlog, un sistema che esegue ragionamenti basati su regole del linguaggio naturale sfruttando le embeddings delle frasi preaddestrate e la messa a punto con strategie di evoluzione, e lo applichiamo a due compiti di risposta alle domande multi-hop.
Proponiamo il Fidelity-weighted Learning, un approccio semi-supervisionato insegnante-studente per l'addestramento delle reti neurali usando dati debolmente etichettati.
Dimostriamo che la discesa del gradiente è robusta alla corruzione delle etichette nonostante la sovra-parametrizzazione sotto un modello di dataset ricco.
Presentiamo un nuovo schema di codifica dei pesi che permette un alto rapporto di compressione e una veloce conversione della matrice da sparsa a densa.
Ha migliorato una rete di inpainting dei pixel basata su GAN per il recupero di immagini sismiche compresse e ha proposto una raccomandazione di indagine a campionamento non uniforme, che può essere facilmente applicata al settore medico e ad altri domini per la tecnica di rilevamento compressivo.
Sviluppiamo Simplified Action Decoder, un semplice algoritmo MARL che batte il precedente SOTA su Hanabi con un grande margine nei giochi da 2 a 5 giocatori.
Riconoscimento dei caratteri ottici addestrabile end-to-end su documenti stampati; raggiungiamo risultati all'avanguardia, battendo Tesseract4 su set di dati di riferimento sia in termini di precisione che di tempo di esecuzione, utilizzando un approccio basato esclusivamente sulla visione artificiale.
NovoGrad - un metodo SGD adattivo con normalizzazione del gradiente a strati e decadimento del peso disaccoppiato. 
Migliore sintesi audio combinando il DSP interpretabile con l'apprendimento end-to-end.
Un nuovo approccio alla classificazione dei grafi basato su reti convoluzionali a grafo spettrale e la sua estensione a multigrafi con relazioni apprendibili e struttura gerarchica. Mostriamo risultati allo stato dell'arte su dataset chimici, sociali e di immagini.
Mostriamo come eseguire con successo attacchi backdoor senza cambiare le etichette di allenamento.
Troviamo che le reti profonde che generalizzano male sono più dipendenti dalle singole direzioni rispetto a quelle che generalizzano bene, e valutiamo l'impatto del dropout e della normalizzazione dei lotti, così come la selettività di classe sulla dipendenza dalla singola direzione.
Invece di imparare i parametri di un modello grafico dai dati, imparate una rete di inferenza che può rispondere alle stesse domande probabilistiche.
Dimostriamo come i blocchi residui possono essere visti come passi di Gauss-Newton; proponiamo un nuovo blocco residuo che sfrutta le informazioni del secondo ordine.
Introduciamo un modello di apprendimento automatico che utilizza caratteristiche indipendenti dal dominio per stimare la criticità dello stato corrente per causare uno stato indesiderato noto.
Sviluppiamo una struttura per trovare rappresentazioni interne modulari nei modelli generativi e manipolare poi per generare esempi controfattuali.
I pesi plastici hebbiani possono comportarsi come un immagazzinamento di memoria episodica compressa nelle reti neurali; migliorando la loro capacità di alleviare la dimenticanza catastrofica nell'apprendimento continuo.
Sviluppiamo un approccio per parcellizzare uno strato nascosto in DNN in gruppi funzionalmente correlati, applicando il coclustering spettrale sui punteggi di attribuzione dei neuroni nascosti.
Distribuire applicazioni di classificazione del testo e di analisi del sentimento per l'inglese e il cinese su un chip acceleratore CNN da 300mW per scenari di applicazione sul dispositivo.
Sviluppiamo VAE in cui il codificatore prende un vettore di parametri del modello come input, così possiamo fare un'inferenza rapida per molti modelli
Secret è un metodo di trasferimento per RL basato sulla cessione di crediti.
Lavorare verso modelli generativi di grafi di conoscenza per stimare meglio l'incertezza predittiva nell'inferenza della conoscenza. 
Un sistema dinamico basato sul flusso di gradiente per la modellazione generativa invertibile
Introduciamo uno strato di memoria efficiente che può apprendere la rappresentazione e coartare i grafi di input simultaneamente senza fare affidamento sul passaggio di messaggi.
Un nuovo schema di codifica che utilizza {-1, +1} per decomporre le QNN in reti binarie multiramo, in cui abbiamo usato operazioni bitwise (xnor e bitcount) per ottenere la compressione del modello, l'accelerazione computazionale e il risparmio di risorse. 
Proponiamo un nuovo modo di incorporare le informazioni condizionali dell'immagine nel discriminatore di GANs usando la fusione delle caratteristiche che può essere usata per compiti di predizione strutturata.
Proponiamo un algoritmo per l'apprendimento di abilità utili senza una funzione di ricompensa, e mostriamo come queste abilità possono essere utilizzate per risolvere compiti a valle.
L'articolo risolve un problema di ambiguità lessicale causato dall'omonimia nella traduzione neurale tramite BERT.
Questo articolo si concentra sulla generazione sintetica di dati sulla mobilità umana nelle aree urbane utilizzando le GAN. 
Questo articolo propone uno schema di codifica efficace per le reti neurali che codifica un insieme casuale di pesi da una distribuzione variazionale.
Analizzando un algoritmo che minimizza una perdita non convessa, dimostriamo che tutto il rumore, tranne una piccola frazione, può essere rimosso da un'immagine utilizzando un priore generativo basato su una rete neurale profonda.
L'architettura multi-task su larga scala risolve ImageNet e la traduzione insieme e mostra il transfer learning.
Approccio ispirato alla filosofia continentale per imparare con pochi dati.
Imparare a sintetizzare audio a forma d'onda grezza con le GAN
Un nuovo metodo di adattamento del dominio per allineare i manifold dai domini di origine e di destinazione utilizzando la propagazione delle etichette per una migliore accuratezza.
Questo articolo propone un nuovo metodo per l'apprendimento delle reti neurali nelle impostazioni online bandit marginalizzando sull'ultimo strato
Dimostriamo in teoria e in pratica che la combinazione di più metodi di spiegazione per DNN giova alla spiegazione.
Imparare con dati di formazione limitati sfruttando istanze "utili" da una ricca fonte di dati.  
Aumentiamo la quantità di supervisione delle tracce possibile da utilizzare quando si addestrano architetture di macchine neurali completamente differenziabili.
Proponiamo reti quantizzate bayesiane, per le quali impariamo una distribuzione posteriore sui loro parametri quantizzati.
La formazione avversaria a cascata + l'apprendimento della somiglianza a basso livello migliorano la robustezza sia contro gli attacchi della scatola bianca che della scatola nera.
Mostriamo che, in contrasto con la saggezza popolare, il problema del gradiente che esplode non è stato risolto e che limita la profondità a cui le MLP possono essere efficacemente addestrate. Mostriamo perché i gradienti esplodono e come ResNet li gestisce.
Abbiamo trovato che l'addestramento adversariale non solo accelera l'addestramento GAN ma aumenta anche la qualità dell'immagine
Un metodo per binarizzare sia i pesi che le attivazioni di una rete neurale profonda che è efficiente nel calcolo e nell'uso della memoria e ha prestazioni migliori dello stato dell'arte.
Presentiamo Good-Enough Model Spaces (GEMS), una struttura per l'apprendimento di un modello aggregato su nodi distribuiti in un piccolo numero di round di comunicazione.
Proponiamo un nuovo autocodificatore basato sulla distanza di Wasserstein, che migliora le proprietà di campionamento del VAE.
Preservare la privacy differenziale nell'apprendimento adversariale con robustezza dimostrabile agli esempi adversariali
Costruiamo ed esploriamo automaticamente un piccolo processo decisionale astratto di Markov, che ci permette di raggiungere risultati all'avanguardia su Montezuma's Revenge, Pitfall e Private Eye con un margine significativo.
Mostriamo che il controllo KL da un priore pre-addestrato può permettere ai modelli RL di imparare da un batch statico di dati raccolti, senza la possibilità di esplorare online nell'ambiente.
Trasferimento della politica di un singolo episodio in una famiglia di ambienti con dinamiche correlate, attraverso un probing ottimizzato per una rapida inferenza delle variabili latenti e l'esecuzione immediata di una politica universale.
Proponiamo un modello codificatore-decodificatore basato su una rete Graph Convolutional Network con attenzione sequenziale per sistemi di dialogo orientati agli obiettivi.
Meccanismo di incorporazione di sequenze di nodi che cattura sia il grafico che le proprietà del testo.
Questo articolo mira a sfruttare le buone proprietà delle caratteristiche visive robuste come SIFT per rinnovare le architetture CNN verso una migliore accuratezza e robustezza.
La teoria prevede la transizione di fase tra valori di beta non apprendibili e apprendibili per l'obiettivo Information Bottleneck
Generare immagini di allenamento corrotte che sono impercettibili ma che cambiano il comportamento della CNN su un obiettivo durante ogni nuovo allenamento.
Diamo un algoritmo per l'apprendimento di una rete neurale a due strati con distribuzione simmetrica dell'input. 
Mostriamo che la formazione di una rete di studenti e insegnanti in modo iterativo, piuttosto che congiunto, può produrre strategie di insegnamento emergenti e interpretabili.
Analisi non asintotica di SGD e SVRG, che mostra la forza di ogni algoritmo in termini di velocità di convergenza e costo computazionale, in entrambe le impostazioni sotto-parametrizzate e sovra-parametrizzate.
Esaminiamo sistematicamente perché la distillazione della conoscenza è cruciale per l'addestramento dei modelli di traduzione non autoregressiva (NAT), e proponiamo metodi per migliorare ulteriormente i dati distillati in modo che corrispondano meglio alla capacità di un modello NAT.
Riusciamo a stabilizzare i trasformatori per l'addestramento nell'impostazione RL e dimostriamo un grande miglioramento rispetto agli LSTM su DMLab-30, abbinando un'architettura di memoria esterna.
Ispirati dalla variabilità trial-to-trial nel cervello che può risultare da più fonti di rumore, introduciamo la variabilità attraverso il rumore nel quadro della distillazione della conoscenza e studiamo il loro effetto sulla generalizzazione e la robustezza.
Introduciamo un nuovo approccio end-to-end per imparare a raggruppare in assenza di esempi etichettati. Definiamo una funzione di perdita differenziabile equivalente ai tagli normalizzati attesi.
Introduciamo diversi set di dati per l'OCR cirillico e un metodo per il suo riconoscimento
Proponiamo un modo non supervisionato per imparare embeddings multiple per frasi e frasi 
Campione di algoritmi efficienti per adattare un modello text-to-speech a un nuovo stile di voce con prestazioni allo stato dell'arte.
Questo articolo introduce un quadro probabilistico per la classificazione delle immagini k-shot che raggiunge risultati all'avanguardia
Indagine sulla combinazione di reti neurali ricorrenti e replay dell'esperienza che porta all'agente allo stato dell'arte sia su Atari-57 che su DMLab-30 usando un singolo set di iper-parametri.
La nostra combinazione di apprendimento multi-task e auto-attenzione, addestrando il modello ad occuparsi dei genitori in un albero sintattico, raggiunge lo stato dell'arte dei risultati CoNLL-2005 e CoNLL-2012 SRL per i modelli che utilizzano predicati.
Proponiamo un nuovo modulo che migliora qualsiasi architettura simile a ResNet imponendo un comportamento "selettivo del canale" agli strati convoluzionali
Una teoria e un quadro algoritmico per la predizione sotto spostamento distributivo, compresa la stima dell'effetto causale e l'adattamento al dominio
Studiamo gli insiemi profondi attraverso la lente del paesaggio di perdita e lo spazio delle previsioni, dimostrando che il potere di decorrelazione delle inizializzazioni casuali è ineguagliato dal campionamento del sottospazio che esplora solo una singola modalità.
Possiamo fidarci dei nostri modelli di apprendimento profondo? Un framework per misurare e migliorare la fiducia di un modello di deep learning durante l'allenamento.
Un approccio RL basato sul modello che utilizza una penalità di incertezza differenziabile per imparare le politiche di guida da dati puramente osservativi.
Personalizzare le previsioni dei modelli di sequenza (come LDS e RNN) attraverso un codice latente esplicito.
Proponiamo un nuovo addestramento avversario con un metodo di adattamento al dominio che migliora significativamente la capacità di generalizzazione su esempi avversari di diversi attacchi.
Questo articolo propone un nuovo Transformer leggero per la modellazione del linguaggio a livello di carattere, utilizzando operazioni di gruppo.
Un approccio di addestramento domain-adversarial stabile per un adattamento robusto e completo del dominio
Usiamo l'apprendimento automatico per generare sinonimi per grandi tassonomie di shopping.
MOHART utilizza un meccanismo di auto-attenzione per eseguire il ragionamento relazionale nel tracciamento di più oggetti.
Indaghiamo e proponiamo soluzioni per due sfide nel reinforcement learning: (a) apprendimento efficiente dell'attore-critico con il replay dell'esperienza (b) stabilità dell'apprendimento molto off-policy.
Proponiamo un algoritmo di selezione del gradiente di stima con l'obiettivo di migliorare l'efficienza dell'ottimizzazione.
Studiamo il problema di alleviare il problema dell'instabilità nella procedura di addestramento GAN attraverso un nuovo design dell'architettura, con garanzie teoriche.
Questo lavoro dimostra la non accelerazione di Nesterov SGD con qualsiasi iper-parametro, e propone un nuovo algoritmo che accelera in modo dimostrabile SGD nell'impostazione iper-parametrizzata.
Uno strato feedforward per incorporare la morbidezza strutturata in un modello di apprendimento profondo
Non deformare le tue convoluzioni, deforma i tuoi kernel.
Presentiamo un metodo per l'apprendimento di modelli di incorporazione di sequenze proteiche utilizzando informazioni strutturali sotto forma di somiglianza strutturale globale tra le proteine e all'interno di contatti residuo-residuo di proteine.
Considerando il processo di ottimizzazione delle reti neurali come un problema di selezione del modello, introduciamo un metodo di normalizzazione biologica plausibile che estrae la regolarità statistica sotto il principio MDL per affrontare il problema dei dati squilibrati e limitati.
"Modellazione generativa senza bisogno di formazione avversaria"
Proponiamo un metodo di apprendimento per imitazione per imparare da dimostrazioni di diversa qualità raccolte da dimostratori con diversi livelli di competenza.
Descrivere un'euristica semantica che si basa su una descrizione di servizio OWL-S e usa misure di distanza di parole e frasi per valutare l'utilità dei servizi per un dato obiettivo. 
Rete convoluzionale a grafo basata sulla topologia (GCN)
Le reti neurali artificiali hanno evoluto le stesse strutture presenti nei sistemi olfattivi di mosche e topi dopo essere state addestrate a classificare gli odori
La regolarizzazione liscia sul grafico del campione per la traduzione da immagine a immagine non accoppiata risulta in una coerenza significativamente migliorata
Una rete neurale di convoluzione per la corrispondenza stereo multi-vista il cui design è ispirato dalle migliori pratiche degli approcci tradizionali basati sulla geometria
Aumentiamo l'apprendimento della politica senza modello con funzioni di ricompensa a livello di sequenza e un bonus di visita basato sul conteggio e dimostriamo l'efficacia nel regime di grandi lotti e basso giro visto nella progettazione di sequenze di DNA e proteine.
Usiamo l'apprendimento di rinforzo per addestrare un agente a risolvere una serie di compiti aritmetici visivi usando moduli percettivi pre-addestrati e trasformazioni di rappresentazioni interne create da questi moduli.
Un nuovo algoritmo RL chiamato Interior Policy Differentiation è proposto per imparare una collezione di politiche diverse per un dato compito primario.
Una valutazione empirica sulle reti generative avversarie
Previsione dei valori numerici degli attributi associati alle entità nelle basi di conoscenza.
Proponiamo procedure per valutare e rafforzare l'allineamento dell'incorporazione contestuale e mostriamo che entrambe migliorano il trasferimento XNLI a zero colpi del BERT multilingue e forniscono utili intuizioni sul modello.
Usiamo le reti neurali addestrate per il denoising delle immagini come priori plug-and-play in algoritmi di minimizzazione dell'energia per problemi di ricostruzione delle immagini con convergenza dimostrabile.
Proponiamo un nuovo metodo per calibrare i modelli di embedding dei grafi di conoscenza senza il bisogno di esempi negativi.
Una nuova perdita Adaptive Curriculum Learning per il riconoscimento profondo dei volti
L'addestramento avversario con metodi a passo singolo si adatta troppo e rimane vulnerabile a semplici attacchi black-box e white-box. Mostriamo che includere esempi avversari da più fonti aiuta a difendersi dagli attacchi black-box.
Questo articolo propone un nuovo approccio per incorporare l'invarianza desiderata all'apprendimento delle rappresentazioni, basato sulle osservazioni che l'attuale stato dell'arte AFL ha problemi pratici.
La superficie di perdita è *molto* degenerata, e non ci sono barriere tra le soluzioni a grandi lotti e quelle a piccoli lotti.
Proponiamo CR-NAS per riallocare le risorse di calcolo impegnate in diverse risoluzioni e posizioni spaziali.
Un metodo di formazione che può far funzionare meglio gli algoritmi di apprendimento profondo su chip di calcolo neuromorfo con incertezza
Un'architettura CNN che può respingere efficacemente le incognite negli oggetti di prova
Eseguiamo un'inferenza variazionale ammortizzata su un modello di processo gaussiano latente per ottenere prestazioni di imputazione superiori su serie temporali multivariate con dati mancanti.
Eseguiamo studi sperimentali massicci che caratterizzano le relazioni tra le norme Jacobiane, le regioni lineari e la generalizzazione.
Il rumore dello spazio dei parametri permette agli algoritmi di apprendimento del rinforzo di esplorare perturbando i parametri invece delle azioni, spesso portando a prestazioni di esplorazione significativamente migliorate.
Presentiamo nuove tecniche di distillazione che permettono di addestrare modelli di studenti con diversi vocabolari e di comprimere BERT di 60x con un minore calo di prestazioni.
Apprendimento end-to-end di rappresentazioni invarianti con variabili attraverso gli esempi, ad esempio se qualcuno è andato da qualche parte allora è lì.
Risolviamo problemi inversi mal posti con scarsi esempi di verità a terra stimando un insieme di proiezioni casuali del modello invece del modello stesso.
Una tecnica per accelerare la selezione dell'architettura neurale approssimando i pesi di ogni architettura candidata invece di addestrarli individualmente.
Proponiamo quattro nuovi modi di raccogliere dati NLI. Alcuni aiutano leggermente come dati di preformazione, tutti aiutano a ridurre gli artefatti di annotazione.
Previsione video variazionale stocastica in impostazioni del mondo reale.
Modellazione di complesse interazioni multi-agente in un quadro di apprendimento per imitazione multi-agente con modellazione esplicita di politiche correlate approssimando le politiche degli avversari. 
Un sistema per il rilevamento del plagio in più lingue (inglese-russo)
Abbiamo proposto un'implementazione per accelerare l'addestramento parallelo dei dati DNN riducendo il requisito di larghezza di banda della comunicazione.
Le perturbazioni possono essere utilizzate per imparare i pesi di feedback su grandi reti completamente connesse e convoluzionali.
Suggeriamo il numero sufficiente di bit per rappresentare i pesi delle DNN e i bit ottimali sono conservativi nella risoluzione dei problemi reali.
Raffinare le proposte di segmentazione eseguendo l'inferenza iterativa con autoencoder di denoising condizionale.
Proponiamo un'architettura GAN basata sull'auto-attenzione per la generazione di testo incondizionato e miglioriamo i precedenti risultati basati su codici avversari.
Proponiamo un nuovo codificatore-decodificatore di filigrana a reti neurali. Eseguono un gioco cooperativo per definire il proprio schema di watermarking. Le persone non hanno più bisogno di progettare metodi di watermarking.
Deriviamo uno stimatore di gradiente a bassa varianza e imparziale per le aspettative su variabili casuali discrete basate sul campionamento senza sostituzione
Proponiamo un metodo che permette il folding della CNN per creare connessioni ricorrenti
Il gradient clipping non conferisce robustezza al rumore delle etichette, ma una semplice variante basata sulla perdita lo fa.
mostrano prove sperimentali sulla debole correlazione tra le probabilità dei flussi e la semantica delle immagini.
Applichiamo una strategia di difesa modello-agnostica contro gli esempi avversari e raggiungiamo il 60% di precisione white-box e il 90% di precisione black-box contro i principali algoritmi di attacco.
Proviamo la prima prova di convergenza in assoluto di un algoritmo accelerato asincrono che raggiunge un aumento di velocità.
Incorporiamo i campionatori SG-MCMC in un'approssimazione variazionale
Noi sosteniamo teoricamente che assumendo semplicemente che i pesi di una rete ReLU siano distribuiti in modo gaussiano (senza nemmeno un formalismo bayesiano) potrebbe risolvere questo problema; per un'incertezza più calibrata, un semplice metodo bayesiano potrebbe già essere sufficiente.
Usiamo rappresentazioni addestrate senza dati paralleli per creare allineamenti di parole.
Un nuovo approccio per l'apprendimento con ricompense rumorose nell'apprendimento per rinforzo
Questo articolo si concentra su un meccanismo tradizionalmente trascurato: un'architettura con unità nascoste private e condivise esplicitamente progettate per mitigare l'influenza negativa della perdita ausiliaria non supervisionata sul compito principale supervisionato.
Uno studio teorico dell'apprendimento multi-task con implicazioni pratiche per migliorare l'addestramento multi-task e l'apprendimento di trasferimento
Nuovo metodo per valutare la qualità dei valutatori di similarità e mostrare il potenziale dei modelli linguistici basati su Transformer nel sostituire BLEU e ROUGE.
I metodi di meta-apprendimento utilizzati per la visione, applicati direttamente al PNL, hanno prestazioni peggiori dei vicini più vicini su nuove classi; possiamo fare meglio con le firme distributive.
Un'analisi teorica di una nuova classe di RNN, addestrata su compiti di neuroscienze, ci permette di identificare il ruolo della dimensionalità dinamica e delle classi di cellule nelle computazioni neurali.
Proponiamo il discriminatore di fusione, una nuova architettura per incorporare informazioni condizionali nel discriminatore di GANs per compiti di predizione strutturati.
Definiamo, esploriamo e cominciamo ad affrontare il problema della mancata corrispondenza degli obiettivi nell'apprendimento per rinforzo basato su modelli.
Diamo una spiegazione dettagliata delle traiettorie nel piano dell'informazione e studiamo il suo utilizzo per la progettazione di reti neurali (pruning)
Impiegare misure di entanglement quantistico per quantificare le correlazioni nell'apprendimento profondo, e utilizzare la connessione per adattare l'architettura della rete profonda alle correlazioni nei dati.
Usiamo un apprendimento di rinforzo su grafi molecolari per generare razionali per la previsione di proprietà molecolari interpretabili.
Unifichiamo le reti convoluzionali a grafo come co-training e fattorizzazione a matrice unitizzata.
Un modello autoregressivo basato sul flusso per la generazione di grafici molecolari. Raggiungere risultati allo stato dell'arte nella generazione di molecole e nell'ottimizzazione delle proprietà.
Proponiamo una nuova struttura per l'apprendimento dei precondizionatori, deriviamo nuove forme di precondizionatori e metodi di apprendimento, e riveliamo la relazione con metodi come RMSProp, Adam, Adagrad, ESGD, KFAC, normalizzazione batch, ecc.
Semplici tecniche di aumento del testo possono aumentare significativamente le prestazioni nei compiti di classificazione del testo, specialmente per piccoli insiemi di dati.
Proponiamo un modello che è in grado di eseguire la stima dei parametri fisici dei sistemi dal video, dove le equazioni differenziali che governano la dinamica della scena sono note, ma gli stati o gli oggetti etichettati non sono disponibili.
ASAL è un metodo di apprendimento attivo basato su pool che genera campioni ad alta entropia e recupera i campioni corrispondenti dal pool in tempo sub-lineare.
Evidenziamo importanti problemi con la pratica comune di utilizzare le migliori prestazioni del singolo modello per confrontare le architetture di apprendimento profondo, e proponiamo un metodo che corregge questi difetti.
Studiamo l'effetto della complessità di incorporazione nell'apprendimento di rappresentazioni invarianti al dominio e sviluppiamo una strategia che mitiga la sensibilità ad essa.
Proponiamo una nuova architettura denominata Dual Adversarial Transfer Network (DATNet) per affrontare il Named Entity Recognition (NER) a basse risorse e raggiungere nuove prestazioni allo stato dell'arte su CoNLL e Twitter NER.
Le GAN di Coulomb possono apprendere in modo ottimale una distribuzione ponendo il problema di apprendimento della distribuzione come ottimizzazione di un campo potenziale
Proponiamo una rete Graph Convolutional Network basata sulla fiducia per l'apprendimento semi-supervisionato.
Proponiamo ImageNet-C per misurare la robustezza della corruzione del classificatore e ImageNet-P per misurare la robustezza della perturbazione
Offuscare il codice usando le reti seq2seq, ed eseguire usando il codice offuscato e la coppia di chiavi
Metodo basato su GAN per la sintesi congiunta di immagini e annotazioni per-pixel
Introduciamo un nuovo compito e un nuovo set di dati sulla navigazione multilingue in lingua della visione, e proponiamo un quadro generale VLN multilingue per il compito.
Classificazione non supervisionata tramite modellazione generativa profonda con apprendimento di caratteristiche controllabili valutato in un difficile compito del mondo reale
Modelli di rappresentazione dell'apprendimento su grafi dinamici come processo latente nascosto che collega due processi osservati di Evoluzione topologica di e Interazioni su grafi dinamici.
Introduciamo una classe di giochi a n giocatori adatti ai metodi basati sul gradiente.
Studiamo la classe dei linguaggi formali accettabili dai controautomi in tempo reale, un modello di calcolo legato ad alcuni tipi di reti neurali ricorrenti.
Un modello di riassunto che combina un nuovo metodo di apprendimento intra-attenzione e rinforzo per aumentare i punteggi ROUGE e la qualità del riassunto per lunghe sequenze.
Studiamo se e come l'aumento adattivo dei dati e la distillazione della conoscenza possono essere sfruttati simultaneamente in modo sinergico per una migliore formazione delle reti di studenti.
Introduciamo una semplice procedura per riproporre modelli linguistici pre-addestrati basati su trasformatori per eseguire bene la sintesi astrattiva.
Presentiamo un'architettura basata sulla memoria neurale per l'adattamento incrementale del dominio e forniamo risultati teorici ed empirici.
Formulando il recupero del segnale sparso come un problema di decisione sequenziale, sviluppiamo un metodo basato su RL e MCTS che impara una politica per scoprire il supporto del segnale sparso. 
Imparare l'embedding per il controllo con osservazioni ad alta densità
Risultati iniziali nell'intersezione delle neuroscienze di rete e dell'apprendimento profondo. C. Elegans e una corteccia visiva di topo imparano a riconoscere le cifre scritte a mano.
Un metodo di apprendimento della struttura non supervisionato per reti Feed-forward profonde parsimoniose.
Utilizzo di GAN come priori per un'inferenza bayesiana efficiente di campi complessi.
Omniglot e miniImageNet sono troppo semplici per l'apprendimento a pochi colpi perché possiamo risolverli senza usare etichette durante la metavalutazione, come dimostrato con un metodo chiamato reti centroidi
Identificare gli stati di decisione (dove l'agente può intraprendere azioni che contano) senza supervisione della ricompensa, usarlo per il trasferimento.
Un approccio per combinare inferenza variazionale e ottimizzazione bayesiana per risolvere problemi inversi complicati
Mostriamo che sotto alcune ipotesi sulla dinamica del veicolo e l'incertezza dell'ambiente è possibile sintetizzare automaticamente primitive di movimento che non accumulano errori nel tempo.
Le reti convoluzionali profonde esistenti nei compiti di classificazione delle immagini sono sensibili ai modelli di rumore Gabor, cioè piccoli cambiamenti strutturati all'input causano grandi cambiamenti all'output.
L'analisi della robustezza e della ridondanza nelle reti neurali profonde rivela le caratteristiche di limitazione della capacità che aiutano a spiegare il non-overfitting.
Un algoritmo scalabile per stabilire derivate robuste di reti profonde rispetto agli ingressi.
In questo articolo, esploriamo una struttura di rete interna densa ma esterna sparsa di reti neurali profonde e analizziamo le sue proprietà chiave.
In questo lavoro, miriamo a migliorare MCMC e VI con un nuovo metodo ibrido basato sull'idea di ridurre i bias di simulazione delle catene MCMC di lunghezza finita usando l'ottimizzazione basata sul gradiente.
Le informazioni sul fatto che l'output di una rete neurale sarà corretto o errato sono in qualche modo presenti negli output degli strati intermedi della rete.
Algoritmo di auto-imitazione non supervisionato capace di inferenza da una singola dimostrazione di un esperto.
Sviluppiamo una struttura per generare spiegazioni umanamente comprensibili del perché l'infeasibilità si verifica in istanze sovraccariche di una classe di problemi di programmazione con risorse limitate.
Mostriamo che i gradienti non sono in grado di catturare gli spostamenti di salienza dovuti a perturbazioni avversarie e presentiamo una difesa avversaria alternativa utilizzando modelli di salienza appresi che è efficace sia contro gli attacchi black-box che white-box.
Inadeguatezza delle metriche di disentanglement
Proponiamo il Mind-aware Multi-agent Management Reinforcement Learning (M^3RL) per addestrare un manager a motivare i lavoratori auto-interessati a raggiungere una collaborazione ottimale, assegnando loro contratti adeguati.
Un metodo per gli stati latenti persistenti in ResBlocks dimostrato per la super-risoluzione di sequenze di immagini alised.
Proponiamo Diversely Stale Parameters per rompere i blocchi dell'algoritmo di backpropoagation e formare una CNN in parallelo.
Un compito ausiliario di predizione può accelerare l'apprendimento nei setup di emergenza linguistica.
Modulo TEB per IPC
Algoritmo di apprendimento metrico completamente parallelizzabile e resistente al rumore avversario con garanzie teoriche.
Sviluppiamo modelli di didascalie di immagini coinvolgenti condizionati dalla personalità che sono anche allo stato dell'arte su compiti di didascalie regolari.
Proponiamo una discesa del gradiente stocastico con smoothing laplaciano differenzialmente privato per addestrare modelli di apprendimento automatico con una migliore utilità e mantenere garanzie di privacy differenziale.
Forniamo un'analisi statistica e computazionale del problema del rilevamento compresso a un bit con un priore generativo. 
Un approccio di principio per l'apprendimento della struttura delle reti neurali profonde con una nuova interpretazione della profondità e della connettività interstrato. 
Studiamo come e perché la forte regolarizzazione L1/L2 fallisce e proponiamo un metodo che può raggiungere una forte regolarizzazione.
Questo lavoro mira a fornire risposte quantitative all'importanza relativa dei concetti di interesse attraverso i vettori di attivazione dei concetti (CAV). In particolare, questa struttura permette agli esperti di apprendimento non-macchina di esprimere concetti di interesse e di testare le ipotesi utilizzando esempi (ad esempio, un insieme di immagini che illustrano il concetto). Mostriamo che CAV può essere appreso con un insieme relativamente piccolo di esempi. Il test di ipotesi con CAV può rispondere se un particolare concetto (ad esempio, il genere) è più importante nel predire una data classe (ad esempio, il medico) rispetto ad altri insiemi di concetti. L'interpretazione delle reti con CAV non richiede alcun retraining o modifica della rete. 
Il Conditional Entropy Bottleneck è una funzione obiettivo della teoria dell'informazione per l'apprendimento di rappresentazioni ottimali.
Proponiamo un approccio per imparare rappresentazioni sparse ad alta dimensione che sono veloci da cercare, incorporando un surrogato del numero di operazioni direttamente nella funzione di perdita.
Combinazione di formazione ausiliaria e avversaria per interrogare e aiutare la comprensione fisica.
Modelli basati sul flusso, ma non invertibili, per imparare anche le variabili discrete
Dimostriamo costruttivamente che anche le minime funzioni di attivazione non lineari introducono minimi locali spuri, per set di dati e funzioni di attivazione generali.
Pianificazione compositiva basata sugli attributi che si generalizza a compiti di prova lunghi, nonostante sia stata addestrata su compiti brevi e semplici.
Identifichiamo e formalizziamo il problema della memorizzazione nel meta-apprendimento e risolviamo questo problema con un nuovo metodo di meta-regolarizzazione, che amplia notevolmente il dominio a cui il meta-apprendimento può essere applicabile ed efficace.
Proponiamo una nuova struttura per il meta-apprendimento di una regola di aggiornamento basata sul gradiente che va oltre l'apprendimento di pochi colpi ed è applicabile a qualsiasi forma di apprendimento, compreso l'apprendimento continuo.
Defense-GAN utilizza una Generative Adversarial Network per difendersi dagli attacchi white-box e black-box nei modelli di classificazione.
Sviluppiamo metodi efficienti per addestrare modelli di embedding neurale con una struttura dot-product, riformulando la funzione obiettivo in termini di matrici di Gram generalizzate e mantenendo le stime di queste matrici.
Presentiamo un benchmark multi-task e una piattaforma di analisi per valutare la generalizzazione nei sistemi di comprensione del linguaggio naturale.
Un metodo modulare per l'apprendimento di rinforzo multi-agente completamente cooperativo, basato sull'apprendimento del curriculum per l'esplorazione efficiente e l'assegnazione di crediti per le interazioni azione-obiettivo.
Affrontiamo l'inefficienza del campione e la distorsione della ricompensa negli algoritmi di apprendimento dell'imitazione avversaria come GAIL e AIRL.
Una variante delle reti di capsule che può essere usata per compiti di apprendimento a coppie. I risultati mostrano che le reti a capsula siamesi funzionano bene nell'impostazione di apprendimento a pochi colpi.
Questo articolo introduce la neuromodulazione nelle reti neurali artificiali.
Proponiamo un metodo di convoluzione dinamica per accelerare significativamente il tempo di inferenza delle CNN mantenendo la precisione.
In questo articolo introduciamo un metodo di formazione, chiamato look-up table quantization (LUT-Q), che impara un dizionario e assegna ogni peso a uno dei valori del dizionario
Guardiamo al trasferimento negativo da un punto di vista di adattamento al dominio per derivare un algoritmo di apprendimento avversario.
Addestriamo le macchine Quantum Boltzmann usando un metodo di impilamento delle repliche e un annealer quantistico per eseguire un compito di apprendimento di rinforzo.
Abbiamo proposto un Nesterov Iterative Fast Gradient Sign Method (NI-FGSM) e un Scale-Invariant attack Method (SIM) che può aumentare la trasferibilità degli esempi avversari per la classificazione delle immagini.
Introduciamo un metodo di addestramento stocastico per l'addestramento di reti neurali binarie con pesi e attivazioni binarie.
Analizziamo l'impatto dello spazio latente dei generatori completamente addestrati tramite pseudo inversione.
Proponiamo un processo di costruzione del modello end-to-end che è universalmente applicabile a un'ampia varietà di corpora di verifica della paternità e supera lo stato dell'arte con poche o nessuna modifica o messa a punto.
Consideriamo di affrontare un problema di RL a singolo agente distribuendolo a $n$ apprendisti.
Un modello ibrido che utilizza sia l'audio grezzo che le informazioni dello spettrogramma per compiti di miglioramento del discorso.
Questo articolo confronta i test statistici per i confronti RL (falsi positivi, potenza statistica), controlla la robustezza delle ipotesi usando distribuzioni simulate e distribuzioni empiriche (SAC, TD3), fornisce linee guida per studenti e ricercatori RL.
Diamo un'analisi teorica dell'obiettivo Information Bottleneck per comprendere e prevedere le transizioni di fase osservate nel tradeoff tra previsione e compressione.
Proporre funzioni di attivazione localmente adattive in reti neurali profonde e informate sulla fisica per una convergenza più veloce
Analisi dell'inferenza bayesiana degli iperparametri nella regressione del processo gaussiano 
Alleniamo modelli variazionali con reti quantizzate per il determinismo computazionale. Questo permette di usarli per la compressione dati multipiattaforma.
Una simulazione neurale della macchina di Turing universale
Decadere il tasso di apprendimento e aumentare la dimensione del batch durante l'allenamento sono equivalenti.
Introduciamo la DCN+ con coattenzione profonda dei residui e RL a obiettivi misti, che raggiunge prestazioni allo stato dell'arte sul set di dati Stanford Question Answering.
Un benchmark NAS applicabile a quasi tutti gli algoritmi NAS.
Proponiamo una penalità a gradiente centrato sullo zero per migliorare la generalizzazione e la stabilità delle GAN
Una visione sobria sullo stato attuale delle GAN da una prospettiva pratica
Proponiamo un approccio model-agnostic per spiegare il comportamento di agenti RL profondi black-box, addestrati a giocare a giochi Atari e da tavolo, evidenziando le caratteristiche rilevanti di uno stato di input.
Indaghiamo la rappresentazione profonda delle architetture CNN-DCN non addestrate, a peso casuale, e mostriamo la loro qualità di ricostruzione delle immagini e le possibili applicazioni.
Questo articolo introduce un nuovo approccio di rappresentazione dinamica delle caratteristiche per fornire un modo più efficiente per fare inferenza sulle reti neurali profonde.
Se inizializzate correttamente, le reti neurali possono imparare la semplice classe di funzioni simmetriche; se inizializzate in modo casuale, falliscono.  
Proponiamo un metodo per un'efficiente ricerca multiobiettivo dell'architettura neurale basata sull'eredità lamarckiana e sugli algoritmi evolutivi.
Modello neurale unificato di topic e language modeling per introdurre la struttura della lingua nei modelli topic per vettori topic contestualizzati 
Proponiamo un nuovo modo di comprimere le reti neurali usando strutture dati probabilistiche.
Studiamo l'impatto dell'uso di diversi tipi di unità di sottoparola sulla qualità delle rappresentazioni risultanti quando sono usate per modellare la sintassi, la semantica e la morfologia.
Uno studio empirico che fornisce una nuova prospettiva sull'apprendimento a pochi colpi, in cui un metodo di fine-tuning mostra un'accuratezza paragonabile ai metodi più complessi dello stato dell'arte in diversi compiti di classificazione.
Proponiamo un approccio per generare dati di mercato azionario realistici e ad alta fedeltà basati su reti generative avversarie.
Presentiamo un approccio di stima del gradiente basato sul segno, piuttosto che sulla magnitudine, che sposta la stima del gradiente dall'ottimizzazione black-box continua a quella binaria.
Analizziamo la propagazione del gradiente nelle RNN profonde e dalla nostra analisi, proponiamo una nuova RNN profonda multistrato.
Analizziamo matematicamente l'effetto della normalizzazione dei lotti su un modello semplice e otteniamo nuove intuizioni chiave che si applicano all'apprendimento supervisionato generale.
Per i vincoli complessi in cui non è facile stimare il gradiente, usiamo la pena scontata come segnale guida. Dimostriamo che sotto certe ipotesi converge ad una soluzione fattibile.
L'articolo studia l'acquisizione del bersaglio per i pannelli virtuali palmari in VR e mostra che la larghezza del bersaglio, la distanza, la direzione dell'approccio rispetto alla gravità e l'angolo di approccio, tutti hanno un impatto sulle prestazioni dell'utente.
iSparse elimina i bordi della rete irrilevanti o insignificanti con un impatto minimo sulle prestazioni della rete, determinando l'importanza dei bordi rispetto all'output finale della rete. 
Impariamo rappresentazioni di entità che possono ricostruire le categorie di Wikipedia con pochi esempi.
Usando il logaritmo q-deformato, deriviamo limiti più stretti di IWAE, per addestrare autoencoders variazionali.
Il dilemma di Bregman è dimostrato nell'apprendimento profondo che il miglioramento dei margini dei modelli iper-parametrizzati può risultare in un overfitting, e le dinamiche delle distribuzioni di margine normalizzate sono proposte per prevedere l'errore di generalizzazione e identificare tale dilemma. 
Abbiamo proposto un sistema di dialogo end-to-end con un nuovo tracciatore di stato di dialogo multilivello e abbiamo ottenuto prestazioni coerenti su MultiWOZ2.1 nel tracciamento dello stato, nel completamento dei compiti e nella generazione di risposte.
Presentiamo un'approssimazione scalabile per una vasta gamma di obiettivi EBM, e applicazioni in VAEs implicite e WAEs
Questo articolo sviluppa un metodo di principio per l'apprendimento continuo nei modelli profondi.
Un algoritmo RL profondo per risolvere POMDPs autocodificando gli stati sottostanti utilizzando un modello ricorrente variazionale
Questo articolo formalizza il problema della selezione degli algoritmi online nel contesto del Reinforcement Learning.
Proponiamo un nuovo modello di variabile latente per imparare embeddings latenti per alcuni dati ad alta densità. 
Proponiamo strategie per la difesa avversaria basate sulla funzione di attivazione dipendente dai dati, la minimizzazione della variazione totale e l'aumento dei dati di formazione
Questo lavoro presenta una soluzione scalabile per il riconoscimento visivo continuo del discorso.
Proponiamo un modello di autoencoder variazionale per la modellazione del testo senza indebolire il decoder, che migliora la qualità della generazione del testo e l'interpretabilità delle rappresentazioni acquisite.
Dimostriamo che i modelli grandi, ma potati (large-sparse) superano le loro controparti più piccole, ma dense (small-dense) con un'impronta di memoria identica.
Controlliamo l'argomento e il sentimento della generazione del testo (quasi) senza alcun addestramento. 
Rilassare il vincolo delle gerarchie condivise permette un apprendimento multitask profondo più efficace.
Proponiamo una struttura per imparare reti calibrate sulla fiducia progettando una nuova funzione di perdita che incorpora l'incertezza predittiva stimata attraverso inferenze stocastiche.
Apprendimento della dinamica delle particelle con grafici di interazione dinamica per la simulazione e il controllo di corpi rigidi, oggetti deformabili e fluidi. 
Introduciamo una teoria per spiegare il fallimento delle GAN su dataset complessi e proponiamo una soluzione per risolverlo.
L'aumento dei dati e l'addestramento avversario sono molto efficaci per distinguere il parlante correlato e il rumore, permettendo un controllo indipendente di ogni attributo per la sintesi text-to-speech.
Gli LSTM imparano le dipendenze a lungo raggio in modo composito costruendole da costituenti più brevi nel corso dell'addestramento.
Addestriamo le reti neurali linearizzandole localmente e utilizzando un solutore SVM lineare (Frank-Wolfe) ad ogni iterazione.
Presentiamo una versione migliorata del metodo DRL basato su Universal Successor Features che può migliorare l'apprendimento di trasferimento degli agenti.
Un metodo per l'apprendimento di rappresentazioni di immagini che sono buone sia per dissociare i fattori di variazione che per ottenere ricostruzioni fedeli.
Usiamo il rango non negativo delle matrici di attivazione ReLU come misura di complessità e dimostriamo che è correlato (negativamente) a una buona generalizzazione.
L'obiettivo di questo articolo è quello di ottenere l'effetto delle reti di insegnanti multipli sfruttando i blocchi stocastici e le connessioni saltate.
Abbiamo costruito una tastiera Android con capacità di suggerimento emoji sia lessicale (basato sulle parole) che semantico (basato sul significato) e abbiamo confrontato i loro effetti in due diversi studi di chat. 
Proponiamo un paradigma di apprendimento auto-avversario (SAL) che migliora il generatore in modo auto-giocante per migliorare le prestazioni delle GAN nella generazione del testo.
In questo studio, introduciamo un nuovo metodo che si basa su SVD per scoprire il numero di dimensioni latenti.
Un nuovo approccio di rilevazione avversaria, che utilizza metodi di spiegabilità per identificare le immagini le cui spiegazioni non sono coerenti con la classe prevista.  
Un metodo di compressione del modello addestrabile end-to-end che ottimizza la precisione insieme alla dimensione prevista del modello.
Suggeriamo una tecnica di selezione intelligente dei lotti chiamata Ada-Boundary.
Presentiamo architetture di reti neurali basate sull'ontologia per la classificazione degli eventi sonori.
Il nostro lavoro mostra che le informazioni posizionali sono state implicitamente codificate in una rete. Queste informazioni sono importanti per rilevare le caratteristiche dipendenti dalla posizione, ad esempio la semantica e la salienza.
Rete neurale generale-dettagliata (GDNN) con apprendimento multi-task incorporando lo schizzo cross-domain (CDS) per il parsing semantico
Mostriamo che la capacità di apprendimento di diverse architetture neurali può essere caratterizzata direttamente da misure calcolabili di complessità dei dati.
Affrontare la progettazione inversa tramite algoritmi genetici aumentati con reti neurali profonde. 
Studiamo le attivazioni degli stati nascosti dei modelli di trasformazione nei compiti di risposta alle domande.
combinare l'apprendimento per rinforzo e l'apprendimento per imitazione per risolvere complessi compiti di manipolazione dei robot dai pixel
Abbiamo introdotto BatchEnsemble, un metodo efficiente per l'ensembling e l'apprendimento permanente che può essere usato per migliorare la precisione e l'incertezza di qualsiasi rete neurale come i tipici metodi di ensemble.
Stima della ricompensa dai video di gioco
Proponiamo la misurazione dell'importanza della frase e algoritmi per la spiegazione gerarchica delle previsioni del modello di sequenza neurale
Un parametro di quantità di moto più alto $\beta$ aiuta a sfuggire più velocemente ai punti di sella
Descriviamo come migliorare un modello generativo d'immagine secondo un obiettivo lento o difficile da valutare, come il feedback umano, che potrebbe avere molte applicazioni, come fare immagini più estetiche.
Il nostro algoritmo proposto non usa tutti i dati non etichettati per l'addestramento, ma li usa selettivamente.
Un nuovo approccio alla generazione condizionale vincolando lo spazio latente di un modello generativo incondizionato.
Quantifichiamo il costo energetico in termini di denaro (crediti cloud) e l'impronta di carbonio della formazione di modelli di reti neurali di recente successo per il NLP. I costi sono alti.
Il Pruning VAE è proposto per cercare le variabili disentangled con dimensione intrinseca.
I modelli linguistici ricorrenti a livello di byte imparano rappresentazioni di testo di alta qualità specifiche del dominio.
Analisi empirica e spiegazione degli stimatori di gradiente basati su particelle per l'inferenza approssimativa con modelli generativi profondi.
Apprendimento profondo multietichetta scalabile e accurato con milioni di etichette.
Si dimostra che le GAN ci forniscono una nuova stima robusta ed efficace della media contro le contaminazioni agnostiche con un'ottimalità statistica e una trattabilità pratica.
Presentiamo modelli State Space LSTM, una combinazione di modelli State Space e LSTM, e proponiamo un algoritmo di inferenza basato su Monte Carlo sequenziale. 
Estendiamo l'algoritmo wake-sleep e lo usiamo per imparare modelli strutturati da pochi esempi, 
Proteine, sequenze di amminoacidi, apprendimento automatico, apprendimento profondo, rete neurale ricorrente (RNN), memoria a breve termine lunga (LSTM), unità ricorrente gated (GRU), reti neurali profonde
Rilevamento del termine parlato, utilizzando la predizione strutturata e le reti profonde, implementando una nuova funzione di perdita che massimizza l'AUC e classifica secondo una soglia predefinita.
Proponiamo un nuovo obiettivo di ottimizzazione che incoraggia l'equità nelle reti federate eterogenee, e sviluppiamo un metodo scalabile per risolverlo.
Proponiamo un nuovo modello di autocodifica con perdita di ricostruzione adversariale aumentata. Induciamo una nuova metrica per la valutazione basata sul contenuto delle ricostruzioni. 
un robusto algoritmo di apprendimento profondo bayesiano per dedurre posteriorità complesse con variabili latenti
Abbiamo esteso la decomposizione tensoriale spazio-temporale a prova singola basata sulla fattorizzazione della matrice non negativa per scontare in modo efficiente l'attività della linea di base pre-stimolo che migliora le prestazioni di decodifica sui dati con linee di base non trascurabili.
Metodo di compressione dell'immagine estrema basato su GAN che utilizza meno della metà dei bit del codec ingegnerizzato SOTA mantenendo la qualità visiva
Imparare a classificare usando l'architettura Transformer.
L'articolo descrive un algoritmo di apprendimento strategico intrinsecamente motivato che affronta l'apprendimento di politiche motorie complesse.
Usiamo MCTS per ottimizzare ulteriormente una politica di bootstrapping per spazi d'azione continui sotto un'impostazione di iterazione della politica.
perché i precedenti VAE sul testo non possono imparare una rappresentazione latente controllabile come sulle immagini, così come una correzione per permettere il primo successo verso la generazione controllata di testo senza supervisione
Un nuovo modello corticale gerarchico per la codifica della memoria spazio-temporale e la predizione video
Proponendo una nuova metodologia basata sul controfattuale per valutare le ipotesi generate dalle mappe di salienza sul comportamento dell'agente di RL profondo. 
La maggior parte delle reti neurali approssima la stessa funzione di classificazione, anche tra le architetture, attraverso tutte le fasi di apprendimento.
Rappresentate ogni entità in base al suo istogramma di contesti e poi Wasserstein è tutto ciò di cui avete bisogno!
Metodologie per sistemi di raccomandazione con informazioni laterali basate sulla regolarizzazione delle tracce-norm
Questo lavoro presenta un agente basato sull'esplorazione e l'apprendimento per imitazione capace di prestazioni all'avanguardia nel giocare a giochi per computer basati sul testo. 
Nella potatura delle reti neurali, l'azzeramento dei pesi potati è importante, il segno dell'inizializzazione è fondamentale, e il mascheramento può essere pensato come un allenamento.
Abbiamo proposto SesameBERT, un metodo generalizzato di fine-tuning che permette l'estrazione di informazioni globali tra tutti gli strati attraverso Squeeze ed Excitation e arricchisce le informazioni locali catturando i contesti vicini attraverso la sfocatura gaussiana.
La formazione dell'avversario è un potente approccio all'apprendimento multi-agente, ma può impedire la convergenza; il nostro algoritmo SOS risolve questo problema con forti garanzie in tutti i giochi differenziabili.
Mostriamo che la corrispondenza domanda-risposta è un compito di pre-addestramento particolarmente buono per la somiglianza delle domande e rilasciamo un set di dati per la somiglianza delle domande mediche
Uno studio sul beneficio della condivisione della rappresentazione nell'apprendimento di rinforzo multi-task.
Architetture profonde per nuvole di punti 3D che sono equivarianti alle rotazioni SO(3), così come alle traslazioni e alle permutazioni. 
Un confronto e un'analisi dettagliata di vari modelli di sentence embedding attraverso il compito del mondo reale del riassunto automatico.
Proponiamo Value Propagation, un nuovo pianificatore end-to-end che può imparare a risolvere compiti di navigazione 2D tramite l'apprendimento di rinforzo, e che si generalizza ad ambienti più grandi e dinamici.
Proposto un metodo per estrarre e sfruttare le interpretazioni delle interazioni delle caratteristiche
Mostriamo che è possibile recuperare i parametri di un modello generativo ReLU a 1 strato guardando i campioni generati da esso
Imparare rappresentazioni vettoriali dense di tipi arbitrari di caratteristiche in set di dati etichettati e non etichettati
Gli automi finiti possono essere decodificati linearmente da Language-Recognizing RNNs usando funzioni di astrazione a bassa grossolanità e decodificatori ad alta precisione. 
Proponiamo HURRICANE per affrontare la sfida della diversità dell'hardware nella ricerca dell'architettura neurale one-shot
Traduzione automatica basata sulla frase neurale con tempo di decodifica lineare
Proponiamo una GAN basata su AE che allevia il collasso delle modalità nelle GAN.
Apprendimento di rinforzo e campionamento adattivo per la compilazione ottimizzata di reti neurali profonde.
Progettiamo una grammatica che viene appresa in un ambiente contraddittorio e la applichiamo alla previsione del futuro nei video.
Proponiamo Janossy pooling, un metodo per l'apprendimento di funzioni invarianti di permutazione profonde progettato per sfruttare le relazioni all'interno della sequenza di input e strategie di inferenza trattabili come una procedura di ottimizzazione stocastica che chiamiamo piSGD
Un nuovo modello di meta-apprendimento che bilancia in modo adattivo l'effetto del meta-apprendimento e dell'apprendimento specifico del compito, e anche l'apprendimento specifico della classe all'interno di ogni compito.
Rivisitiamo l'idea dell'architettura master-slave nell'apprendimento di rinforzo profondo multi-agente e superiamo lo stato dell'arte.
Studiamo la distorsione implicita dei metodi a gradiente nella risoluzione di un problema di classificazione binaria con modelli ReLU non lineari.
Un metodo di potatura del modello CNN utilizzando ISTA e il trucco di rescaling per imporre la sparsità dei parametri di scala nella normalizzazione del batch.
Cosa possiamo imparare sull'addestramento delle reti neurali se trattiamo ogni strato come un problema di gradient boosting?
L'anticipazione migliora la convergenza dell'apprendimento di rinforzo profondo.
Troviamo che il movimento nello spazio delle funzioni non è proporzionale al movimento nello spazio dei parametri durante l'ottimizzazione. Proponiamo un nuovo ottimizzatore in stile natural-gradient per risolvere questo problema.
Introduciamo una famiglia generale di Lagrangiani che permettono di esplorare la curva IB in tutti gli scenari. Quando queste vengono utilizzate, e la curva IB è nota, si può ottimizzare direttamente per un livello di prestazione/compressione.
Proponiamo la Neural Logic Machine (NLM), un'architettura neurale-simbolica per l'apprendimento induttivo e il ragionamento logico.
Proponiamo un modello di riassunto astrattivo neurale semantico e un nuovo schema di valutazione del riassunto automatico che misura quanto bene un modello identifica le informazioni fuori tema da campioni avversari.
Stampa la frase di input e la frase di risposta corrente su un'immagine e usa il modello ImageNet CNN per prevedere la prossima parola di risposta.
Noi abilitiamo le CNN ordinarie per l'apprendimento di pochi colpi sfruttando i concetti visivi che sono spunti visivi interpretabili appresi all'interno delle CNN.
Applicare un modello di equazione differenziale ordinaria su dati strutturati da grafici
Proposta di un nuovo compito, set di dati e linee di base; 3D Conv CycleGAN conserva le proprietà dell'oggetto attraverso i fotogrammi; la struttura del batch nei metodi a livello di fotogramma conta.
Un nuovo modello scalabile, gruppo-equivariante per le reti di capsule che conserva la composizionalità sotto le trasformazioni, ed è empiricamente più resistente alle trasformazioni dei vecchi modelli di reti di capsule.
L'articolo ha proposto una linea di base semplice ma efficace per l'apprendimento con etichette rumorose.
I valutatori preferiscono l'adeguatezza della traduzione umana rispetto a quella automatica quando valutano interi documenti, ma non quando valutano singole frasi.
Questo articolo estende l'apprendimento generativo multi-agente di imitazione avversaria ai giochi di Markov a forma estesa.
Rivisitiamo l'auto-addestramento come un metodo di apprendimento semi-supervisionato per il problema della generazione di sequenze neurali, e mostriamo che l'auto-addestramento può avere abbastanza successo con il rumore iniettato.
Un modello di memoria generativa che combina reti neurali ad apprendimento lento e un modello gaussiano lineare ad adattamento rapido come memoria.
Presentiamo un nuovo approccio, SNIP, che è semplice, versatile e interpretabile; pota le connessioni irrilevanti per un dato compito a colpo singolo prima dell'allenamento ed è applicabile a una varietà di modelli di reti neurali senza modifiche.
Una tecnica per etichettare automaticamente grandi insiemi di dati non etichettati in modo da poter addestrare modelli di origine per l'apprendimento di trasferimento e la sua valutazione sperimentale. 
Il nostro articolo propone un modulo di attenzione che cattura le relazioni inter-canale e offre grandi guadagni di prestazioni.
L'applicabilità dell'apprendimento di rinforzo inverso è spesso ostacolata dalla spesa per la raccolta di dimostrazioni di esperti; questo articolo cerca di ampliare la sua applicabilità incorporando informazioni precedenti sul compito attraverso il meta-apprendimento.
Una nuova architettura neurale in cui gli strati superiori densi delle architetture convoluzionali standard sono sostituiti da un'approssimazione di una funzione kernel basandosi sull'approssimazione di Nyström.
Ci sono immagini non consensuali e pornografiche nel dataset ImageNet
Questo articolo ha proposto una nuova struttura per l'apprendimento della somiglianza dei grafi in uno scenario induttivo e non supervisionato.
Mostriamo come i modelli di codifica neurale possono essere addestrati per catturare sia il segnale che la variabilità spike dei dati delle popolazioni neurali usando le GAN.
Un quadro di clustering basato sull'apprendimento debolmente supervisionato ha prestazioni paragonabili a quelle dei modelli di apprendimento completamente supervisionati sfruttando il conteggio unico delle classi.
Deep Model-Based RL che funziona bene.
Analizziamo e determiniamo i requisiti di precisione per l'addestramento delle reti neurali quando tutti i tensori, compresi i segnali back-propagated e gli accumulatori di peso, sono quantizzati in formato a virgola fissa.
Possiamo identificare esempi prototipici e outlier nell'apprendimento automatico che sono quantificabilmente molto diversi, e farne uso per migliorare molti aspetti delle reti neurali.
Proponiamo di migliorare la Deep Scattering Network al fine di migliorare il controllo e la stabilità di qualsiasi pipeline di apprendimento automatico proponendo uno schema di soglia wavelet continua
Clustering neurale senza bisogno di un numero di cluster
Il modello di riconciliazione è un quadro consolidato per le spiegazioni dei piani, ma può essere facilmente dirottato per produrre bugie.
Consideriamo nuove varianti di algoritmi di ottimizzazione per l'addestramento di reti profonde.
Acceleriamo l'inferenza RNN riducendo dinamicamente l'accesso ridondante alla memoria usando una miscela di moduli accurati e approssimativi.
Iniziamo una spinta verso la costruzione di sistemi ER per riconoscere migliaia di tipi, fornendo un metodo per costruire automaticamente set di dati adatti basati sulla gerarchia dei tipi. 
Questo articolo propone una teoria per classificare le invocazioni di metodi in base a diversi livelli di astrazione e condurre un approccio statistico per il completamento del codice dal nome del metodo all'invocazione del metodo.
Ci concentriamo sulla creazione di avversari universali per ingannare i rilevatori di oggetti e nascondere gli oggetti ai rilevatori. 
Autoencoder di Wasserstein con spazio latente iperbolico
Metodo di compressione della mappa delle caratteristiche che converte le attivazioni quantizzate in vettori binari seguiti da strati di riduzione della dimensionalità non lineare incorporati in una DNN
Raggiungere una forte robustezza adversariale paragonabile all'addestramento adversariale senza addestramento su esempi adversariali
Impariamo un algoritmo di apprendimento non supervisionato che produce rappresentazioni utili da un insieme di compiti supervisionati. Al momento del test, applichiamo questo algoritmo a nuovi compiti senza alcuna supervisione e mostriamo prestazioni paragonabili a un VAE.
La sovra-parametrizzazione in larghezza sembra aiutare nell'apprendimento di rinforzo profondo, proprio come nell'apprendimento supervisionato.
Modello generativo gerarchico (ibrido di VAE e GAN) che impara una rappresentazione distinta dei dati senza compromettere la qualità generativa.
Introduciamo un'architettura leggera per il riconoscimento delle entità nominate e realizziamo un apprendimento attivo incrementale, che è in grado di eguagliare le prestazioni allo stato dell'arte con solo il 25% dei dati di formazione originali.
Addestriamo reti accurate completamente quantizzate usando una funzione di perdita che massimizza l'accuratezza del modello a precisione completa e minimizza la differenza tra la precisione completa e le reti quantizzate.
In questo articolo abbiamo introdotto un algoritmo per imparare la connettività delle reti profonde multiramo. L'approccio viene valutato sulla categorizzazione delle immagini, dove produce costantemente guadagni di precisione rispetto ai modelli allo stato dell'arte che utilizzano una connettività fissa.
Mostriamo che le singole unità nelle rappresentazioni CNN apprese in compiti NLP sono selettivamente reattive ai concetti del linguaggio naturale.
Proponiamo un nuovo quadro HRL, in cui formuliamo il problema dell'astrazione temporale come apprendimento di una rappresentazione latente della sequenza di azioni.
Introduciamo le RNN MIST, che a) mostrano proprietà superiori a gradiente di fuga rispetto alle LSTM; b) migliorano sostanzialmente le prestazioni rispetto alle LSTM e alle RNN Clockwork in compiti che richiedono dipendenze a lungo termine; e c) sono molto più efficienti delle RNN NARX proposte in precedenza, con un numero di parametri e operazioni ancora inferiore alle LSTM.
(Versione pronta per la telecamera) Un modulo di intreccio di caratteristiche per sfruttare le caratteristiche di un insieme accurato per aiutare l'apprendimento di un altro insieme meno affidabile.
Una struttura di apprendimento continuo che impara ad adattare automaticamente la sua architettura basata su un algoritmo di inferenza variazionale proposto. 
Proponiamo Noisy-DR-L0-SSC (Noisy Dimension Reduction L0-Sparse Subspace Clustering) per partizionare in modo efficiente i dati rumorosi secondo la loro struttura di sottospazio sottostante.
Un nuovo approccio che utilizza la connettività del modo nei paesaggi di perdita per mitigare gli effetti avversari, riparare i modelli manomessi e valutare la robustezza avversaria
Una struttura GAN multi-generatore con una rete aggiuntiva per imparare una priorità sul rumore in ingresso.
Le BigGAN non catturano le distribuzioni di dati ImageNet e hanno solo un successo modesto per l'aumento dei dati.
Presentiamo Leaf, un framework di benchmarking modulare per l'apprendimento in dati federati, con applicazioni a paradigmi di apprendimento come l'apprendimento federato, il meta-apprendimento e l'apprendimento multi-task.
Introduciamo una nuova perdita di incorporazione spazio-temporale sui video che genera una segmentazione di istanze video temporalmente coerente, anche con occlusioni e rilevamenti mancati, utilizzando l'aspetto, la geometria e il contesto temporale.
Questo articolo propone un metodo avanzato di ottimizzazione della politica con esperienza a posteriori per l'apprendimento di rinforzo a ricompensa sparsa.
Esploriamo come l'uso della conoscenza di base con la riformulazione della query può aiutare a recuperare migliori prove di supporto quando si risponde a domande scientifiche a scelta multipla.
Comprimiamo le CNN profonde riutilizzando un singolo strato di convoluzione in modo iterativo, riducendo così il loro numero di parametri di un fattore proporzionale alla loro profondità, pur lasciando le loro accuratezze in gran parte inalterate
Analisi spettrale per capire come diverse rappresentazioni possono migliorare l'ottimizzazione e la generalizzazione.
Forniamo un supporto teorico alle stime di incertezza per l'apprendimento profondo ottenute adattando priori casuali.
Proponiamo un quadro di imputazione dei dati condizionati arbitrariamente costruito su autocodificatori variazionali e flussi di normalizzazione
Sviluppiamo un attacco alla privacy che può recuperare i dati sensibili di input di una rete profonda dal suo output
Presentiamo un nuovo metodo per la generazione di testi bilingui che produce frasi parallele in due lingue.
Introduciamo la spiegazione online per considerare il requisito cognitivo dell'uomo per comprendere la spiegazione generata dall'agente.
Proponiamo un algoritmo di reinforcement learning basato sullo swapping e sulla ricomputazione delle variabili per ridurre il costo della memoria.
La differenziazione temporale iterativa con allineamento casuale fisso di feedback supporta la plasticità dipendente dal tempo di picco nella backpropagation di vaniglia per l'apprendimento profondo.
Questo articolo propone l'uso di un modello acustico generativo profondo per il riconoscimento automatico del discorso, combinandolo naturalmente con altri moduli profondi sequenza-sequenza utilizzando la regola di Bayes.
Proponiamo un nuovo approccio per la generazione di esempi avversari basato sulla trasformazione spaziale, che produce esempi percettivamente realistici rispetto agli attacchi esistenti. 
Un algoritmo ibrido DQN e DDPG è proposto per affrontare lo spazio d'azione ibrido discreto-continuo.
Un nuovo metodo di modellazione dei Knowledge Graphs basato su Distance Embeddings e reti neurali
Migliorare la stabilità dell'addestramento delle reti generative semi-supervisionate con l'addestramento collaborativo
Mostriamo come fare previsioni usando reti profonde, senza addestrare reti profonde.
Graphon è un buon spazio di ricerca per la ricerca di architetture neurali e produce empiricamente buone reti.
Addestramento contraddittorio adattivo all'istanza per migliorare il compromesso robustezza-accuratezza
Proponiamo un approccio di protezione difensiva della distinzione e dimostriamo la forte distinguibilità degli esempi avversari.
Introduciamo la NLC, una metrica che è economica da calcolare nello stato di inizializzazione casuale delle reti ed è altamente predittiva della generalizzazione, almeno nelle reti completamente connesse.
colmare il divario nel soft computing
Questo articolo introduce MarginAttack, un attacco avversario a confidenza zero più forte e veloce.
L'ottimizzazione non supervisionata durante l'inferenza fornisce un feedback top-down per regolare iterativamente la previsione feedforward della variazione di scala per un riconoscimento più equivariante.
Indaghiamo le proprietà del Priore dell'Immagine Profonda recentemente introdotto (Ulyanov et al, 2017)
Proponiamo una metodologia per aumentare i dati pubblicamente disponibili per gli studi sul rumor basati sulla correlazione samantica tra dati limitati etichettati e non etichettati.
Le convoluzioni dinamiche leggere sono competitive all'auto-attenzione nei compiti linguistici.
Mostriamo come l'inclusione di un passo extra-gradiente nei metodi di formazione GAN del primo ordine può migliorare la stabilità e portare a risultati di convergenza migliori.
La normalizzazione dei lotti riduce la robustezza in fase di test alle corruzioni comuni e agli esempi avversari.
Impariamo un algoritmo di ottimizzazione che generalizza ai compiti non visti
Prevediamo l'errore di generalizzazione e specifichiamo il modello che lo raggiunge attraverso le scale modello/dati.
Metodo di apprendimento di rinforzo non supervisionato per l'apprendimento di una politica per raggiungere in modo robusto obiettivi specificati percettivamente.
Modello di sequenza che regola dinamicamente la quantità di calcolo per ogni input.
Caratterizziamo gli ottimali globali problematici dell'obiettivo VAE e presentiamo un nuovo metodo di inferenza per evitare tali ottimali.
Proponiamo un nuovo incorporamento di parole non supervisionato che conserva la proprietà di inclusione nella distribuzione del contesto e raggiungiamo risultati all'avanguardia nel rilevamento non supervisionato dell'ipernimia
Un approccio basato sulla regolarizzazione per l'apprendimento continuo utilizzando reti neurali bayesiane per prevedere l'importanza dei parametri
Questo articolo esplora l'uso di una tecnologia di aumento sensoriale indossabile per facilitare la presa di prospettiva di prima mano di ciò che è come avere baffi da gatto.
Diamo alcuni limiti di errore di generalizzazione dei metodi a gradiente rumoroso come SGLD, dinamica di Langevin, momento rumoroso e così via.
Per lo sparse-reward reinforcement learning, l'ensemble di modelli dinamici multipli è usato per generare la ricompensa intrinseca progettata come il minimo della sorpresa.
Studiamo le rappresentazioni della fonologia nei modelli di rete neurale del linguaggio parlato con diverse varianti di tecniche analitiche.
Risolviamo il problema specifico di SR delle immagini JPG di bassa qualità tramite sottomodelli funzionali.
Proponiamo un modello interpretabile per rilevare le wakewords scelte dall'utente che impara dagli esempi dell'utente.
Proponiamo un modello che impara a scoprire fotogrammi informativi in una sequenza video futura e a rappresentare il video attraverso i suoi fotogrammi chiave.
Impariamo la rappresentazione profonda massimizzando l'informazione reciproca, sfruttando la struttura nell'obiettivo, e siamo in grado di calcolare con classificatori completamente supervisionati con architetture comparabili
Proponiamo innanzitutto uno stimatore d'importanza atomica completamente automatizzato e diretto all'obiettivo, basato sulle reti neurali a grafo e su un nuovo concetto di auto-attenzione inversa.
Clustering spettrale non supervisionato utilizzando reti neurali profonde
Troviamo che i modelli profondi sono cruciali per il funzionamento di MAML e proponiamo un metodo che permette un meta-apprendimento efficace nei modelli più piccoli.
Il pooling si ottiene usando le wavelets invece dei tradizionali approcci di vicinato (massimo, medio, ecc.).
Proponiamo un nuovo quadro dinamico di ridesharing per formare viaggi che ottimizza sia il valore operativo per il fornitore di servizi che il valore utente per i passeggeri, inserendo le preferenze sociali degli utenti nel processo decisionale.
Caratterizziamo le proprietà dimensionali dei sottospazi avversari nel quartiere degli esempi avversari attraverso l'uso della dimensionalità intrinseca locale (LID).
Progettiamo e analizziamo un nuovo algoritmo di ottimizzazione stocastica di ordine zerotico, ZO-signSGD, e dimostriamo la sua connessione e applicazione agli attacchi avversari black-box nell'apprendimento profondo robusto
Questo articolo propone un'architettura di rete neurale ricorrente unificata per la previsione solare a breve termine con orizzonte temporale multiplo e convalida i guadagni di prestazione della previsione rispetto ai metodi precedentemente riportati
La Skip-connection in ResNet e la normalizzazione dei lotti migliorano la capacità di separazione dei dati e aiutano ad addestrare una rete neurale profonda.
Proponiamo un modello generativo che non solo produce dati con le caratteristiche desiderate dallo spazio latente predefinito, ma comprende anche completamente le caratteristiche dei dati per creare caratteristiche che non sono nel dataset.
Un quadro per studiare la comunicazione emergente in una configurazione di apprendimento di rinforzo multi-agente in rete.
Estendiamo gli insiemi profondi alle incorporazioni funzionali e ai processi neurali per includere membri equivarianti di traduzione
Un modello CNN rotazionale-equivariante di V1 che supera i modelli precedenti e suggerisce raggruppamenti funzionali di neuroni V1.
Rideriva un'ampia classe di procedure di inferenza da un obiettivo di collo di bottiglia informativo globale.
L'addestramento di agenti con calcolo adattivo basato sul collo di bottiglia dell'informazione può promuovere la generalizzazione. 
Abbiamo utilizzato uno studio intra-soggetto per valutare quattro immagini di respirazione ritmata comuni nelle applicazioni mobili per capire quale è più efficace nel fornire una guida all'esercizio della respirazione.
Un modo per generare corpora di allenamento per la sintesi del codice neurale usando un discriminatore addestrato su dati non etichettati
Dimostriamo la vulnerabilità agli attacchi undersensitivity nei modelli di comprensione di lettura neurale SQuAD2.0 e NewsQA, dove il modello predice la stessa risposta con maggiore confidenza a domande scelte avversariamente, e confrontiamo le strategie di difesa.
L'utilizzo di tecniche di compressione per la codifica delle parole è una possibilità per un addestramento più veloce della CNN e la riduzione della dimensionalità della rappresentazione
Un formalismo di ottimizzazione della politica regolarizzata dall'entropia sussume un insieme di algoritmi di apprendimento delle previsioni di sequenza. Un nuovo algoritmo di interpolazione con risultati migliori sulla generazione di testo e sull'apprendimento dell'imitazione dei giochi.
Proponiamo un modello CNN puramente convoluzionale con meccanismo di attenzione per prevedere i flussi di origine-destinazione spazio-temporali. 
Proponiamo un nuovo approccio di formazione avversaria chiamato Robust Local Features for Adversarial Training (RLFAT) che migliora significativamente sia la generalizzazione robusta avversaria che la generalizzazione standard.
Perché e come vincolare la verifica del modello del dominio di pianificazione con obiettivi di pianificazione per evitare controesempi irraggiungibili (risultati di verifica falsi positivi).
StrokeNet è una nuova architettura in cui l'agente è addestrato a disegnare a colpi su una simulazione differenziabile dell'ambiente, che potrebbe sfruttare efficacemente la potenza della back-propagation.
Dimostriamo come il machine learning è in grado di modellare gli esperimenti di fisica quantistica.
 un quadro di apprendimento metrico non lineare non supervisionato per migliorare le prestazioni degli algoritmi di clustering.
Di fronte a modelli complessi, black-box, criptare i dati non è utilizzabile come approssimare il modello e usarlo per prezzare una potenziale transazione.
Sistema di scrittura interattivo basato su uno stilo che incorpora il suono
Presentiamo una struttura encoder-decoder per il trasferimento dello stile linguistico, che permette l'uso di dati non paralleli e di dati sorgente con vari stili linguistici sconosciuti.
Una nuova funzione di perdita per PCA con autocodificatori lineari che produce in modo dimostrabile autovettori ordinati esatti 
Questo articolo sviluppa una struttura per integrare il feedback degli utenti sotto l'incertezza dell'identità nelle basi di conoscenza. 
In questo articolo proponiamo un nuovo modello generativo per creare attacchi di avvelenamento sistematico con vincoli di rilevabilità contro i classificatori di apprendimento automatico, comprese le reti profonde. 
È l'algoritmo quantistico per la massimizzazione delle aspettative. È veloce: il tempo di esecuzione dipende solo polilogaritmicamente dal numero di elementi nel set di dati. 
Un algoritmo di ottimizzazione sparsa per modelli CNN profondi.
Un'alternativa semplice ed efficace all'apprendimento per imitazione avversaria: inizializzare il buffer di replay dell'esperienza con le dimostrazioni, impostare la loro ricompensa a +1, impostare la ricompensa per tutti gli altri dati a 0, eseguire Q-learning o soft actor-critic per allenarsi.
Presentiamo una nuova architettura profonda, VarPSOM, e la sua estensione ai dati delle serie temporali, VarTPSOM, che raggiungono prestazioni di clustering superiori rispetto agli attuali metodi di clustering profondo su dati statici e temporali.
Analizziamo quali compiti è meglio imparare insieme in una rete e quali è meglio imparare separatamente. 
Una struttura semantica profonda per il recupero dei documenti nei motori di ricerca testuali
Proponiamo un nuovo algoritmo basato sul trasporto ottimale per addestrare una CNN in modo SSL.
La normalizzazione dei lotti riduce la robustezza avversaria, così come la robustezza generale in molti casi, in particolare alle corruzioni da rumore.
Apprendimento delle HGN, domini ND
un semplice meta-apprendista basato su RNN che raggiunge prestazioni SOTA su benchmark popolari
Presentato in EMNLP
Introduciamo un nuovo ambiente di calcio MuJoCo per la ricerca continua sull'apprendimento di rinforzo multi-agente, e mostriamo che l'addestramento basato sulla popolazione di apprendenti di rinforzo indipendenti può imparare comportamenti cooperativi
Utilizzando la grammatica DSL e il reinforcement learning per migliorare la sintesi di programmi con flusso di controllo complesso.
Proponiamo un nuovo modello di serie temporale dello spazio di stato con la capacità di catturare la struttura dei punti di cambiamento e dei punti di anomalia, in modo da avere una migliore performance di previsione quando esistono punti di cambiamento e anomalie nella serie temporale.
Un trasformatore multimodale per l'apprendimento sequenziale multimodale, con forti risultati empirici su metriche del linguaggio multimodale come l'analisi del sentimento multimodale, il riconoscimento delle emozioni e dei tratti di personalità. 
Utilizziamo un coefficiente adattivo sopra il momento regolare ispirato all'ottimizzazione geodetica che accelera significativamente l'addestramento in funzioni sia convesse che non convesse.
Usiamo un codificatore di trasformatori per fare la traduzione allenandolo nello stile di un modello di traduzione mascherato.
Presentiamo gli ensemble locali, un metodo per rilevare l'estrapolazione nei modelli addestrati, che approssima la varianza di un ensemble usando informazioni locali di secondo ordine.
La privacy può essere pensata allo stesso modo di altre risorse nella pianificazione
apprendimento della rappresentazione disentangled
Proponiamo un approccio di formazione avversaria al problema della generazione di domande di chiarimento che utilizza la risposta alla domanda per modellare la ricompensa. 
L'uso del partizionamento a costi saturi per selezionare i modelli è preferibile a tutti gli algoritmi di selezione dei modelli esistenti.
L'uso dell'attenzione ramificata con pesi di combinazione appresi supera il trasformatore di base per compiti di traduzione automatica.
Apprendimento per imitazione guidato dalla visione e apprendimento per rinforzo basato su modelli per la pianificazione, la previsione e il controllo
Evidenziamo i problemi con le metriche comuni di incertezza nel dominio ed eseguiamo un ampio studio delle moderne tecniche di ensembling.
Sviluppare un quadro generale per stabilire la robustezza certificata dei modelli ML contro varie classi di perturbazioni avversarie
Proponiamo un modello generativo di variabile latente per la decomposizione non supervisionata della scena che fornisce una rappresentazione fattorizzata dell'oggetto per oggetto in primo piano, decomponendo anche segmenti di sfondo di morfologia complessa.
Proponiamo un'estensione dell'autoencoder variazionale condizionale che permette il condizionamento su un sottoinsieme arbitrario delle caratteristiche e il campionamento di quelle rimanenti.
In questo articolo proponiamo una rappresentazione gerarchica dell'architettura in cui la ricerca casuale o evolutiva dell'architettura produce risultati altamente competitivi utilizzando meno risorse computazionali rispetto all'arte precedente.
Proponiamo Hallucinative Topological Memory (HTM), un algoritmo di pianificazione visiva che può eseguire la pianificazione a zero colpi di orizzonte lungo in nuovi ambienti. 
Proponiamo di accelerare la normalizzazione in batch (BN) attraverso il campionamento di dati meno correlati per le operazioni di riduzione con un modello di esecuzione regolare, che raggiunge fino a 2x e 20% di accelerazione per la BN stessa e l'addestramento complessivo, rispettivamente.
Apprendimento federato efficiente dal punto di vista della comunicazione con abbinamento a livello
Imparare con dati di formazione limitati sfruttando istanze "utili" da una ricca fonte di dati.  
un nuovo algoritmo di ottimizzazione senza derivati derivato dai metodi a gradiente accelerato di Nesterov e dalla dinamica hamiltoniana
Binarized Back-Propagation tutto ciò di cui avete bisogno per un addestramento completamente binarizzato è di gonfiare la dimensione della rete
Come scegliere efficacemente la funzione di inizializzazione e attivazione per le reti neurali profonde
Introduciamo le decomposizioni contestuali, un algoritmo di interpretazione per LSTMs in grado di estrarre il punteggio di importanza a livello di parola, frase e interazione
Questo articolo propone un nuovo metodo di mascheramento complesso per il miglioramento del discorso insieme a una funzione di perdita per una stima efficiente della fase.
Imparare il comportamento emergente minimizzando la sorpresa bayesiana con RL in ambienti naturali con entropia.
Le rappresentazioni profonde combinate con la discesa del gradiente possono approssimare qualsiasi algoritmo di apprendimento.
Presentiamo un'interfaccia cervello-macchina ad anello aperto le cui prestazioni non sono vincolate all'approccio bag-of-words tradizionalmente utilizzato.
Presentiamo un'incorporazione a rete completa di CNN che supera le incorporazioni a strato singolo per compiti di apprendimento di trasferimento.
Presentiamo un nuovo metodo di potatura della rete che può trovare la struttura rada ottimale durante il processo di formazione con una soglia di potatura allenabile
Valutiamo la plausibilità biologica dei nuovi algoritmi di apprendimento ML in astratto sulla base delle operazioni matematiche necessarie
Introduciamo un metodo per addestrare modelli con una robustezza dimostrabile rispetto a tutte le $l_p$-norme per $p\geq 1$ contemporaneamente.
Proponiamo un nuovo metodo per gestire le degradazioni dell'immagine di diversi livelli imparando un tempo terminale di diffusione. Il nostro modello può generalizzarsi a livelli di degrado non visti e a diverse statistiche di rumore.
Mostriamo che è possibile approssimare velocemente il calcolo delle distanze di Wasserstein trovando un appropriato embedding dove la distanza euclidea emula la distanza di Wasserstein
Presentiamo un nuovo schema di addestramento per ottenere in modo efficiente rappresentazioni di frasi consapevoli dell'ordine.
La parametrizzazione ricorsiva dei modelli ricorrenti migliora le prestazioni 
Uno studio comparativo di modelli generativi su scenari di apprendimento continuo.
prima ponendo e risolvendo il problema di ottimizzazione dell'efficienza del campione nello spazio della politica non parametrizzata, e poi risolvendo un problema di regressione supervisionata per trovare una politica parametrizzata che sia vicina alla politica ottimale non parametrizzata.
Un approccio guidato dall'obiettivo per modellare quattro aree visive del topo (V1, LM, AL, RL) basato su reti neurali profonde addestrate sul riconoscimento statico degli oggetti non svela un'organizzazione funzionale della corteccia visiva a differenza dei primati
un modello di gradiente generalizzato basato sulla trasformazione per l'inferenza variazionale
Introduciamo un nuovo modello linguistico a contesto più ampio per catturare simultaneamente la sintassi e la semantica, rendendolo capace di generare frasi e paragrafi altamente interpretabili
Addestriamo un agente di pittura di media naturali usando il modello dell'ambiente. Sulla base del nostro agente di pittura, presentiamo un nuovo approccio per addestrare un agente di pittura vincolato che segue il comando codificato nell'osservazione.
Abbiamo sviluppato un quadro di ricerca e una penalità di coerenza per mitigare i bias di delusione.
Il sistema proposto può impedire agli impersonatori con travestimenti facciali di completare una transazione fraudolenta utilizzando una DCNN pre-addestrata.
analisi teorica dell'autocodificatore largo non lineare
Introduciamo il primo approccio RL gerarchico per imparare con successo gerarchie a 3 livelli in parallelo in compiti con spazi di stato e di azione continui.
Questo articolo ha studiato il problema di classificazione PUbN, in cui incorporiamo dati negativi distorti (bN), cioè dati negativi che non sono pienamente rappresentativi della vera distribuzione negativa sottostante, nell'apprendimento positivo senza etichetta (PU).
Le pratiche di rinforzo per l'aumento delle prestazioni della traduzione automatica potrebbero non provenire da previsioni migliori.
Addestriamo una piccola ed efficiente CNN con le stesse prestazioni di OpenAI Transformer su compiti di classificazione del testo
Metodo di ensemble per l'apprendimento di rinforzo che pondera le funzioni Q in base agli errori TD accumulati.
Bsuite è una collezione di esperimenti accuratamente progettati che indagano le capacità fondamentali degli agenti RL.
miglioramento del preaddestramento e analisi dell'output del codificatore e dell'attenzione
Una formulazione per una scatola nera, metodo di apprendimento di rinforzo per trovare il fallimento più probabile di un sistema che agisce in scenari complessi.
Usare algoritmi senza modello come DQN/TRPO per risolvere problemi a breve orizzonte (senza modello) in modo iterativo in un modo di Policy/Value Iteration.
Mostriamo che anche i metodi di addestramento avversari più forti non possono difendersi dagli esempi avversari creati su immagini di prova leggermente scalate e spostate.
Migliorare le attivazioni saturanti (sigmoide, tanh, htanh ecc.) e la rete neurale binarizzata con inizializzazione Bias
utilizzando reti neurali profonde e algoritmi intelligenti per catturare concetti visivi mentali umani
Presentiamo un nuovo attacco mirato black-box che è in grado di ingannare lo stato dell'arte della trascrizione da discorso a testo.
Sintetizzare i movimenti umani su compiti interattivi usando dati mocap e RL gerarchico.
Analisi della convergenza e del collasso della modalità studiando il processo di formazione GAN come minimizzazione del rimpianto
Proponiamo un nuovo quadro per valutare l'interpretabilità delle reti neurali.
Un agente RL profondo che impara i valori Q iperbolici (e altri non esponenziali) e un nuovo compito ausiliario multi-orario.
Questo articolo presenta il rilevamento delle emozioni basato sull'EEG di una persona verso uno stimolo di immagine e la sua applicabilità al neuromarketing.
Approssimazioni variazionali veloci per l'approssimazione di uno stato utente e l'apprendimento di embeddings del prodotto
Presentiamo una funzione di valutazione dimostrabile e facilmente calcolabile che stima le prestazioni delle rappresentazioni trasferite da un compito di apprendimento a un altro nell'apprendimento di trasferimento dei compiti.
Proponiamo uno schema di apprendimento condizionale affidabile insieme a un quadro semplice, generico ma efficace per i compiti UDA.
Dalla distanza al kernel e all'inclusione tramite funzioni casuali per input strutturati
Un kernel di ispirazione quantistica per la rete di convoluzione, che mostra fenomeni di interferenza, può essere molto utile (e confrontato con la controparte di valore reale).
Una piattaforma di gioco di ricerca ispirata agli MMO per studiare i comportamenti emergenti di grandi popolazioni in un ambiente complesso
Questo documento migliora la valutazione esistente basata sul campione per le GAN e contiene alcuni esperimenti perspicaci.
Le reti neurali binarie residue migliorano significativamente il tasso di convergenza e la precisione di inferenza delle reti neurali binarie.
Metodo non supervisionato per rilevare campioni avversari nello spazio delle attivazioni dell'autoencoder e degli errori di ricostruzione
Proponiamo di imparare rappresentazioni di entità e relazioni consapevoli da Bert per l'embedding dei grafi di conoscenza.
Un modulo neurale scalabile e differenziabile che implementa il ragionamento su KB simboliche.
DCEM apprende i domini latenti per i problemi di ottimizzazione e aiuta a colmare il divario tra RL basato sul modello e senza modello --- creiamo un controller differenziabile e mettiamo a punto parti di esso con PPO
Usiamo ricompense dinamiche per addestrare gli estrattori di eventi.
I GAN beneficiano dello scaling up.
L'errore congiunto conta per l'adattamento di dominio non supervisionato, specialmente quando lo spostamento di dominio è enorme
Knowledge Flow' allena una rete profonda (studente) iniettando informazioni da più reti (insegnanti). Lo studente è indipendente dall'addestramento ed esegue molto bene i compiti appresi, indipendentemente dall'impostazione (rinforzo o apprendimento supervisionato).
Una stima efficiente del primo momento gaussiano delle DNN come regolatore per l'addestramento di reti robuste.
Proponiamo cascate neurali, un approccio semplice e banalmente parallelizzabile alla comprensione della lettura, composto solo da reti feed-forward e attenzione che raggiunge prestazioni allo stato dell'arte sul dataset TriviaQA.
Noi avanziamo lo stato dell'arte nella compressione dei modelli proponendo Atomic Compression Networks (ACNs), una nuova architettura che è costruita dalla ripetizione ricorsiva di un piccolo insieme di neuroni.
Dimostriamo che i modelli generativi basati sul flusso offrono un approccio valido e competitivo alla modellazione generativa dei video.
Forniamo un'analisi teorica ed empirica sul ruolo del rumore anisotropo introdotto dal gradiente stocastico sulla fuga dai minimi.
Gradiente della politica attraverso la backpropagation nel tempo usando modelli appresi e funzioni Q. Risultati SOTA in ambienti di riferimento per l'apprendimento con rinforzo.
Meta-apprendimento su distribuzioni di compiti autoproposti per accelerare l'apprendimento di rinforzo senza distribuzioni di compiti specificati dall'uomo 
Un metodo nuovo e praticamente efficace per adattare le reti neurali preaddestrate a nuovi compiti riqualificando un numero minimo (per esempio, meno del 2%) di parametri
Una nuova spiegazione teorica per l'esistenza di esempi contraddittori
Elastic-InfoGAN è una modifica di InfoGAN che apprende, senza alcuna supervisione, rappresentazioni dissociate in dati sbilanciati in classi
un quadro di condivisione della conoscenza basato sullo spazio latente distribuito per l'apprendimento multi-task profondo
Game Changer è un sistema che fornisce sia descrizioni audio che aggiunte tattili per rendere lo stato del gioco da tavolo accessibile ai giocatori non vedenti e ipovedenti.
La supervisione accoppiata regola-esemplare e una perdita di implicazione aiuta ad apprendere congiuntamente a denudare le regole e implicare le etichette.
Il nostro metodo introduce l'empowerment-regolarizzato maximum-entropy inverse reinforcement learning per imparare ricompense e politiche quasi ottimali da dimostrazioni di esperti.
Le RNN implementano implicitamente rappresentazioni tensore-prodotto, un metodo di principio e interpretabile per rappresentare strutture simboliche nello spazio continuo.
L'aumento dei dati appresi instilla pregiudizi induttivi favorevoli all'algoritmo che permettono alle RNN di imparare algoritmi di elaborazione delle liste da un minor numero di esempi.
Proponiamo un problema speciale di apprendimento multietichetta debolmente supervisionato insieme a un nuovo algoritmo su misura che impara il classificatore sottostante imparando ad assegnare pseudo-etichette.
Un assistente di ricerca conversazionale basato sul Reinforcement Learning che fornisce assistenza contestuale nella ricerca soggettiva (come i beni digitali).
Le reti neurali convoluzionali si comportano come Compositional Nearest Neighbors!
Fattorizzare gli stati LSTM e azzerare/legare le matrici dei pesi LSTM secondo i bias strutturali del mondo reale espressi da programmi Datalog.
Proponiamo un nuovo approccio per risolvere problemi di ottimizzazione basati su modelli guidati dai dati in entrambe le impostazioni passive e attive che possono scalare a spazi di input ad alta densità.
In questo articolo, proponiamo un nuovo modello di codificatore-decodificatore basato su rappresentazioni di prodotti tensoriali per la generazione di linguaggio da naturale a formale, chiamato TP-N2F.
Questo articolo presenta un defogger, un modello che impara a prevedere informazioni nascoste future da osservazioni parziali, applicato a un set di dati di StarCraft.
Studiamo la generalizzazione delle reti neurali nel meta-apprendimento basato sul gradiente analizzando varie proprietà del paesaggio obiettivo.
Presentiamo un modello generativo che dimostra risultati all'avanguardia su immagini in scala di grigi e naturali.
Proponiamo una nuova rete chiamata Recurrent Identity Network (RIN) che permette a una semplice rete ricorrente di superare il problema del gradiente vanificante mentre addestra modelli molto profondi senza l'uso di porte.
L'articolo affronta la tolleranza ai guasti sotto arresti casuali e avversari.
Presentiamo una nuova architettura unificata che ripristina i fotogrammi video da una singola immagine sfocata dal movimento in modo end-to-end.
Proponiamo una nuova tecnica di class-blind pruning strutturata per produrre reti neurali altamente compresse.
Usiamo approssimazioni di somma di Kronecker per l'addestramento a basso rango per affrontare le sfide nell'addestramento di reti neurali su dispositivi di bordo che utilizzano tecnologie di memoria emergenti.
Esamina sistematicamente quanto bene possiamo spiegare le caratteristiche nascoste di una rete profonda in termini di regole logiche.
Stime di verosimiglianza migliorate negli autocodificatori variazionali utilizzando l'apprendimento auto-supervisionato delle caratteristiche
Questo articolo mostra che i metodi di gradiente della politica senza modello possono convergere alla soluzione ottimale globale per problemi di controllo linearizzati non convessi.
Usiamo la teoria del rilevamento compresso per dimostrare che gli LSTM possono fare almeno altrettanto bene nella classificazione lineare del testo come il Bag-of-n-Grams.
Introduciamo nuovi strati di convoluzione puntuali dotati di trasformazioni convenzionali estremamente veloci nella rete neurale profonda.
Proponiamo di utilizzare i tralicci per rappresentare gli oggetti e dimostriamo un risultato fondamentale su come addestrare le reti che li utilizzano.
Cerchiamo di progettare e addestrare un classificatore la cui robustezza avversaria è più simile alla robustezza umana.
Proponiamo un modello Discrete Wasserstein GAN (DWGAN) che si basa su una formulazione duale della distanza Wasserstein tra due distribuzioni discrete.
Si tratta di una nuova architettura AGI per prestazioni trans-sapiente.Questa è una panoramica di alto livello dell'architettura Omega AGI che è la base di un sistema di automazione della scienza dei dati. Presentato ad un workshop. 
Proponiamo il meccanismo Flow e un'architettura end-to-end, FlowQA, che realizza SotA su due dataset di QA conversazionale e un compito di comprensione di istruzioni sequenziali.
Presentiamo un nuovo algoritmo per risolvere l'apprendimento di rinforzo e i problemi di predizione strutturata di bandit con feedback di perdita molto sparsi.
Presentiamo una semplice modifica al metodo SGD alternato, chiamato passo di predizione, che migliora la stabilità delle reti avversarie.
Questo articolo introduce compilazioni indipendenti dal dominio delle domande degli utenti in vincoli per spiegazioni contrastive.
 Incorporiamo i nodi in un grafico come distribuzioni gaussiane che ci permettono di catturare l'incertezza sulla loro rappresentazione.
I metodi di regolarizzazione Logit aiutano a spiegare e migliorare lo stato dell'arte delle difese avversarie
Descriviamo un linguaggio modulare e componibile per descrivere spazi di ricerca espressivi su architetture e semplici algoritmi di ricerca per modelli applicati a questi spazi di ricerca. 
Mostriamo che le tecniche di trasferimento della conoscenza possono migliorare l'accuratezza delle reti a bassa precisione e impostare una nuova accuratezza allo stato dell'arte per la precisione ternaria e a 4 bit. 
L'articolo presenta un meccanismo di addestramento migliorato per ottenere reti binarie con una minore caduta di precisione che aiuta a colmare il divario con la sua controparte a piena precisione.
Struttura unificante per eseguire il clustering usando reti neurali profonde
HYPE è una metrica di valutazione umana affidabile per il punteggio dei modelli generativi, a partire dalla generazione di volti umani attraverso 4 GAN.
Proponiamo un nuovo modello di traduzione automatica non supervisionata che può imparare senza usare corpora paralleli; i risultati sperimentali mostrano prestazioni impressionanti su più corpora e coppie di lingue.
Premiamo gli agenti per avere un'influenza causale sulle azioni di altri agenti, e mostriamo che questo dà luogo a una migliore cooperazione e a protocolli di comunicazione emergenti più significativi. 
Sviluppiamo un agente che chiamiamo l'algoritmo Distributional Deterministic Deep Policy Gradient, che raggiunge prestazioni allo stato dell'arte su una serie di impegnativi problemi di controllo continuo.
Proponiamo una nuova funzione Q-value che permette un migliore apprendimento delle politiche gaussiane.
Presentiamo KG-A2C, un agente di apprendimento con rinforzo che costruisce un grafo di conoscenza dinamico mentre esplora e genera un linguaggio naturale utilizzando uno spazio d'azione basato su un modello - superando tutti gli agenti attuali su un ampio set di giochi basati sul testo.
Dimostriamo che le reti neurali profonde sono esponenzialmente più efficienti di quelle superficiali nell'approssimazione di polinomi multivariati sparsi.
Proponiamo la classificazione dei neuroni della CNN con due metodi diversi e mostriamo la loro coerenza nel produrre il risultato che permette di interpretare ciò che la rete ritiene importante e comprimere la rete mantenendo i nodi più rilevanti.
Un approccio modulare e gerarchico per imparare le politiche di esplorazione degli ambienti 3D.
Un metodo di adattamento non supervisionato da sim a dominio reale per la segmentazione semantica usando informazioni privilegiate da un simulatore con traduzione di immagini basata su GAN.
La prima diagnosi di rigore dell'addestramento adversariale su larga scala su ImageNet
Attribuire i termini di polarizzazione delle reti neurali profonde alle caratteristiche di input mediante un algoritmo di tipo backpropagation; generare spiegazioni complementari e altamente interpretabili delle DNN oltre alle attribuzioni basate sul gradiente.
Questo articolo presenta un metodo per trovare autonomamente più periodicità in un segnale, usando FFT e ACF e aggiungendo tre nuovi passi (clustering/filtering/detrending)
Uno schema di apprendimento per imitazione semplice ma efficace che incentiva l'esplorazione di un ambiente senza alcuna ricompensa estrinseca o dimostrazione umana.
 un nuovo quadro che utilizza lo spazio duale per generare immagini corrispondenti a etichette multiclasse quando il numero di classi è grande
Presentiamo un nuovo feed forward graph ConvNet basato sulla generalizzazione della trasformazione di dispersione wavelet di Mallat, e dimostriamo la sua utilità nella classificazione dei grafi e nei compiti di esplorazione dei dati.
Introduciamo un set di dati di ricezione su larga scala per compiti di parsing post-OCR.
Accelerazione della formazione CNN su una pipeline di acceleratori con pesi stantii
Mostriamo che le reti profonde non sono solo troppo sensibili ai cambiamenti irrilevanti del loro input, ma anche troppo invarianti a una vasta gamma di cambiamenti rilevanti per il compito, rendendo così vaste regioni nello spazio di input vulnerabili agli attacchi avversari.
Addestramento migliorato degli attuali modelli generativi basati sul flusso (Glow e RealNVP) su benchmark di stima della densità
Le reti neurali profonde addestrate con l'aumento dei dati non richiedono altre regolarizzazioni esplicite (come il decadimento dei pesi e il dropout) e mostrano una maggiore adattabilità ai cambiamenti nell'architettura e nella quantità di dati di allenamento.
Questo articolo migliora la qualità dell'approccio adversarial feature leaning (AFL) recentemente proposto per incorporare vincoli espliciti alle rappresentazioni, introducendo il concetto di vulnerabilità dell'avversario. 
Estendiamo un autoencoder variazionale ricorrente di successo per sistemi dinamici per modellare un'istanza di gerarchia di sistemi dinamici nelle neuroscienze usando il metodo ladder.
Introduciamo un processo di quantizzazione efficiente che permette un'accelerazione delle prestazioni su un acceleratore di reti neurali specializzato per soli interi.
Questo articolo propone un nuovo modello CNN che combina il costo energetico con una strategia di routing dinamico per consentire un'inferenza adattiva efficiente dal punto di vista energetico.
presentiamo LSH Softmax, un livello di approssimazione softmax per l'apprendimento sub-lineare e l'inferenza con forti garanzie teoriche; mostriamo sia la sua applicabilità che l'efficienza valutando su un compito del mondo reale: la modellazione del linguaggio.
RL può risolvere problemi (stocastici) di multi-robot/scheduling in modo scalabile e trasferibile usando l'incorporazione di grafi
Presentiamo un nuovo algoritmo per l'apprendimento per curriculum basato sulla nozione di tasso di padronanza che supera gli algoritmi precedenti.
Ispirazione dai processi dendritici locali dell'apprendimento neocorticale per rendere di nuovo grande l'apprendimento non supervisionato.
Reti di memoria con inferenza più veloce
Prendendo ispirazione dalla linguistica, in particolare dall'ipotesi della Grammatica Universale, impariamo rappresentazioni universali agnostiche alla lingua che possiamo utilizzare per fare un apprendimento a colpo zero attraverso le lingue.
Questo articolo mostra che l'obiettivo della distanza di Wasserstein permette l'addestramento di modelli di variabili latenti con latenti discreti in un caso in cui l'obiettivo dell'autoencoder variazionale non riesce a farlo.
Una rete neurale a grafo in grado di apprendere automaticamente e sfruttare una struttura a grafo dinamica interattiva
Un nuovo algoritmo per l'addestramento delle reti neurali che si confronta favorevolmente con i metodi adattivi popolari.
Sottolinea i problemi nella funzione di perdita usata in IRGAN, una struttura GAN recentemente proposta per l'Information Retrieval. Inoltre, viene proposto un modello motivato dal co-training, che raggiunge prestazioni migliori.
Proponiamo Federated User Representation Learning (FURL), un modo semplice, scalabile, rispettoso della privacy ed efficiente in termini di larghezza di banda per utilizzare le tecniche di personalizzazione neurale esistenti nell'impostazione Federated Learning (FL).
Autoencoder per il testo con un nuovo metodo per utilizzare lo spazio latente discreto.
Spazio latente strutturato per modelli generativi
LoopGAN estende la lunghezza del ciclo in CycleGAN per consentire la trasformazione sequenziale non allineata per più di due passi temporali.
Proponiamo SWAP, un algoritmo distribuito per l'addestramento in grandi lotti di reti neurali.
Un nuovo algoritmo di formazione di grandi lotti basato su Layer-wise Adaptive Rate Scaling (LARS); usando LARS, abbiamo scalato AlexNet e ResNet-50 a un lotto di 16K.
Apprendimento degli operatori compositivi di Koopman per l'identificazione efficiente del sistema e il controllo basato sul modello.
Presentiamo una procedura di calcolo del gradiente a memoria costante attraverso soluzioni di equazioni differenziali stocastiche (SDE) e applichiamo il metodo per imparare modelli SDE latenti.
Apprendimento di trasformazioni che preservano la privacy dai dati. Un approccio collaborativo
Proponiamo diverse funzioni di ricompensa intrinseca per incoraggiare l'esplorazione coordinata nei problemi multi-agente, e introduciamo un approccio per selezionare dinamicamente il miglior metodo di esplorazione per un dato compito, online.
Proponiamo di imparare a sintetizzare classificatori a pochi colpi e classificatori a molti colpi usando una singola funzione obiettivo per GFSL.
Combiniamo la ricerca A* con l'apprendimento di rinforzo per accelerare il codice di apprendimento automatico
L'apprendimento di rinforzo profondo efficiente dal punto di vista dei dati può essere utilizzato per apprendere precise politiche di impilamento.
Parametrizzazioni della politica e stimatori imparziali dell'entropia della politica per MDP con grande spazio d'azione discreto multidimensionale
Decomporre i pesi per usare meno FLOP con SVD
Convergenza asintotica per il metodo stocastico di subgradien con momentum sotto il calcolo asincrono parallelo generale per l'ottimizzazione generale non convessa nonsmooth
Presentiamo uno stimatore a basso bias per modelli booleani a variabili stocastiche con molti strati stocastici.
Proponiamo un nuovo metodo per manipolare immagini date usando descrizioni in linguaggio naturale.
Utilizzare il metodo basato su GAN per risolvere in modo scalabile il trasporto ottimale
Sfruttando il controllo come inferenza e i metodi Sequential Monte Carlo, abbiamo proposto un algoritmo di pianificazione probabilistica.
Una semplice modifica GAN che migliora le prestazioni attraverso molte perdite, architetture, schemi di regolarizzazione e set di dati. 
Come stimare il vettore di probabilità originale per milioni di classi a partire da misurazioni di schizzi count-min - una configurazione teorica e pratica.
È possibile fissare il classificatore nelle reti neurali senza perdere la precisione
Imparare a rilevare oggetti senza etichette di immagine da 3 minuti di video
Introduciamo ReClor, un dataset di comprensione della lettura che richiede un ragionamento logico, e scopriamo che gli attuali modelli allo stato dell'arte lottano con un vero ragionamento logico, con prestazioni scarse vicine a quelle di un'ipotesi casuale.
Solo il rumore in ingresso, raccogliere le uscite di softmax, rubare i pesi
Proponiamo una nuova forma di modello di autocodifica che incorpora le migliori proprietà degli autocodificatori variazionali (VAE) e delle reti generative avversarie (GAN)
Usiamo la connessione tra il meta-apprendimento basato sul gradiente e il Bayes gerarchico per apprendere una miscela di meta-apprenditori che è appropriata per una distribuzione di compiti eterogenea e in evoluzione.
Presentiamo un nuovo metodo di routing per le reti Capsule, e si comporta alla pari con ResNet-18 su CIFAR-10/ CIFAR-100.
Introduciamo Doc2Dial, un framework end-to-end per la generazione di dati di conversazione basati su documenti aziendali tramite crowdsourcing per formare agenti di dialogo automatizzati
Introduciamo un modello generativo autoregressivo per gli spettrogrammi e dimostriamo le applicazioni alla generazione del discorso e della musica
Le moderne CNN profonde non sono invarianti a traslazioni, scalature e altre trasformazioni realistiche delle immagini, e questa mancanza di invarianza è legata all'operazione di sottocampionamento e alle distorsioni contenute nei dataset di immagini.
Sintetizzare movimenti umani complessi ed estesi usando una rete LSTM autocondizionata
Abbiamo ideato un meccanismo chiamato competizione tra pixel che permette ai metodi di salienza (approssimativamente) completi di passare i controlli di sanità mentale.
Classificazione delle immagini tramite interrogazione iterativa dell'immagine di riferimento di una classe candidata con una RNN e uso di CNN per confrontare l'immagine di input
definiamo per la prima volta il problema della potatura a livello di filtro per le reti neurali binarie e proponiamo un metodo per risolverlo.
Riduzione della complessità di calcolo e di memoria dei modelli RNN fino a 100 volte utilizzando moduli di compressione sparsi a basso rango, addestrati tramite distillazione della conoscenza.
Confrontiamo le RNN a grafo e le Convnet a grafo, e consideriamo la classe più generica di Convnet a grafo con residualità.
Confronto tra perceptron multistrato a valore complesso e reale rispetto al numero di parametri a valore reale.
Una rete neurale convoluzionale a grafo spettrale con proprietà di zoom spettrale.
Presentiamo un modello di segmentazione in tempo reale scoperto automaticamente da un framework NAS multiscala, ottenendo il 30% più veloce dei modelli allo stato dell'arte.
Introduciamo R2D3, un agente che fa un uso efficiente delle dimostrazioni per risolvere problemi di esplorazione difficili in ambienti parzialmente osservabili con condizioni iniziali altamente variabili.
Studiamo come una rete neurale ricorrente apprende con successo un compito che combina la memoria a lungo termine e il richiamo sequenziale.
Proponiamo l'idea di usare la norma della rappresentazione del successore come bonus di esplorazione nell'apprendimento di rinforzo. Nei giochi Atari a esplorazione difficile, il nostro algoritmo di RL profondo corrisponde alle prestazioni dei recenti metodi basati su pseudo-conteggio.
Fattorizzazione dipendente dai dati delle dimensioni in un'architettura multiscala basata sul contributo alla log-likelihood totale
Quattro metodi di attribuzione esistenti basati sulla backpropagation sono fondamentalmente simili. Come valutarli?
SGD e Adam sotto il modello a spiga singola per la PCA dei tensori
Questo articolo presenta un metodo per spiegare la conoscenza codificata in una rete neurale convoluzionale (CNN) quantitativamente e semanticamente.
Il documento presenta una metodologia di valutazione dinamica per la modellazione adattiva della sequenza
Proponiamo un nuovo modo, basato sulla proiezione, di incorporare l'informazione condizionale nel discriminatore di GANs che rispetta il ruolo dell'informazione condizionale nel modello probabilistico sottostante.
La distanza di Frechet tra la distribuzione del treno e quella del test è correlata al cambiamento delle prestazioni per le funzioni che non sono invarianti allo spostamento.
Viene introdotto un nuovo sistema dinamico molto semplice che genera modelli graziosi; vengono dimostrate le proprietà ed esplorate le possibilità
GMM-UNIT è un modello di traduzione immagine-immagine che mappa un'immagine in più domini in modo stocastico.
Presentiamo una nuova architettura, basata su memoria dinamica, attenzione e composizione per il compito di ragionare in macchina.
Per comprendere le informazioni memorizzate nello spazio latente, addestriamo un decodificatore in stile GAN vincolato a produrre immagini che il codificatore VAE mapperà nella stessa regione dello spazio latente.
Due nuove GAN sono costruite per generare immagini cerebrali fMRI 3D di alta qualità e immagini cerebrali sintetiche aiutano notevolmente a migliorare i compiti di classificazione a valle.
Trasferimento linguistico incrociato a zero colpi utilizzando la traduzione automatica neurale multilingue 
Proponiamo un algoritmo di ricerca dell'architettura differenziabile sia per reti convoluzionali che ricorrenti, ottenendo prestazioni competitive con lo stato dell'arte usando ordini di grandezza meno risorse di calcolo.
Gli attuali sistemi di generazione del linguaggio o puntano ad un'alta probabilità e cadono nella ripetizione generica o calibrano male la loro stocasticità - noi forniamo prove di entrambe e proponiamo una soluzione: Campionamento del nucleo.
Il primo metodo di difesa avversaria del testo a livello di parola, e il metodo di attacco generico migliorato contro gli attacchi basati sulla sostituzione dei sinonimi.
Verso un'efficiente assegnazione dei crediti nelle reti ricorrenti senza backpropagation attraverso il tempo
Proponiamo un nuovo quadro di apprendimento avversario per la predizione strutturata, in cui i modelli discriminativi possono essere usati per raffinare i modelli di predizione strutturata nella fase di inferenza. 
Una nuova metodologia per il rilevamento delle novità utilizzando i valori di attivazione dello spazio nascosto ottenuti da un autocodificatore profondo.
Imparare le preferenze sulle tracce dei piani usando l'apprendimento attivo.
Abbiamo messo a terra i comandi linguistici in un ambiente visivo ad alta densità imparando ricompense condizionate dalla lingua utilizzando l'apprendimento di rinforzo inverso.
Sosteniamo le caratteristiche casuali come teoria delle reti neurali biologiche, concentrandoci sulle reti scarsamente connesse
Proponiamo il metodo Prob2Vec per l'incorporazione del problema utilizzato in uno strumento di e-learning personalizzato in aggiunta a un metodo di classificazione a livello di dati, chiamato pre-addestramento negativo, per i casi in cui il set di dati di formazione è squilibrato.
Introduciamo CrescendoNet, un'architettura CNN profonda impilando semplici blocchi di costruzione senza connessioni residue.
Combiniamo le spline con le reti neurali per ottenere una nuova distribuzione su funzioni e la usiamo per modellare le funzioni di intensità dei processi puntuali.
Sviluppiamo un BERT compresso, che è 4.3x più piccolo e 4.0x più veloce di BERT-BASE, mentre raggiunge prestazioni competitive su GLUE e SQuAD.
Mostriamo che la maggior parte delle varianti degli autocodificatori ponderati per l'importanza possono essere derivati in un modo più principesco come casi speciali di approcci adattativi di campionamento dell'importanza come l'algoritmo di sonno ponderato.
NUQSGD colma il divario tra le garanzie teoriche di QSGD e le prestazioni empiriche di QSGDinf.
Le reti neurali possono essere addestrate a modificare la propria connettività, migliorando le loro prestazioni di apprendimento online su compiti impegnativi.
Un metodo geometrico basato su simplex è proposto per far fronte ai problemi di apprendimento di pochi colpi.
Mostriamo che un input di memoria di lavoro a una rete di riserva fa sì che una regola di Hebbian modulata a ricompensa locale funzioni altrettanto bene di quella dei minimi quadrati ricorsivi (aka FORCE)
Combiniamo i vantaggi computazionali delle architetture di convoluzione temporale con l'espressività delle variabili latenti stocastiche.
Un metodo senza gradiente è proposto per un problema di ottimizzazione non convesso 
Proponiamo un nuovo metodo che sfrutta i gradienti dei simulatori differenziabili per migliorare le prestazioni della RL per il controllo della robotica
Proponiamo hypernetwork bayesiani: una struttura per l'inferenza bayesiana approssimativa nelle reti neurali.
Deep Innovation Protection permette l'evoluzione di modelli di mondo complessi end-to-end per compiti 3D.
Proponiamo MACER: un algoritmo di difesa dimostrabile che allena modelli robusti massimizzando il raggio certificato. Non utilizza l'addestramento avversario ma si comporta meglio di tutte le difese dimostrabili l2 esistenti.
Questo articolo propone un nuovo metodo actor-critic che usa gli Hessiani di un critico per aggiornare un attore.
classificatori generativi in scala su insiemi di dati complessi, e valutare la loro efficacia per rifiutare input illegali, compresi i campioni fuori distribuzione e gli esempi avversari.
Una teoria per l'inizializzazione e lo scaling degli strati della rete neurale ReLU
Gli output delle moderne API NLP su testi senza senso forniscono forti segnali sui modelli interni, permettendo agli avversari di rubare le API.
Introduciamo SeaRNN, un nuovo algoritmo per l'addestramento RNN, ispirato all'approccio di apprendimento alla ricerca per la previsione strutturata, al fine di evitare le limitazioni dell'addestramento MLE.
Un metodo di apprendimento continuo che usa la distillazione per combinare politiche esperte e apprendimento di trasferimento per accelerare l'apprendimento di nuove competenze.
Modello di apprendimento di rinforzo spiegabile usando una nuova combinazione di miscela di esperti con esperti di alberi decisionali non differenziabili.
Sviluppiamo e analizziamo un nuovo algoritmo di ottimizzazione senza derivati con campionamento di momento e di importanza con applicazioni al controllo continuo.
Proponiamo un nuovo metodo per addestrare l'hashing profondo per il recupero delle immagini utilizzando solo una metrica di distanza relazionale tra i campioni
Proponiamo un nuovo approccio per migliorare una data mappatura della superficie incrociata attraverso il raffinamento locale con un nuovo metodo iterativo per deformare la mesh al fine di soddisfare i vincoli dell'utente.
Introdurre un punto di vista teorico dell'informazione sul comportamento dei processi di ottimizzazione delle reti profonde e le loro capacità di generalizzazione
Rappresentare l'architettura della rete come un insieme di alberi sintattici e ottimizzare la loro struttura porta a modelli di regressione accurati e concisi. 
Studio empirico e teorico degli effetti della staleness in esecuzione non sincrona su algoritmi di apprendimento automatico.
Questo lavoro presenta un algoritmo scalabile per l'identificazione non lineare del sistema offline da osservazioni parziali.
Analisi generale dei metodi basati sui segni (per esempio signSGD) per l'ottimizzazione non convessa, costruita su limiti intuitivi delle probabilità di successo.
Per l'apprendimento off-policy con feedback banditi, proponiamo un nuovo algoritmo di apprendimento controfattuale regolarizzato dalla varianza, che ha sia basi teoriche che prestazioni empiriche superiori.
Combiniamo vincoli duri fatti a mano con un vincolo debole a priori profondo per eseguire l'imaging sismico e raccogliere informazioni sulla distribuzione "posteriore" sfruttando la molteplicità nei dati.
Stato dell'arte nel parsing complesso da testo a SQL combinando il ragionamento relazionale duro e morbido nella codifica di schema/domanda.
Introduciamo una configurazione di apprendimento continuo basata sulla modellazione del linguaggio in cui non viene dato alcun segnale esplicito di segmentazione del compito e proponiamo un modello di rete neurale con memoria a lungo termine crescente per affrontarlo.
Algoritmo proposto basato su RNN per stimare la distribuzione predittiva nelle previsioni a uno e più passi nei problemi di previsione delle serie temporali
Le LSTM possono modellare più efficacemente la memoria di lavoro se sono apprese utilizzando l'apprendimento di rinforzo, molto simile al sistema di dopamina che modula la memoria nella corteccia prefrontale    
Riformulare le nonlinearità delle reti profonde da un ambito di quantizzazione vettoriale e collegare la maggior parte delle nonlinearità conosciute.
Impariamo a generare condizionatamente sequenze di proteine date strutture con un modello che cattura le dipendenze sparse e a lungo raggio.
Una struttura che collega gli strati profondi della rete agli algoritmi di ottimizzazione stocastica; può essere usata per migliorare l'accuratezza del modello e informare la progettazione della rete.
Un metodo per imparare la configurazione di quantizzazione per le reti a bassa precisione che raggiunge lo stato dell'arte delle prestazioni per le reti quantizzate.
Proponiamo diverse strategie generali di debiasing per affrontare i bias comuni visti in diversi set di dati e ottenere un sostanziale miglioramento delle prestazioni fuori dal dominio in tutte le impostazioni.
Presentiamo un algoritmo di ricostruzione basato sull'inferenza CNN per affrontare CT con pochissime viste. 
Costruiamo agenti di conversazione consapevoli condizionando su Wikipedia + un nuovo compito supervisionato.
Sintesi degli algoritmi GCN e LINUCB per l'apprendimento online con feedback mancanti
Un buon tagger dà tag simili a un dato articolo e agli articoli che cita
Proponiamo un metodo basato sulla quantizzazione che regolarizza le rappresentazioni apprese da una CNN per essere automaticamente allineate con la matrice concettuale allenabile, filtrando quindi efficacemente le perturbazioni avversarie.
L'articolo fornisce una caratterizzazione completa degli strati lineari invarianti di permutazione ed equivarianti per i dati del grafico.
I modelli parziali causalmente corretti non devono generare l'intera osservazione per rimanere causalmente corretti in ambienti stocastici.
Un efficiente algoritmo di apprendimento permanente che fornisce un migliore compromesso tra accuratezza e complessità di tempo/memoria rispetto ad altri algoritmi. 
Abbiamo dimostrato risultati di addestramento all'avanguardia utilizzando la rappresentazione in virgola mobile a 8 bit, attraverso Resnet, GNMT, Transformer.
Proponiamo l'entropia incrociata di istanza (ICE) che misura la differenza tra una distribuzione stimata di corrispondenza a livello di istanza e la sua distribuzione ground-truth. 
L'incorporazione, nel modello, di variabili latenti che codificano il contenuto futuro migliora l'accuratezza della previsione a lungo termine, che è fondamentale per una migliore pianificazione nella RL basata sul modello.
Struttura di rilevamento delle anomalie basata su tensori integrativi (ITAD) per un sistema satellitare.
Limitare le informazioni di stato per la politica predefinita può migliorare le prestazioni, in un quadro RL regolarizzato da KL in cui sia l'agente che la politica predefinita sono ottimizzati insieme
Calcoliamo la salienza utilizzando un modello generativo forte per marginalizzare in modo efficiente su input alternativi plausibili, rivelando aree di pixel concentrate che conservano le informazioni dell'etichetta.
Il Variation Network è un modello generativo in grado di apprendere attributi di alto livello senza supervisione che possono poi essere utilizzati per la manipolazione controllata degli input.
Gli esseri umani nel ciclo rivedono i documenti per accordarsi con le etichette controfattuali, la risorsa risultante aiuta a ridurre la dipendenza dalle associazioni spurie.
Proponiamo una nuova misura oggettiva per valutare le spiegazioni basata sulla nozione di robustezza avversaria. Il criterio di valutazione ci permette inoltre di derivare nuove spiegazioni che catturano le caratteristiche pertinenti qualitativamente e quantitativamente.
Questo articolo presenta una struttura basata su GAN per imparare la distribuzione da dati incompleti ad alta densità.
Proponiamo un nuovo metodo di compressione, Inter-Layer Weight Prediction (ILWP) e un metodo di quantizzazione che quantizza i residui predetti tra i pesi negli strati di convoluzione.
Estendiamo una tecnica all'avanguardia per incorporare direttamente i FLOP come parte dell'obiettivo di ottimizzazione, e mostriamo che, dato un requisito FLOPs desiderato, diverse reti neurali sono addestrate con successo.
Metodo di traduzione immagine-immagine multidominio e multimodale con controllo della granularità
Analisi dell'espressività e della generalità delle reti neurali ricorrenti con nonlinearità ReLu utilizzando la decomposizione Tensor-Train.
Proponiamo un nuovo ed efficiente algoritmo per costruire esempi avversari per mezzo di deformazioni, piuttosto che perturbazioni additive.
Regolarizzazione dell'apprendimento contraddittorio con un collo di bottiglia informativo, applicato all'apprendimento per imitazione, all'apprendimento di rinforzo inverso e alle reti contraddittorie generative.
Il semplice metodo di incremento supera il trade-off robustezza/precisione osservato in letteratura e apre domande sull'effetto della distribuzione di addestramento sulla generalizzazione fuori dalla distribuzione.
Usiamo reti di densità mista per fare una stima di densità condizionale completa per la regressione di offset spaziale e la applichiamo al compito di stima della posa umana.
Visualizzazione delle differenze tra attenzione regolare e relativa per Music Transformer.
Tre fattori (dimensione del lotto, tasso di apprendimento, rumore del gradiente) cambiano in modo prevedibile le proprietà (per esempio la nitidezza) dei minimi trovati da SGD.
Semplice approccio generativo per risolvere il problema dell'analogia delle parole che produce intuizioni sulle relazioni tra le parole e i problemi con la loro stima
Questo articolo riesamina diverse pratiche comuni di impostazione degli iper-parametri per la messa a punto.
migliorare l'apprendimento di trasferimento profondo con regolarizzazione usando mappe di caratteristiche basate sull'attenzione
Modello neurale che predice sentimenti multiaspetto e genera simultaneamente una maschera probabilistica multidimensionale. Il modello supera le forti linee di base e genera maschere che sono: forti predittori di caratteristiche, significative e interpretabili.
Proporre una nuova funzione obiettivo per la generazione di sequenze neurali che integra le funzioni obiettivo basate su ML e RL.
Una rete a capsula appresa a coppie che si comporta bene in compiti di verifica del viso dati dati con etichetta limitata 
Reactor combina molteplici contributi algoritmici e architettonici per produrre un agente con una maggiore efficienza di campionamento rispetto al Prioritized Dueling DQN, dando allo stesso tempo migliori prestazioni di run-time rispetto all'A3C.
L'articolo descrive i metodi per verificare e riconoscere i piani HTN attraverso il parsing delle grammatiche degli attributi.
Esploriamo la ricerca dell'architettura neurale per compiti linguistici. La ricerca di cellule ricorrenti è impegnativa per la NMT, ma la ricerca del meccanismo di attenzione funziona. Il risultato della ricerca dell'attenzione sulla traduzione è trasferibile alla comprensione della lettura.
Proponiamo un regolatore che migliora l'interpolazione e gli autocodificatori e mostriamo che migliora anche la rappresentazione appresa per i compiti a valle.
Questo articolo presenta un metodo per la generazione stocastica di fotogrammi video intermedi a partire da fotogrammi chiave dati, utilizzando convoluzioni 3D dirette.
Questo articolo studia l'allineamento debole-supervisionato dei grafi di conoscenza con quadri di formazione avversaria.
L'apprendimento multi vista migliora l'apprendimento non supervisionato della rappresentazione della frase
Proponiamo un approccio di meta-apprendimento per guidare compiti di segmentazione visiva da quantità variabili di supervisione.
L'ottimizzazione latente migliora le dinamiche di formazione avversaria. Presentiamo sia l'analisi teorica che lo stato dell'arte della generazione di immagini con ImageNet 128x128.
Questo articolo parla delle proprietà teoriche del punto ottimale del primo ordine di una rete neurale a due strati nel caso sovra-parametrizzato
Un'architettura permette alla CNN addestrata sulle sequenze video di convergere rapidamente 
Presentiamo un nuovo metodo che combina l'attacco avversario black-box basato sul trasferimento e sul punteggio, migliorando il tasso di successo e l'efficienza della query dell'attacco avversario black-box su diverse architetture di rete.
Descrivere una tecnica di interfaccia neuro-AI per valutare le reti generative avversarie
Utilizzando metodi di campionamento adattivo per accelerare la valutazione della probabilità di eventi rari, stimiamo la probabilità di un incidente sotto una distribuzione di base che governa il comportamento standard del traffico. 
Un approccio dinamico con metodi di bagging per evitare il trasferimento negativo nell'apprendimento di trasferimento a pochi colpi delle reti neurali
Un nuovo algoritmo basato sul completamento della matrice per modellare la progressione della malattia con gli eventi
Semplici vincoli di somiglianza sopra la NMT multilingue permettono per la prima volta una traduzione di alta qualità tra coppie di lingue non viste.
Il kernel della tangente neurale in una rete ReLU inizializzata in modo casuale è una fluttuazione non banale, purché la profondità e la larghezza siano comparabili. 
Proponiamo nuove decomposizioni tensoriali e regolatori associati per ottenere prestazioni allo stato dell'arte sul completamento della base di conoscenza temporale.
Abbiamo usato una struttura di modello di tipo CVAE per imparare a generare direttamente liste/pagine intere per i sistemi di raccomandazione.
Combinando le reti neurali a grafo e il modello generativo a grafo RNN, proponiamo una nuova architettura che è in grado di imparare da una sequenza di grafi in evoluzione e prevedere l'evoluzione della topologia del grafo per i tempi futuri
Proponiamo un agente che impara a scomporre che aiuta chi risponde a domande semplici a rispondere a domande composte su un grafico di conoscenza.
Modello basato sull'energia appresa con corrispondenza del punteggio
Proporre un modello RBM generale basato su tensori che può comprimere notevolmente il modello allo stesso tempo mantenere una forte capacità di espressione del modello
Un approccio di apprendimento di rinforzo actor-critic con rendimenti multi-step applicato alla guida autonoma con il simulatore Carla.
Proponiamo nuovi metodi per valutare e quantificare la qualità delle distribuzioni GAN sintetiche dal punto di vista dei compiti di classificazione
L'obiettivo del clustering di sopravvivenza è quello di mappare i soggetti in cluster. Senza segnali di fine vita, questo è un compito impegnativo. Per affrontare questo compito proponiamo una nuova funzione di perdita modificando la statistica di Kuiper.
Mostriamo come l'uso di stime semi-parametriche a priori può accelerare HPO in modo significativo attraverso i set di dati e le metriche.
Le procedure di routing non sono necessarie per i Capsnet
Impostando la larghezza o la varianza di inizializzazione di ogni strato in modo diverso, possiamo effettivamente sottomettere i problemi di esplosione del gradiente nelle reti residuali (con strati completamente connessi e senza batchnorm). Viene sviluppata una teoria matematica che non solo ti dice come farlo, ma sorprendentemente è anche in grado di prevedere, dopo aver applicato tali trucchi, quanto velocemente la tua rete si allena per raggiungere una certa performance del test set. Questa è roba da magia nera, e si chiama "Deep Mean Field Theory".
Comunicazione mirata nell'apprendimento di rinforzo cooperativo multi-agente
Abbiamo sviluppato un sistema di supporto per l'etching latte art che proietta la procedura di fabbricazione direttamente su un cappuccino per aiutare i principianti a fare un'etching latte art ben bilanciata.
Proponiamo auto-supervisioni temporali per l'apprendimento di funzioni temporali stabili con le GAN.
Classificazione semi-supervisionata di documenti multilingue
Le HMM sono un caso speciale di RNN? Indaghiamo una serie di trasformazioni architettoniche tra HMMs e RNNs, sia attraverso derivazioni teoriche che ibridazioni empiriche e forniamo nuove intuizioni.
Forniamo un'analisi teorica dell'informazione e sperimentale degli autocodificatori variazionali allo stato dell'arte.
Sviluppiamo basi teoriche per la potenza espressiva delle GNN e progettiamo una GNN provabilmente più potente.
Un nuovo algoritmo per l'apprendimento multi-task online che impara senza ricominciare ai confini del compito
Capacità interlinguistica del BERT multilingue: uno studio empirico
Un quadro teorico per la rete profonda ReLU che può spiegare molteplici fenomeni sconcertanti come l'iperparametrizzazione, la regolarizzazione implicita, i biglietti della lotteria, ecc. 
Allineare le lingue senza la Stele di Rosetta: senza dati paralleli, costruiamo dizionari bilingui usando l'addestramento avversario, lo scaling locale cross-domain e un accurato criterio di proxy per la validazione incrociata.
Eseguiamo il conteggio per rispondere alle domande visive; il nostro modello produce output interpretabili contando direttamente dagli oggetti rilevati.
Studiamo il problema della generazione di grafi e proponiamo un potente modello generativo profondo capace di generare grafi arbitrari.
Rappresentare frasi componendole con Tree-LSTMs secondo alberi di parsing indotti automaticamente.
Tre nuovi algoritmi con studi di ablazione per potare la rete neurale per ottimizzare la lunghezza del cablaggio, al contrario del numero di pesi rimanenti.
Recupero di momenti video basato su testo debolmente supervisionato
Come utilizzare la generalizzazione impilata per migliorare le prestazioni degli algoritmi di apprendimento di trasferimento esistenti quando sono disponibili dati etichettati limitati.
Questo articolo introduce un priore fisico per il Deep Learning e applica la topologia di rete risultante per il controllo basato sul modello.
Miglioriamo i modelli generativi proponendo un meta-algoritmo che filtra i nuovi dati di allenamento dagli output del modello.
Usiamo un simulatore srotolato come un modello differenziabile end-to-end della struttura delle proteine e dimostriamo che può (a volte) generalizzare gerarchicamente a topologie di pieghe non viste.
Addestramento automatizzato dei topi per le neuroscienze con inferenza iterativa online della strategia latente per la previsione del comportamento
Analizziamo le reti ricorrenti addestrate per la classificazione del sentimento, e troviamo che tutte mostrano una dinamica di attrazione approssimativa quando risolvono questo compito.
Abbiamo costruito una simulazione fisica di un roditore, l'abbiamo addestrato a risolvere una serie di compiti e abbiamo analizzato le reti risultanti.
Un'estensione delle GAN che combina il trasporto ottimale in forma primordiale con una distanza energetica definita in uno spazio di caratteristiche apprese avversariamente.
Addestrare un agente in un mondo virtuale 2D per l'acquisizione e la generalizzazione del linguaggio a terra.
Un algoritmo RL che impara ad essere robusto ai cambiamenti nella dinamica
Questo articolo fornisce uno schema di astrazione basato sul gioco per calcolare politiche provatamente valide per POMDP.
Un set di dati giocattolo basato sulla percolazione critica in un grafico planare fornisce una finestra analitica alle dinamiche di formazione delle reti neurali profonde  
Riformuliamo il problema di generazione come uno di modifica dei punti esistenti, e come risultato estrapoliamo meglio delle GAN tradizionali.
Un nuovo approccio che impara una rappresentazione per descrivere modelli di transizione in complessi uncertaindomini usando regole relazionali. 
Proponiamo una rete di pianificazione differenziabile end-to-end per i grafi. Questo può essere applicabile a molti problemi di pianificazione del movimento
Impariamo il denoising di alta qualità usando solo singole istanze di immagini corrotte come dati di allenamento.
Risolviamo il problema delle ricompense sparse su compiti web UI usando l'esplorazione guidata da dimostrazioni
Architettura embedded per l'apprendimento profondo su dispositivi ottimizzati per il rilevamento dei volti e il riconoscimento delle emozioni 
Usare la stessa incorporazione tra le covariate non ha senso, dimostriamo che un algoritmo di decomposizione tensoriale impara le incorporazioni sparse specifiche per le covariate e gli argomenti naturalmente separabili congiuntamente e in modo efficiente dai dati.
Usando la programmazione lineare mostriamo che la complessità computazionale dell'addestramento approssimativo delle reti neurali profonde dipende polinomialmente dalla dimensione dei dati per diverse architetture
Unifichiamo il filtro Kalman esteso (EKF) e l'approccio allo spazio di stato alla propagazione delle aspettative di potenza (PEP) risolvendo gli integrali intrattabili del momento corrispondente in PEP tramite linearizzazione. Questo porta a un'estensione globalmente iterata dell'EKF.
Esplorare la capacità di apprendimento delle reti neurali apprese
Proponiamo una metodologia di valutazione generalizzata per interpretare i bias del modello, i bias del dataset e la loro correlazione.
Gli agenti sociali imparano a parlare tra loro in linguaggio naturale verso un obiettivo
Mostriamo che il collasso posteriore nelle VAE lineari è causato interamente dalla log-likelihood marginale (non ELBO). Gli esperimenti sulle VAE profonde suggeriscono che un fenomeno simile è in gioco.
Questo articolo propone un nuovo modello che combina informazioni multi-scala per l'apprendimento sequenza per sequenza.
Proponiamo un nuovo metodo certificato di addestramento avversario, CROWN-IBP, che raggiunge una robustezza allo stato dell'arte per le perturbazioni avversarie di norma L_inf.
Nel pruning di rete strutturato, il fine-tuning di un modello potato dà solo prestazioni comparabili con l'addestramento da zero.
Tecnica interattiva per migliorare il brushing in serie di dati di traiettorie dense tenendo conto della forma del pennello.
Sviluppiamo un nuovo approccio per modellare la compostezza degli oggetti nelle immagini in una struttura GAN.
Discriminazione audio avversaria usando la dipendenza temporale
 Proponiamo un nuovo metodo di formazione GAN considerando alcuni campioni falsi come reali per alleviare il collasso della modalità e stabilizzare il processo di formazione.
Presentiamo uno strumento visivo per esplorare interattivamente lo spazio latente di un auto-encoder per sequenze di peptidi e i loro attributi.
Riportiamo esperimenti che forniscono una forte evidenza che un neurone si comporta come un classificatore binario durante l'addestramento e il test
Un metodo per arricchire e combinare le caratteristiche per migliorare la precisione della classificazione
Estendere l'architettura GAN per ottenere il controllo sulle posizioni e le identità di più oggetti all'interno delle immagini generate.
Proponiamo un nuovo modello end-to-end (SPNet) per incorporare scaffold semantici per migliorare la sintesi astrattiva dei dialoghi.
Presentiamo un agente RL MINERVA che impara a camminare su un grafo di conoscenza e a rispondere alle domande
Un'approssimazione del flusso ventrale dei primati come una rete convoluzionale funziona male nel riconoscimento degli oggetti, e molteplici caratteristiche architettoniche contribuiscono a questo. 
Consideriamo il problema dell'apprendimento di politiche ottimali in domini a tempo limitato e a tempo illimitato usando interazioni a tempo limitato.
Uno dei problemi teorici nell'apprendimento profondo
Analizziamo e sviluppiamo un'implementazione computazionalmente efficiente della regolarizzazione Jacobian che aumenta i margini di classificazione delle reti neurali.
Siamo i primi nel campo a mostrare come realizzare un design efficace del kernel sparso da tre aspetti: composizione, performance ed efficienza.
Una nuova rete attenzionale media marginalizzata per la localizzazione temporale dell'azione debolmente sorvegliata 
Proponiamo un nuovo autocodificatore incorporato con una trasformazione multiway delay-embedding per interpretare le immagini profonde precedenti.
Garantire che i modelli appresi in modo federato non rivelino la partecipazione di un cliente.
Mostriamo come il pre-addestramento di una rete neurale non addestrata con un minimo di 5-25 esempi può migliorare i risultati di ricostruzione nel rilevamento compresso e nei problemi di recupero semantico come la colorazione.
Abbiamo proposto Cooperative Training, un nuovo algoritmo di formazione per la modellazione generativa di dati discreti.
Introduciamo un metodo per calcolare una ricompensa intrinseca per la curiosità usando metriche derivate dal campionamento di un modello di variabile latente usato per stimare le dinamiche.
Presentiamo un modello generativo per embeddings di parole compositive che cattura le relazioni sintattiche, e forniamo una verifica empirica e una valutazione.
Proponiamo un approccio ibrido basato sul modello e senza modello che utilizza informazioni semantiche per migliorare la generalizzazione della DRL in ambienti artificiali.
Usiamo tecniche di apprendimento profondo per risolvere il problema della rappresentazione e del recupero del segnale sparso.
Presentiamo Dreamer, un agente che impara comportamenti a lungo orizzonte puramente dall'immaginazione latente usando gradienti di valore analitici.
Proponiamo MULTIPOLAR, un metodo RL di trasferimento che sfrutta un insieme di politiche di origine raccolte sotto diverse dinamiche ambientali sconosciute per imparare in modo efficiente una politica di destinazione in un'altra dinamica.
Un agente addestrato solo con curiosità, e nessuna ricompensa estrinseca, fa sorprendentemente bene su 54 ambienti popolari, tra cui la suite di giochi Atari, Mario ecc.
per le trasformazioni spaziali il minimizzatore robusto minimizza anche la precisione standard; la regolarizzazione che induce invarianza porta a una migliore robustezza rispetto alle architetture specializzate
Viene proposta la nozione di apprendimento dell'ordine e la si applica a problemi di regressione nella visione artificiale
Mostriamo che le reti neurali operano cambiando la topologia di un set di dati ed esploriamo come le scelte architettoniche influenzano questo cambiamento.
Usiamo strumenti empirici di connettività di modalità e SVCCA per studiare l'euristica di formazione delle reti neurali di riavvio del tasso di apprendimento, di riscaldamento e di distillazione della conoscenza.
Inferenza variazionale per l'inferenza di una distribuzione discreta da cui deriva una rete neurale a bassa precisione
Proponiamo un nuovo metodo basato su tensori per reti convoluzionali su grafici dinamici
"Generazione di nuovi materiali chimici usando nuove GAN a domini incrociati".
Forniamo uno stimatore e un algoritmo di stima per una classe di problemi di regressione multi-task e forniamo analisi statistiche e computazionali.
Utilizzato Deep Reinforcement Learning per insegnare agli agenti la coordinazione dello stile della flotta di ride-sharing.
Stabilità delle rappresentazioni di trasformazione di dispersione dei dati del grafico alle deformazioni del supporto del grafico sottostante.
Proponiamo una nuova architettura di rete profonda che può decidere dinamicamente la sua capacità di rete mentre si allena su uno scenario di apprendimento permanente.
Questo articolo discute diversi metodi di accoppiamento del VO con l'apprendimento profondo e propone una previsione simultanea di correzioni e incertezze.
Abbiamo introdotto Deep Density Network, un modello DNN unificato per stimare l'incertezza per l'esplorazione/sfruttamento nei sistemi di raccomandazione.
Addestriamo RNN su utenti famosi di Twitter per determinare se la popolazione generale di Twitter è più propensa a credere nel cambiamento climatico dopo un disastro naturale.
Usando una nuova rappresentazione dei sistemi dinamici lineari simmetrici con uno stato latente, formuliamo il controllo ottimale come un programma convesso, dando il primo algoritmo in tempo polinomiale che risolve il controllo ottimale con una complessità del campione solo polilogaritmica nell'orizzonte temporale.
Modelliamo il generatore di dati (in GAN) per mezzo di un polinomio di alto ordine rappresentato da tensori di alto ordine.
Mostriamo che le reti neurali profonde sono in grado di imparare da dati che sono stati diluiti da una quantità arbitraria di rumore.
proponiamo un approccio di meta-apprendimento per la traduzione automatica neurale a bassa risorsa che può rapidamente imparare a tradurre in una nuova lingua
Un metodo per il rilevamento attivo delle anomalie. Presentiamo un nuovo strato che può essere allegato a qualsiasi modello di apprendimento profondo progettato per il rilevamento delle anomalie non supervisionato per trasformarlo in un metodo attivo.
Generiamo degli esempi per spiegare una designazione del classificatore tramite interpolazioni nello spazio latente. Il costo variazionale del codificatore automatico è esteso con un funzionale del classificatore sul percorso dell'esempio generato nello spazio dei dati.
Introdurre un approccio per permettere agli agenti di imparare i modelli di azione PPDDL in modo incrementale su più problemi di pianificazione nel quadro dell'apprendimento per rinforzo.
Proponiamo un nuovo algoritmo DRL off-policy che raggiunge prestazioni all'avanguardia. 
Proponiamo un metodo che può utilizzare le informazioni di passaggi multipli per l'AQ a dominio aperto.
Algoritmo di riduzione della dimensionalità per visualizzare il testo con informazioni di rete, per esempio un corpus di email o co-autorizzazioni.
Presentiamo una struttura che sfrutta simulazioni al computer ad alta fedeltà per interrogare e diagnosticare le distorsioni all'interno dei classificatori ML. 
Presentiamo e valutiamo i decodificatori basati sul campionamento delle nuvole di punti che superano l'approccio MLP di base, adattandosi meglio alla semantica delle nuvole di punti.
Usiamo la RL profonda per imparare una politica che dirige la ricerca di un algoritmo genetico per ottimizzare meglio il costo di esecuzione dei grafi di calcolo, e mostriamo risultati migliori sui grafi TensorFlow del mondo reale.
Mostriamo che con la giusta perdita e architettura, l'apprendimento predittivo della vista migliora il rilevamento degli oggetti 3D
una rete generativa adversariale per la modellazione dello stile in un sistema text-to-speech
Mostriamo in un compito di apprendimento semplificato che l'iperparametrizzazione migliora la generalizzazione di una convnet addestrata con la discesa del gradiente.
Il meta-apprendimento bayesiano utilizzando la struttura PAC-Bayes e le distribuzioni a priori implicite
Position paper che propone spiegazioni ribelli e ingannevoli per gli agenti.
Studiamo una variante degli autocodificatori variazionali in cui c'è una sovrastruttura di variabili latenti discrete in cima alle caratteristiche latenti.
Mostriamo che la chiave per ottenere buone prestazioni con gli IDM sta nell'apprendimento di rappresentazioni latenti per codificare le informazioni condivise tra esperienze equivalenti, in modo che possano essere generalizzate a scenari non visti.
Identifichiamo la distorsione dell'angolo che causa il problema del gradiente che svanisce nelle reti profonde e proponiamo un metodo efficiente per ridurre la distorsione.
Impieghiamo reti neurali a grafo nel quadro dell'EM variazionale per un'inferenza e un apprendimento efficienti delle reti logiche di Markov.
Un approccio di meta-reinforcement learning che incorpora un controller di rete neurale applicato alla guida autonoma con il simulatore Carla.
Derivare un quadro del collo di bottiglia dell'informazione nell'apprendimento per rinforzo e alcune semplici teorie e strumenti pertinenti.
Proponiamo un approccio a moduli neurali per l'apprendimento continuo utilizzando un ambiente visivo unificato con un grande spazio d'azione.
Proponiamo un metodo per utilizzare i GAN per generare razionali visivi di alta qualità per aiutare a spiegare le previsioni del modello. 
Proponiamo un nuovo algoritmo che sfrutta l'espressività delle reti neurali generative per migliorare gli algoritmi delle strategie evolutive.
Comprimiamo e velocizziamo i modelli di riconoscimento vocale sui dispositivi embedded attraverso una tecnica di regolarizzazione di trace norm e kernel ottimizzati.
Facciamo una giustificazione teorica per il concetto di stimatore diretto.
Con una serie di modifiche, sotto 10 LOC, ad A2C si ottiene un attore-critico off-policy che supera A2C e si comporta in modo simile ad ACER. Le modifiche sono grandi dimensioni dei lotti, un clamping aggressivo, e una "forzatura" della politica con rumore gumbel.
Generazione di testo usando le embeddings di frasi dai vettori di Skip-Thought con l'aiuto delle Reti Adversariali Generative.
nuovo decoder out-of-order per la traduzione automatica neurale
In questo articolo, studiamo un nuovo problema di apprendimento dei grafi: imparare a contare gli isomorfismi dei sottografi.
Presentiamo un agente che utilizza un beta-vae per estrarre le caratteristiche visive e un meccanismo di attenzione per ignorare le caratteristiche irrilevanti dalle osservazioni visive per consentire un trasferimento robusto tra domini visivi.
Proponiamo il primo algoritmo per verificare la robustezza dei trasformatori.
Contrariamente alle credenze precedenti, le prestazioni di allenamento delle reti profonde, se misurate in modo appropriato, sono predittive delle prestazioni di test, in linea con la teoria classica dell'apprendimento automatico.
Proponiamo un quadro che incorpora la pianificazione per un'esplorazione e un apprendimento efficienti in ambienti complessi.
Il nostro articolo analizza l'enorme potere di rappresentazione delle reti, specialmente con "connessioni saltate", che possono essere utilizzate come metodo per una migliore generalizzazione.
Questo articolo propone una nuova funzione obiettivo per sostituire il termine KL con uno che emula l'obiettivo della massima discrepanza media (MMD). 
Poniamo che le verosimiglianze dei modelli generativi siano eccessivamente influenzate dalla complessità dell'input, e proponiamo un modo per compensarla quando si individuano input fuori distribuzione
Studiamo la convergenza di algoritmi di ottimizzazione popolari come Adam, RMSProp e proponiamo nuove varianti di questi metodi che convergono in modo dimostrabile alla soluzione ottimale in ambienti convessi. 
Presentiamo difese efficaci contro gli attacchi clean-label poisoning. 
MXGNet è un'architettura multistrato basata su grafi multipli che raggiunge buone prestazioni su vari compiti di ragionamento diagrammatico.
Proponiamo un nuovo quadro multi-task che impara il rilevamento delle tabelle, il riconoscimento dei componenti semantici e la classificazione del tipo di cella per le tabelle dei fogli di calcolo con risultati promettenti.
Proponiamo metriche automatiche per valutare olisticamente la generazione di dialoghi aperti e sono fortemente correlate con la valutazione umana.
Abbiamo ideato un nuovo Depthwise Separable Graph Convolution (DSGC) per i dati generici del dominio spaziale, che è altamente compatibile con la convoluzione separabile depthwise.
Addestriamo una suite di modelli in grado di trascrivere, comporre e sintetizzare forme d'onda audio con una struttura musicale coerente, grazie al nuovo dataset MAESTRO.
Uno studio empirico dell'inferenza variazionale basata sulla minimizzazione della divergenza del chi-quadrato, mostrando che minimizzare il CUBO è più complicato che massimizzare l'ELBO
Sfruttiamo la linearità globale dei modelli addestrati per il mixup nell'inferenza per rompere la località delle perturbazioni avversarie.
La messa a punto del BERT sui corpora legali fornisce miglioramenti marginali, ma preziosi, nei compiti di NLP nel dominio legale.
Formuliamo un modello probabilistico di sequenza latente per affrontare il trasferimento di stile di testo non supervisionato e mostriamo la sua efficacia in una serie di compiti di trasferimento di stile di testo non supervisionato. 
Propone un modello analiticamente trattabile e una procedura di inferenza (regressione sparsa misparametrizzata, dedotta usando la penalità L_1 e studiata nel limite di interpolazione dei dati) per studiare i fenomeni legati alle reti profonde nel contesto dei problemi inversi. 
Proponiamo un nuovo approccio di filtraggio collaborativo basato sull'hashing variazionale, ottimizzato per una nuova variante self-mask della distanza di Hamming, che supera lo stato dell'arte fino al 12% su NDCG.
Un algoritmo di ottimizzazione che esplora varie dimensioni dei lotti in base alla probabilità e sfrutta automaticamente la dimensione del lotto di successo che minimizza la perdita di convalida.
Abbiamo proposto una struttura unificata di Generative Adversarial Networks (GAN) per imparare l'incorporazione di grafi di conoscenza consapevole del rumore.
Un EBM residuo per il testo la cui formulazione è equivalente alla discriminazione tra testo umano e testo generato dalla macchina. Studiamo il suo comportamento di generalizzazione.
La pseudo-etichettatura ha dimostrato di essere un'alternativa debole per l'apprendimento semi-supervisionato. Noi, al contrario, dimostriamo che la gestione dei bias di conferma con diverse regolarizzazioni rende la pseudo-etichettatura un approccio adatto.
Mostriamo che una speciale funzione di valore a condizione di obiettivo addestrata con metodi senza modello può essere usata all'interno del controllo basato sul modello, ottenendo un'efficienza del campione e prestazioni sostanzialmente migliori.
Una nuova architettura neurale per un'efficiente inferenza ammortizzata su permutazioni latenti 
Proponiamo una nuova architettura di modello a due torri con fondo condiviso per trasferire la conoscenza da ricchi feedback impliciti per prevedere la rilevanza per sistemi di recupero su larga scala.
Affrontiamo il compito di esplorazione e navigazione autonoma usando mappe di affordance spaziali che possono essere apprese in modo auto-supervisionato, queste superano le classiche basi geometriche mentre sono più efficienti rispetto agli algoritmi RL contemporanei.
